{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "mount_file_id": "https://github.com/KendallScott/QTW/blob/main/Case%20Study%207/CaseStudy7.ipynb",
      "authorship_tag": "ABX9TyMczOqaNA8i/m8XODgjKtJF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/boneeyah/QTW/blob/main/Case%20Study%207/CaseStudy7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "OZryWKHR3JAd"
      },
      "outputs": [],
      "source": [
        "#!pip install scikit-learn-intelex\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearnex import patch_sklearn\n",
        "patch_sklearn()\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import NuSVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_val_predict\n",
        "import datetime"
      ],
      "metadata": {
        "id": "HrVUsV_b8Ezp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f1772df-2e1e-4cec-ac81-4107bb2ae587"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('drive')"
      ],
      "metadata": {
        "id": "T6H6L4bc8YlZ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df = pd.read_csv(\"drive/My Drive/final_project(5).csv\")\n",
        "df = pd.read_csv(\"/home/migue/Downloads/final_project(5).csv\")"
      ],
      "metadata": {
        "id": "hngzaeNL-EXs"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()\n",
        "#there are NAs will need handling"
      ],
      "metadata": {
        "id": "kjzOue9y_SuK",
        "outputId": "52bae632-6a08-4d2d-ca3f-7097392db146",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 160000 entries, 0 to 159999\n",
            "Data columns (total 51 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   x0      159974 non-null  float64\n",
            " 1   x1      159975 non-null  float64\n",
            " 2   x2      159962 non-null  float64\n",
            " 3   x3      159963 non-null  float64\n",
            " 4   x4      159974 non-null  float64\n",
            " 5   x5      159963 non-null  float64\n",
            " 6   x6      159974 non-null  float64\n",
            " 7   x7      159973 non-null  float64\n",
            " 8   x8      159979 non-null  float64\n",
            " 9   x9      159970 non-null  float64\n",
            " 10  x10     159957 non-null  float64\n",
            " 11  x11     159970 non-null  float64\n",
            " 12  x12     159964 non-null  float64\n",
            " 13  x13     159969 non-null  float64\n",
            " 14  x14     159966 non-null  float64\n",
            " 15  x15     159965 non-null  float64\n",
            " 16  x16     159974 non-null  float64\n",
            " 17  x17     159973 non-null  float64\n",
            " 18  x18     159960 non-null  float64\n",
            " 19  x19     159965 non-null  float64\n",
            " 20  x20     159962 non-null  float64\n",
            " 21  x21     159971 non-null  float64\n",
            " 22  x22     159973 non-null  float64\n",
            " 23  x23     159953 non-null  float64\n",
            " 24  x24     159972 non-null  object \n",
            " 25  x25     159978 non-null  float64\n",
            " 26  x26     159964 non-null  float64\n",
            " 27  x27     159970 non-null  float64\n",
            " 28  x28     159965 non-null  float64\n",
            " 29  x29     159970 non-null  object \n",
            " 30  x30     159970 non-null  object \n",
            " 31  x31     159961 non-null  float64\n",
            " 32  x32     159969 non-null  object \n",
            " 33  x33     159959 non-null  float64\n",
            " 34  x34     159959 non-null  float64\n",
            " 35  x35     159970 non-null  float64\n",
            " 36  x36     159973 non-null  float64\n",
            " 37  x37     159977 non-null  object \n",
            " 38  x38     159969 non-null  float64\n",
            " 39  x39     159977 non-null  float64\n",
            " 40  x40     159964 non-null  float64\n",
            " 41  x41     159960 non-null  float64\n",
            " 42  x42     159974 non-null  float64\n",
            " 43  x43     159963 non-null  float64\n",
            " 44  x44     159960 non-null  float64\n",
            " 45  x45     159971 non-null  float64\n",
            " 46  x46     159969 non-null  float64\n",
            " 47  x47     159963 non-null  float64\n",
            " 48  x48     159968 non-null  float64\n",
            " 49  x49     159968 non-null  float64\n",
            " 50  y       160000 non-null  int64  \n",
            "dtypes: float64(45), int64(1), object(5)\n",
            "memory usage: 62.3+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in df.columns:\n",
        "    if df[i].isna().sum() > 0:\n",
        "        print('{} has {}% NAs'.format(i,(df[i].isna().sum() / len(df))*100))"
      ],
      "metadata": {
        "id": "CC3yFJ6BzzOw",
        "outputId": "aa88f8d7-a084-480c-f0ec-7953148255ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x0 has 0.01625% NAs\n",
            "x1 has 0.015625% NAs\n",
            "x2 has 0.02375% NAs\n",
            "x3 has 0.023125% NAs\n",
            "x4 has 0.01625% NAs\n",
            "x5 has 0.023125% NAs\n",
            "x6 has 0.01625% NAs\n",
            "x7 has 0.016875% NAs\n",
            "x8 has 0.013125% NAs\n",
            "x9 has 0.01875% NAs\n",
            "x10 has 0.026875% NAs\n",
            "x11 has 0.01875% NAs\n",
            "x12 has 0.0225% NAs\n",
            "x13 has 0.019375% NAs\n",
            "x14 has 0.021249999999999998% NAs\n",
            "x15 has 0.021875000000000002% NAs\n",
            "x16 has 0.01625% NAs\n",
            "x17 has 0.016875% NAs\n",
            "x18 has 0.025% NAs\n",
            "x19 has 0.021875000000000002% NAs\n",
            "x20 has 0.02375% NAs\n",
            "x21 has 0.018125% NAs\n",
            "x22 has 0.016875% NAs\n",
            "x23 has 0.029375000000000002% NAs\n",
            "x24 has 0.017499999999999998% NAs\n",
            "x25 has 0.01375% NAs\n",
            "x26 has 0.0225% NAs\n",
            "x27 has 0.01875% NAs\n",
            "x28 has 0.021875000000000002% NAs\n",
            "x29 has 0.01875% NAs\n",
            "x30 has 0.01875% NAs\n",
            "x31 has 0.024374999999999997% NAs\n",
            "x32 has 0.019375% NAs\n",
            "x33 has 0.025625000000000002% NAs\n",
            "x34 has 0.025625000000000002% NAs\n",
            "x35 has 0.01875% NAs\n",
            "x36 has 0.016875% NAs\n",
            "x37 has 0.014374999999999999% NAs\n",
            "x38 has 0.019375% NAs\n",
            "x39 has 0.014374999999999999% NAs\n",
            "x40 has 0.0225% NAs\n",
            "x41 has 0.025% NAs\n",
            "x42 has 0.01625% NAs\n",
            "x43 has 0.023125% NAs\n",
            "x44 has 0.025% NAs\n",
            "x45 has 0.018125% NAs\n",
            "x46 has 0.019375% NAs\n",
            "x47 has 0.023125% NAs\n",
            "x48 has 0.02% NAs\n",
            "x49 has 0.02% NAs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['x24'].value_counts()"
      ],
      "metadata": {
        "id": "TybuIbMLz6Ng",
        "outputId": "9c540ba9-0e5a-412b-e472-9142b8431107",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "x24\n",
              "asia       138965\n",
              "euorpe      16538\n",
              "america      4469\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(x=df['x24'].value_counts().index,height=df['x24'].value_counts().values)"
      ],
      "metadata": {
        "id": "ME56MKaIz7sN",
        "outputId": "b0943b49-27bd-4098-9e43-903d41350369",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 3 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['x29'].value_counts()"
      ],
      "metadata": {
        "id": "P7rMlCalz9WH",
        "outputId": "7e126411-5254-4e11-8962-cec0c60bd75a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "x29\n",
              "July       45569\n",
              "Jun        41329\n",
              "Aug        29406\n",
              "May        21939\n",
              "sept.      10819\n",
              "Apr         6761\n",
              "Oct         2407\n",
              "Mar         1231\n",
              "Nov          337\n",
              "Feb          140\n",
              "Dev           23\n",
              "January        9\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#clean up month formatting to standard 3 letters\n",
        "df['x29'].replace(to_replace=['July','sept.','Dev','January'],value=['Jul','Sep','Dec','Jan'],inplace=True)"
      ],
      "metadata": {
        "id": "gB-gkjC2z_fK"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mo = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
        "heights = []\n",
        "for i in mo:\n",
        "    x = df['x29'].to_list().count(i)\n",
        "    heights.append(x)\n",
        "plt.bar(x=mo,height=heights)"
      ],
      "metadata": {
        "id": "eZTNOL9P0CM3",
        "outputId": "da846767-9006-4857-fdb2-d929138c2d50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 12 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['x30'].value_counts()"
      ],
      "metadata": {
        "id": "_1LSKgy80ENF",
        "outputId": "8ebc2a60-a612-4324-872c-67e508741792",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "x30\n",
              "wednesday    101535\n",
              "thurday       29429\n",
              "tuesday       27954\n",
              "friday          564\n",
              "monday          488\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# thursday is incorrect\n",
        "df['x30'].replace(to_replace = 'thurday',value='thursday')\n",
        "days = ['monday','tuesday','wednesday','thursday','friday']\n",
        "d_heights = []\n",
        "for i in days:\n",
        "    x = df['x30'].to_list().count(i)\n",
        "    d_heights.append(x)\n",
        "plt.bar(x=days,height = d_heights)"
      ],
      "metadata": {
        "id": "3hFwgArL0GAB",
        "outputId": "4c8eaa02-bc6a-4d89-a365-ad0c9a440b9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 5 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['x32'].value_counts()"
      ],
      "metadata": {
        "id": "WErTHaJ70Ia2",
        "outputId": "a5c3ee18-4306-42b6-9f04-03d22030ebda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "x32\n",
              "0.01%     40767\n",
              "-0.01%    34094\n",
              "0.0%      33923\n",
              "-0.0%     30492\n",
              "-0.02%     9924\n",
              "0.02%      7987\n",
              "-0.03%     1727\n",
              "0.03%       855\n",
              "-0.04%      138\n",
              "0.04%        55\n",
              "-0.05%        6\n",
              "0.05%         1\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['x37'].value_counts()\n"
      ],
      "metadata": {
        "id": "r98Zehw50LS1",
        "outputId": "71de40f9-b6d8-4806-d0a5-d10216762738",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "x37\n",
              "$-311.26     6\n",
              "$-336.77     6\n",
              "$237.4       6\n",
              "$72.42       6\n",
              "$341.26      6\n",
              "            ..\n",
              "$-505.21     1\n",
              "$770.07      1\n",
              "$74.62       1\n",
              "$-1082.96    1\n",
              "$-1229.34    1\n",
              "Name: count, Length: 129198, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### x32 and x37 are actually numeric with string format (even though x32 has few \"levels\" or possible values)\n",
        "### x32 is in percentage, but don't think it needs to be transformed to proportion since data will be scaled later (will double check, but should make no difference)\n",
        "\n",
        "df['x32'] = df['x32'].transform(lambda x: float(str(x).replace('%','')))\n",
        "df['x37'] = df['x37'].transform(lambda x: float(str(x).replace('$','')))"
      ],
      "metadata": {
        "id": "-8HSIli70VDX"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#all significanlty less than 5%, should be no issue imputing,\n",
        "#imputing categorical features with modes\n",
        "# imputing continent with mode, then dates by mode grouped by continent\n",
        "\n",
        "print('imputing continent with mode: {}'.format(df['x24'].aggregate(pd.Series.mode)))\n",
        "df['x24'] = df['x24'].transform(lambda x: x.fillna(pd.Series.mode(x)[0]))\n",
        "\n",
        "print('imputing month with mode by cont: {}'.format(df[['x24','x29']].groupby(by='x24').aggregate(pd.Series.mode)))\n",
        "idx_29 = df.loc[df['x29'].isna(),:].index #saving NAs indices to quick check what they've been imputed with\n",
        "df['x29'] = df[['x24','x29']].groupby(by='x24').transform(lambda grp: grp.fillna(pd.Series.mode(grp)[0]))\n",
        "\n",
        "# will fix index showing on print later\n"
      ],
      "metadata": {
        "id": "qyAc5R1u209T",
        "outputId": "dc87f0b5-0845-4224-efa3-f7b36d4efe9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "imputing continent with mode: 0    asia\n",
            "Name: x24, dtype: object\n",
            "imputing month with mode by cont:          x29\n",
            "x24         \n",
            "america  Jul\n",
            "asia     Jul\n",
            "euorpe   Jul\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[['x24','x29','x30']].groupby(by=['x24','x29']).aggregate(pd.Series.mode)\n",
        "# could just impute with wednesday since Wed is mode per month, but adding continent gives more context and different days for some months"
      ],
      "metadata": {
        "id": "2iV02zDI3Emu",
        "outputId": "70cdd003-bf6f-4d78-a19c-469ceef462f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   x30\n",
              "x24     x29           \n",
              "america Apr  wednesday\n",
              "        Aug  wednesday\n",
              "        Feb    tuesday\n",
              "        Jul  wednesday\n",
              "        Jun  wednesday\n",
              "        Mar  wednesday\n",
              "        May  wednesday\n",
              "        Nov  wednesday\n",
              "        Oct  wednesday\n",
              "        Sep  wednesday\n",
              "asia    Apr  wednesday\n",
              "        Aug  wednesday\n",
              "        Dec  wednesday\n",
              "        Feb  wednesday\n",
              "        Jan  wednesday\n",
              "        Jul  wednesday\n",
              "        Jun  wednesday\n",
              "        Mar  wednesday\n",
              "        May  wednesday\n",
              "        Nov  wednesday\n",
              "        Oct  wednesday\n",
              "        Sep  wednesday\n",
              "euorpe  Apr  wednesday\n",
              "        Aug  wednesday\n",
              "        Dec  wednesday\n",
              "        Feb    tuesday\n",
              "        Jul  wednesday\n",
              "        Jun  wednesday\n",
              "        Mar  wednesday\n",
              "        May  wednesday\n",
              "        Nov  wednesday\n",
              "        Oct  wednesday\n",
              "        Sep  wednesday"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>x30</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x24</th>\n",
              "      <th>x29</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"10\" valign=\"top\">america</th>\n",
              "      <th>Apr</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Aug</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feb</th>\n",
              "      <td>tuesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jul</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jun</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mar</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>May</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nov</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Oct</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sep</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"12\" valign=\"top\">asia</th>\n",
              "      <th>Apr</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Aug</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dec</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feb</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jan</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jul</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jun</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mar</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>May</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nov</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Oct</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sep</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"11\" valign=\"top\">euorpe</th>\n",
              "      <th>Apr</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Aug</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dec</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feb</th>\n",
              "      <td>tuesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jul</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jun</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mar</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>May</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nov</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Oct</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sep</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# impute day\n",
        "df['x30'] = df[['x24','x29','x30']].groupby(by=['x24','x29']).transform(lambda grp: grp.fillna(pd.Series.mode(grp)[0]))"
      ],
      "metadata": {
        "id": "HVQavir8IV9m"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.loc[:,df.columns != 'y']\n",
        "y = df['y'].values.flatten()\n",
        "\n",
        "df_num = X.select_dtypes(exclude='object')\n",
        "num_cols = df_num.columns\n",
        "\n",
        "# impute numeric with median\n",
        "for i in num_cols:\n",
        "    df_num[i] = df_num[i].transform(lambda x: x.fillna(pd.Series.mode(x)[0]))\n",
        "df_num.info()\n",
        "\n",
        "df_cat = X.select_dtypes(include='object')\n",
        "cat_cols = df_cat.columns\n",
        "\n",
        "# scale numerical data\n",
        "scaler = StandardScaler()\n",
        "df_num = scaler.fit_transform(df_num)\n",
        "\n",
        "#one hot encode cat data\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "df_cat = encoder.fit_transform(df_cat)"
      ],
      "metadata": {
        "id": "w8Uy9xG3Iern",
        "outputId": "d84af43f-6958-4422-aab7-96035806ff97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 160000 entries, 0 to 159999\n",
            "Data columns (total 47 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   x0      160000 non-null  float64\n",
            " 1   x1      160000 non-null  float64\n",
            " 2   x2      160000 non-null  float64\n",
            " 3   x3      160000 non-null  float64\n",
            " 4   x4      160000 non-null  float64\n",
            " 5   x5      160000 non-null  float64\n",
            " 6   x6      160000 non-null  float64\n",
            " 7   x7      160000 non-null  float64\n",
            " 8   x8      160000 non-null  float64\n",
            " 9   x9      160000 non-null  float64\n",
            " 10  x10     160000 non-null  float64\n",
            " 11  x11     160000 non-null  float64\n",
            " 12  x12     160000 non-null  float64\n",
            " 13  x13     160000 non-null  float64\n",
            " 14  x14     160000 non-null  float64\n",
            " 15  x15     160000 non-null  float64\n",
            " 16  x16     160000 non-null  float64\n",
            " 17  x17     160000 non-null  float64\n",
            " 18  x18     160000 non-null  float64\n",
            " 19  x19     160000 non-null  float64\n",
            " 20  x20     160000 non-null  float64\n",
            " 21  x21     160000 non-null  float64\n",
            " 22  x22     160000 non-null  float64\n",
            " 23  x23     160000 non-null  float64\n",
            " 24  x25     160000 non-null  float64\n",
            " 25  x26     160000 non-null  float64\n",
            " 26  x27     160000 non-null  float64\n",
            " 27  x28     160000 non-null  float64\n",
            " 28  x31     160000 non-null  float64\n",
            " 29  x32     160000 non-null  float64\n",
            " 30  x33     160000 non-null  float64\n",
            " 31  x34     160000 non-null  float64\n",
            " 32  x35     160000 non-null  float64\n",
            " 33  x36     160000 non-null  float64\n",
            " 34  x37     160000 non-null  float64\n",
            " 35  x38     160000 non-null  float64\n",
            " 36  x39     160000 non-null  float64\n",
            " 37  x40     160000 non-null  float64\n",
            " 38  x41     160000 non-null  float64\n",
            " 39  x42     160000 non-null  float64\n",
            " 40  x43     160000 non-null  float64\n",
            " 41  x44     160000 non-null  float64\n",
            " 42  x45     160000 non-null  float64\n",
            " 43  x46     160000 non-null  float64\n",
            " 44  x47     160000 non-null  float64\n",
            " 45  x48     160000 non-null  float64\n",
            " 46  x49     160000 non-null  float64\n",
            "dtypes: float64(47)\n",
            "memory usage: 57.4 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.hstack([df_num,df_cat])"
      ],
      "metadata": {
        "id": "R4oaw8CgIkXV"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['y'].value_counts() # not balanced"
      ],
      "metadata": {
        "id": "xbzdACUdImVy",
        "outputId": "cd6cd8b5-97bd-4a53-a32b-2c794771c7b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "y\n",
              "0    95803\n",
              "1    64197\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#add y plot"
      ],
      "metadata": {
        "id": "vUXTcWUZIoot"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## define cost function\n",
        "def cost(y_pred,y_true):\n",
        "    diff = y_pred - y_true\n",
        "    x = 0\n",
        "    for i in diff:\n",
        "        #false pos (y_pred -y_true == 1)\n",
        "        if i == 1:\n",
        "            x += 100\n",
        "        #false neg (y_pred -y_true ==-1)\n",
        "        elif i == -1:\n",
        "            x += 150\n",
        "    return(x)"
      ],
      "metadata": {
        "id": "HRJz__nu_bxm"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skf = StratifiedKFold(n_splits=5,random_state=807,shuffle=True)\n",
        "skf.get_n_splits(X,y)"
      ],
      "metadata": {
        "id": "qIgBnSnHIqjU",
        "outputId": "5428c04f-6150-448e-f273-72b677e3d8c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logR = LogisticRegression(random_state=807,penalty='elasticnet',class_weight='balanced',solver='saga')\n",
        "params = {'C':[0.00001,0.0001,0.001,0.01,0.1,1,2,5,10],'l1_ratio':[0,0.001,0.01,0.1,0.25,0.5,0.75,0.9,0.99,1],'max_iter':[25,50,75]}\n",
        "\n",
        "lr_clf = GridSearchCV(estimator=logR,param_grid=params,n_jobs=-1,cv=skf)\n",
        "lr_clf.fit(X,y)"
      ],
      "metadata": {
        "id": "AcpquSzJO6SF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_params = lr_clf.best_params_\n",
        "lr_params"
      ],
      "metadata": {
        "id": "Eb5e2xOvO8pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "{'C': 0.001, 'l1_ratio': 0.5, 'max_iter': 50}"
      ],
      "metadata": {
        "id": "gfllGKF4pUMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = LogisticRegression(random_state=807,penalty='elasticnet',class_weight='balanced',solver='saga')\n",
        "model1.set_params(**lr_params)\n",
        "model1.fit(X,y)\n",
        "\n",
        "preds_m1 = cross_val_predict(model1,X,y,cv=skf)"
      ],
      "metadata": {
        "id": "RHUkzlw2PATu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cr_m1 = classification_report(y,preds_m1,output_dict=True)\n",
        "cr_m1\n"
      ],
      "metadata": {
        "id": "3katCHeBPQB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ConfusionMatrixDisplay.from_predictions(y,preds_m1)\n"
      ],
      "metadata": {
        "id": "ent8XHdUPayB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cost_m1 = cost(preds_m1,y)\n",
        "cost_m1"
      ],
      "metadata": {
        "id": "zawbBlwk_fbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(random_state=807,criterion='gini',class_weight='balanced')\n",
        "params = {'n_estimators':[200,250,500],'max_features':['sqrt','log2',20]}\n",
        "rf_clf = GridSearchCV(rf,param_grid=params,cv=skf,n_jobs = -1)"
      ],
      "metadata": {
        "id": "4HWotr_VPhhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_clf.fit(X,y)"
      ],
      "metadata": {
        "id": "soQp5nQ8PkUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_params = rf_clf.best_params_\n",
        "rf_params"
      ],
      "metadata": {
        "id": "Hz6owkMTPlOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = RandomForestClassifier(random_state=807,criterion='gini',class_weight='balanced')\n",
        "model2.set_params(**rf_params)\n",
        "preds_m2 = cross_val_predict(model2,X,y,cv=skf)"
      ],
      "metadata": {
        "id": "hvIbks5bPnfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cr_m2 = classification_report(y,preds_m2,output_dict=True)\n",
        "cr_m2"
      ],
      "metadata": {
        "id": "Aaw8aFI7PpCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ConfusionMatrixDisplay.from_predictions(y,preds_m2)"
      ],
      "metadata": {
        "id": "BK6zSOo4Pq_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cost_m2 = cost(preds_m2,y)\n",
        "cost_m2\n"
      ],
      "metadata": {
        "id": "XqmhfmAx9Ge2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "id": "Fdw5gLOk9oBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svc = NuSVC(random_state=807,class_weight='balanced',cache_size = 8192)\n",
        "params = {'nu':[0.0001,0.01, 0.1, 0.25, 0.5, 0.75, 0.99,1],'kernel':['linear','rbf','sigmoid']}\n",
        "svc_clf = GridSearchCV(svc,param_grid=params,cv=skf,n_jobs=-1)"
      ],
      "metadata": {
        "id": "zYBX6GGsPwEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svc_clf.fit(X,y)"
      ],
      "metadata": {
        "id": "EjZRywoCP6hm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svc_params = svc_clf.best_params_\n",
        "svc_params"
      ],
      "metadata": {
        "id": "yYiNL9AlP98A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = NuSVC(random_state=807,class_weight='balanced',cache_size = 2048)\n",
        "model3.set_params(**svc_params)\n",
        "preds_m3 = cross_val_predict(model3,X,y,cv=skf)"
      ],
      "metadata": {
        "id": "_58pwDIoQGHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cr_m3 = classification_report(y,preds_m3,output_dict=True)\n",
        "cr_m3"
      ],
      "metadata": {
        "id": "5AVAi2z8QPOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ConfusionMatrixDisplay.from_predictions(y,preds_m3)"
      ],
      "metadata": {
        "id": "j5nGHzRUQUOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cost_m3 = cost(preds_m3,y)\n",
        "cost_m3"
      ],
      "metadata": {
        "id": "sefhH4BT-Rd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "8946dca4-81fe-4bfb-be64-a384b53f9eb4"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cost_m3 \u001b[38;5;241m=\u001b[39m cost(\u001b[43mpreds_m3\u001b[49m,y)\n\u001b[1;32m      2\u001b[0m cost_m3\n",
            "\u001b[0;31mNameError\u001b[0m: name 'preds_m3' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min',patience=10,restore_best_weights=True,start_from_epoch=10)"
      ],
      "metadata": {
        "id": "F7PDvk6faa4X"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "now = datetime.datetime.now\n"
      ],
      "metadata": {
        "id": "b04x7Mf5dBDd"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fold_results = {}\n",
        "t_tot = now()\n",
        "for i, (train_index, test_index) in enumerate(skf.split(X,y)):\n",
        "  # building model within loop to reset weights each time\n",
        "  tf.keras.backend.clear_session()\n",
        "  model4 = tf.keras.Sequential()\n",
        "  model4.add(tf.keras.Input(shape=(X.shape[1],)))\n",
        "  model4.add(tf.keras.layers.Dense(64, activation='relu',name=\"Relu1\"))\n",
        "  model4.add(tf.keras.layers.Dense(64, activation='relu', name=\"Relu2\"))\n",
        "  model4.add(tf.keras.layers.Dropout(0.4))\n",
        "  model4.add(tf.keras.layers.Dense(1, activation='sigmoid', name=\"Activation\"))\n",
        "  model4.compile(optimizer='adam',\n",
        "                loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "                metrics = [tf.keras.metrics.AUC(from_logits=False), 'accuracy'])\n",
        "  t_fold = now()\n",
        "  print('x_train shape:', X[train_index].shape)\n",
        "  model4.fit(X[train_index],y[train_index],epochs=100,batch_size=128,validation_split=0.2,callbacks=[es])\n",
        "  fold_results.update({i:{'predictions':np.round(model4.predict(X[test_index]).flatten(),0),'index':test_index,'y_true':y[test_index]}})\n",
        "  print('fold train/predict time: %s' % (now()-t_fold))\n",
        "print('total train/predict time: %s' % (now()-t_tot))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEjPIqNtVPF1",
        "outputId": "4a98bdb5-27a3-40d2-db96-f664467c9318"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (128000, 67)\n",
            "Epoch 1/100\n",
            "800/800 [==============================] - 4s 3ms/step - loss: 0.4184 - auc: 0.8842 - accuracy: 0.8048 - val_loss: 0.3038 - val_auc: 0.9420 - val_accuracy: 0.8712\n",
            "Epoch 2/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.2839 - auc: 0.9491 - accuracy: 0.8843 - val_loss: 0.2499 - val_auc: 0.9612 - val_accuracy: 0.9000\n",
            "Epoch 3/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.2394 - auc: 0.9638 - accuracy: 0.9071 - val_loss: 0.2145 - val_auc: 0.9713 - val_accuracy: 0.9171\n",
            "Epoch 4/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.2110 - auc: 0.9718 - accuracy: 0.9206 - val_loss: 0.1912 - val_auc: 0.9767 - val_accuracy: 0.9284\n",
            "Epoch 5/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.1915 - auc: 0.9765 - accuracy: 0.9296 - val_loss: 0.1754 - val_auc: 0.9803 - val_accuracy: 0.9362\n",
            "Epoch 6/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1770 - auc: 0.9796 - accuracy: 0.9370 - val_loss: 0.1627 - val_auc: 0.9825 - val_accuracy: 0.9439\n",
            "Epoch 7/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1666 - auc: 0.9817 - accuracy: 0.9410 - val_loss: 0.1574 - val_auc: 0.9835 - val_accuracy: 0.9450\n",
            "Epoch 8/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1588 - auc: 0.9832 - accuracy: 0.9453 - val_loss: 0.1485 - val_auc: 0.9853 - val_accuracy: 0.9488\n",
            "Epoch 9/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1508 - auc: 0.9847 - accuracy: 0.9475 - val_loss: 0.1420 - val_auc: 0.9861 - val_accuracy: 0.9518\n",
            "Epoch 10/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1453 - auc: 0.9855 - accuracy: 0.9508 - val_loss: 0.1388 - val_auc: 0.9870 - val_accuracy: 0.9522\n",
            "Epoch 11/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1390 - auc: 0.9866 - accuracy: 0.9532 - val_loss: 0.1349 - val_auc: 0.9873 - val_accuracy: 0.9548\n",
            "Epoch 12/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1351 - auc: 0.9873 - accuracy: 0.9546 - val_loss: 0.1301 - val_auc: 0.9879 - val_accuracy: 0.9577\n",
            "Epoch 13/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1305 - auc: 0.9880 - accuracy: 0.9570 - val_loss: 0.1270 - val_auc: 0.9885 - val_accuracy: 0.9587\n",
            "Epoch 14/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.1267 - auc: 0.9886 - accuracy: 0.9584 - val_loss: 0.1217 - val_auc: 0.9892 - val_accuracy: 0.9610\n",
            "Epoch 15/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1239 - auc: 0.9888 - accuracy: 0.9597 - val_loss: 0.1207 - val_auc: 0.9892 - val_accuracy: 0.9626\n",
            "Epoch 16/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1202 - auc: 0.9894 - accuracy: 0.9618 - val_loss: 0.1172 - val_auc: 0.9896 - val_accuracy: 0.9625\n",
            "Epoch 17/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1179 - auc: 0.9898 - accuracy: 0.9628 - val_loss: 0.1165 - val_auc: 0.9898 - val_accuracy: 0.9634\n",
            "Epoch 18/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1148 - auc: 0.9900 - accuracy: 0.9638 - val_loss: 0.1148 - val_auc: 0.9901 - val_accuracy: 0.9640\n",
            "Epoch 19/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1112 - auc: 0.9907 - accuracy: 0.9648 - val_loss: 0.1148 - val_auc: 0.9900 - val_accuracy: 0.9639\n",
            "Epoch 20/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1104 - auc: 0.9906 - accuracy: 0.9658 - val_loss: 0.1086 - val_auc: 0.9909 - val_accuracy: 0.9669\n",
            "Epoch 21/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1086 - auc: 0.9910 - accuracy: 0.9661 - val_loss: 0.1114 - val_auc: 0.9905 - val_accuracy: 0.9664\n",
            "Epoch 22/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1073 - auc: 0.9909 - accuracy: 0.9675 - val_loss: 0.1085 - val_auc: 0.9908 - val_accuracy: 0.9676\n",
            "Epoch 23/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1042 - auc: 0.9914 - accuracy: 0.9681 - val_loss: 0.1105 - val_auc: 0.9903 - val_accuracy: 0.9661\n",
            "Epoch 24/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.1039 - auc: 0.9915 - accuracy: 0.9680 - val_loss: 0.1069 - val_auc: 0.9911 - val_accuracy: 0.9672\n",
            "Epoch 25/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.1018 - auc: 0.9918 - accuracy: 0.9694 - val_loss: 0.1063 - val_auc: 0.9907 - val_accuracy: 0.9680\n",
            "Epoch 26/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0998 - auc: 0.9920 - accuracy: 0.9693 - val_loss: 0.1051 - val_auc: 0.9912 - val_accuracy: 0.9683\n",
            "Epoch 27/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0995 - auc: 0.9919 - accuracy: 0.9698 - val_loss: 0.1065 - val_auc: 0.9910 - val_accuracy: 0.9681\n",
            "Epoch 28/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0977 - auc: 0.9922 - accuracy: 0.9698 - val_loss: 0.1090 - val_auc: 0.9906 - val_accuracy: 0.9671\n",
            "Epoch 29/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.0986 - auc: 0.9921 - accuracy: 0.9705 - val_loss: 0.1057 - val_auc: 0.9911 - val_accuracy: 0.9691\n",
            "Epoch 30/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0970 - auc: 0.9924 - accuracy: 0.9703 - val_loss: 0.1028 - val_auc: 0.9912 - val_accuracy: 0.9701\n",
            "Epoch 31/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0962 - auc: 0.9922 - accuracy: 0.9715 - val_loss: 0.1064 - val_auc: 0.9910 - val_accuracy: 0.9685\n",
            "Epoch 32/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.0954 - auc: 0.9923 - accuracy: 0.9716 - val_loss: 0.1058 - val_auc: 0.9909 - val_accuracy: 0.9694\n",
            "Epoch 33/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.0947 - auc: 0.9925 - accuracy: 0.9714 - val_loss: 0.1046 - val_auc: 0.9912 - val_accuracy: 0.9693\n",
            "Epoch 34/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0931 - auc: 0.9927 - accuracy: 0.9723 - val_loss: 0.1029 - val_auc: 0.9912 - val_accuracy: 0.9695\n",
            "Epoch 35/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0931 - auc: 0.9926 - accuracy: 0.9720 - val_loss: 0.1030 - val_auc: 0.9914 - val_accuracy: 0.9698\n",
            "Epoch 36/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0930 - auc: 0.9927 - accuracy: 0.9723 - val_loss: 0.1026 - val_auc: 0.9915 - val_accuracy: 0.9692\n",
            "Epoch 37/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0916 - auc: 0.9929 - accuracy: 0.9728 - val_loss: 0.1054 - val_auc: 0.9912 - val_accuracy: 0.9692\n",
            "Epoch 38/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0915 - auc: 0.9929 - accuracy: 0.9731 - val_loss: 0.1052 - val_auc: 0.9914 - val_accuracy: 0.9697\n",
            "Epoch 39/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0913 - auc: 0.9929 - accuracy: 0.9732 - val_loss: 0.1049 - val_auc: 0.9912 - val_accuracy: 0.9693\n",
            "Epoch 40/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0910 - auc: 0.9929 - accuracy: 0.9730 - val_loss: 0.1038 - val_auc: 0.9915 - val_accuracy: 0.9691\n",
            "Epoch 41/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0908 - auc: 0.9929 - accuracy: 0.9730 - val_loss: 0.1035 - val_auc: 0.9911 - val_accuracy: 0.9700\n",
            "Epoch 42/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0889 - auc: 0.9932 - accuracy: 0.9737 - val_loss: 0.1044 - val_auc: 0.9914 - val_accuracy: 0.9709\n",
            "Epoch 43/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0898 - auc: 0.9931 - accuracy: 0.9734 - val_loss: 0.1033 - val_auc: 0.9912 - val_accuracy: 0.9708\n",
            "Epoch 44/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0901 - auc: 0.9928 - accuracy: 0.9732 - val_loss: 0.1029 - val_auc: 0.9913 - val_accuracy: 0.9700\n",
            "Epoch 45/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0877 - auc: 0.9932 - accuracy: 0.9743 - val_loss: 0.1023 - val_auc: 0.9913 - val_accuracy: 0.9703\n",
            "Epoch 46/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0878 - auc: 0.9933 - accuracy: 0.9744 - val_loss: 0.1036 - val_auc: 0.9916 - val_accuracy: 0.9696\n",
            "Epoch 47/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0874 - auc: 0.9932 - accuracy: 0.9741 - val_loss: 0.1052 - val_auc: 0.9911 - val_accuracy: 0.9700\n",
            "Epoch 48/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0866 - auc: 0.9933 - accuracy: 0.9742 - val_loss: 0.1042 - val_auc: 0.9911 - val_accuracy: 0.9708\n",
            "Epoch 49/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0873 - auc: 0.9934 - accuracy: 0.9739 - val_loss: 0.1057 - val_auc: 0.9911 - val_accuracy: 0.9701\n",
            "Epoch 50/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0860 - auc: 0.9935 - accuracy: 0.9741 - val_loss: 0.1029 - val_auc: 0.9911 - val_accuracy: 0.9708\n",
            "Epoch 51/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0871 - auc: 0.9933 - accuracy: 0.9741 - val_loss: 0.1042 - val_auc: 0.9912 - val_accuracy: 0.9710\n",
            "Epoch 52/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0848 - auc: 0.9936 - accuracy: 0.9751 - val_loss: 0.1076 - val_auc: 0.9909 - val_accuracy: 0.9699\n",
            "Epoch 53/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0860 - auc: 0.9936 - accuracy: 0.9745 - val_loss: 0.1057 - val_auc: 0.9912 - val_accuracy: 0.9702\n",
            "Epoch 54/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0856 - auc: 0.9935 - accuracy: 0.9753 - val_loss: 0.1071 - val_auc: 0.9910 - val_accuracy: 0.9703\n",
            "Epoch 55/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.0849 - auc: 0.9936 - accuracy: 0.9751 - val_loss: 0.1055 - val_auc: 0.9911 - val_accuracy: 0.9700\n",
            "1000/1000 [==============================] - 2s 2ms/step\n",
            "fold train/predict time: 0:02:39.365897\n",
            "x_train shape: (128000, 67)\n",
            "Epoch 1/100\n",
            "800/800 [==============================] - 6s 5ms/step - loss: 0.4116 - auc: 0.8883 - accuracy: 0.8097 - val_loss: 0.3009 - val_auc: 0.9438 - val_accuracy: 0.8728\n",
            "Epoch 2/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.2791 - auc: 0.9509 - accuracy: 0.8879 - val_loss: 0.2368 - val_auc: 0.9645 - val_accuracy: 0.9071\n",
            "Epoch 3/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.2301 - auc: 0.9667 - accuracy: 0.9116 - val_loss: 0.2046 - val_auc: 0.9733 - val_accuracy: 0.9225\n",
            "Epoch 4/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.2030 - auc: 0.9737 - accuracy: 0.9250 - val_loss: 0.1875 - val_auc: 0.9779 - val_accuracy: 0.9310\n",
            "Epoch 5/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.1845 - auc: 0.9781 - accuracy: 0.9336 - val_loss: 0.1721 - val_auc: 0.9809 - val_accuracy: 0.9394\n",
            "Epoch 6/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1729 - auc: 0.9805 - accuracy: 0.9388 - val_loss: 0.1614 - val_auc: 0.9829 - val_accuracy: 0.9434\n",
            "Epoch 7/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1634 - auc: 0.9826 - accuracy: 0.9431 - val_loss: 0.1559 - val_auc: 0.9837 - val_accuracy: 0.9459\n",
            "Epoch 8/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1554 - auc: 0.9839 - accuracy: 0.9455 - val_loss: 0.1504 - val_auc: 0.9846 - val_accuracy: 0.9479\n",
            "Epoch 9/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1512 - auc: 0.9847 - accuracy: 0.9483 - val_loss: 0.1445 - val_auc: 0.9857 - val_accuracy: 0.9516\n",
            "Epoch 10/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1452 - auc: 0.9857 - accuracy: 0.9500 - val_loss: 0.1425 - val_auc: 0.9861 - val_accuracy: 0.9509\n",
            "Epoch 11/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1407 - auc: 0.9864 - accuracy: 0.9521 - val_loss: 0.1409 - val_auc: 0.9865 - val_accuracy: 0.9526\n",
            "Epoch 12/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1380 - auc: 0.9868 - accuracy: 0.9538 - val_loss: 0.1369 - val_auc: 0.9867 - val_accuracy: 0.9546\n",
            "Epoch 13/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1339 - auc: 0.9876 - accuracy: 0.9554 - val_loss: 0.1353 - val_auc: 0.9870 - val_accuracy: 0.9551\n",
            "Epoch 14/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1311 - auc: 0.9880 - accuracy: 0.9564 - val_loss: 0.1330 - val_auc: 0.9871 - val_accuracy: 0.9568\n",
            "Epoch 15/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1292 - auc: 0.9881 - accuracy: 0.9577 - val_loss: 0.1330 - val_auc: 0.9876 - val_accuracy: 0.9576\n",
            "Epoch 16/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1263 - auc: 0.9886 - accuracy: 0.9585 - val_loss: 0.1302 - val_auc: 0.9878 - val_accuracy: 0.9576\n",
            "Epoch 17/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1236 - auc: 0.9890 - accuracy: 0.9591 - val_loss: 0.1280 - val_auc: 0.9879 - val_accuracy: 0.9579\n",
            "Epoch 18/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1214 - auc: 0.9893 - accuracy: 0.9600 - val_loss: 0.1290 - val_auc: 0.9879 - val_accuracy: 0.9586\n",
            "Epoch 19/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1212 - auc: 0.9892 - accuracy: 0.9606 - val_loss: 0.1286 - val_auc: 0.9878 - val_accuracy: 0.9586\n",
            "Epoch 20/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1191 - auc: 0.9896 - accuracy: 0.9610 - val_loss: 0.1262 - val_auc: 0.9880 - val_accuracy: 0.9589\n",
            "Epoch 21/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.1187 - auc: 0.9896 - accuracy: 0.9618 - val_loss: 0.1263 - val_auc: 0.9881 - val_accuracy: 0.9595\n",
            "Epoch 22/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1154 - auc: 0.9902 - accuracy: 0.9624 - val_loss: 0.1246 - val_auc: 0.9884 - val_accuracy: 0.9610\n",
            "Epoch 23/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.1153 - auc: 0.9901 - accuracy: 0.9625 - val_loss: 0.1270 - val_auc: 0.9881 - val_accuracy: 0.9604\n",
            "Epoch 24/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.1135 - auc: 0.9903 - accuracy: 0.9636 - val_loss: 0.1268 - val_auc: 0.9881 - val_accuracy: 0.9603\n",
            "Epoch 25/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.1118 - auc: 0.9905 - accuracy: 0.9637 - val_loss: 0.1245 - val_auc: 0.9884 - val_accuracy: 0.9614\n",
            "Epoch 26/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.1114 - auc: 0.9905 - accuracy: 0.9639 - val_loss: 0.1286 - val_auc: 0.9879 - val_accuracy: 0.9607\n",
            "Epoch 27/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.1100 - auc: 0.9907 - accuracy: 0.9650 - val_loss: 0.1255 - val_auc: 0.9884 - val_accuracy: 0.9623\n",
            "Epoch 28/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.1098 - auc: 0.9909 - accuracy: 0.9647 - val_loss: 0.1249 - val_auc: 0.9883 - val_accuracy: 0.9618\n",
            "Epoch 29/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1079 - auc: 0.9912 - accuracy: 0.9646 - val_loss: 0.1217 - val_auc: 0.9887 - val_accuracy: 0.9620\n",
            "Epoch 30/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1070 - auc: 0.9913 - accuracy: 0.9662 - val_loss: 0.1209 - val_auc: 0.9889 - val_accuracy: 0.9622\n",
            "Epoch 31/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1057 - auc: 0.9914 - accuracy: 0.9658 - val_loss: 0.1208 - val_auc: 0.9888 - val_accuracy: 0.9629\n",
            "Epoch 32/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1057 - auc: 0.9915 - accuracy: 0.9655 - val_loss: 0.1242 - val_auc: 0.9888 - val_accuracy: 0.9623\n",
            "Epoch 33/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1047 - auc: 0.9916 - accuracy: 0.9667 - val_loss: 0.1204 - val_auc: 0.9890 - val_accuracy: 0.9621\n",
            "Epoch 34/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1045 - auc: 0.9916 - accuracy: 0.9666 - val_loss: 0.1224 - val_auc: 0.9887 - val_accuracy: 0.9633\n",
            "Epoch 35/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1033 - auc: 0.9917 - accuracy: 0.9672 - val_loss: 0.1189 - val_auc: 0.9891 - val_accuracy: 0.9640\n",
            "Epoch 36/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1031 - auc: 0.9917 - accuracy: 0.9672 - val_loss: 0.1209 - val_auc: 0.9890 - val_accuracy: 0.9637\n",
            "Epoch 37/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1023 - auc: 0.9919 - accuracy: 0.9675 - val_loss: 0.1188 - val_auc: 0.9892 - val_accuracy: 0.9638\n",
            "Epoch 38/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1023 - auc: 0.9918 - accuracy: 0.9685 - val_loss: 0.1193 - val_auc: 0.9890 - val_accuracy: 0.9631\n",
            "Epoch 39/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1005 - auc: 0.9920 - accuracy: 0.9679 - val_loss: 0.1200 - val_auc: 0.9891 - val_accuracy: 0.9625\n",
            "Epoch 40/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1007 - auc: 0.9920 - accuracy: 0.9683 - val_loss: 0.1198 - val_auc: 0.9891 - val_accuracy: 0.9641\n",
            "Epoch 41/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0996 - auc: 0.9922 - accuracy: 0.9691 - val_loss: 0.1218 - val_auc: 0.9891 - val_accuracy: 0.9639\n",
            "Epoch 42/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0990 - auc: 0.9922 - accuracy: 0.9689 - val_loss: 0.1175 - val_auc: 0.9895 - val_accuracy: 0.9655\n",
            "Epoch 43/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0990 - auc: 0.9922 - accuracy: 0.9685 - val_loss: 0.1197 - val_auc: 0.9893 - val_accuracy: 0.9646\n",
            "Epoch 44/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0979 - auc: 0.9922 - accuracy: 0.9698 - val_loss: 0.1191 - val_auc: 0.9891 - val_accuracy: 0.9645\n",
            "Epoch 45/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0973 - auc: 0.9924 - accuracy: 0.9695 - val_loss: 0.1191 - val_auc: 0.9891 - val_accuracy: 0.9655\n",
            "Epoch 46/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0968 - auc: 0.9925 - accuracy: 0.9694 - val_loss: 0.1219 - val_auc: 0.9890 - val_accuracy: 0.9636\n",
            "Epoch 47/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0974 - auc: 0.9924 - accuracy: 0.9697 - val_loss: 0.1204 - val_auc: 0.9893 - val_accuracy: 0.9639\n",
            "Epoch 48/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0951 - auc: 0.9927 - accuracy: 0.9706 - val_loss: 0.1214 - val_auc: 0.9888 - val_accuracy: 0.9633\n",
            "Epoch 49/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0969 - auc: 0.9923 - accuracy: 0.9700 - val_loss: 0.1187 - val_auc: 0.9894 - val_accuracy: 0.9651\n",
            "Epoch 50/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.0948 - auc: 0.9927 - accuracy: 0.9708 - val_loss: 0.1172 - val_auc: 0.9892 - val_accuracy: 0.9651\n",
            "Epoch 51/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0940 - auc: 0.9926 - accuracy: 0.9711 - val_loss: 0.1218 - val_auc: 0.9888 - val_accuracy: 0.9629\n",
            "Epoch 52/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0952 - auc: 0.9927 - accuracy: 0.9711 - val_loss: 0.1183 - val_auc: 0.9892 - val_accuracy: 0.9649\n",
            "Epoch 53/100\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.0935 - auc: 0.9927 - accuracy: 0.9716 - val_loss: 0.1184 - val_auc: 0.9890 - val_accuracy: 0.9648\n",
            "Epoch 54/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0932 - auc: 0.9929 - accuracy: 0.9706 - val_loss: 0.1185 - val_auc: 0.9894 - val_accuracy: 0.9645\n",
            "Epoch 55/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0943 - auc: 0.9928 - accuracy: 0.9706 - val_loss: 0.1191 - val_auc: 0.9894 - val_accuracy: 0.9652\n",
            "Epoch 56/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0929 - auc: 0.9929 - accuracy: 0.9714 - val_loss: 0.1186 - val_auc: 0.9892 - val_accuracy: 0.9656\n",
            "Epoch 57/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0938 - auc: 0.9928 - accuracy: 0.9712 - val_loss: 0.1194 - val_auc: 0.9892 - val_accuracy: 0.9655\n",
            "Epoch 58/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0918 - auc: 0.9930 - accuracy: 0.9715 - val_loss: 0.1172 - val_auc: 0.9891 - val_accuracy: 0.9651\n",
            "Epoch 59/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0913 - auc: 0.9930 - accuracy: 0.9722 - val_loss: 0.1191 - val_auc: 0.9891 - val_accuracy: 0.9650\n",
            "Epoch 60/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0913 - auc: 0.9931 - accuracy: 0.9716 - val_loss: 0.1177 - val_auc: 0.9894 - val_accuracy: 0.9656\n",
            "1000/1000 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:03:10.247254\n",
            "x_train shape: (128000, 67)\n",
            "Epoch 1/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.4123 - auc: 0.8885 - accuracy: 0.8103 - val_loss: 0.3041 - val_auc: 0.9417 - val_accuracy: 0.8740\n",
            "Epoch 2/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2811 - auc: 0.9503 - accuracy: 0.8870 - val_loss: 0.2455 - val_auc: 0.9624 - val_accuracy: 0.9008\n",
            "Epoch 3/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.2355 - auc: 0.9651 - accuracy: 0.9091 - val_loss: 0.2069 - val_auc: 0.9729 - val_accuracy: 0.9221\n",
            "Epoch 4/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.2053 - auc: 0.9733 - accuracy: 0.9233 - val_loss: 0.1820 - val_auc: 0.9789 - val_accuracy: 0.9337\n",
            "Epoch 5/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1864 - auc: 0.9777 - accuracy: 0.9315 - val_loss: 0.1670 - val_auc: 0.9819 - val_accuracy: 0.9414\n",
            "Epoch 6/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1732 - auc: 0.9806 - accuracy: 0.9392 - val_loss: 0.1567 - val_auc: 0.9841 - val_accuracy: 0.9460\n",
            "Epoch 7/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1617 - auc: 0.9829 - accuracy: 0.9443 - val_loss: 0.1511 - val_auc: 0.9848 - val_accuracy: 0.9473\n",
            "Epoch 8/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1545 - auc: 0.9840 - accuracy: 0.9471 - val_loss: 0.1430 - val_auc: 0.9866 - val_accuracy: 0.9516\n",
            "Epoch 9/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1460 - auc: 0.9856 - accuracy: 0.9510 - val_loss: 0.1366 - val_auc: 0.9872 - val_accuracy: 0.9539\n",
            "Epoch 10/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1399 - auc: 0.9866 - accuracy: 0.9528 - val_loss: 0.1342 - val_auc: 0.9875 - val_accuracy: 0.9553\n",
            "Epoch 11/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.1366 - auc: 0.9870 - accuracy: 0.9556 - val_loss: 0.1288 - val_auc: 0.9883 - val_accuracy: 0.9582\n",
            "Epoch 12/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.1308 - auc: 0.9879 - accuracy: 0.9569 - val_loss: 0.1276 - val_auc: 0.9886 - val_accuracy: 0.9589\n",
            "Epoch 13/100\n",
            "800/800 [==============================] - 4s 6ms/step - loss: 0.1290 - auc: 0.9881 - accuracy: 0.9583 - val_loss: 0.1230 - val_auc: 0.9892 - val_accuracy: 0.9600\n",
            "Epoch 14/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.1248 - auc: 0.9887 - accuracy: 0.9599 - val_loss: 0.1238 - val_auc: 0.9890 - val_accuracy: 0.9591\n",
            "Epoch 15/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.1230 - auc: 0.9890 - accuracy: 0.9611 - val_loss: 0.1197 - val_auc: 0.9895 - val_accuracy: 0.9614\n",
            "Epoch 16/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.1189 - auc: 0.9897 - accuracy: 0.9614 - val_loss: 0.1209 - val_auc: 0.9895 - val_accuracy: 0.9618\n",
            "Epoch 17/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.1178 - auc: 0.9898 - accuracy: 0.9625 - val_loss: 0.1171 - val_auc: 0.9898 - val_accuracy: 0.9623\n",
            "Epoch 18/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1155 - auc: 0.9900 - accuracy: 0.9637 - val_loss: 0.1180 - val_auc: 0.9896 - val_accuracy: 0.9619\n",
            "Epoch 19/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1125 - auc: 0.9903 - accuracy: 0.9648 - val_loss: 0.1136 - val_auc: 0.9900 - val_accuracy: 0.9644\n",
            "Epoch 20/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1122 - auc: 0.9904 - accuracy: 0.9648 - val_loss: 0.1168 - val_auc: 0.9897 - val_accuracy: 0.9626\n",
            "Epoch 21/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1106 - auc: 0.9907 - accuracy: 0.9657 - val_loss: 0.1161 - val_auc: 0.9898 - val_accuracy: 0.9631\n",
            "Epoch 22/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1088 - auc: 0.9909 - accuracy: 0.9661 - val_loss: 0.1146 - val_auc: 0.9899 - val_accuracy: 0.9647\n",
            "Epoch 23/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1082 - auc: 0.9908 - accuracy: 0.9666 - val_loss: 0.1137 - val_auc: 0.9901 - val_accuracy: 0.9647\n",
            "Epoch 24/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1078 - auc: 0.9910 - accuracy: 0.9669 - val_loss: 0.1137 - val_auc: 0.9902 - val_accuracy: 0.9646\n",
            "Epoch 25/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1067 - auc: 0.9911 - accuracy: 0.9677 - val_loss: 0.1086 - val_auc: 0.9907 - val_accuracy: 0.9664\n",
            "Epoch 26/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1051 - auc: 0.9914 - accuracy: 0.9676 - val_loss: 0.1110 - val_auc: 0.9903 - val_accuracy: 0.9660\n",
            "Epoch 27/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1051 - auc: 0.9913 - accuracy: 0.9679 - val_loss: 0.1104 - val_auc: 0.9904 - val_accuracy: 0.9655\n",
            "Epoch 28/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1024 - auc: 0.9916 - accuracy: 0.9692 - val_loss: 0.1103 - val_auc: 0.9906 - val_accuracy: 0.9652\n",
            "Epoch 29/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1026 - auc: 0.9916 - accuracy: 0.9689 - val_loss: 0.1089 - val_auc: 0.9905 - val_accuracy: 0.9672\n",
            "Epoch 30/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1022 - auc: 0.9917 - accuracy: 0.9690 - val_loss: 0.1109 - val_auc: 0.9905 - val_accuracy: 0.9662\n",
            "Epoch 31/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0991 - auc: 0.9920 - accuracy: 0.9704 - val_loss: 0.1079 - val_auc: 0.9904 - val_accuracy: 0.9679\n",
            "Epoch 32/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0994 - auc: 0.9919 - accuracy: 0.9698 - val_loss: 0.1095 - val_auc: 0.9904 - val_accuracy: 0.9671\n",
            "Epoch 33/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0975 - auc: 0.9923 - accuracy: 0.9711 - val_loss: 0.1074 - val_auc: 0.9907 - val_accuracy: 0.9689\n",
            "Epoch 34/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0969 - auc: 0.9922 - accuracy: 0.9708 - val_loss: 0.1078 - val_auc: 0.9907 - val_accuracy: 0.9681\n",
            "Epoch 35/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0993 - auc: 0.9920 - accuracy: 0.9703 - val_loss: 0.1075 - val_auc: 0.9908 - val_accuracy: 0.9681\n",
            "Epoch 36/100\n",
            "800/800 [==============================] - 4s 6ms/step - loss: 0.0969 - auc: 0.9922 - accuracy: 0.9709 - val_loss: 0.1052 - val_auc: 0.9910 - val_accuracy: 0.9696\n",
            "Epoch 37/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0960 - auc: 0.9923 - accuracy: 0.9710 - val_loss: 0.1066 - val_auc: 0.9910 - val_accuracy: 0.9700\n",
            "Epoch 38/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0946 - auc: 0.9925 - accuracy: 0.9721 - val_loss: 0.1059 - val_auc: 0.9909 - val_accuracy: 0.9685\n",
            "Epoch 39/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0951 - auc: 0.9925 - accuracy: 0.9722 - val_loss: 0.1058 - val_auc: 0.9910 - val_accuracy: 0.9686\n",
            "Epoch 40/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0950 - auc: 0.9924 - accuracy: 0.9719 - val_loss: 0.1050 - val_auc: 0.9909 - val_accuracy: 0.9696\n",
            "Epoch 41/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0924 - auc: 0.9927 - accuracy: 0.9729 - val_loss: 0.1077 - val_auc: 0.9906 - val_accuracy: 0.9688\n",
            "Epoch 42/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0926 - auc: 0.9927 - accuracy: 0.9727 - val_loss: 0.1096 - val_auc: 0.9902 - val_accuracy: 0.9685\n",
            "Epoch 43/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0938 - auc: 0.9926 - accuracy: 0.9727 - val_loss: 0.1057 - val_auc: 0.9909 - val_accuracy: 0.9691\n",
            "Epoch 44/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0924 - auc: 0.9927 - accuracy: 0.9723 - val_loss: 0.1067 - val_auc: 0.9909 - val_accuracy: 0.9698\n",
            "Epoch 45/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0911 - auc: 0.9930 - accuracy: 0.9732 - val_loss: 0.1067 - val_auc: 0.9908 - val_accuracy: 0.9688\n",
            "Epoch 46/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0902 - auc: 0.9931 - accuracy: 0.9737 - val_loss: 0.1063 - val_auc: 0.9907 - val_accuracy: 0.9697\n",
            "Epoch 47/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0900 - auc: 0.9931 - accuracy: 0.9738 - val_loss: 0.1091 - val_auc: 0.9904 - val_accuracy: 0.9688\n",
            "Epoch 48/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0904 - auc: 0.9930 - accuracy: 0.9739 - val_loss: 0.1070 - val_auc: 0.9906 - val_accuracy: 0.9687\n",
            "Epoch 49/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0893 - auc: 0.9932 - accuracy: 0.9737 - val_loss: 0.1074 - val_auc: 0.9907 - val_accuracy: 0.9690\n",
            "Epoch 50/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0888 - auc: 0.9932 - accuracy: 0.9737 - val_loss: 0.1073 - val_auc: 0.9908 - val_accuracy: 0.9693\n",
            "1000/1000 [==============================] - 2s 2ms/step\n",
            "fold train/predict time: 0:02:35.521755\n",
            "x_train shape: (128000, 67)\n",
            "Epoch 1/100\n",
            "800/800 [==============================] - 5s 4ms/step - loss: 0.4119 - auc: 0.8883 - accuracy: 0.8096 - val_loss: 0.2943 - val_auc: 0.9453 - val_accuracy: 0.8757\n",
            "Epoch 2/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.2793 - auc: 0.9508 - accuracy: 0.8866 - val_loss: 0.2438 - val_auc: 0.9637 - val_accuracy: 0.9015\n",
            "Epoch 3/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.2348 - auc: 0.9652 - accuracy: 0.9089 - val_loss: 0.2119 - val_auc: 0.9717 - val_accuracy: 0.9183\n",
            "Epoch 4/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.2091 - auc: 0.9722 - accuracy: 0.9208 - val_loss: 0.1906 - val_auc: 0.9769 - val_accuracy: 0.9281\n",
            "Epoch 5/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1900 - auc: 0.9768 - accuracy: 0.9296 - val_loss: 0.1778 - val_auc: 0.9798 - val_accuracy: 0.9343\n",
            "Epoch 6/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.1771 - auc: 0.9798 - accuracy: 0.9358 - val_loss: 0.1677 - val_auc: 0.9817 - val_accuracy: 0.9385\n",
            "Epoch 7/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.1686 - auc: 0.9814 - accuracy: 0.9399 - val_loss: 0.1624 - val_auc: 0.9827 - val_accuracy: 0.9420\n",
            "Epoch 8/100\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.1619 - auc: 0.9827 - accuracy: 0.9430 - val_loss: 0.1573 - val_auc: 0.9836 - val_accuracy: 0.9438\n",
            "Epoch 9/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1568 - auc: 0.9837 - accuracy: 0.9445 - val_loss: 0.1526 - val_auc: 0.9846 - val_accuracy: 0.9472\n",
            "Epoch 10/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1512 - auc: 0.9848 - accuracy: 0.9474 - val_loss: 0.1510 - val_auc: 0.9846 - val_accuracy: 0.9476\n",
            "Epoch 11/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1457 - auc: 0.9857 - accuracy: 0.9499 - val_loss: 0.1446 - val_auc: 0.9859 - val_accuracy: 0.9503\n",
            "Epoch 12/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1424 - auc: 0.9862 - accuracy: 0.9513 - val_loss: 0.1421 - val_auc: 0.9861 - val_accuracy: 0.9513\n",
            "Epoch 13/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1393 - auc: 0.9867 - accuracy: 0.9519 - val_loss: 0.1401 - val_auc: 0.9866 - val_accuracy: 0.9526\n",
            "Epoch 14/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1360 - auc: 0.9873 - accuracy: 0.9542 - val_loss: 0.1357 - val_auc: 0.9872 - val_accuracy: 0.9546\n",
            "Epoch 15/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1321 - auc: 0.9879 - accuracy: 0.9557 - val_loss: 0.1344 - val_auc: 0.9875 - val_accuracy: 0.9550\n",
            "Epoch 16/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1308 - auc: 0.9881 - accuracy: 0.9561 - val_loss: 0.1300 - val_auc: 0.9880 - val_accuracy: 0.9583\n",
            "Epoch 17/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1279 - auc: 0.9884 - accuracy: 0.9572 - val_loss: 0.1291 - val_auc: 0.9881 - val_accuracy: 0.9578\n",
            "Epoch 18/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1255 - auc: 0.9889 - accuracy: 0.9586 - val_loss: 0.1269 - val_auc: 0.9882 - val_accuracy: 0.9593\n",
            "Epoch 19/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1235 - auc: 0.9890 - accuracy: 0.9597 - val_loss: 0.1267 - val_auc: 0.9883 - val_accuracy: 0.9600\n",
            "Epoch 20/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.1208 - auc: 0.9895 - accuracy: 0.9602 - val_loss: 0.1232 - val_auc: 0.9889 - val_accuracy: 0.9607\n",
            "Epoch 21/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1204 - auc: 0.9895 - accuracy: 0.9607 - val_loss: 0.1221 - val_auc: 0.9889 - val_accuracy: 0.9621\n",
            "Epoch 22/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.1162 - auc: 0.9901 - accuracy: 0.9625 - val_loss: 0.1215 - val_auc: 0.9889 - val_accuracy: 0.9620\n",
            "Epoch 23/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1157 - auc: 0.9902 - accuracy: 0.9626 - val_loss: 0.1214 - val_auc: 0.9890 - val_accuracy: 0.9630\n",
            "Epoch 24/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1132 - auc: 0.9904 - accuracy: 0.9639 - val_loss: 0.1203 - val_auc: 0.9890 - val_accuracy: 0.9627\n",
            "Epoch 25/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1133 - auc: 0.9904 - accuracy: 0.9639 - val_loss: 0.1196 - val_auc: 0.9891 - val_accuracy: 0.9630\n",
            "Epoch 26/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.1105 - auc: 0.9908 - accuracy: 0.9646 - val_loss: 0.1183 - val_auc: 0.9893 - val_accuracy: 0.9643\n",
            "Epoch 27/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1092 - auc: 0.9910 - accuracy: 0.9650 - val_loss: 0.1187 - val_auc: 0.9892 - val_accuracy: 0.9639\n",
            "Epoch 28/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1078 - auc: 0.9912 - accuracy: 0.9654 - val_loss: 0.1202 - val_auc: 0.9891 - val_accuracy: 0.9635\n",
            "Epoch 29/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1068 - auc: 0.9913 - accuracy: 0.9658 - val_loss: 0.1194 - val_auc: 0.9892 - val_accuracy: 0.9646\n",
            "Epoch 30/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1061 - auc: 0.9913 - accuracy: 0.9667 - val_loss: 0.1171 - val_auc: 0.9896 - val_accuracy: 0.9643\n",
            "Epoch 31/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1057 - auc: 0.9913 - accuracy: 0.9661 - val_loss: 0.1169 - val_auc: 0.9897 - val_accuracy: 0.9648\n",
            "Epoch 32/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1056 - auc: 0.9914 - accuracy: 0.9665 - val_loss: 0.1152 - val_auc: 0.9898 - val_accuracy: 0.9656\n",
            "Epoch 33/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1037 - auc: 0.9916 - accuracy: 0.9676 - val_loss: 0.1166 - val_auc: 0.9896 - val_accuracy: 0.9641\n",
            "Epoch 34/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1027 - auc: 0.9918 - accuracy: 0.9681 - val_loss: 0.1146 - val_auc: 0.9899 - val_accuracy: 0.9650\n",
            "Epoch 35/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1008 - auc: 0.9921 - accuracy: 0.9682 - val_loss: 0.1142 - val_auc: 0.9898 - val_accuracy: 0.9658\n",
            "Epoch 36/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1014 - auc: 0.9919 - accuracy: 0.9683 - val_loss: 0.1176 - val_auc: 0.9895 - val_accuracy: 0.9652\n",
            "Epoch 37/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1008 - auc: 0.9919 - accuracy: 0.9683 - val_loss: 0.1151 - val_auc: 0.9898 - val_accuracy: 0.9650\n",
            "Epoch 38/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1001 - auc: 0.9921 - accuracy: 0.9688 - val_loss: 0.1122 - val_auc: 0.9898 - val_accuracy: 0.9676\n",
            "Epoch 39/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.1001 - auc: 0.9921 - accuracy: 0.9689 - val_loss: 0.1149 - val_auc: 0.9895 - val_accuracy: 0.9663\n",
            "Epoch 40/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0993 - auc: 0.9919 - accuracy: 0.9698 - val_loss: 0.1165 - val_auc: 0.9896 - val_accuracy: 0.9651\n",
            "Epoch 41/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.0978 - auc: 0.9923 - accuracy: 0.9698 - val_loss: 0.1143 - val_auc: 0.9898 - val_accuracy: 0.9659\n",
            "Epoch 42/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0968 - auc: 0.9924 - accuracy: 0.9701 - val_loss: 0.1177 - val_auc: 0.9892 - val_accuracy: 0.9652\n",
            "Epoch 43/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0989 - auc: 0.9922 - accuracy: 0.9688 - val_loss: 0.1163 - val_auc: 0.9897 - val_accuracy: 0.9663\n",
            "Epoch 44/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0973 - auc: 0.9925 - accuracy: 0.9704 - val_loss: 0.1151 - val_auc: 0.9897 - val_accuracy: 0.9659\n",
            "Epoch 45/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0958 - auc: 0.9926 - accuracy: 0.9702 - val_loss: 0.1155 - val_auc: 0.9899 - val_accuracy: 0.9667\n",
            "Epoch 46/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0961 - auc: 0.9924 - accuracy: 0.9701 - val_loss: 0.1151 - val_auc: 0.9894 - val_accuracy: 0.9665\n",
            "Epoch 47/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0951 - auc: 0.9927 - accuracy: 0.9707 - val_loss: 0.1148 - val_auc: 0.9897 - val_accuracy: 0.9668\n",
            "Epoch 48/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0957 - auc: 0.9926 - accuracy: 0.9702 - val_loss: 0.1185 - val_auc: 0.9896 - val_accuracy: 0.9665\n",
            "1000/1000 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:02:36.338100\n",
            "x_train shape: (128000, 67)\n",
            "Epoch 1/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.4209 - auc: 0.8829 - accuracy: 0.8053 - val_loss: 0.2985 - val_auc: 0.9438 - val_accuracy: 0.8741\n",
            "Epoch 2/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.2825 - auc: 0.9494 - accuracy: 0.8863 - val_loss: 0.2437 - val_auc: 0.9629 - val_accuracy: 0.9048\n",
            "Epoch 3/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.2371 - auc: 0.9644 - accuracy: 0.9094 - val_loss: 0.2118 - val_auc: 0.9720 - val_accuracy: 0.9195\n",
            "Epoch 4/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.2090 - auc: 0.9721 - accuracy: 0.9213 - val_loss: 0.1912 - val_auc: 0.9767 - val_accuracy: 0.9290\n",
            "Epoch 5/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1912 - auc: 0.9764 - accuracy: 0.9299 - val_loss: 0.1774 - val_auc: 0.9796 - val_accuracy: 0.9352\n",
            "Epoch 6/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1786 - auc: 0.9792 - accuracy: 0.9351 - val_loss: 0.1712 - val_auc: 0.9810 - val_accuracy: 0.9394\n",
            "Epoch 7/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1690 - auc: 0.9812 - accuracy: 0.9396 - val_loss: 0.1658 - val_auc: 0.9820 - val_accuracy: 0.9409\n",
            "Epoch 8/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.1616 - auc: 0.9826 - accuracy: 0.9427 - val_loss: 0.1561 - val_auc: 0.9836 - val_accuracy: 0.9463\n",
            "Epoch 9/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.1545 - auc: 0.9841 - accuracy: 0.9457 - val_loss: 0.1524 - val_auc: 0.9846 - val_accuracy: 0.9473\n",
            "Epoch 10/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.1492 - auc: 0.9850 - accuracy: 0.9483 - val_loss: 0.1473 - val_auc: 0.9854 - val_accuracy: 0.9512\n",
            "Epoch 11/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.1429 - auc: 0.9860 - accuracy: 0.9511 - val_loss: 0.1442 - val_auc: 0.9859 - val_accuracy: 0.9520\n",
            "Epoch 12/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.1388 - auc: 0.9868 - accuracy: 0.9524 - val_loss: 0.1409 - val_auc: 0.9866 - val_accuracy: 0.9527\n",
            "Epoch 13/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.1353 - auc: 0.9874 - accuracy: 0.9543 - val_loss: 0.1378 - val_auc: 0.9870 - val_accuracy: 0.9547\n",
            "Epoch 14/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1296 - auc: 0.9882 - accuracy: 0.9573 - val_loss: 0.1364 - val_auc: 0.9875 - val_accuracy: 0.9558\n",
            "Epoch 15/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1270 - auc: 0.9886 - accuracy: 0.9575 - val_loss: 0.1362 - val_auc: 0.9874 - val_accuracy: 0.9543\n",
            "Epoch 16/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1248 - auc: 0.9888 - accuracy: 0.9589 - val_loss: 0.1299 - val_auc: 0.9883 - val_accuracy: 0.9574\n",
            "Epoch 17/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1226 - auc: 0.9892 - accuracy: 0.9599 - val_loss: 0.1287 - val_auc: 0.9880 - val_accuracy: 0.9589\n",
            "Epoch 18/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1201 - auc: 0.9896 - accuracy: 0.9608 - val_loss: 0.1279 - val_auc: 0.9885 - val_accuracy: 0.9600\n",
            "Epoch 19/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1172 - auc: 0.9899 - accuracy: 0.9617 - val_loss: 0.1286 - val_auc: 0.9885 - val_accuracy: 0.9588\n",
            "Epoch 20/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1164 - auc: 0.9900 - accuracy: 0.9625 - val_loss: 0.1326 - val_auc: 0.9882 - val_accuracy: 0.9591\n",
            "Epoch 21/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1141 - auc: 0.9903 - accuracy: 0.9635 - val_loss: 0.1233 - val_auc: 0.9891 - val_accuracy: 0.9611\n",
            "Epoch 22/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1123 - auc: 0.9905 - accuracy: 0.9640 - val_loss: 0.1234 - val_auc: 0.9887 - val_accuracy: 0.9613\n",
            "Epoch 23/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.1112 - auc: 0.9908 - accuracy: 0.9644 - val_loss: 0.1227 - val_auc: 0.9890 - val_accuracy: 0.9622\n",
            "Epoch 24/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1113 - auc: 0.9905 - accuracy: 0.9645 - val_loss: 0.1242 - val_auc: 0.9888 - val_accuracy: 0.9617\n",
            "Epoch 25/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1076 - auc: 0.9911 - accuracy: 0.9656 - val_loss: 0.1219 - val_auc: 0.9892 - val_accuracy: 0.9626\n",
            "Epoch 26/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1072 - auc: 0.9912 - accuracy: 0.9661 - val_loss: 0.1204 - val_auc: 0.9892 - val_accuracy: 0.9634\n",
            "Epoch 27/100\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.1060 - auc: 0.9913 - accuracy: 0.9654 - val_loss: 0.1189 - val_auc: 0.9893 - val_accuracy: 0.9640\n",
            "Epoch 28/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.1052 - auc: 0.9915 - accuracy: 0.9665 - val_loss: 0.1187 - val_auc: 0.9895 - val_accuracy: 0.9638\n",
            "Epoch 29/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.1028 - auc: 0.9918 - accuracy: 0.9669 - val_loss: 0.1192 - val_auc: 0.9896 - val_accuracy: 0.9642\n",
            "Epoch 30/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.1019 - auc: 0.9919 - accuracy: 0.9677 - val_loss: 0.1226 - val_auc: 0.9891 - val_accuracy: 0.9629\n",
            "Epoch 31/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.1002 - auc: 0.9921 - accuracy: 0.9680 - val_loss: 0.1188 - val_auc: 0.9896 - val_accuracy: 0.9650\n",
            "Epoch 32/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.1000 - auc: 0.9921 - accuracy: 0.9690 - val_loss: 0.1174 - val_auc: 0.9895 - val_accuracy: 0.9664\n",
            "Epoch 33/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0999 - auc: 0.9921 - accuracy: 0.9686 - val_loss: 0.1165 - val_auc: 0.9898 - val_accuracy: 0.9652\n",
            "Epoch 34/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0979 - auc: 0.9923 - accuracy: 0.9700 - val_loss: 0.1190 - val_auc: 0.9895 - val_accuracy: 0.9650\n",
            "Epoch 35/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0979 - auc: 0.9924 - accuracy: 0.9692 - val_loss: 0.1177 - val_auc: 0.9900 - val_accuracy: 0.9663\n",
            "Epoch 36/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0965 - auc: 0.9926 - accuracy: 0.9699 - val_loss: 0.1209 - val_auc: 0.9893 - val_accuracy: 0.9645\n",
            "Epoch 37/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0988 - auc: 0.9922 - accuracy: 0.9697 - val_loss: 0.1146 - val_auc: 0.9900 - val_accuracy: 0.9669\n",
            "Epoch 38/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.0963 - auc: 0.9926 - accuracy: 0.9702 - val_loss: 0.1171 - val_auc: 0.9897 - val_accuracy: 0.9661\n",
            "Epoch 39/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0948 - auc: 0.9927 - accuracy: 0.9711 - val_loss: 0.1180 - val_auc: 0.9896 - val_accuracy: 0.9656\n",
            "Epoch 40/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0946 - auc: 0.9927 - accuracy: 0.9708 - val_loss: 0.1185 - val_auc: 0.9896 - val_accuracy: 0.9658\n",
            "Epoch 41/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0941 - auc: 0.9928 - accuracy: 0.9707 - val_loss: 0.1184 - val_auc: 0.9898 - val_accuracy: 0.9670\n",
            "Epoch 42/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0941 - auc: 0.9928 - accuracy: 0.9706 - val_loss: 0.1169 - val_auc: 0.9899 - val_accuracy: 0.9677\n",
            "Epoch 43/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0935 - auc: 0.9929 - accuracy: 0.9710 - val_loss: 0.1172 - val_auc: 0.9900 - val_accuracy: 0.9670\n",
            "Epoch 44/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0928 - auc: 0.9930 - accuracy: 0.9718 - val_loss: 0.1189 - val_auc: 0.9891 - val_accuracy: 0.9657\n",
            "Epoch 45/100\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.0913 - auc: 0.9931 - accuracy: 0.9720 - val_loss: 0.1174 - val_auc: 0.9898 - val_accuracy: 0.9668\n",
            "Epoch 46/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0914 - auc: 0.9930 - accuracy: 0.9716 - val_loss: 0.1218 - val_auc: 0.9892 - val_accuracy: 0.9661\n",
            "Epoch 47/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0916 - auc: 0.9931 - accuracy: 0.9719 - val_loss: 0.1179 - val_auc: 0.9897 - val_accuracy: 0.9675\n",
            "1000/1000 [==============================] - 2s 1ms/step\n",
            "fold train/predict time: 0:02:38.105049\n",
            "total train/predict time: 0:13:40.049858\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_m4 = np.zeros(len(y))\n",
        "for i in fold_results.keys():\n",
        "  for j in range(len(fold_results.get(i).get('predictions'))):\n",
        "    idx = fold_results.get(i).get('index')[j]\n",
        "    preds_m4[idx] = np.round(fold_results.get(i).get('predictions')[j],0)\n",
        "\n"
      ],
      "metadata": {
        "id": "WMZkaNGNeKT0"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cost(preds_m4,y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkQAh6OMjjJp",
        "outputId": "3093b3a9-1d74-473c-ff55-6e1e1d8b05c4"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "679150"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model4.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jg2oQFvH2QS",
        "outputId": "bffccd04-49d0-44e0-afac-0d1c25f463aa"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Relu1 (Dense)               (None, 64)                4352      \n",
            "                                                                 \n",
            " Relu2 (Dense)               (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " Activation (Dense)          (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,577\n",
            "Trainable params: 8,577\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(preds_m4-y).value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVNOkJr3oYGb",
        "outputId": "397b6208-91a5-4876-82ba-0a45b43fa562"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 0.0    152999\n",
              "-1.0      3795\n",
              " 1.0      3206\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    }
  ]
}