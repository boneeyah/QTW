{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/boneeyah/QTW/blob/main/Case%20Study%207/CaseStudy7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OZryWKHR3JAd"
      },
      "outputs": [],
      "source": [
        "#!pip install scikit-learn-intelex\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "tf.keras.utils.set_random_seed(807)\n",
        "tf.config.experimental.enable_op_determinism\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow.keras.backend as K\n",
        "#from sklearnex import patch_sklearn\n",
        "#patch_sklearn()\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_val_predict\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from numpy import random\n",
        "from itertools import product\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, classification_report, ConfusionMatrixDisplay\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "import xgboost as xgb\n",
        "from xgboost import DMatrix\n",
        "\n",
        "from numpy import random\n",
        "from itertools import product\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import datetime\n",
        "import pydot\n",
        "import graphviz\n"
      ],
      "metadata": {
        "id": "HrVUsV_b8Ezp",
        "outputId": "cc90dd69-b5d1-4522-abd9-3c6bd93eb3cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-08-05 18:24:34.090973: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-08-05 18:24:34.819084: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('drive')\n",
        "\n",
        "#df = pd.read_csv(\"drive/My Drive/final_project(5).csv\")\n",
        "df = pd.read_csv(\"/home/migue/Downloads/final_project(5).csv\")"
      ],
      "metadata": {
        "id": "hngzaeNL-EXs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()\n",
        "#there are NAs will need handling"
      ],
      "metadata": {
        "id": "kjzOue9y_SuK",
        "outputId": "bdf20ac5-1692-49d7-c254-24fe8937b53e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 160000 entries, 0 to 159999\n",
            "Data columns (total 51 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   x0      159974 non-null  float64\n",
            " 1   x1      159975 non-null  float64\n",
            " 2   x2      159962 non-null  float64\n",
            " 3   x3      159963 non-null  float64\n",
            " 4   x4      159974 non-null  float64\n",
            " 5   x5      159963 non-null  float64\n",
            " 6   x6      159974 non-null  float64\n",
            " 7   x7      159973 non-null  float64\n",
            " 8   x8      159979 non-null  float64\n",
            " 9   x9      159970 non-null  float64\n",
            " 10  x10     159957 non-null  float64\n",
            " 11  x11     159970 non-null  float64\n",
            " 12  x12     159964 non-null  float64\n",
            " 13  x13     159969 non-null  float64\n",
            " 14  x14     159966 non-null  float64\n",
            " 15  x15     159965 non-null  float64\n",
            " 16  x16     159974 non-null  float64\n",
            " 17  x17     159973 non-null  float64\n",
            " 18  x18     159960 non-null  float64\n",
            " 19  x19     159965 non-null  float64\n",
            " 20  x20     159962 non-null  float64\n",
            " 21  x21     159971 non-null  float64\n",
            " 22  x22     159973 non-null  float64\n",
            " 23  x23     159953 non-null  float64\n",
            " 24  x24     159972 non-null  object \n",
            " 25  x25     159978 non-null  float64\n",
            " 26  x26     159964 non-null  float64\n",
            " 27  x27     159970 non-null  float64\n",
            " 28  x28     159965 non-null  float64\n",
            " 29  x29     159970 non-null  object \n",
            " 30  x30     159970 non-null  object \n",
            " 31  x31     159961 non-null  float64\n",
            " 32  x32     159969 non-null  object \n",
            " 33  x33     159959 non-null  float64\n",
            " 34  x34     159959 non-null  float64\n",
            " 35  x35     159970 non-null  float64\n",
            " 36  x36     159973 non-null  float64\n",
            " 37  x37     159977 non-null  object \n",
            " 38  x38     159969 non-null  float64\n",
            " 39  x39     159977 non-null  float64\n",
            " 40  x40     159964 non-null  float64\n",
            " 41  x41     159960 non-null  float64\n",
            " 42  x42     159974 non-null  float64\n",
            " 43  x43     159963 non-null  float64\n",
            " 44  x44     159960 non-null  float64\n",
            " 45  x45     159971 non-null  float64\n",
            " 46  x46     159969 non-null  float64\n",
            " 47  x47     159963 non-null  float64\n",
            " 48  x48     159968 non-null  float64\n",
            " 49  x49     159968 non-null  float64\n",
            " 50  y       160000 non-null  int64  \n",
            "dtypes: float64(45), int64(1), object(5)\n",
            "memory usage: 62.3+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in df.columns:\n",
        "    if df[i].isna().sum() > 0:\n",
        "        print('{} has {}% NAs'.format(i,(df[i].isna().sum() / len(df))*100))"
      ],
      "metadata": {
        "id": "CC3yFJ6BzzOw",
        "outputId": "5b003ba3-6fdb-4d4a-b348-fd424c73127e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x0 has 0.01625% NAs\n",
            "x1 has 0.015625% NAs\n",
            "x2 has 0.02375% NAs\n",
            "x3 has 0.023125% NAs\n",
            "x4 has 0.01625% NAs\n",
            "x5 has 0.023125% NAs\n",
            "x6 has 0.01625% NAs\n",
            "x7 has 0.016875% NAs\n",
            "x8 has 0.013125% NAs\n",
            "x9 has 0.01875% NAs\n",
            "x10 has 0.026875% NAs\n",
            "x11 has 0.01875% NAs\n",
            "x12 has 0.0225% NAs\n",
            "x13 has 0.019375% NAs\n",
            "x14 has 0.021249999999999998% NAs\n",
            "x15 has 0.021875000000000002% NAs\n",
            "x16 has 0.01625% NAs\n",
            "x17 has 0.016875% NAs\n",
            "x18 has 0.025% NAs\n",
            "x19 has 0.021875000000000002% NAs\n",
            "x20 has 0.02375% NAs\n",
            "x21 has 0.018125% NAs\n",
            "x22 has 0.016875% NAs\n",
            "x23 has 0.029375000000000002% NAs\n",
            "x24 has 0.017499999999999998% NAs\n",
            "x25 has 0.01375% NAs\n",
            "x26 has 0.0225% NAs\n",
            "x27 has 0.01875% NAs\n",
            "x28 has 0.021875000000000002% NAs\n",
            "x29 has 0.01875% NAs\n",
            "x30 has 0.01875% NAs\n",
            "x31 has 0.024374999999999997% NAs\n",
            "x32 has 0.019375% NAs\n",
            "x33 has 0.025625000000000002% NAs\n",
            "x34 has 0.025625000000000002% NAs\n",
            "x35 has 0.01875% NAs\n",
            "x36 has 0.016875% NAs\n",
            "x37 has 0.014374999999999999% NAs\n",
            "x38 has 0.019375% NAs\n",
            "x39 has 0.014374999999999999% NAs\n",
            "x40 has 0.0225% NAs\n",
            "x41 has 0.025% NAs\n",
            "x42 has 0.01625% NAs\n",
            "x43 has 0.023125% NAs\n",
            "x44 has 0.025% NAs\n",
            "x45 has 0.018125% NAs\n",
            "x46 has 0.019375% NAs\n",
            "x47 has 0.023125% NAs\n",
            "x48 has 0.02% NAs\n",
            "x49 has 0.02% NAs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['x24'].value_counts()"
      ],
      "metadata": {
        "id": "TybuIbMLz6Ng",
        "outputId": "8f3804c5-4d3e-475b-f2d8-eee22732dd23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "x24\n",
              "asia       138965\n",
              "euorpe      16538\n",
              "america      4469\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(x=df['x24'].value_counts().index,height=df['x24'].value_counts().values)"
      ],
      "metadata": {
        "id": "ME56MKaIz7sN",
        "outputId": "034c6f8c-5876-4f3c-c523-852d30d0db1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 3 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['x29'].value_counts()"
      ],
      "metadata": {
        "id": "P7rMlCalz9WH",
        "outputId": "82cb20e6-10b1-4579-e4b5-547d34a69cfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "x29\n",
              "July       45569\n",
              "Jun        41329\n",
              "Aug        29406\n",
              "May        21939\n",
              "sept.      10819\n",
              "Apr         6761\n",
              "Oct         2407\n",
              "Mar         1231\n",
              "Nov          337\n",
              "Feb          140\n",
              "Dev           23\n",
              "January        9\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#clean up month formatting to standard 3 letters\n",
        "df['x29'].replace(to_replace=['July','sept.','Dev','January'],value=['Jul','Sep','Dec','Jan'],inplace=True)"
      ],
      "metadata": {
        "id": "gB-gkjC2z_fK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mo = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
        "heights = []\n",
        "for i in mo:\n",
        "    x = df['x29'].to_list().count(i)\n",
        "    heights.append(x)\n",
        "plt.bar(x=mo,height=heights)"
      ],
      "metadata": {
        "id": "eZTNOL9P0CM3",
        "outputId": "e649f7b9-cb3d-4540-d9a4-0a0214abd1fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 12 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1,3, figsize = (25, 5))\n",
        "plt.subplots_adjust(wspace=.18,hspace=1)\n",
        "fig.subplots_adjust(top = .96)\n",
        "sns.set(rc={'figure.figsize':(5.5,6)})\n",
        "sns.countplot(x = 'x29', data = df, hue = 'y', ax = axes[0]);\n",
        "sns.countplot(x = 'x30', data = df, hue = 'y', ax = axes[1]);\n",
        "sns.countplot(x = 'x24', data = df, hue = 'y', ax = axes[2]);\n",
        "\n",
        "fig.suptitle('Count plots for categorical features')"
      ],
      "metadata": {
        "id": "lCaK4Zy0zbuh",
        "outputId": "c5aada9a-f49c-4401-bcc2-793c0c153e26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0.98, 'Count plots for categorical features')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2500x500 with 3 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAB+kAAAHyCAYAAAAnavyMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAADDnklEQVR4nOzdeVxU9f7H8fcgyiauKQKCoIaVZmYBg5JpdbUUS8TrtQUbQ69a5r7gzWtpi5pF8oss3CoXbDPNvJqt2kVBTc26anUzUjDIxIUEGRfO749+nJ+TgBvOoLyej8c84pzPOd/5fM9Mj8fH85lzjsUwDEMAAAAAAAAAAAAAAOCyc3N1AgAAAAAAAAAAAAAAVBc06QEAAAAAAAAAAAAAcBKa9AAAAAAAAAAAAAAAOAlNegAAAAAAAAAAAAAAnIQmPQAAAAAAAAAAAAAATkKTHgAAAAAAAAAAAAAAJ6FJDwAAAAAAAAAAAACAk9CkBwAAAAAAAAAAAADASWjSAwAAAAAAAAAAAADgJDTpAQAAAMCJdu7cqcmTJ+vuu+/WTTfdpPbt26tfv35asmSJTp065er0ypWenq5vvvmmUseMj49Xq1atVFBQcFH7nz59WosXL1ZRUVGl5VRUVKSJEycqMjJSbdu21eDBgyttbGe6HMfmcnv55ZfVqlUrffrpp5f1fVq1aqX77rvvnNudOnVKM2bMUMeOHXXjjTeqZ8+elzWvK/EzAwAAAABcHJr0AAAAAOAEJSUlSk5OVlxcnJYvX64WLVrogQceUPfu3ZWXl6epU6dqwIABKi4udnWqZ0lLS1NCQoIOHDjg6lQcjBkzRk8//XSl/rjh1Vdf1fvvv6+mTZvq4YcfVrdu3SptbGe6HMfmcouIiNCwYcMUGhrq6lQkSe+9954WLFggX19fPfzww+rdu/dlfb8r8TMDAAAAAFwcd1cnAAAAAADVwWuvvabZs2erXbt2+p//+R/5+fmZsRMnTugf//iHPvzwQyUmJmrWrFmuS7QM+fn5rk6hTJcjr127dkmSkpKS1KxZs0of31mq6mdWkcjISEVGRro6DVPpd2Hy5Mnq0KHDZX+/K/EzAwAAAABcHK6kBwAAAIDLLCsrS7Nnz1aDBg00d+5chwa9JNWqVUvTpk1TYGCgPvroI+3Zs8dFmeLEiROSpPr167s4E7ga3wUAAAAAwOVCkx4AAAAALrMVK1bo5MmTevDBB1WnTp0yt6lZs6b++c9/6rnnnjurKbh69Wr169dP7dq1080336x+/frpX//6l8M2OTk5atWqlR599NGzxi7rWd933HGH4uPjtWfPHg0ZMkS33HKLbr75Zg0aNEjfffeduV18fLxSUlIkSY899phatWpV4Vzj4+PVqVMn7d+/X0OGDNHNN9+sDh06aNy4cfrll18qPlAXMN9WrVpp8+bNkqTw8HDFx8ebsUWLFql37966+eab1b59ez3wwANas2ZNhe+5adOms8Zs1aqVcnJyJP3RsH3ttdfUvXt3tWnTRpGRkRo6dKi+/fZbh3Hef/99tWrVSmvWrFFCQoJuvPFGdenSRdnZ2RW+/6effqr4+HjdeuutioyMlM1m05YtWxy2OXnypN5880317dtXt9xyi9q0aaMuXbpo8uTJOnTo0HkdmxMnTig1NVXdu3fXjTfeqKioKI0ZM6bM/AoLCzVz5kzdcccdatu2rXr37q3PP/9cTzzxxFnfg5KSEqWlpalXr15q27atbrnlFg0YMEAbNmwo8zinpaVp9OjRatu2raKjo7V169Zyn0m/ZcsWDR48WJGRkbrlllvUr1+/Mp9bv2LFCsXHxys8PFxt2rRRdHR0uXOrSOn/S8uXL5ck9erVS61atdKmTZvMbdasWaN+/fqZ37GHH35YmZmZZ411qZ9ZYmKiWrVqpd27d581dqtWrXTfffeZy6XHLyMjQ3/961/Vpk0bdevWTYWFhZKk3377TU899ZQ6deqkNm3a6I477tDMmTN17Ngxh3FPnTqllJQU9ezZU+3atVNERIQSEhKUkZFxQccRAAAAAFA+mvQAAAAAcJn9+9//liTddtttFW7XpUsX9e7dWw0aNDDXzZgxQ6NGjVJOTo5iYmLUo0cP5eTkaPTo0Zo5c+Yl5ZWbm6t+/fopPz9fffv2VWRkpL788kvFx8ebDcTY2FhFRERIkrp3765hw4adc9zi4mL1799fWVlZ6tevn9q0aaOVK1eqX79++vXXXyvc93znO2zYMAUGBkqSBg0apNjYWEnSnDlz9Mwzz0iS+vXrp969e2vfvn0aOXKkVqxYUe77BgYGnjXmsGHDVKdOHdntdtlsNr300kuqUaOG7r//fnXo0EHp6em6//77y2wYP/PMMzp06JDi4+N14403KigoqNz3Tk1N1WOPPaY9e/aoW7du6tGjh3bt2iWbzebQ5B4zZoyee+45ubu7q2/fvvrb3/6mWrVq6e2339agQYPOeWxOnjypQYMGKSkpST4+PnrooYd022236eOPP1afPn30ww8/mGOcOHFCAwYM0Lx589S4cWM9+OCDql27th599NGzmrUlJSUaNWqUpkyZomPHjikuLk533XWXvv32WyUkJGjJkiVnzfmVV17Rt99+q4ceekg33HCDWrduXeax+eCDD/Twww9ry5Yt6tSpk+Li4pSbm6vHHntMy5YtM7ebMWOGJkyYoIKCAsXGxurBBx9U48aNtWrVKsXHx6u4uLjc4/9nderU0bBhw3TddddJkv72t785HNPk5GSNHDlSBw4cUGxsrGJjY/Xjjz9qwIAB+uCDDxzGutTP7GKMHTtWnp6eio+PV2RkpHx8fPTLL7+oT58+euutt9S6dWvZbDaFhoZq3rx5io+PV1FRkbn/008/rZdffln16tXTgw8+qLvvvls7duxQQkKCww8VAAAAAACXwAAAAAAAXFZRUVFGWFiYceTIkQvab8uWLUZYWJjRq1cvIz8/31yfn59vxMTEGGFhYcbmzZsNwzCM7OxsIywszBg6dOhZ4/zP//yPERYWZnzyySfmui5duhhhYWHGlClTjJKSEnP9pEmTjLCwMCMtLa3C/cvz0EMPGWFhYUZcXJxx/Phxc/38+fONsLAwY8KECWdte/To0Queb1n7G4ZhREREGHfddZdx8uRJc11ubq7Rpk0bo3fv3ued/5ljpqSkGGFhYUZiYqLDuP/5z3+Mtm3bGrfeeqvx+++/G4ZhGMuWLTPCwsKMTp06GUVFRed8v59++sm44YYbjLvvvts4cOCAuf7nn3822rVrZ8TExBiGYRjbt283wsLCjDFjxjjsf/LkSfPY/PTTTxXOY+7cuUZYWJjx/PPPO4zxzTffGK1btzbi4uLMdaWf19SpUx2+H9OnTzfCwsKMsLAwc93y5cuNsLAw45FHHjEKCwvN9fv27TM6duxo3HDDDca+ffsMwzCMzMxMIywszLjpppsc5msYZ3/Pjhw5Ytxyyy1GVFSUw9zy8/ON6OhoIyIiwjhx4oSRl5dnXHfddcaDDz5onDp1ymHMQYMGGWFhYca///1vc11YWJhx7733GucyYcIEIywszNi1a5e5bseOHUarVq2Mhx56yOHzPXTokPGXv/zFuOmmm8zvbmV8ZmXlUN48So9f7969jdOnT591HFq1amV88cUXDuvffPNNIywszJgxY4ZhGIbx+++/m8fyTN98840RFhZmPP744xUeMwAAAADA+eFKegAAAAC4zAoKCiRJPj4+F7Tf+++/L0kaP368w9X1DRo00JgxYyTJ4WriizFo0CBZLBZz+fbbb5ck7d+//5LGHT16tDw9Pc3lhx9+WIGBgVq7dq35rO8/q4z5GoahQ4cOOdzivEmTJlqzZo3S0tIuai7Lly+Xl5eXnnjiCbm7u5vrW7durQceeEAFBQX6+OOPHfbp1KmTvLy8zjn2Rx99pFOnTunRRx9Vo0aNzPXNmjXThAkTFBcXp5MnT6pJkyaaPn26RowY4bC/u7u7brnlFklSfn5+he/13nvvqU6dOho1apTD+htvvFF33323vv32W/33v/815+zt7a2RI0c6fD+GDRumunXrOuxfelv4p556St7e3ub6oKAgDR06VKdOnTrrLgbt27d3mG9Z1q9fr99//139+/dXaGioub5BgwaaOHGiBg4cqKKiItWqVUvPP/+8nnjiCdWoUcNhjPDwcEnnPjbn67333pNhGBo/frzD51u/fn0NGjRIx48fNx+tUBmf2cX4y1/+Ije3/z/dc+DAAX355Ze6/fbb1blzZ4dtH3roIfn7+5ufYUlJiQzDUG5urn777TdzuxtvvFGffvqpXnzxxUrPFwAAAACqI/dzbwIAAAAAuBT16tXTb7/9poKCAofm87l89913cnNzMxt6Zypdd+bz4y+Uh4eH/P39HdbVrl1bksptpJ8Pi8WiW2+91WFdjRo11Lp1a3388cfat2+fWrZsedZ+lTHfv/3tb5ozZ475zPVOnTrp9ttv14033nhRczl27Jiys7PVvn1789j8Oa8FCxaclVfTpk3Pa/zS/dq1a3dWrF+/fubfTZo0UWxsrE6dOqWdO3cqKytL+/bt0+7du7Vx40ZJfzRYy1NYWKisrCw1atRIr7766lnxgwcPSpJ2796t4OBg/fDDD2rdurV8fX0dtvPx8XF4fnrpHPz8/Mq8pX95n9v5HJ+Kjk337t0dlnv27KmSkhL98MMP2rNnj7Kzs/X999+f17G5EDt37pQkffzxx1q3bp1DLC8vT5LM58df6md2sf58bHft2iXDMHTkyBG9/PLLZ21fs2ZN5ebm6tdff5Wfn5+6d++uf/3rX+rSpYtuvvlmderUSV26dCnz/1kAAAAAwMWhSX8RSkpK9Msvv8jX19fhigIAAICrmWEY+v333xUQEOBwhR5cj/q06gsICNBvv/2mXbt2qW3btuVud+zYMRUXF+uaa66R9McV+LVq1VJxcXGZz9T29PRUYWGhCgoKdOzYMUnSqVOnzCv3S9ntdklSUVGRGSspKVHNmjXP2vb48ePmPqWxsvYvz6lTp1SvXr0yc65Tp46kP5qZjRs31qlTpyRJv//++wXPt/S9ztxfkgYOHCg/Pz8tW7ZM33zzjXbs2KGXX37ZvDK99MrqivI/c8wDBw5Ikry8vMqce+ndEQoKClRQUGAeP8MwznmsJOnQoUPnvf3777+vefPmmVc4+/r6qk2bNgoJCdF//vOfCo9N6Tx+++03paSklPsev/76q3kXgvr165eZU/369c05l75HeduWXm1+7NgxFRQUmM8+t1gs5/yelv5woKxt/+zzzz/XK6+8on379kmSvL29dd1116lly5bavHnzWd/d06dPn3PM0h+qlOYuSUePHpUkzZkzp9z9Dh48aG5/KZ9ZeTmc6cx5lB6/kpISh21//fVXSdLXX3+tr7/+uty89+/fLy8vL02aNEktW7bUhx9+qM2bN2vz5s164YUXdP311+uJJ55Qq1atyh0DcDbq06qNGhUAAFRH51ujWgzDMJyY11UhJyenzCsEAAAAqoPs7OzzvkIUzkF9WvU1aNBA11xzjQ4ePGg2ZctSv359NWrUSPn5+crPz1dwcLA8PT31448/nnXFrcViUcuWLVVcXKzs7Gy5u7urefPmOnbsmH755ReHba+55ho1aNBA+/fvV2FhoSQpNDRUbm5u2rNnj8O2Xl5eCgoK0uHDh83GYsOGDdWwYUOH/cvTtGlTeXh4nDWu9MeVxXXq1FFWVpZOnjyppk2bytvb25zfhcy39L3O3P/PatSoIW9vb9WuXVu1a9eWYRj66aefKrx6+c9jurm5me9b2gA+k7e3t5o2bWp+ZnXq1FGTJk104MABHTlypMJjJf3xA47atWvrp59+Mpu0Z8659J/stWvXVkBAgOx2uw4ePCi73W5u37hxY9WrV0/Z2dnmjwTKm0dRUZFycnIqzOlc25bm/MMPP0iSWrRoIUllfuY1a9ZUaGioCgoKlJeXV+b3q9Sfv2eNGjVS/fr1HeZV1rHx9PRUUFCQTp06pYMHD6q4uFgnT56U9P//T+Xl5ZmN67CwsHI/zzP5+fmpbt262rt3r9kADw4OloeHh/lYgIpc6mdWXg6l87/22msd5lHe/6c+Pj4KDAw0v6MXwt3dXd7e3vL19ZWPj49OnjyprKysCxoDcAbq06qJGhUAAFRn56pRuZL+IpTe7i87O9u8EgQAAOBqV1BQoKCgoLNufQzXoz6t+nJyctS3b1+1bNlSy5cvL/O26cXFxXrwwQe1b98+vffee2rfvr2mTp2qDz/8UCtXrtRtt93msP2mTZs0bNgw9evXT5MmTdLBgwd1zz33qHPnzmfdznz8+PH64osvlJaWZj6T+t5779Xvv/9uXhlcauvWrRoyZIiGDh1qPgd+7ty5mjNnjsP+5Rk8eLC2bdumHTt2KCQkxCHWq1cvFRYW6tdff1WNGjXMbfft2ydfX98Lmq8kDRkyRFu3bjX3P3LkiN555x0FBAQoJibGYf+nn35aK1eu1Jo1a2S1Ws+Zf+mYknTfffcpPz9fP//8s3kVealXX31VCxYs0CuvvKJ77rlHH374oaZOnapp06bpgQceqPBYSdJrr72m+fPn66233tJf/vIXh9gzzzyjNWvW6J133tGsWbO0bt06LV++3GyK/znnVatWmY8Z+POxkf64Jfzx48e1detWeXp6Oozxr3/9S/v371dMTIwCAgIUFxen/Px8bd++XbVq1TK3O336tHr06KH8/HzzuzN06FB99dVX2rp161m3RF+xYoWeffZZTZgwQY888kiZ369Sc+bM0dy5c83v2cqVK/X000/r+eefV//+/R22XbBggebMmaNXXnlF69ev19KlS5WSkqLo6GiH7Z566in961//0iuvvKJ7771X0h/Pqb/xxhv17bffVvjZlO7773//27x6vHTdxo0b1bp1a4ftv/32W61bt07R0dG6+eabNW7cuEv+zJ577jktX75ca9eu1c0332zu/+OPP+r+++93mMefj1+p/fv3q1evXurZs6eSk5PPmmdqaqo8PDz04IMP6sCBA1qxYoXatm171v+DpZ/zN998o2bNmlV47ABnoT6t2qhRAQBAdXS+NSpN+otQenumOnXqUGACAIBqh1tVVj3Up1XfDTfcIJvNprlz52rUqFF6+eWX1bhxYzP++++/a8qUKdq3b5+6dOliNtj+9re/6cMPP9Rrr72mqKgo83n2hw4d0iuvvCJJ+utf/6o6derIx8dHdevW1a5du3Ty5Ek1bNhQ0h/Po96wYYOkP676Lv2OuLm5yWKxnPWd8fb2liTVqlXLjJXe0t3d3f2c3zF39z/+mfnqq68qOTnZbPAuWLBA+/fv1yOPPGI2uku39fX1VZ06dS5ovpLMRrOnp6fq1KkjT09Pvf322/Ly8lL37t1Vr149M6/Sq7ZbtmxZ4Rz+nJMkxcXF6eWXX9bLL7+s6dOnm9vs3LlT77zzjurUqaMePXqodu3a5u3dS3M6l7i4OL3++ut68803dccdd5jHZt++ffrss88UFBSk66+/3vwMiouLHcZdsWKFtm3bJsnxM/vzsSl9r1deeUVz5szRP/7xD/O2ez/++KNmzpwp6Y9Gce3atdWnTx8lJSXpzTffdGimz54927wau3Tcv/71r/rqq6+UnJysV1991fwOZWdna8GCBapZs6Z69+6tOnXqlPn9KuXh4SHp/7+nMTExevHFF/X2228rNjZWgYGBkqQjR45oxYoVql27tjp27GjOv6ioyGHMjIwMffzxx5L+uKL/zFiNGjXO+fmUfndr165tbtu3b1/961//UnJysubNm2f+4ObYsWOaOXOmdu/erbvuusv8f/JSP7PrrrtOkrR582bdfvvtkv64ffSiRYvOmsefj1+pOnXqKDw8XBs3btTGjRt19913O+Qyb948RUREaPjw4SopKdHChQvVqlUr/eUvfzGPwYkTJ3T48GHVqlVLoaGhZf7QCHAl6tOqiRoVAABUZ+eqUWnSAwAAAIATjBo1Svn5+Xr//fd15513qnPnzgoODtavv/6qDRs26NChQ2rfvr2ef/55c5/w8HANGDBAr7/+uu6991516dJFkvTFF1/ot99+06BBg8xnrNeoUUNxcXFasGCB/vrXv6pbt246dOiQPvroI7Vt21ZfffXVRefu5+cn6Y/G++7duzVs2DCzIVieLVu2KC4uTlFRUdqzZ4/S09N17bXX6rHHHit3nwuZ75l5/eMf/1DHjh3Vv39/DR8+XM8884xiYmL0l7/8RZ6entqyZYu+/fZb3XfffWrevPkFz3/QoEFKT0/Xhx9+qO+//15Wq1X5+fn69NNPZRiGXnrppYtuWrZo0ULDhg3T//zP/+i+++5Tly5dZBiGVq9eLbvdrunTp0v6484H//rXvzRs2DDzBwHffvutNm/erIYNGyo/P9/h9vplHZu///3vSk9P16JFi7R161ZFRESooKBAH330kY4fP64XXnjBnIfNZtNHH32kOXPmaOvWrWrbtq127dqlr776SnXq1NGxY8fM97rvvvv0+eefa+3atbr33nvVqVMnFRUV6bPPPtOxY8c0adIkBQcHX/CxqVevniZPnqyJEycqNjZWd955p3x8fPTRRx/pt99+U0pKimrVqqXu3bvr9ddf15QpU7RlyxY1atRI33//vdLT01W/fv2zjs2lsFqtio+P16JFi9SjRw/dfvvtqlWrlj799FPl5uaqX79+ioyMlFQ5n1lMTIySk5M1f/5881aJGzZsMJ9veL6mTp2qBx98UCNGjFCnTp107bXXKisrS+vWrVO9evX05JNPSpIaNWqkhx9+WK+//rpiYmJ0++23y83NTf/+97+1Z88ePfroozToAQAAAKASlP+0egAAAABApalRo4amTZum+fPn6/bbb9d3332nRYsW6fPPP1dISIimTJmixYsXn3WlWWJiombOnKnAwEB9+OGHWrNmjUJDQ/Xyyy9r7NixDtuOHj3abIIvWrRIO3fu1D//+U8NGDDgknLv3r277rnnHmVnZystLU379+8/5z7z5s1T48aN9fbbb+u///2v+vfvr7S0tHM2+C5kvkOGDNFNN92kDRs2aMmSJZKk+Ph4vfTSS2ratKlWr16tJUuW6MSJE5o4caKee+65i5q/h4eH3njjDQ0fPlwnT57U0qVLlZmZqS5duujtt9/WXXfddVHjlnrsscf00ksvyd/fXx988IE+/PBDtW3bVosXL1bbtm0lSZ07d9ZLL72k4OBgffjhh1q+fLnsdrsmT56sefPmSZLWr19f4bHx9PTUwoUL9fjjj8tutystLU3r169X+/bttXDhQodHBJTO+YEHHtC+ffu0ePFiHTt2THPmzFFISIjD7fItFotmzZqlSZMmycfHR++9956++OILtWvXTq+//roefPDBiz42sbGxWrBgga6//nqtXbtW77zzjpo2bao5c+aYjwe4/vrrNWfOHLVu3Vqffvqp3nnnHR08eFDDhw/XBx98IDc3N4djc6kmTZqk559/Xv7+/lq5cqWWL1+ua665Rs8995zZ7JYq5zO75pprtHDhQkVFRenLL7/Uu+++qxYtWigtLe2Crkpt3ry53n//ffXt21fff/+9Fi5cqO+//1733Xef3nvvPYfHFIwbN05PPfWUateureXLl+udd96Rj4+Ppk+frhEjRlzq4QMAAAAASLIYhmG4OokrTUFBgerWraujR49yqyYAAFBtUANVXXw2qEri4+O1efNmbdmyhe/jFSwnJ0cNGjQwb09/pi5dusjLy0urV692QWYA8P+ogao2Ph8AAFAdnW8NxO3uAQAAynH69GmdPHnS1Wk4Rc2aNVWjRg1XpwEAqCKefvppffnll/r4448VFBRkrl+9erV++eUXPfDAAy7MDqi+qE8BAABQlVSn+lSq3BqVJj0AAMCfGIah3NxcHTlyRNXlnkMWyx/P/vX395fFYnF1OgAAF/vb3/6m9evXq0+fPuratavq1aunPXv2aN26dWrSpImGDRvm6hSBaoX6lPoUAACgKqmO9alUuTUqTXoAAIA/yc3N1eHDR+TrW08eHh6SrvaTgobsdrsOHz4iSQoICHBtOgAAl7vjjjv0xhtvaMGCBfriiy909OhRNWrUSPfff78effRRNWzY0NUpAtUK9Sn1KQAAQFVS/epTqbJrVJr0AAAAZzh9+rSOHPmjwPT1revqdJymVi1PSdKRI0fk5+fHrUUBXLRFixa5OgVUEqvVKqvV6uo0gGqP+pT6FAAAoCqprvWpVLk1qltlJQUAAHA1OHnypAxD//cL0OrFw8NDhqFq9RwpAACAqo76lPoUAACgKqnO9alUeTUqTXoAAIAyVYdbNP1ZdZwzAADAlaI61mrVcc4AAABXiupaq1XOvGnSAwAAAAAAAAAAAADgJDTpAQAAAAAAAAAAAABwEpr0AAAAAAAAAAAAAAA4CU16AAAAAAAAAAAAAACchCY9AAAAAAAAAAAAAABOQpMeAADAhV5++SXdfnuUjh373WH9ggXzdOednVRcfNxFmQEAAKC6okYFAABAVXI11qc06QEAAFyoZ89estvt+vzzzxzWr1mzSnfd9Rd5enq5KDMAAABUV9SoAAAAqEquxvqUJj0AAIALhYSE6sYb22rNmlXmum++2aHs7H2KibnXhZlVX3a7XY899pjq168vPz8//eMf/5BhGJKk7du3KzIyUt7e3goPD9fWrVsd9l26dKlatGghb29vxcbG6uDBg2bMMAwlJiaqUaNGatCggcaPH6+SkhIznp+fr7i4OPn6+io0NFSLFy92zoQBAAD+hBoVAAAAVcnVWJ/SpK9EJSVGlRwLAABUbT179tLXX29Xbu4vkqR//WulmjUL0Y033uTizKqnESNG6JNPPtHatWuVlpamuXPnas6cOSosLFT37t112223aevWrerQoYN69OihwsJCSdLmzZuVkJCgJ598UpmZmTp8+LBsNps5blJSktLS0rR8+XItW7ZMS5YsUVJSkhm32Ww6evSoMjIyNGnSJA0cOFCbN2929vRxBbpS/+1wpeYNANUFNSoAVB3UzheOYwZcfa62+tTd1QlcTdzcLHpl6QbtP3D0ksYJbFxXj93fsZKyAgAAVd1dd3XVrFkvaM2a1XrwwXh99tkn6t9/gKvTqpYOHTqk+fPn69NPP1VERIQkacyYMdq0aZNq1qwpLy8vzZw5UxaLRbNmzdLq1av17rvvymazKSUlRX379lX//v0lSYsWLVKzZs2UlZWl0NBQJScna+rUqYqOjpYkzZgxQ5MmTdLYsWO1Z88erVq1SllZWQoJCVGbNm2UkZGh2bNnm3kA5amsf4c4E//mAYCqjxoVAKqOK7HmdyX+vQFcna62+pQmfSXbf+Coft5/2NVpAACAK4i3t7fuuOMuffbZx2rZsqWOHz+ue+6JcXVa1VJ6errq1q2r22+/3VyXmJgoSfr73/+u6OhoWSwWSZLFYlHHjh2VkZEhm82mzMxMc1tJCgoKUnBwsDIzM+Xh4aHs7Gx16tTJjEdHR2vv3r3Kzc3Vpk2bFBQUpJCQEIf4tGnTLvOMcbXg3yEAgMpGjQoAVQs1P4Dq7mqrT7ndPQAAQBXQs2cv7dnzo5YuXaLw8Eg1atTI1SlVSz/99JNCQkK0cOFCXXfddWrevLmefvpplZSUKDc3VwEBAQ7b+/n5KScnR5IqjOfm5kqSQ9zPz0+SzHhFY/+Z3W5XQUGBwwsAAKCyUaMCAACgKrma6lOupAcAAKgCbrqpnZo1C9H27Vv1zDPTXZ1OtXXs2DH997//VWpqql5//XXl5uZq8ODB8vb2VlFRkTw8PBy29/DwkN1ul6QK40VFRebymTFJZryisf9s2rRpmjJlyqVNFgAA4ByoUQEAAFCVXE31KU16AACAKqJDh2gdPnxInTp1dnUq1Za7u7sKCgqUlpamZs2aSZL27dun2bNn69prrz2raW632+Xt7S1J8vT0LDfu6elpLp/5tyQzXtHYfzZx4kSNHj3aXC4oKFBQUNDFThsAAKBc1KgAAACoSq6W+pTb3QMAAFQBhmEoI2ODunePUa1atVydTrXl7+8vT09Ps0EvSa1atVJ2drYCAwOVl5fnsH1eXp78/f0lqcJ4YGCguXxmrPQ9zzX2n3l4eKhOnToOLwAAgMpGjVo1ZGdnKyYmRnXq1FFISIhmzZplxrZv367IyEh5e3srPDxcW7duddh36dKlatGihby9vRUbG6uDBw+aMcMwlJiYqEaNGqlBgwYaP368SkpKzHh+fr7i4uLk6+ur0NBQLV68+LLPFQAAoCJXU31Kkx4AAMCFCgsLNW9eqsaOHaFfftmvvn3vd3VK1ZrValVxcbF++OEHc93u3bsVEhIiq9WqjRs3yjAMSX/8o2DDhg2yWq3mvunp6eZ+2dnZys7OltVqVUBAgIKDgx3i6enpCg4Olr+/v6xWq/bu3evwDPr09HRzbAAAAGeiRq1a+vbtq9q1a2vr1q1KTk7WE088oeXLl6uwsFDdu3fXbbfdpq1bt6pDhw7q0aOHCgsLJUmbN29WQkKCnnzySWVmZurw4cOy2WzmuElJSUpLS9Py5cu1bNkyLVmyRElJSWbcZrPp6NGjysjI0KRJkzRw4EBt3rzZ2dMHAAC4KutTbncPAADgQh4eHlqxYplOny7RE088qYCAQFenVK21atVKPXr0kM1m06uvvqq8vDxNnz5dkyZNUp8+fZSYmKiRI0dq8ODBSk1NVWFhofr27StJGjp0qDp37qyoqCiFh4drxIgRiomJUWhoqBmfMGGCmjZtKklKTEzUmDFjJEnNmzdXt27dFB8fr+TkZG3ZskVpaWlav369aw4EAACo1qhRq47Dhw8rMzNTc+fO1bXXXqtrr71Wd999tz777DMdPnxYXl5emjlzpiwWi2bNmqXVq1fr3Xfflc1mU0pKivr27av+/ftLkhYtWqRmzZopKytLoaGhSk5O1tSpUxUdHS1JmjFjhiZNmqSxY8dqz549WrVqlbKyshQSEqI2bdooIyNDs2fPVkREhCsPCQAAqIauxvqUJj0AAIALubu7a9Wqj12dBs6wZMkSPf7444qOjpa3t7eGDRumxx9/XBaLRatWrdKQIUM0Z84ctW3bVqtXr5aPj48kKSoqSqmpqZo8ebIOHTqkrl27au7cuea448aN04EDBxQbGyt3d3clJCRo1KhRZnzhwoUaOHCgIiMj5e/vrwULFnACFAAAuAQ1atXh5eUlb29vvf7665o+fbp++uknbdiwQc8++6wyMzMVHR0ti8UiSbJYLOrYsaMyMjJks9mUmZmpxMREc6ygoCAFBwcrMzNTHh4eys7OVqdOncx4dHS09u7dq9zcXG3atElBQUEKCQlxiE+bNs1pcwcAACh1NdanNOkBAACAM9StW1cLFy4sMxYREaFt27aVu6/NZnO4heiZatSooaSkJIdbiJ6pcePGWrly5QXnCwAAgKuXp6enXnnlFQ0bNkzJyck6ffq0bDabEhIStGLFCrVu3dphez8/P/3nP/+RJOXm5iogIOCseE5OjnJzcyXJIe7n5ydJZry8fctjt9tlt9vN5YKCgouYMQAAQPXAM+kBAAAAAAAAoIravXu3evbsqczMTL3++ut67733tGTJEhUVFcnDw8NhWw8PD7NRXlG8qKjIXD4zJsmMVzR2WaZNm6a6deuar6CgoIufNAAAwFWOK+kBAAAAAAAAoAr67LPPNG/ePOXk5MjLy0u33nqr9u/fr2eeeUbNmzc/q2lut9vl7e0t6Y+r8MuLe3p6mstn/i3JjFc0dlkmTpyo0aNHm8sFBQU06gEAAMrBlfQAAAAAAAAAUAVt3bpV1157rby8vMx1N998s/bu3avAwEDl5eU5bJ+Xlyd/f39JqjAeGBhoLp8Zk2TGKxq7LB4eHqpTp47DCwAAAGWjSQ8AAAAAAAAAVVBAQIB+/PFHnThxwlz33XffKTQ0VFarVRs3bpRhGJIkwzC0YcMGWa1WSZLValV6erq5X3Z2trKzs2W1WhUQEKDg4GCHeHp6uoKDg+Xv7y+r1aq9e/c6PIM+PT3dHBsAAACXhtvdAwAAnCeLxSI3N4vT37ekxDBPvAEAAAClXFWfStSoztKzZ0+NGzdOAwcO1KRJk/T999/rueee07PPPqs+ffooMTFRI0eO1ODBg5WamqrCwkL17dtXkjR06FB17txZUVFRCg8P14gRIxQTE6PQ0FAzPmHCBDVt2lSSlJiYqDFjxkiSmjdvrm7duik+Pl7JycnasmWL0tLStH79etccCAAAcMXgHOr5oUkPAABwHiwWi3x9PVWjhvNvRHT6dIl+/734govMkpISzZ+fqpUrV+j333/XzTffonHjEhUQEHiZMgUAAICzuLI+lS6uRqU+vXB169bVZ599phEjRig8PFyNGjXSpEmT9Pe//10Wi0WrVq3SkCFDNGfOHLVt21arV6+Wj4+PJCkqKkqpqamaPHmyDh06pK5du2ru3Lnm2OPGjdOBAwcUGxsrd3d3JSQkaNSoUWZ84cKFGjhwoCIjI+Xv768FCxYoIiLC6ccAAABcOTiHev5o0gMAAJwHNzeLatRw0ytLN2j/gaNOe9/AxnX12P0d5eZm0enTF1ZgLlgwV8uWvat//nOKGjf2U0rKLI0Y8ZjS0t5VzZo1L1PGAAAAcAZX1afSxdeo1KcX54YbbtAnn3xSZiwiIkLbtm0rd1+bzSabzVZmrEaNGkpKSlJSUlKZ8caNG2vlypUXnC8AAKi+OId6/mjSAwAAXID9B47q5/2HXZ3GOZ08eVJpaYv12GPD1bHjbZKkZ56ZoZiYbvrii8/UtevdLs4QAAAAlYH6FAAAAFUNNeq5ueZ+WAAAALisfvjhexUVFSo8/P9vR+nr66tWra7T9u3lX2kDAAAAXA7UpwAAAKhqXFmj0qQHAAC4Ch048KskqXFjP4f1jRo10oEDea5ICQAAANUY9SkAAACqGlfWqDTpAQAArkLFxcWSpFq1ajmsr1Wrluz2E65ICQAAANUY9SkAAACqGlfWqDTpAQAArkIeHp6SpBMnHIvJEydOyMvLyxUpAQAAoBqjPgUAAEBV48oalSY9AADAVcjP749bNB08+JvD+t9++02NGjV2RUoAAACoxqhPAQAAUNW4skalSQ8AAHAVuvbaMPn41Na2bVvNdb///ru+//473XxzexdmBgAAgOqI+hQAAABVjStrVPfLOjoAAABcolatWurTp69eeeV/VK9effn7+yslZZb8/PzUpcsdrk4PAAAA1Qz1KQAAAKoaV9aoNOkBAAAuQGDjulfM+/3970N1+vRpTZs2VXa7Xe3atdesWa/I3b1mJWYIAAAAV3J2fXop70l9CgAAUD1wDvXcaNIDAACch5ISQ6dPl+ix+zs6/b1Pny5RSYlxwfvVqFFDw4aN0LBhIy5DVgAAAHAlV9an0sXVqNSnAAAAVzfOoZ4/mvQAAADnwTAM/f57sdzcLE5/75ISQ4Zx4QUmAAAArl6urE8lalQAAACcjXOo548mPQAAwHkyDEOnT185hR4AAACubtSnAAAAqGqoUc+PmyvffP/+/erTp48aNGigwMBAjR49WsXFxZKkESNGyGKxOLxSUlLMfZcuXaoWLVrI29tbsbGxOnjwoBkzDEOJiYlq1KiRGjRooPHjx6ukpMSM5+fnKy4uTr6+vgoNDdXixYudN2kAAAAAAAAAAAAAQLXlsivpDcNQnz59VL9+ff373//WoUOH9Mgjj6hGjRqaOXOmdu3apWnTpslms5n71KlTR5K0efNmJSQk6LXXXlO7du00fPhw2Ww2rVq1SpKUlJSktLQ0LV++XCdPntRDDz2kxo0ba+zYsZIkm82m48ePKyMjQ5s2bdLAgQMVFhamiIgIpx8HAAAAAAAAAAAAAED14bIm/ffff6/MzEzl5eXJz89PkjR16lSNHTtWM2fO1O7duzVu3Dg1adLkrH1TUlLUt29f9e/fX5K0aNEiNWvWTFlZWQoNDVVycrKmTp2q6OhoSdKMGTM0adIkjR07Vnv27NGqVauUlZWlkJAQtWnTRhkZGZo9ezZNegAAAAAAAAAAAADAZeWy2903adJEH330kdmgL3X06FEVFBRo//79CgsLK3PfzMxMderUyVwOCgpScHCwMjMz9csvvyg7O9shHh0drb179yo3N1ebNm1SUFCQQkJCHOIZGRmVO0EAAAAAAAAAAAAAAP7EZU36evXqqVu3buZySUmJUlJSdOedd2r37t2yWCx69tln1bRpU91000168803zW1zc3MVEBDgMJ6fn59ycnKUm5srSQ7x0h8ClMbL27c8drtdBQUFDi8AAAAAAAAAAAAAAC6Uy5r0fzZ+/Hht27ZNzz77rL777jtZLBZdd911Wr16tQYOHKi///3vWr58uSSpqKhIHh4eDvt7eHjIbrerqKjIXD4zJsmMl7dveaZNm6a6deuar6CgoEqZMwAAAAAAAAAAAACgenHZM+nPNGHCBM2aNUtvv/222rRpo9atW6tnz55q0KCBJKlt27b64Ycf9Oqrryo2Nlaenp5nNdXtdru8vb3l6elpLp/5tyQzXt6+5Zk4caJGjx5tLhcUFNCoBwAAAAAAAAAAAABcMJc36R9//HG9+uqrWrx4seLi4iRJFovFbNCXuv766/X5559LkgIDA5WXl+cQz8vLk7+/vwIDA83l0ufOl25bGi9v3/J4eHicdfU9AACofiwWi9zcLE5/35ISQ4ZhOP19AQAAULW5qj6VqFEBAABQNs6hnh+XNumnTJmi1157TW+99Zb69Oljrp88ebI2btyoTz/91Fz39ddf67rrrpMkWa1Wpaeny2azSZKys7OVnZ0tq9WqgIAABQcHKz093WzSp6enKzg4WP7+/rJardq7d69ycnLUtGlTM261Wp0zaQAAcEWyWCyqU8dDbm41nP7eJSWnVVBgv6Qi8803FygzM0Ovvjq3EjMDAACAq7iyPpWoUQEAAHA2zqGeP5c16Xfv3q2nn35aEydOVHR0tMPV7T179tS0adP0wgsvKDY2Vh9//LEWLlyoL774QpI0dOhQde7cWVFRUQoPD9eIESMUExOj0NBQMz5hwgSzCZ+YmKgxY8ZIkpo3b65u3bopPj5eycnJ2rJli9LS0rR+/XonHwFUtpISo9J+mVOZYwEArg5ubha5udVQ1qq5Op6f67T39Wror9CYQXJzs+j06YsrMN977x2lps7WTTfdXMnZAQAAwFVcVZ9K1KgAAAAoG+dQz5/LmvQffPCBTp8+rWeeeUbPPPOMQ8wwDL333nuaPHmy/vnPfyokJERpaWmKioqSJEVFRSk1NVWTJ0/WoUOH1LVrV82d+/+/aBg3bpwOHDig2NhYubu7KyEhQaNGjTLjCxcu1MCBAxUZGSl/f38tWLBAERERzpk4Lhs3N4teWbpB+w8cvaRxAhvX1WP3d6ykrAAAV5vj+bk6/us+V6dxXn777TdNn/6Mtm37SkFBwa5OBwAAAJfBlVSfStSoAAAA1cGVVKO6qj51WZM+MTFRiYmJ5cbvu+8+3XfffeXGbTabebv7P6tRo4aSkpKUlJRUZrxx48ZauXLlBeWLK8P+A0f18/7Drk4DAIAq4bvvdqlmzZpavPhtzZ8/V7m5v7g6JQAAAFRz1KgAAACoSlxVn7r0mfQAAAC4fG677Xbddtvtrk4DAAAAMFGjAgAAoCpxVX3q5vR3BAAAAAAAAAAAAACgmqJJDwAAAAAAAAAAAACAk9CkBwAAAAAAAAAAAADASWjSAwAAAAAAAAAAAADgJDTpAQAAAAAAAAAAAABwEndXJwAAAHAl8Wrof1W/HwAAAK4srqgXqVEBAABQEc6hnhtNegAAgPNQUmKopOS0QmMGueC9T6ukxLikMSZPnlJJ2QAAAKAqcGV9+sf7U6MCAADAEedQzx9NegAAgPNgGIYKCuxyc7M4/b1LSgwZxqUVmAAAALi6uLI+lahRAQAAcDbOoZ4/mvQAAADnyTAMnT595RR6AAAAuLpRnwIAAKCqoUY9P26uTgAAAAAAAAAAAAAAgOqCJj0AAAAAAAAAAAAAAE5Ckx4AAAAAAAAAAAAAACehSQ8AAFCm6vjcpOo4ZwAAgCtFdazVquOcHb3xxhuyWCxnvdzc/jitu337dkVGRsrb21vh4eHaunWrw/5Lly5VixYt5O3trdjYWB08eNCMGYahxMRENWrUSA0aNND48eNVUlJixvPz8xUXFydfX1+FhoZq8eLFzpk0AAC4QlTXWq1y5k2THgAA4Aw1a9aUxSLZ7XZXp+J0drtdFssfxwAAAABVA/Vp9a5P//a3vyk3N9d87du3Ty1bttSIESNUWFio7t2767bbbtPWrVvVoUMH9ejRQ4WFhZKkzZs3KyEhQU8++aQyMzN1+PBh2Ww2c+ykpCSlpaVp+fLlWrZsmZYsWaKkpCQzbrPZdPToUWVkZGjSpEkaOHCgNm/e7OxDAAAAqpjqXJ9KlVejuldSPgAAAFeFGjVqqF69ejp8+IgkycPDQ5LFpTldfobsdrt+//2I6tevpxo1arg6IQAAAPwf6tPqXZ96eXnJy8vLXJ42bZoMw9D06dO1ZMkSeXl5aebMmbJYLJo1a5ZWr16td999VzabTSkpKerbt6/69+8vSVq0aJGaNWumrKwshYaGKjk5WVOnTlV0dLQkacaMGZo0aZLGjh2rPXv2aNWqVcrKylJISIjatGmjjIwMzZ49WxERES45FgAAoGqonvWpVNk1Kk16AACAP/H395ckHTlyRL//7uJknMRikerXr2fOHQAAAFUH9Skk6dChQ5oxY4bmzZsnDw8PZWZmKjo6WhbLHyfFLRaLOnbsqIyMDNlsNmVmZioxMdHcPygoSMHBwcrMzJSHh4eys7PVqVMnMx4dHa29e/cqNzdXmzZtUlBQkEJCQhzi06ZNc9p8AQBA1VUd61OpcmtUmvQAAAB/YrFYFBAQID8/P508edLV6ThFzZo1q/UVSgAAAFUZ9Skk6dVXX1VAQID69OkjScrNzVXr1q0dtvHz89N//vMfMx4QEHBWPCcnR7m5uZLkEPfz85MkM17evuWx2+0Ot70tKCi40CkCAIArRHWsT6XKrVFp0gMAAJSjRo0anBgEAABAlUF9Wn0ZhqF58+Zp/Pjx5rqioqL/u73s//Pw8DAb5RXFi4qKzOUzY5LMeEVjl2XatGmaMmXKRcwOAABcqahPL56bqxMAAAAAAAAAAJTvq6++Uk5Ojvr162eu8/T0PKtpbrfb5e3tfc64p6enuXxmTJIZr2jsskycOFFHjx41X9nZ2RcxUwAAgOqBK+kBAAAAAAAAoAr76KOP1KlTJ9WvX99cFxgYqLy8PIft8vLyzGekVhQPDAw0l0ufO1+6bWm8orHL4uHhcdbV9wAAACgbV9IDAAAAAAAAQBW2adMmdezY0WGd1WrVxo0bZRiGpD9uib9hwwZZrVYznp6ebm6fnZ2t7OxsWa1WBQQEKDg42CGenp6u4OBg+fv7y2q1au/evQ7PoE9PTzfHBgAAwKWhSQ8AAAAAAAAAVdh//vMf3XDDDQ7r+vTpoyNHjmjkyJHatWuXRo4cqcLCQvXt21eSNHToUC1atEjz58/XN998o/79+ysmJkahoaFmfMKECVq3bp3WrVunxMREjRgxQpLUvHlzdevWTfHx8frmm280f/58paWl6bHHHnPuxAEAAK5S3O4eAAAAAAAAAKqwX3/91eFW95JUp04drVq1SkOGDNGcOXPUtm1brV69Wj4+PpKkqKgopaamavLkyTp06JC6du2quXPnmvuPGzdOBw4cUGxsrNzd3ZWQkKBRo0aZ8YULF2rgwIGKjIyUv7+/FixYoIiICOdMGAAA4CrHlfQAAADAGZYvXy6LxeLw6tOnjyRp+/btioyMlLe3t8LDw7V161aHfZcuXaoWLVrI29tbsbGxOnjwoBkzDEOJiYlq1KiRGjRooPHjx6ukpMSM5+fnKy4uTr6+vgoNDdXixYudM2EAAABUecePH1e3bt3OWh8REaFt27bp+PHj2rRpk26++WaHuM1m0759+3Ts2DG9//77atiwoRmrUaOGkpKSdPjwYf3222+aPn26LBaLGW/cuLFWrlyp48eP66efftL9999/+SYIAABQzdCkBwAAAM6wa9cu9ezZU7m5ueZr3rx5KiwsVPfu3XXbbbdp69at6tChg3r06KHCwkJJ0ubNm5WQkKAnn3xSmZmZOnz4sGw2mzluUlKS0tLStHz5ci1btkxLlixRUlKSGbfZbDp69KgyMjI0adIkDRw4UJs3b3b29AEAAAAAAABcZtzuHgAAADjD7t271aZNGzVp0sRh/YIFC+Tl5aWZM2fKYrFo1qxZWr16td59913ZbDalpKSob9++6t+/vyRp0aJFatasmbKyshQaGqrk5GRNnTpV0dHRkqQZM2Zo0qRJGjt2rPbs2aNVq1YpKytLISEhatOmjTIyMjR79mxuKQoAAAAAAABcZbiSHgAAADjDrl27FBYWdtb6zMxMRUdHm7cAtVgs6tixozIyMsx4p06dzO2DgoIUHByszMxM/fLLL8rOznaIR0dHa+/evcrNzdWmTZsUFBSkkJAQh3jp2AAAAAAAAACuHjTpAQAAgP9jGIa+//57rV27VmFhYWrRooUSExN14sQJ5ebmKiAgwGF7Pz8/5eTkSFKF8dzcXElyiPv5+UmSGa9o7D+z2+0qKChweAEAAAAAAAC4MnC7ewAAAOD/7Nu3T0VFRfLw8NA777yjrKwsDR8+XMePHzfXn8nDw0N2u12SKowXFRWZy2fGJJnxisb+s2nTpmnKlCmXNlkAAAAAAAAALkGTHgAAAPg/zZo1U35+vurXry+LxaJ27dqppKREDz30kDp37nxW09xut8vb21uS5OnpWW7c09PTXD7zb0lmvKKx/2zixIkaPXq0uVxQUKCgoKBLmDkAAAAAAAAAZ6FJDwAAAJyhQYMGDsvXX3+9iouL1aRJE+Xl5TnE8vLy5O/vL0kKDAwsNx4YGGgulz53vnTb0nhFY/+Zh4fHWVfeAwAAAAAAALgy8Ex6AAAA4P+sXbtWDRs2NG9PL0lff/21GjZsqNtuu00bN26UYRiS/nh+/YYNG2S1WiVJVqtV6enp5n7Z2dnKzs6W1WpVQECAgoODHeLp6ekKDg6Wv7+/rFar9u7d6/AM+vT0dHNsAAAAAAAAAFcPmvQAAADA/+nQoYO8vLw0cOBAff/991qzZo3GjRun8ePHq0+fPjpy5IhGjhypXbt2aeTIkSosLFTfvn0lSUOHDtWiRYs0f/58ffPNN+rfv79iYmIUGhpqxidMmKB169Zp3bp1SkxM1IgRIyRJzZs3V7du3RQfH69vvvlG8+fPV1pamh577DGXHQsAAAAAAAAAlwe3uwcAAAD+j6+vr9auXauRI0fq1ltvla+vrwYPHqxx48bJYrFo1apVGjJkiObMmaO2bdtq9erV8vHxkSRFRUUpNTVVkydP1qFDh9S1a1fNnTvXHHvcuHE6cOCAYmNj5e7uroSEBI0aNcqML1y4UAMHDlRkZKT8/f21YMECRUREOP0YAAAAAAAAALi8aNIDAAAAZ2jdurU++eSTMmMRERHatm1bufvabDbZbLYyYzVq1FBSUpKSkpLKjDdu3FgrV6684HwBAAAAAAAAXFm43T0AAAAAAAAAAAAAAE5Ckx4AAAAAAAAAAAAAACehSQ8AAAAAAAAAAAAAgJPQpAcAAAAAAAAAAAAAwElo0gMAAAAAAAAAAAAA4CQ06QEAAAAAAAAAAAAAcBKa9AAAAAAAAAAAAAAAOAlNegAAAAAAAAAAAAAAnIQmPQAAAAAAAAAAAAAATkKTHgAAAAAAAAAAAAAAJ6FJDwAAAAAAAAAAAACAk9CkBwAAAAAAAAAAAADASWjSAwAAAAAAAAAAAADgJDTpAQAAAAAAAAAAAABwEpr0AAAAAAAAAAAAAAA4CU16AAAAAAAAAAAAAACchCY9AAAAAAAAAAAAAABOQpMeAAAAAAAAAAAAAAAnoUkPAAAAAAAAAAAAAICT0KQHAAAAAAAAAAAAAMBJaNIDAAAAAAAAAAAAAOAkNOkBAAAAAAAAAAAAAHASmvQAAAAAAAAAAAAAADgJTXoAAAAAAAAAAAAAAJyEJj0AAAAAAAAAAAAAAE5Ckx4AAAAAAAAAAAAAACdxaZN+//796tOnjxo0aKDAwECNHj1axcXFkqSsrCzddddd8vHx0Q033KCPP/7YYd9PP/1Ubdq0kbe3t+644w799NNPDvFZs2YpMDBQvr6+SkhIUFFRkRkrLi5WQkKC6tWrJ39/f7344ouXf7IAAAAAAAAAcIHsdrsee+wx1a9fX35+fvrHP/4hwzAkSdu3b1dkZKS8vb0VHh6urVu3Ouy7dOlStWjRQt7e3oqNjdXBgwfNmGEYSkxMVKNGjdSgQQONHz9eJSUlZjw/P19xcXHy9fVVaGioFi9e7JwJAwAAVAMua9IbhqE+ffqoqKhI//73v/XWW2/pww8/1D//+U8ZhqFevXqpSZMm+uqrrxQfH6/Y2Fjt27dPkrRv3z716tVLAwYM0JYtW9SoUSP16tXLLE6XLVump556Sqmpqfr888+VmZmp8ePHm+89btw4ffXVV/r88881e/ZsTZkyRe+9955LjgMAAAAAAAAAlGfEiBH65JNPtHbtWqWlpWnu3LmaM2eOCgsL1b17d912223aunWrOnTooB49eqiwsFCStHnzZiUkJOjJJ59UZmamDh8+LJvNZo6blJSktLQ0LV++XMuWLdOSJUuUlJRkxm02m44ePaqMjAxNmjRJAwcO1ObNm509fQAAgKuSu6ve+Pvvv1dmZqby8vLk5+cnSZo6darGjh2re+65R3v27NHGjRvl4+Oj66+/Xp999pkWLFigp556SvPmzdOtt96qMWPGSJJef/11NWnSROvXr1fnzp2VnJyskSNHKiYmRpKUmpqqrl276vnnn5dhGJo3b57WrFmj9u3bq3379tq5c6dSUlLUp08fVx0OAAAAAAAAAHBw6NAhzZ8/X59++qkiIiIkSWPGjNGmTZtUs2ZNeXl5aebMmbJYLJo1a5ZWr16td999VzabTSkpKerbt6/69+8vSVq0aJGaNWumrKwshYaGKjk5WVOnTlV0dLQkacaMGZo0aZLGjh2rPXv2aNWqVcrKylJISIjatGmjjIwMzZ4928wDAAAAF89lV9I3adJEH330kdmgL3X06FFlZmaqffv28vHxMddHR0crIyNDkpSZmalOnTqZMW9vb7Vv314ZGRk6ffq0tmzZ4hC3Wq06ceKEduzYoR07dujkyZPq0KGDw9ibNm1yuJ0TAAAAAAAAALhSenq66tatq9tvv91cl5iYqAULFigzM1PR0dGyWCySJIvFoo4dO5Z7DjUoKEjBwcHKzMzUL7/8ouzsbId4dHS09u7dq9zcXG3atElBQUEKCQlxiJeODQAAgEvjsiZ9vXr11K1bN3O5pKREKSkpuvPOO5Wbm6uAgACH7f38/JSTkyNJFcaPHDmi4uJih7i7u7saNmyonJwc5ebm6pprrlGtWrUc9i0uLlZ+fn6ZudrtdhUUFDi8AAAAAAAAAOBy+umnnxQSEqKFCxfquuuuU/PmzfX000+rpKTkks6h5ubmSpJDvPRiqtJ4RWOXhXOoAAAA589lt7v/s/Hjx2vbtm3asmWLXnrpJXl4eDjEPTw8ZLfbJUlFRUXlxouKiszlsuKGYZQZk2SO/2fTpk3TlClTLn5yAAAAAAAAAHCBjh07pv/+979KTU3V66+/rtzcXA0ePFje3t4VniOVLvwc6pnnSM81dlk4hwoAAHD+XHYl/ZkmTJigWbNmafHixWrTpo08PT3PKvjsdru8vb0lqcK4p6enuVxevKyYJHP8P5s4caKOHj1qvrKzsy9+sgAAAAAAAABwHtzd3VVQUKC0tDRFRUWpd+/eeuKJJ5Samlrp51DPPEd6rrHLwjlUAACA8+fyJv3jjz+uF198UYsXL1ZcXJwkKTAwUHl5eQ7b5eXlyd/f/5zxhg0bytPT0yF+6tQp5efny9/fX4GBgTp48KBOnTrlsK+Xl5fq1atXZo4eHh6qU6eOwwsAAAAAAAAALid/f395enqqWbNm5rpWrVopOzv7ks6hBgYGmstnxkrf81xjl4VzqAAAAOfPpU36KVOm6LXXXtNbb72lfv36meutVqu2bdum48ePm+vS09NltVrNeHp6uhkrKirS9u3bZbVa5ebmpvDwcId4RkaGatasqZtuuknt2rVTzZo1lZmZ6TB2eHi43Nxc/psFAAAAAAAAAJD0x3nQ4uJi/fDDD+a63bt3KyQkRFarVRs3bpRhGJIkwzC0YcOGcs+hZmdnKzs7W1arVQEBAQoODnaIp6enKzg4WP7+/rJardq7d6/DM+jPPD8LAACAS+OyrvTu3bv19NNPKzExUdHR0crLyzNft99+u4KCgjRgwADt3LlT06dP1+bNm5WQkCBJeuSRR7RhwwZNnz5dO3fu1IABAxQaGqrOnTtLkh599FHNnDlTK1as0JYtWzR06FANGjRI3t7e8vb21sMPP6whQ4Zoy5YtWrFihV544QWNGDHCVYcCAAAAAAAAAM7SqlUr9ejRQzabTTt27NDatWs1ffp0DR06VH369NGRI0c0cuRI7dq1SyNHjlRhYaH69u0rSRo6dKgWLVqk+fPn65tvvlH//v0VExOj0NBQMz5hwgStW7dO69atU2JionmOtHnz5urWrZvi4+P1zTffaP78+UpLS9Njjz3msmMBAABwNXF31Rt/8MEHOn36tJ555hk988wzDjHDMPTBBx8oISFBt9xyi1q2bKnly5crODhYkhQSEqL3339fI0eO1NSpU9WhQwetWLFCFotFktSvXz/9/PPPGjx4sOx2u+Li4vT888+b4yclJWno0KHq0qWL6tatqylTpqh3797OmzwAAAAAAAAAnIclS5bo8ccfV3R0tLy9vTVs2DA9/vjjslgsWrVqlYYMGaI5c+aobdu2Wr16tXx8fCRJUVFRSk1N1eTJk3Xo0CF17dpVc+fONccdN26cDhw4oNjYWLm7uyshIUGjRo0y4wsXLtTAgQMVGRkpf39/LViwQBEREU6fPwAAwNXIYpTeDwnnraCgQHXr1tXRo0fPerbSP5JX6+f9hy9p/JDA+npuRPdLGqO64vgDAHD5VFQDwbX4bFAZdbAzUXMDACoDNVDVxucDVK4rreZ3Jf69AcCVzrcG4iHsAAAAAAAAAAAAAAA4CU16AAAAAAAAAAAAAACchCY9AAAAAAAAAAAAAABOQpMeAAAAAAAAAAAAAAAnoUkPAAAAAAAAAAAAAICT0KQHAAAAAAAAAAAAAMBJaNIDAAAAAAAAAAAAAOAkNOkBAAAAAAAAAAAAAHASmvQAAAAAAAAAAAAAADgJTXoAAAAAAAAAAAAAAJyEJj0AAAAAAAAAAACuCnV9PWWUlLg6jSsOxwxwLndXJwAAAAAAAAAAAABUBh/PWrK4uSlr1Vwdz891dTpXBK+G/gqNGeTqNIBqhSY9AAAAAAAAAAAArirH83N1/Nd9rk4DAMrE7e4BAAAAAAAAAAAAAHASmvQAAAAAAAAAAAAAADgJTXoAAAAAAAAAAAAAAJyEJj0AAAAAwKnq+nrKKClxdRoX7UrOHQAAAAAAuJ67qxMAAAAAqqIePXqoUaNGeuONNyRJ27dv15AhQ/Ttt9+qdevWeu2113TLLbeY2y9dulSTJk1Sbm6uunXrprlz5+qaa66RJBmGoYkTJ2r+/Pk6ffq0Bg4cqOnTp8vN7Y/fzObn5+vvf/+7Pv74Y11zzTV6+umn9dBDDzl9zoCz+HjWksXNTVmr5up4fq6r07kgXg39FRozyNVpAAAAAACAKxhNegAAAOBP3nrrLa1evVoPP/ywJKmwsFDdu3fXgw8+qDfeeEOvvfaaevTooT179sjHx0ebN29WQkKCXnvtNbVr107Dhw+XzWbTqlWrJElJSUlKS0vT8uXLdfLkST300ENq3Lixxo4dK0my2Ww6fvy4MjIytGnTJg0cOFBhYWGKiIhw2TEAnOF4fq6O/7rP1WkAAAAAAAA4Fbe7BwAAAM5w6NAhjRs3TuHh4ea6t99+W15eXpo5c6auv/56zZo1S76+vnr33XclSSkpKerbt6/69++vtm3batGiRVq9erWysrIkScnJyZo6daqio6PVpUsXzZgxQykpKZKkPXv2aNWqVZo3b57atGmjhIQEPfTQQ5o9e7bzJw8AAAAAAADgsqNJXwVV9vMZeV4iAADA+Rs7dqzi4+N1ww03mOsyMzMVHR0ti8UiSbJYLOrYsaMyMjLMeKdOncztg4KCFBwcrMzMTP3yyy/Kzs52iEdHR2vv3r3Kzc3Vpk2bFBQUpJCQEId46dgAAAAAAAAAri7c7r4KqsznM/K8RAAAgPP3+eef68svv9S3336roUOHmutzc3PVunVrh239/Pz0n//8x4wHBAScFc/JyVFu7h/13JlxPz8/STLj5e1bHrvdLrvdbi4XFBRcyDQBAAAAAAAAuBBN+iqM5zMCAAA4T3FxsQYPHqxXXnlFXl5eDrGioiJ5eHg4rPPw8DAb5RXFi4qKzOUzY5LMeEVjl2XatGmaMmXKBc4QAAAAAAAAQFXA7e4BAAAASVOmTNGtt96qbt26nRXz9PQ8q2lut9vl7e19zrinp6e5fGZMkhmvaOyyTJw4UUePHjVf2dnZFzBTAAAAAAAAAK7ElfQAAACApLfeekt5eXmqXbu2pP9vpL/33nt64IEHlJeX57B9Xl6e/P39JUmBgYHlxgMDA83l0ufOl25bGq9o7LJ4eHicdfU9AAAAAAAAgCsDV9IDAAAAktatW6dvv/1WX3/9tb7++mvde++9uvfee/X111/LarVq48aNMgxDkmQYhjZs2CCr1SpJslqtSk9PN8fKzs5Wdna2rFarAgICFBwc7BBPT09XcHCw/P39ZbVatXfvXodn0Kenp5tjAwAAAAAAALi6cCU9AAAAIKlZs2YOy76+vpKkli1bqnHjxkpMTNTIkSM1ePBgpaamqrCwUH379pUkDR06VJ07d1ZUVJTCw8M1YsQIxcTEKDQ01IxPmDBBTZs2lSQlJiZqzJgxkqTmzZurW7duio+PV3JysrZs2aK0tDStX7/eWVMHAAAAAAAA4EQ06QEAAIBzqFOnjlatWqUhQ4Zozpw5atu2rVavXi0fHx9JUlRUlFJTUzV58mQdOnRIXbt21dy5c839x40bpwMHDig2Nlbu7u5KSEjQqFGjzPjChQs1cOBARUZGyt/fXwsWLFBERITT5wkAAAAAAADg8qNJD1NJiSE3N0uVGwsAAMAV3njjDYfliIgIbdu2rdztbTabbDZbmbEaNWooKSlJSUlJZcYbN26slStXXmyqAAAAAAAAAK4gNOlhcnOz6JWlG7T/wNFLGiewcV09dn/HSsoKAAAAAAAAAAAAAK4eNOnhYP+Bo/p5/2FXpwEAAAAAAAAAAAAAVyU3VycAAAAAAAAAAAAAAEB1QZMeAAAAAAAAAAAAAAAnoUkPAAAAAAAAAAAAAICT0KQHAAAAAAAAAAAAAMBJaNIDAAAAAAAAAAAAAOAkNOkBAAAAAAAAAAAAAHASmvQAAAAAAAAAUEUtX75cFovF4dWnTx9J0vbt2xUZGSlvb2+Fh4dr69atDvsuXbpULVq0kLe3t2JjY3Xw4EEzZhiGEhMT1ahRIzVo0EDjx49XSUmJGc/Pz1dcXJx8fX0VGhqqxYsXO2fCAAAA1QBNegAAAAAAAACoonbt2qWePXsqNzfXfM2bN0+FhYXq3r27brvtNm3dulUdOnRQjx49VFhYKEnavHmzEhIS9OSTTyozM1OHDx+WzWYzx01KSlJaWpqWL1+uZcuWacmSJUpKSjLjNptNR48eVUZGhiZNmqSBAwdq8+bNzp4+AADAVcnd1QkAAAAAAAAAAMq2e/dutWnTRk2aNHFYv2DBAnl5eWnmzJmyWCyaNWuWVq9erXfffVc2m00pKSnq27ev+vfvL0latGiRmjVrpqysLIWGhio5OVlTp05VdHS0JGnGjBmaNGmSxo4dqz179mjVqlXKyspSSEiI2rRpo4yMDM2ePVsRERFOPwYAAABXG66kBwAAAAAAAIAqateuXQoLCztrfWZmpqKjo2WxWCRJFotFHTt2VEZGhhnv1KmTuX1QUJCCg4OVmZmpX375RdnZ2Q7x6Oho7d27V7m5udq0aZOCgoIUEhLiEC8dGwAAAJeGJj0AAAAAAAAAVEGGYej777/X2rVrFRYWphYtWigxMVEnTpxQbm6uAgICHLb38/NTTk6OJFUYz83NlSSHuJ+fnySZ8YrGBgAAwKXhdvcAAAAAAAAAUAXt27dPRUVF8vDw0DvvvKOsrCwNHz5cx48fN9efycPDQ3a7XZIqjBcVFZnLZ8YkmfGKxi6L3W53iBcUFFzEjAEAAKoHmvQAAAAAAAAAUAU1a9ZM+fn5ql+/viwWi9q1a6eSkhI99NBD6ty581lNc7vdLm9vb0mSp6dnuXFPT09z+cy/JZnxisYuy7Rp0zRlypRLmzAAAEA1we3ugT+p6+spo6Sk0sarzLEAAAAAAABQvTRo0MB87rwkXX/99SouLlaTJk2Ul5fnsG1eXp78/f0lSYGBgeXGAwMDzeUzY5LMeEVjl2XixIk6evSo+crOzr6I2QIAAFQPXEkP/ImPZy1Z3NyUtWqujufnXtJYXg39FRozqJIyAwAAAAAAQHWydu1aPfDAA8rOzjavYv/666/VsGFD3XbbbZo+fboMw5DFYpFhGNqwYYOeeOIJSZLValV6erpsNpskKTs7W9nZ2bJarQoICFBwcLDS09MVEhIiSUpPT1dwcLD8/f1ltVq1d+9e5eTkqGnTpmbcarWWm6uHh8dZt8gHAABA2WjSA+U4np+r47/uc3UaAAAAAAAAqKY6dOggLy8vDRw4UE8++aR++uknjRs3TuPHj1efPn2UmJiokSNHavDgwUpNTVVhYaH69u0rSRo6dKg6d+6sqKgohYeHa8SIEYqJiVFoaKgZnzBhgtmET0xM1JgxYyRJzZs3V7du3RQfH6/k5GRt2bJFaWlpWr9+vWsOBAAAwFWGJj0AAAAAAAAAVEG+vr5au3atRo4cqVtvvVW+vr4aPHiwxo0bJ4vFolWrVmnIkCGaM2eO2rZtq9WrV8vHx0eSFBUVpdTUVE2ePFmHDh1S165dNXfuXHPscePG6cCBA4qNjZW7u7sSEhI0atQoM75w4UINHDhQkZGR8vf314IFCxQREeH0YwAAAHA1okkPAAAAAAAAAFVU69at9cknn5QZi4iI0LZt28rd12azmbe7/7MaNWooKSlJSUlJZcYbN26slStXXnC+AAAAODc3VycAAAAAAAAAAAAAAEB1QZMeAAAAAAAAAAAAAAAnoUkPAAAAAAAAAAAAAICT0KQHAAAAAAAAAAAAAMBJaNIDAAAAAAAAAAAAAOAkNOkBAAAAAAAAAAAAAHASmvQAAAAAAAAAAAAAADgJTXoAAAAAAAAAAAAAAJyEJj0AAAAAAAAAAAAAAE5Ckx4AAAAAAAAAAAAAACehSQ8AAAAAAAAAAAAAgJPQpAcAAAAAAAAAAAAAwElo0gMAAAAAAAAAAAAA4CQX3KS/4447dOTIkbPW//bbb7r11lsvKgm73a42bdpo3bp15roRI0bIYrE4vFJSUsz40qVL1aJFC3l7eys2NlYHDx40Y4ZhKDExUY0aNVKDBg00fvx4lZSUmPH8/HzFxcXJ19dXoaGhWrx48UXlDQAAgKrhctSoAAAAwMWiPgUAAEBF3M9no48++kibN2+WJK1fv17PPfecateu7bDNf//7X/38888XnEBxcbEeeOAB7dy502H9rl27NG3aNNlsNnNdnTp1JEmbN29WQkKCXnvtNbVr107Dhw+XzWbTqlWrJElJSUlKS0vT8uXLdfLkST300ENq3Lixxo4dK0my2Ww6fvy4MjIytGnTJg0cOFBhYWGKiIi44PwBAADgGpezRgUAAAAuFPUpAAAAztd5NelbtWql559/XoZhyDAMbdiwQbVq1TLjFotFPj4+mj9//gW9+a5du/TAAw/IMIyzYrt379a4cePUpEmTs2IpKSnq27ev+vfvL0latGiRmjVrpqysLIWGhio5OVlTp05VdHS0JGnGjBmaNGmSxo4dqz179mjVqlXKyspSSEiI2rRpo4yMDM2ePZsmPQAAwBXkctWoAAAAwMWgPgUAAMD5Oq8mfWhoqD7//HNJ0oABA5ScnGxe1X4p1q9fry5duujZZ5+Vj4+Pub6goED79+9XWFhYmftlZmYqMTHRXA4KClJwcLAyMzPl4eGh7OxsderUyYxHR0dr7969ys3N1aZNmxQUFKSQkBCH+LRp0y55PgAAAHCey1WjAgAAABeD+hQAAADn67ya9Gd6/fXXJUl5eXk6efLkWVfBBwcHn/dYQ4cOLXP97t27ZbFY9Oyzz2rNmjVq2LChRo8erYcffliSlJubq4CAAId9/Pz8lJOTo9zcXElyiPv5+UmSGS9v3/LY7XbZ7XZzuaCg4LznCAAAgMuvMmtUAAAA4FJRnwIAAKAiF9yk/+STTzRo0CBlZ2dLkgzDkMViMf97+vTpS07qu+++k8Vi0XXXXafHH39c69ev19///nfVqVNHsbGxKioqkoeHh8M+Hh4estvtKioqMpfPjEky4+XtW55p06ZpypQplzwvAAAAXB7OqFEBAACA80V9CgAAgIpccJN+2LBhioyM1IcffnjZbtfUv39/9ezZUw0aNJAktW3bVj/88INeffVVxcbGytPT86ymut1ul7e3tzw9Pc3lM/+WZMbL27c8EydO1OjRo83lgoICBQUFXfpEAQAAUCmcUaMCAAAA54v6FAAAABW54CZ9dna2PvroI4WGhl6OfCRJFovFbNCXuv76681nOgUGBiovL88hnpeXJ39/fwUGBprLpc+dL922NF7evuXx8PA46+p7AAAAVB3OqFEBAACA80V9CgAAgIq4XegOnTp1Unp6+uXIxTR58mTdddddDuu+/vprXXfddZIkq9XqkEN2drays7NltVoVEBCg4OBgh3h6erqCg4Pl7+8vq9WqvXv3OjyDPj09XVar9bLOCQAAAJePM2pUAAAA4HxRnwIAAKAiF3wlfadOnTR06FCtWrVK1157rWrVquUQnzx58iUn1bNnT02bNk0vvPCCYmNj9fHHH2vhwoX64osvJElDhw5V586dFRUVpfDwcI0YMUIxMTHmL1OHDh2qCRMmqGnTppKkxMREjRkzRpLUvHlzdevWTfHx8UpOTtaWLVuUlpam9evXX3LeAAAAcA1n1KgAAADA+aI+BQAAQEUuuEn/ySefKDw8XAcOHNCBAwccYhaLpVIKzPDwcL333nuaPHmy/vnPfyokJERpaWmKioqSJEVFRSk1NVWTJ0/WoUOH1LVrV82dO9fcf9y4cTpw4IBiY2Pl7u6uhIQEjRo1yowvXLhQAwcOVGRkpPz9/bVgwQJFRERcct4AAABwDWfUqAAAAMD5oj4FAABARS64SV96NXtlMwzDYfm+++7TfffdV+72NptNNputzFiNGjWUlJSkpKSkMuONGzfWypUrLzpXAAAAVC2Xq0YFAAAALgb1KQAAACpywU36hQsXVhjv37//RScDAAAAXAxqVAAAAFQl1KcAAACoyAU36Z988kmH5VOnTunAgQNyd3dXZGQkBSYAAACcjhoVAAAAVQn1KQAAACpywU36rKyss9YdO3ZMgwcP1o033lgpSQEAAAAXghoVAAAAVQn1KQAAACriVhmD1K5dW0899VS5z4AHAAAAnI0aFQAAAFUJ9SkAAABKVUqTXpJ27Nih06dPV9ZwAAAAwCWjRgUAAEBVQn0KAAAA6SJud9+lSxdZLBaHdb///rt27Nih0aNHV1piAAAAwPmiRgUAAEBVQn0KAACAilxwk75z584OyxaLRbVq1dL06dN15513VlZeAAAAwHmjRgUAAEBVQn0KAACAilxwk/7JJ580/y4oKNDp06dVv379Sk0KAAAAuBDUqAAAAKhKqE8BAABQkYt6Jn1ycrICAwNVv359XXPNNWrSpImmTp1a2bkBAAAA540aFQAAAFUJ9SkAAADKc8FN+qefflrPPvusJk+erK+//lpbt27V5MmTlZKSounTp1+OHAEAAIAKVWaN+uOPP6pbt26qXbu2goODNXPmTDOWlZWlu+66Sz4+Prrhhhv08ccfO+z76aefqk2bNvL29tYdd9yhn376ySE+a9YsBQYGytfXVwkJCSoqKjJjxcXFSkhIUL169eTv768XX3zxIo4EAAAAqgLOoQIAAKAiF3y7+zlz5mj+/Pnq2bOnua5du3YKDAzU8OHDlZiYWKkJAgAAAOdSWTVqSUmJevToofDwcG3fvl3//e9/df/99yswMFD333+/evXqpRtvvFFfffWVVqxYodjYWO3evVvBwcHat2+fevXqpSlTpujuu+/W1KlT1atXL+3YsUMWi0XLli3TU089pcWLF8vPz082m03jx49XSkqKJGncuHH66quv9Pnnn2vv3r16+OGH1axZM/Xp0+eyHDMAAABcPpxDBQAAQEUuuElfUFCgsLCws9a3atVKv/32W6UkBQAAAFyIyqpRf/31V7Vr106vvvqqfH19de211+rOO+9Uenq6mjRpoj179mjjxo3y8fHR9ddfr88++0wLFizQU089pXnz5unWW2/VmDFjJEmvv/66mjRpovXr16tz585KTk7WyJEjFRMTI0lKTU1V165d9fzzz8swDM2bN09r1qxR+/bt1b59e+3cuVMpKSk06QEAAK5AnEMFAABARS74dvcdOnTQCy+8oJKSEnPd6dOnNXPmTEVERFRqcgAAAMD5qKwa1d/fX2+//bZ8fX1lGIY2bNigL7/8Up07d1ZmZqbat28vHx8fc/vo6GhlZGRIkjIzM9WpUycz5u3trfbt2ysjI0OnT5/Wli1bHOJWq1UnTpzQjh07tGPHDp08eVIdOnRwGHvTpk0OcwIAAMCVgXOoAAAAqMgFN+mTkpK0YsUKNW/eXHFxcYqLi1OLFi20evVqJScnX44cAQAAgApdjho1JCRE0dHRioqKUlxcnHJzcxUQEOCwjZ+fn3JyciSpwviRI0dUXFzsEHd3d1fDhg2Vk5Oj3NxcXXPNNapVq5bDvsXFxcrPz7+o/AEAAOA6l+scao8ePWSz2czl7du3KzIyUt7e3goPD9fWrVsdtl+6dKlatGghb29vxcbG6uDBg2bMMAwlJiaqUaNGatCggcaPH+/wo4L8/HzFxcXJ19dXoaGhWrx48UXnDQAAAEcX3KS//vrrNWvWLI0ePVp+fn5q1qyZcnNzNWfOHN10002XI0cAAACgQpejRl22bJk+/PBDff311xo1apSKiork4eHhsI2Hh4fsdrskVRgvKioyl8uLlxWTZI5/JrvdroKCAocXAAAAqo7LUZ++9dZbWr16tblcWFio7t2767bbbtPWrVvVoUMH9ejRQ4WFhZKkzZs3KyEhQU8++aQyMzN1+PBhhwZ/UlKS0tLStHz5ci1btkxLlixRUlKSGbfZbDp69KgyMjI0adIkDRw4UJs3b764AwIAAAAHF/xM+pdffllPPPGEXn75Zc2ePVuS5ObmpgcffFAvvviiBg0aVOlJAgAAABW5HDXqrbfeKkkqLi7Wgw8+qEceecQ84VnKbrfL29tbkuTp6XlWQ91ut6tevXry9PQ0l8va//Tp02XGJJnjn2natGmaMmXKBc8JAAAAzlHZ9emhQ4c0btw4hYeHm+vefvtteXl5aebMmbJYLJo1a5ZWr16td999VzabTSkpKerbt6/69+8vSVq0aJGaNWumrKwshYaGKjk5WVOnTlV0dLQkacaMGZo0aZLGjh2rPXv2aNWqVcrKylJISIjatGmjjIwMzZ49m9v1AwAAVIILvpL+xRdfVFpamh5++GFz3QsvvKDFixdr+vTplZocAAAAcD4qq0b99ddftWLFCod1N9xwg06cOCF/f3/l5eU5xPLy8uTv7y9JCgwMLDfesGFDeXp6OsRPnTql/Px8+fv7KzAwUAcPHtSpU6cc9vXy8lK9evXOynPixIk6evSo+crOzj7vOQIAAODyq+xzqGPHjlV8fLxuuOEGc11mZqaio6NlsVgkSRaLRR07dlRGRoYZ79Spk7l9UFCQgoODlZmZqV9++UXZ2dkO8ejoaO3du1e5ubnatGmTgoKCFBIS4hAvHRsAAACX5oKb9Pn5+WrZsuVZ61u1anXWSUkAAADAGSqrRs3KylLv3r21f/9+c93WrVvVqFEjRUdHa9u2bTp+/LgZS09Pl9VqlSRZrValp6ebsaKiIm3fvl1Wq1Vubm4KDw93iGdkZKhmzZq66aab1K5dO9WsWVOZmZkOY4eHh8vN7eyS3cPDQ3Xq1HF4AQAAoOqozHOon3/+ub788kv985//dFifm5urgIAAh3V+fn7Kyck5Zzw3N1eSHOJ+fn6SZMYrGrssPJIJAADg/F1wkz46OlpPPvmk+VxN6Y9bgD777LPq0KFDpSYHAAAAnI/KqlHDw8N1yy236JFHHtGuXbu0evVqjRs3Tk888YRuv/12BQUFacCAAdq5c6emT59uPudTkh555BFt2LBB06dP186dOzVgwACFhoaqc+fOkqRHH31UM2fO1IoVK7RlyxYNHTpUgwYNkre3t7y9vfXwww9ryJAh2rJli1asWKEXXnhBI0aMqNTjBAAAAOeorPq0uLhYgwcP1iuvvCIvLy+HWFFRkTw8PBzWeXh4mI9NqihemteZ8dK/S+MVjV2WadOmqW7duuYrKCjovOcJAABQ3VzwM+lTUlLUtWtX+fv7KywsTJL0448/qkmTJvrggw8qPUEAAADgXCqrRq1Ro4Y++OADDRs2TFFRUfLx8dHw4cM1fPhwWSwWffDBB0pISNAtt9yili1bavny5QoODpYkhYSE6P3339fIkSM1depUdejQQStWrDBvP9qvXz/9/PPPGjx4sOx2u+Li4vT888+b752UlKShQ4eqS5cuqlu3rqZMmaLevXtX4lECAACAs1RWfTplyhTdeuut6tat21kxT0/Ps5rmdrtd3t7e54x7enqay2f+LcmMVzR2WSZOnKjRo0ebywUFBTTqAQAAynHBTfoWLVpo165dWrt2rX744QfVrFlT1157rbp166YaNWpcjhwBAACAClVmjRoQEKD333+/zFjLli21fv36cve95557dM8995QbT0xMVGJiYpkxb29vvfnmm3rzzTcvKF8AAABUPZVVn7711lvKy8tT7dq1Jf1/I/29997TAw88cNat8/Py8uTv7y9JCgwMLDceGBhoLpc+d75029J4RWOXxcPD46yr7wEAAFC2C27SS38UXPfee29l5wIAAABcNGpUAAAAVCWVUZ+uW7dOJ0+eNJcnTJggSZoxY4a+/PJLTZ8+XYZhyGKxyDAMbdiwQU888YQkyWq1Kj09XTabTZKUnZ2t7OxsWa1WBQQEKDg4WOnp6WaTPj09XcHBwfL395fVatXevXuVk5Ojpk2bmnGr1XpJ8wEAAMAfLqpJD6DylZQYcnOzVLmxAAAAAAAA4BrNmjVzWPb19ZX0xx2eGjdurMTERI0cOVKDBw9WamqqCgsL1bdvX0nS0KFD1blzZ0VFRSk8PFwjRoxQTEyMQkNDzfiECRPMJnxiYqLGjBkjSWrevLm6deum+Ph4JScna8uWLUpLS6vwrlIAAAA4fzTpgSrCzc2iV5Zu0P4DRy9pnMDGdfXY/R0rKSsAAAAAAABURXXq1NGqVas0ZMgQzZkzR23bttXq1avl4+MjSYqKilJqaqomT56sQ4cOqWvXrpo7d665/7hx43TgwAHFxsbK3d1dCQkJGjVqlBlfuHChBg4cqMjISPn7+2vBggWKiIhw+jwBAACuRjTpgSpk/4Gj+nn/YVenAQAAAAAAgCrojTfecFiOiIjQtm3byt3eZrOZt7v/sxo1aigpKUlJSUllxhs3bqyVK1debKoAAACogJurEwAAAAAAAAAAAAAAoLqgSQ8AAAAAAAAAAAAAgJPQpAcAAAAAAAAAAAAAwElo0gMAAAAAAAAAAAAA4CQ06QEAAAAAAAAAAAAAcBKa9AAAAAAAAAAAAAAAOAlNegAAAAAAAAAAAAAAnIQmPQAAAAAAAAAAAAAATkKTHgAAAAAAAAAAAAAAJ6FJDwAAAAAAAAAAAACAk9CkBwAAAAAAAAAAAADASWjSAwAAAAAAAAAAAADgJDTpAQAAAAAAAAAAAABwEpr0AAAAAAAAAAAAAAA4CU16AAAAAAAAAAAAAACchCY9Kl1dX08ZJSWVNl5ljgUAAAAAAAAAAAAAruTu6gRw9fHxrCWLm5uyVs3V8fzcSxrLq6G/QmMGVVJmAAAAAAAAAAAAAOBaNOlx2RzPz9XxX/e5Og0AAAAAAAAAAAAAqDK43T0AAAAAAAAAAAAAAE5Ckx4AAAAAAAAAAAAAACehSQ8AAAAAAAAAAAAAgJPQpAcAAAAAAAAAAAAAwElo0gMAAAAAAAAAAAAA4CQ06QEAAAAAAAAAAAAAcBKa9AAAAAAAAAAAAAAAOAlNegAAAAAAAAAAAAAAnIQmPQAAAAAAAAAAAAAATkKTHgAAAAAAAAAAAAAAJ6FJDwAAAAAAAAAAAACAk9CkBwAAAAAAAAAAAADASWjSAwAAAAAAAAAAAADgJDTpAQAAAAAAAAAAAABwEpr0AAAAAAAAAAAAAAA4CU16AAAAAAAAAAAAAACchCY9AAAAAAAAAAAAAABOQpMeAAAAAAAAAAAAAAAnoUkPAAAAAAAAAAAAAICTVIkmvd1uV5s2bbRu3TpzXVZWlu666y75+Pjohhtu0Mcff+ywz6effqo2bdrI29tbd9xxh3766SeH+KxZsxQYGChfX18lJCSoqKjIjBUXFyshIUH16tWTv7+/Xnzxxcs6PwAAAAAAAAC4GD/++KO6deum2rVrKzg4WDNnzjRjnEMFAAC4Mrm8SV9cXKz7779fO3fuNNcZhqFevXqpSZMm+uqrrxQfH6/Y2Fjt27dPkrRv3z716tVLAwYM0JYtW9SoUSP16tVLhmFIkpYtW6annnpKqamp+vzzz5WZmanx48eb448bN05fffWVPv/8c82ePVtTpkzRe++959yJAwAAAAAAAEAFSkpK1KNHDzVq1Ejbt2/Xa6+9pmeeeUZpaWmcQwUAALiCubvyzXft2qUHHnjALAxLffHFF9qzZ482btwoHx8fXX/99frss8+0YMECPfXUU5o3b55uvfVWjRkzRpL0+uuvq0mTJlq/fr06d+6s5ORkjRw5UjExMZKk1NRUde3aVc8//7wMw9C8efO0Zs0atW/fXu3bt9fOnTuVkpKiPn36OP0YAAAAAAAAAEBZfv31V7Vr106vvvqqfH19de211+rOO+9Uenq6mjRpwjlUAACAK5RLr6Rfv369unTpooyMDIf1mZmZat++vXx8fMx10dHR5naZmZnq1KmTGfP29lb79u2VkZGh06dPa8uWLQ5xq9WqEydOaMeOHdqxY4dOnjypDh06OIy9adMmlZSUXK6pAgAAAAAAAMAF8ff319tvvy1fX18ZhqENGzboyy+/VOfOnTmHCgAAcAVz6ZX0Q4cOLXN9bm6uAgICHNb5+fkpJyfnnPEjR46ouLjYIe7u7q6GDRsqJydHbm5uuuaaa1SrVi2HfYuLi5Wfn69GjRqdlY/dbpfdbjeXCwoKLnyyAAAAAAAAAHCRQkJCtG/fPsXExCguLk4jR47kHCoAAMAVyuXPpC9LUVGRPDw8HNZ5eHiYRV5F8aKiInO5vHhZMUkOReSZpk2bprp165qvoKCgi58cAAAAAAAAAFygZcuW6cMPP9TXX3+tUaNGcQ4VAADgClYlm/Senp5nFXt2u13e3t7njHt6eprL5cXLikkyx/+ziRMn6ujRo+YrOzv74icHAAAAAAAAABfo1ltvVUxMjF566SWlpqaqVq1anEMFAAC4QlXJJn1gYKDy8vIc1uXl5cnf3/+c8YYNG8rT09MhfurUKeXn58vf31+BgYE6ePCgTp065bCvl5eX6tWrV2Y+Hh4eqlOnjsMLAAAAAAAAAC6nX3/9VStWrHBYd8MNN+jEiRPy9/fnHCoAAMAVqko26a1Wq7Zt26bjx4+b69LT02W1Ws14enq6GSsqKtL27dtltVrl5uam8PBwh3hGRoZq1qypm266Se3atVPNmjWVmZnpMHZ4eLjc3Krk4QAAAAAAAABQDWVlZal3797av3+/uW7r1q1q1KiRoqOjOYcKAABwhaqSFdXtt9+uoKAgDRgwQDt37tT06dO1efNmJSQkSJIeeeQRbdiwQdOnT9fOnTs1YMAAhYaGqnPnzpKkRx99VDNnztSKFSu0ZcsWDR06VIMGDZK3t7e8vb318MMPa8iQIdqyZYtWrFihF154QSNGjHDhjAEAAAAAAADAUXh4uG655RY98sgj2rVrl1avXq1x48bpiSee4BwqAADAFczd1QmUpUaNGvrggw+UkJCgW265RS1bttTy5csVHBwsSQoJCdH777+vkSNHaurUqerQoYNWrFghi8UiSerXr59+/vlnDR48WHa7XXFxcXr++efN8ZOSkjR06FB16dJFdevW1ZQpU9S7d2+XzBUAAAAAAAAAylJ6nnTYsGGKioqSj4+Phg8fruHDh8tisXAOFQAA4ApVZZr0hmE4LLds2VLr168vd/t77rlH99xzT7nxxMREJSYmlhnz9vbWm2++qTfffPPikgUAAAAAAAAAJwgICND7779fZoxzqAAAAFemKnm7ewAAAAAAAAAAAAAArkY06QEAAAAAAAAAAAAAcJL/be/e43uu//+P3zezw3vYMofNHEvknKFGcyqHj6icCpUcllOUQ459PnIoUQ5R8qFklCKZYxLlsBqbNkQhkgn7btSqKTswe/7+8Nvr482GmPd7h9v1cnldeL+er9fz/Xi9X6/n6/V8vR57vV4k6QEAAID/Lz4+Xl27dlXJkiUVGBioESNGKC0tTZIUFxenVq1aydvbWzVr1tTmzZvt5v3qq69Uu3Zt2Ww2Pfjggzp27Jhd+ezZsxUYGKjixYsrNDRUKSkpVllaWppCQ0Pl6+urgIAAzZw58/YvLAAAAAAAAACnIEkPAAAASDLGqGvXrkpJSdE333yj5cuXa/369Ro/fryMMerYsaP8/f0VGxurnj17qlOnTjpx4oQk6cSJE+rYsaP69OmjmJgYlS5dWh07dpQxRpIUHh6uiRMnasGCBdq6dauio6M1evRo67tHjRql2NhYbd26VfPmzdOkSZO0cuVKp/wOAAAAAAAAAG4vN2cHAAAAAOQFhw8fVnR0tBITE1W2bFlJ0uTJkzVy5Ei1a9dOP//8s3bu3Clvb2/VqFFDW7Zs0aJFizRx4kQtXLhQDRs21IsvvihJCgsLk7+/vyIiItSiRQvNmTNHw4YNU4cOHSRJCxYsUJs2bfTGG2/IGKOFCxdq48aNCgoKUlBQkA4cOKC5c+eqa9euTvs9AAAAAAAAANwe3EkPAAAASPL399cXX3xhJeizJCcnKzo6WkFBQfL29rbGh4SEKCoqSpIUHR2tZs2aWWU2m01BQUGKiorSxYsXFRMTY1ceHBys8+fPa9++fdq3b58uXLigJk2a2NW9a9cuZWZm3q7FBQAAAAAAAOAk3EkPAAAASPL19VXbtm2tz5mZmZo7d64eeughJSQkqFy5cnbTly1bVqdOnZKka5b/+eefSktLsyt3c3OTn5+fTp06JVdXV5UqVUru7u5286alpSkpKUmlS5e+Ktb09HSlp6dbn8+ePXtrCw8AAAAAAADAYbiTHgAAAMjG6NGjtWfPHk2ZMkUpKSny8PCwK/fw8LAS5dcqT0lJsT7nVJ5dmSS7RPzlpk6dKh8fH2uoUKHCzS8oAAAAAAAAAIciSQ8AAABcYcyYMZo9e7aWLl2q2rVry9PT86qEeXp6umw2myRds9zT09P6nFN5dmWSrPqvNG7cOCUnJ1vDyZMnb35hAQAAAAAAADgUSXqggPEp7imTi++vzc26AADID55//nnNnDlTS5cuVZcuXSRJgYGBSkxMtJsuMTFRAQEB1y338/OTp6enXXlGRoaSkpIUEBCgwMBA/fbbb8rIyLCb18vLS76+vtnG6OHhoRIlStgNAAAAAAAAAPIH3kkPFDDenu5ycXVV3GfvKTUp4Zbq8vILUJUO/XIpMgAA8r5JkyZp/vz5Wr58ubp27WqNDw4O1rRp05SamiovLy9JUmRkpEJCQqzyyMhIa/qUlBTt3btXEydOlKurqxo1aqTIyEi1aNFCkhQVFaWiRYuqXr16kqSiRYsqOjraqi8yMlKNGjWSqyt/UwsAAAAAAAAUNCTpgQIqNSlBqadPODsMAADyjUOHDumVV17RuHHjFBISYnfne/PmzVWhQgX16dNH48eP1/r16/Xtt98qLCxMktS3b19Nnz5d06ZN0yOPPKLJkyerSpUqVlL+ueee04ABA1S7dm0FBgZq0KBB6tevn/U4+169emngwIEKCwtTfHy8ZsyYYdUNAAAAAAAAoGDh1hwAAABA0tq1a3Xx4kW9+uqrCggIsBuKFCmitWvXKiEhQQ0aNNDSpUu1evVqVaxYUZJUuXJlrVq1SmFhYWrUqJGSkpK0Zs0aubi4SJK6d++ucePGacCAAWrdurXuv/9+vfHGG9Z3z5o1Sw0aNFDLli01ePBgTZo0SZ07d3bK7wAAAAAAAADg9uJOegAAAEDS2LFjNXbs2BzLq1atqoiIiBzL27Vrp3bt2t1U/TabTUuWLNGSJUtuPGAAAAAAAAAA+RJ30gMAAAAAAAAAAAAA4CAk6QEAAAAAAAAAAAAAcBCS9AAAAAAAAAAAAAAAOAhJegAAAAAAAAAAAAAAHIQkPQAAAAAAAAAAAAAADkKSHgAAAAAAAAAAAAAAByFJDwAAAAAAAAAAAACAg5CkBwAAAAAAAAAAAADAQUjSAwAAAAAAAAAAAADgICTpAQAAAADIIzIzjbNDuCn5NW4AAAAAAJzBzdkBAAAAAACAS1xdXfTOsh2KP5Ps7FBuWGAZHw3u8YCzwwAAAAAAIN8gSQ8AAAAAQB4SfyZZx+P/cHYYAAAAAADgNuFx9wAAAAAAAAAAAAAAOAhJegAAAAAAAAAAAAAAHIQkPQAAAAAAAAAAAAAADkKSHgAAACiEMjONs0O4Kfk1bgAAAAAAACCLm7MDAAAAAOB4rq4uemfZDsWfSXZ2KDcssIyPBvd4wNlhAAAAAAAAALeEJD0AAABQSMWfSdbx+D+cHQYAAAAAAABQqPC4ewAAAAAAAAAAAAAAHIQkPQAAAAAAAAAAAAAADkKSHgAAAAAAAAAAAAAAByFJDwAAAAAAAAAAAACAg5CkBwAAAAAAAAAAAADAQUjSAwAAAAAAAEAeFR8fr65du6pkyZIKDAzUiBEjlJaWJkmKi4tTq1at5O3trZo1a2rz5s1283711VeqXbu2bDabHnzwQR07dsyufPbs2QoMDFTx4sUVGhqqlJQUqywtLU2hoaHy9fVVQECAZs6cefsXFgAAoJAgSQ8AAAAAAAAAeZAxRl27dlVKSoq++eYbLV++XOvXr9f48eNljFHHjh3l7++v2NhY9ezZU506ddKJEyckSSdOnFDHjh3Vp08fxcTEqHTp0urYsaOMMZKk8PBwTZw4UQsWLNDWrVsVHR2t0aNHW989atQoxcbGauvWrZo3b54mTZqklStXOuV3AAAAKGjcnB0AAAAAAAAAAOBqhw8fVnR0tBITE1W2bFlJ0uTJkzVy5Ei1a9dOP//8s3bu3Clvb2/VqFFDW7Zs0aJFizRx4kQtXLhQDRs21IsvvihJCgsLk7+/vyIiItSiRQvNmTNHw4YNU4cOHSRJCxYsUJs2bfTGG2/IGKOFCxdq48aNCgoKUlBQkA4cOKC5c+eqa9euTvs9AAAACgrupAcAAAAAAACAPMjf319ffPGFlaDPkpycrOjoaAUFBcnb29saHxISoqioKElSdHS0mjVrZpXZbDYFBQUpKipKFy9eVExMjF15cHCwzp8/r3379mnfvn26cOGCmjRpYlf3rl27lJmZebsWFwAAoNDgTnoAAAAAAAAAyIN8fX3Vtm1b63NmZqbmzp2rhx56SAkJCSpXrpzd9GXLltWpU6ck6Zrlf/75p9LS0uzK3dzc5Ofnp1OnTsnV1VWlSpWSu7u73bxpaWlKSkpS6dKlr4o1PT1d6enp1uezZ8/e2sIDAAAUYNxJDwAAAAAAAAD5wOjRo7Vnzx5NmTJFKSkp8vDwsCv38PCwEuXXKk9JSbE+51SeXZkku0T85aZOnSofHx9rqFChws0vKAAAQAFHkh4AAAAAAAAA8rgxY8Zo9uzZWrp0qWrXri1PT8+rEubp6emy2WySdM1yT09P63NO5dmVSbLqv9K4ceOUnJxsDSdPnrz5hQUAACjgSNIDAAAAAAAAQB72/PPPa+bMmVq6dKm6dOkiSQoMDFRiYqLddImJiQoICLhuuZ+fnzw9Pe3KMzIylJSUpICAAAUGBuq3335TRkaG3bxeXl7y9fXNNkYPDw+VKFHCbgAAAED2SNIDyBWZmSZP1gUAAAAAAJCfTZo0SfPnz9fy5cvVvXt3a3xwcLD27Nmj1NRUa1xkZKSCg4Ot8sjISKssJSVFe/fuVXBwsFxdXdWoUSO78qioKBUtWlT16tXTvffeq6JFiyo6Otqu7kaNGsnVlUvKAAAAt8rN2QEAKBhcXV30zrIdij+TfEv1BJbx0eAeD+RSVAAAAAAAAPnXoUOH9Morr2jcuHEKCQmxu/O9efPmqlChgvr06aPx48dr/fr1+vbbbxUWFiZJ6tu3r6ZPn65p06bpkUce0eTJk1WlShW1aNFCkvTcc89pwIABql27tgIDAzVo0CD169fPepx9r169NHDgQIWFhSk+Pl4zZsyw6gYAAMCtIUkPINfEn0nW8fg/nB0GAAAAAABAgbB27VpdvHhRr776ql599VW7MmOM1q5dq9DQUDVo0EBVq1bV6tWrVbFiRUlS5cqVtWrVKg0bNkyTJ09WkyZNtGbNGrm4uEiSunfvruPHj2vAgAFKT09Xly5d9MYbb1j1z5o1S4MGDVLLli3l4+OjSZMmqXPnzo5beAAAgAKMJD0AAAAAAAAA5EFjx47V2LFjcyyvWrWqIiIicixv166d2rVrd1P122w2LVmyREuWLLnxgAEAAHBDeIEQAAAAAAAAAAAAAAAOQpIeAAAAAAAAAAAAAAAHIUkPAAAAAAAAAAAAAICDkKQHAAAAAAAAAAAAAMBBSNIDAAAAAAAAAAAAAOAgJOkBAAAAAAAAAAAAAHAQkvQAAAAAAAAAAAAAADgISXoAAAAAAAAAAAAAAByEJD0AAAAAAAAAAAAAAA5Ckh4AAAAAAAAAAAAAAAchSQ8AAAAAAAAAAAAAgIOQpAcAAAAAAAAAAAAAwEFI0gMAAAAAAAAAAAAA4CB5Okm/evVqubi42A1du3aVJO3du1f333+/bDabGjVqpN27d9vNu2zZMt11112y2Wzq1KmTfvvtN6vMGKOxY8eqdOnSKlmypEaPHq3MzEyHLhsAAAAAAAAAAAAAoPDJ00n6gwcP6pFHHlFCQoI1LFy4UOfOndPDDz+spk2bavfu3WrSpInat2+vc+fOSZK+/fZbhYaGasKECYqOjtYff/yh3r17W/XOmjVLH3/8sVavXq3w8HB99NFHmjVrlpOWEgAAAACA/MunuKdMPv3D9/waNwAAAAAgf3NzdgDXcujQIdWuXVv+/v524xctWiQvLy9Nnz5dLi4umj17tj7//HN9+umn6t27t+bOnasnnnhCzzzzjCTpww8/VKVKlRQXF6cqVapozpw5mjx5skJCQiRJr7/+uv7zn/9o5MiRDl9GAAAAAADyM29Pd7m4uirus/eUmpTg7HBumJdfgKp06OfsMAAAAAAAhVCeTtIfPHhQrVq1ump8dHS0QkJC5OLiIklycXHRAw88oKioKPXu3VvR0dEaO3asNX2FChVUsWJFRUdHy8PDQydPnlSzZs2s8pCQEP3yyy9KSEhQQEDA7V8wAAAAAAAKmNSkBKWePuHsMAAAAAAAyPPy7OPujTE6fPiwNm3apGrVqumuu+7S2LFjdf78eSUkJKhcuXJ205ctW1anTp2SpGuWJyRc+qv+y8vLli0rSdb8V0pPT9fZs2ftBgAAAACOxSO1AQAAAAAAUBDk2TvpT5w4oZSUFHl4eGjFihWKi4vTCy+8oNTUVGv85Tw8PJSeni5J1yxPSUmxPl9eJsma/0pTp07VpEmTcm3ZAAAAAPxzPFIbAAAAAAAABUGeTdJXqlRJSUlJuuOOO+Ti4qJ7771XmZmZevrpp9WiRYurEurp6emy2WySJE9PzxzLPT09rc+X/1+SNf+Vxo0bpxEjRlifz549qwoVKuTOggIAAAD4R3ikNgAAAAAAAPKzPPu4e0kqWbKk9d55SapRo4bS0tLk7++vxMREu2kTExOt98kHBgbmWB4YGGh9vrxMUo7vo/fw8FCJEiXsBgAAABRs6enpql27trZv326Ni4uLU6tWreTt7a2aNWtq8+bNdvN89dVXql27tmw2mx588EEdO3bMrnz27NkKDAxU8eLFFRoaaj3lSZLS0tIUGhoqX19fBQQEaObMmbd1+QAAAAAAAAA4R55N0m/atEl+fn52Fy6/++47+fn5qWnTptq5c6eMMZIuvb9+x44dCg4OliQFBwcrMjLSmu/kyZM6efKkgoODVa5cOVWsWNGuPDIyUhUrVswxSQ8AAIDCJS0tTT169NCBAwesccYYdezYUf7+/oqNjVXPnj3VqVMnnThx6Y7uEydOqGPHjurTp49iYmJUunRpdezY0eqzhoeHa+LEiVqwYIG2bt2q6OhojR492qp/1KhRio2N1datWzVv3jxNmjRJK1eudOyCAwAAAAAAALjt8mySvkmTJvLy8tKzzz6rw4cPa+PGjRo1apRGjx6trl276s8//9SwYcN08OBBDRs2TOfOndMTTzwhSRo0aJA+/PBDvf/++9q/f7+eeeYZdejQQVWqVLHKx4wZo+3bt2v79u0aO3ashg4d6szFBQAAQB5x8OBBBQcH6+eff7Ybv23bNv38889asGCBatSooXHjxqlx48ZatGiRJGnhwoVq2LChXnzxRdWqVUthYWE6fvy4IiIiJElz5szRsGHD1KFDBzVq1EgLFizQokWLlJKSonPnzmnhwoWaM2eOgoKC1KlTJ40ePVpz5851+PIDAAAAAAAAuL3ybJK+ePHi2rRpk3799Vc1bNhQoaGh6t+/v0aNGqUSJUros88+0zfffKMGDRooOjpan3/+uby9vSVJjRs31oIFCzRp0iQ1adJEd9xxh8LCwqy6R40apW7duqlTp056/PHH1bNnTw0fPtxZiwoAAIA8JCIiQi1btlRUVJTd+OjoaAUFBVl9TkkKCQmxpouOjlazZs2sMpvNpqCgIEVFRenixYuKiYmxKw8ODtb58+e1b98+7du3TxcuXFCTJk3s6t61a5cyMzNv16ICAAAAAAAAcAI3ZwdwLbVq1dKXX36Zbdl9992nPXv25Dhv79691bt372zLihQpolmzZmnWrFm5ESYAAAAKkEGDBmU7PiEhQeXKlbMbV7ZsWZ06deq65X/++afS0tLsyt3c3OTn56dTp07J1dVVpUqVkru7u928aWlpSkpKUunSpe3qTU9PV3p6uvX57NmzN7ewAAAAAAAAABwuz95JDwAAAOQlKSkp8vDwsBvn4eFhJcuvVZ6SkmJ9zqk8uzJJdsn4LFOnTpWPj481VKhQ4dYWDgAAAAAAAIDDkKQHAAAAboCnp+dVCfP09HTZbLbrlnt6elqfcyrPrkySVf/lxo0bp+TkZGs4efLkrS0cAAAAAAAAAIchSQ8AAADcgMDAQCUmJtqNS0xMVEBAwHXL/fz85OnpaVeekZGhpKQkBQQEKDAwUL/99psyMjLs5vXy8pKvr+9VsXh4eKhEiRJ2AwAAAAAAAID8gSQ9gDzFp7inTGZmrtWXm3UBAAq34OBg7dmzR6mpqda4yMhIBQcHW+WRkZFWWUpKivbu3avg4GC5urqqUaNGduVRUVEqWrSo6tWrp3vvvVdFixZVdHS0Xd2NGjWSqytddgAAAAAAAKAgcXN2AABwOW9Pd7m4uirus/eUmpRwS3V5+QWoSod+uRQZAKCwa968uSpUqKA+ffpo/PjxWr9+vb799luFhYVJkvr27avp06dr2rRpeuSRRzR58mRVqVJFLVq0kCQ999xzGjBggGrXrq3AwEANGjRI/fr1sx5n36tXLw0cOFBhYWGKj4/XjBkzrLoBAAAAAAAAFBwk6QHkSalJCUo9fcLZYQAAYClSpIjWrl2r0NBQNWjQQFWrVtXq1atVsWJFSVLlypW1atUqDRs2TJMnT1aTJk20Zs0aubi4SJK6d++u48ePa8CAAUpPT1eXLl30xhtvWPXPmjVLgwYNUsuWLeXj46NJkyapc+fOTllWAAAAAAAAALcPSXoAAAAgB8YYu89Vq1ZVREREjtO3a9dO7dq1y7F87NixGjt2bLZlNptNS5Ys0ZIlS24uWAAAAAAAAAD5Ai+4BABJmZnm+hM5oS4AAAAAAAAAAAAULNxJDwCSXF1d9M6yHYo/k3xL9QSW8dHgHg/kUlQAAAAAAAAAAAAoaEjSA8D/F38mWcfj/3B2GAAAAAAAAAAAACjAeNw9AAAAAAAAAAAAAAAOQpIeAAAAAAAAAAAAAAAHIUkPAAAAAAAAAHlcenq6ateure3bt1vj4uLi1KpVK3l7e6tmzZravHmz3TxfffWVateuLZvNpgcffFDHjh2zK589e7YCAwNVvHhxhYaGKiUlxSpLS0tTaGiofH19FRAQoJkzZ97W5QMAAChMSNIDAAAAAAAAQB6WlpamHj166MCBA9Y4Y4w6duwof39/xcbGqmfPnurUqZNOnDghSTpx4oQ6duyoPn36KCYmRqVLl1bHjh1ljJEkhYeHa+LEiVqwYIG2bt2q6OhojR492qp/1KhRio2N1datWzVv3jxNmjRJK1eudOyCAwAAFFBuzg4AAAAAAAAAAJC9gwcP6sknn7SS61m2bdumn3/+WTt37pS3t7dq1KihLVu2aNGiRZo4caIWLlyohg0b6sUXX5QkhYWFyd/fXxEREWrRooXmzJmjYcOGqUOHDpKkBQsWqE2bNnrjjTdkjNHChQu1ceNGBQUFKSgoSAcOHNDcuXPVtWtXh/8GAAAABQ130gMAAAAAAABAHhUREaGWLVsqKirKbnx0dLSCgoLk7e1tjQsJCbGmi46OVrNmzawym82moKAgRUVF6eLFi4qJibErDw4O1vnz57Vv3z7t27dPFy5cUJMmTezq3rVrlzIzM2/XogIAABQa3EkPAAAAAAAAAHnUoEGDsh2fkJCgcuXK2Y0rW7asTp06dd3yP//8U2lpaXblbm5u8vPz06lTp+Tq6qpSpUrJ3d3dbt60tDQlJSWpdOnSubV4Nywz08jV1cXh35uf8ZsBAJB3kaQHAAAAAAAAgHwmJSVFHh4eduM8PDyUnp5+3fKUlBTrc3blxphsyyRZ9V8pPT3druzs2bM3sVQ5c3V10TvLdij+THKu1ltQBZbx0eAeDzg7DAAAkAOS9AAAAAAAAACQz3h6eiopKcluXHp6umw2m1V+ZUI9PT1dvr6+8vT0tD5nN//FixezLZNk1X+lqVOnatKkSTe/QDcg/kyyjsf/cVu/AwAAwBF4Jz0AAAAAAAAA5DOBgYFKTEy0G5eYmKiAgIDrlvv5+cnT09OuPCMjQ0lJSQoICFBgYKB+++03ZWRk2M3r5eUlX1/fbOMZN26ckpOTreHkyZO5tKQAAAAFD0l6AAAAAAAAAMhngoODtWfPHqWmplrjIiMjFRwcbJVHRkZaZSkpKdq7d6+Cg4Pl6uqqRo0a2ZVHRUWpaNGiqlevnu69914VLVpU0dHRdnU3atRIrq7ZX1L28PBQiRIl7AYAAABkjyQ9AAAAAAAAAOQzzZs3V4UKFdSnTx8dOHBA06ZN07fffqvQ0FBJUt++fbVjxw5NmzZNBw4cUJ8+fVSlShW1aNFCkvTcc89p+vTpWrNmjWJiYjRo0CD169dPNptNNptNvXr10sCBAxUTE6M1a9ZoxowZGjp0qBOXGAAAoODgnfQAAAAAAAAAkM8UKVJEa9euVWhoqBo0aKCqVatq9erVqlixoiSpcuXKWrVqlYYNG6bJkyerSZMmWrNmjVxcXCRJ3bt31/HjxzVgwAClp6erS5cueuONN6z6Z82apUGDBqlly5by8fHRpEmT1LlzZ6csKwAAQEFDkh4AAAAAAAAA8gFjjN3nqlWrKiIiIsfp27Vrp3bt2uVYPnbsWI0dOzbbMpvNpiVLlmjJkiU3FywAAAByxOPuAQAAAAAAAAAAAABwEJL0AAAAAAAAAAAAAAA4CEl6AMhFPsU9ZTIzc7XO3K4PAAAAAAAAAAAAzsM76QEgF3l7usvF1VVxn72n1KSEW67Pyy9AVTr0y4XIAAAAAAAAAAAAkBeQpAeA2yA1KUGpp084OwwAAAAAAAAAAADkMTzuHgAAAAAAAAAAAAAAByFJDwAAAAAAAAAAAACAg5CkBwAAAAAAAAAAAADAQUjSAwAAAAAAAAAAAADgICTpAQAAAAAAAAAAAABwEJL0AAAAAAAAAAAAAAA4CEl6AAAAAAAAAAAAAAAchCQ9AAAAAAAAAAAFiE9xT5nMTGeHke/wmwEAHMXN2QEAAAAAAAAAAIDc4+3pLhdXV8V99p5SkxKcHU6+4OUXoCod+jk7DABAIUGSHgAAAAAAAACAAig1KUGpp084OwwAAHAFHncPAAAAAAAAAAAAAICDkKQHAAAAAAAAAAAAAMBBSNIDAAAAAAAAAAAAAOAgJOkBAAAAAAAAAAAAAHAQkvQAAAAAAAAAAAAAADgISXoAAAAAAAAAAAAAAByEJD0AAAAAAAAAAAAAAA5Ckh4A4HSZmSZP1gUAAAAAAAAAAJDb3JwdAAAArq4uemfZDsWfSb6legLL+GhwjwdyKSoAAAAAAAAAAIDcR5IeAJAnxJ9J1vH4P5wdBgAAAAAAAAAAwG3F4+4BAAAAAAAAAAAAAHAQkvQAAAAAAAAAAAAA8qTMTOPsEPIVfq/8gcfdAwAAAAAAAAAAAMiTXF1d9M6yHYo/k+zsUPK8wDI+GtzjAWeHgRtAkh4AUGD4FPeUycyUi2vuPSgmt+sDAAAAAAAAAPwz8WeSdTz+D2eHAeQakvQAgALD29NdLq6uivvsPaUmJdxyfV5+AarSoV8uRAYAAAAAAAAAAHAJSXoAQIGTmpSg1NMnnB0GAAAAAAAAAADAVXh+LwAAAAAAAAAAAAAADkKSHgCAW5SZafJkXQAAAAAAAAAAIO/hcfcAANwiV1cXvbNsh+LPJN9SPYFlfDS4xwO5FBUAAAAAAAAAAMiLSNIDAJAL4s8k63j8H84OAwAAAAAAAAAA5HE87h4AAAAAAAAAAAAAAAchSQ8AQB7hU9xTJjMzV+vM7foAAAAAAAAAAMCtKbSPu09LS9PgwYMVHh4uLy8vjRw5Ui+++KKzwwIAFGLenu5ycXVV3GfvKTUp4Zbr8/ILUJUO/XIhMgCOQh8VAAAAeQn9UwAA8pesG8FcXLlP+59wxm9WaJP0o0aNUmxsrLZu3apffvlFvXr1UqVKldS1a1dnhwYAKORSkxKUevqEs8MA4AT0UQEAAJCX0D8FACB/ye0bwQoDZ93sViiT9OfOndPChQu1ceNGBQUFKSgoSAcOHNDcuXPpYAIAAMAp6KMCAAAgL6F/CgBA/sWNYHlfoXzWwb59+3ThwgU1adLEGhcSEqJdu3Ypk3f3AsiHMjNNnqwLAHDj6KMCAJA35ddzpPwaN/IO+qcAAAC3T6G8kz4hIUGlSpWSu7u7Na5s2bJKS0tTUlKSSpcu7cToAOCfc3V10TvLdij+TPIt1VO9cmk980gDSS65E5ic8y4X/DOZmUaurrm3znO7PqCwoI8KAAVLfu0T5df+++2MO7fOtxzpdpzbOVJ+3Q4LGvqnAAAAt0+hTNKnpKTIw8PDblzW5/T09KumT09PtxufnHzppOzs2bNXTVuymJvS/TyuGv9PeHtcqjvDy1cXS6TdUl0ZXr7ZxpkT4if+yxH/P5eb8Uv/bBlSU84pPS3llr4vMyNdf/39txJ3bVT62T9uqS5J8ihxh/zvb3dD0+b33z+/x79+2wH9lnxr248klS/jo1bBVXPtghoX5/KWrO3JGO7Kuh3+SR/1n/RPryU39l2OlNv7SUf5p32Sm8G6dBzW59Xy6/p0xLrMrT6Wo9xZvqSaN7wr184HHOWfnHfcrNw433Kk3D63c6R/sj7pn95et/Ma6s3Kb8dIZ8qvx2dnckTf4Faw/d84tv9/Lq9v/xJt4Eax/f9zub3933Af1RRCK1asMGXLlrUbd/DgQSPJJCUlXTX9hAkTjCQGBgYGBgYGBgbJnDx50lHdtkLln/RR6Z8yMDAwMDAwMPxvoH96e3ANlYGBgYGBgYHh5ofr9VFdjCl8f2q6c+dONWvWTGlpaXJzu/QwgW3btql9+/b6+++/5XrFHXtX/hVoZmamfv/9d/n5+cnFJfcfG3b27FlVqFBBJ0+eVIkSJXK9/tuN+J2L+J2L+J2L+J0vvy8D8V+bMUZ//fWXypUrd1V/Cbfun/RRHd0/zSvyexvF/7AuCxbWZ8HBuiw4Csu6pH96e+X1a6i4tsKyHwCyw/aPwozt3/lutI9aKB93f++996po0aKKjo5WSEiIJCkyMlKNGjXK9sfy8PC46tFOvr6+tz3OEiVK5OsGRPzORfzORfzORfzOl9+Xgfhz5uPjc1vqxT/rozqrf5pX5Pc2iv9hXRYsrM+Cg3VZcBSGdUn/9PbJL9dQcW2FYT8A5ITtH4UZ279z3UgftVAm6W02m3r16qWBAwcqLCxM8fHxmjFjhsLCwpwdGgAAAAop+qgAAADIS+ifAgAA3D6FMkkvSbNmzdKgQYPUsmVL+fj4aNKkSercubOzwwIAAEAhRh8VAAAAeQn9UwAAgNuj0CbpbTablixZoiVLljg7lKt4eHhowoQJVz0eKr8gfucifucifucifufL78tA/HC2vNxHzQvYxgsO1mXBwvosOFiXBQfrErmF/mn+xX4AhRnbPwoztv/8w8UYY5wdBAAAAAAAAAAAAAAAhYGrswMAAAAAAAAAAAAAAKCwIEkPAAAAAAAAAAAAAICDkKQHAAAAAAAAAAAAAMBBSNLnAYsXL1blypVzbTpHWLx4sVxcXPT+++87O5Sblpd+z+txcXGRi4uLTpw4cVXZ/Pnz5eLiookTJzo+sH/owoULmjhxou688055eHioYsWKGjFihP766y9nh3ZT8lM7cHFx0ZNPPnnV+PzUDrIkJCSof//+CggIkJeXl2rVqqUZM2YoIyPjuvMaYzRv3jwHRHm1/N6OK1eubC3D5UNISMh153VxcdH27dtvf5A5uDx2V1dXFStWTA888IA2bdrktJhuVX5suyhcvvvuO+3cudOh37l9+3a5uLg49DvxPy1atHDKcax3797q3bu3w783P8tqn45oMxMnTlSLFi1u63fAsVinjrVu3TqVL19eNpvtqr7r9daFs/bLAADkNfRfAHu0ibyDJD1uyrJly3TXXXfpgw8+cHYohUbRokW1bt26q8avXr0631yQHjNmjMLDw/Xee+/p8OHDCgsL0+bNm7NNHucH+a0dLFu2TFu3bnV2GLfk5MmTuu+++xQXF6cVK1bo4MGDevnllzV37lw9+uijyszMvOb8X3/9tQYPHuygaK+W39vx7NmzlZCQYDdktzx5UVbsp06dUnR0tB544AG1b99eX331lbNDAwqkTp066ciRI84OA0A2aJ9A/vHyyy+rbdu2OnTokJo1a2ZXNnLkSK1atcpJkQEAkH9wzATs0SbyDjdnB4D858yZM9qyZYvCwsLUq1cvxcXFqUqVKs4Oq8Br1qyZ1q1bpyFDhljjzp49q6ioKNWvX9+Jkd24xYsXa9GiRXrooYckXbq7df78+WratKkSEhIUEBDg5AhvXH5sB5UrV9bgwYO1b98+ubu7Ozucm/L888/rzjvv1BdffKEiRYpIkqpUqaLGjRurVq1a+u9//3vNJLwxxlGhZiu/t2MfHx/5+/s7O4ybcnns5cqV0xtvvKGEhAQNHz5c33//vZOjAwoeZ+9vAeSM9gnkH8nJyQoJCVGlSpWuKitWrJgTIgIAIP/hmAnYo03kHdxJn4ccP35cLi4uOn78uDUuLz524tNPP5Wvr6+eeuoplStXzu4u4sqVK2vx4sXW5ysfoXjs2DG1atVKNptNderU0YwZM5z+uN7r/e6LFy9WixYtNGHCBJUqVUq+vr4aMWKEwy9uPfbYY4qIiNDZs2etcRs2bFDTpk1VvHhxa9z58+c1YsQIBQYGqmjRoqpcubLeffddSdJHH30kPz8/u8eCh4eHq2LFig5ZHldXV23dutXubufGjRvrwIEDKlWqlNLT0zV06FCVKlVKpUqV0tNPP63ff/9d0v/W08cff6zAwED5+vpq6NChN/SI89vheu1g9uzZqlu3rry9vdW+fXslJiZKutQmKleurEGDBsnHx0evv/66w2J+9dVXFR8fr+nTp+c4zalTp/TEE0+oZMmSKlWqlF544QWlp6crMzNTgYGBCgsLs6Y1xqh8+fJaunSpI8LX6dOntW7dOo0ZM8ZK0GepWLGievfurffee0+S9MUXXygoKEg2m0316tXTli1bdPz4cbVs2VKS8x6/nhvtWLq0jY0ZM0YBAQGqX7++0y+2G2P0yiuvqFy5cvL19dUjjzxy1WP9IyIidPfdd8tms+mJJ57QH3/84aRo/6d///764YcfdPToUf3555/q2bOnSpQooXLlyun5559XamqqNW1MTIxCQkJks9lUrVo1LV++3ImR29uxY4cVm7e3tx5++GElJCRIyjvHMBQuLVq00C+//KI+ffpYr5u43JWPJ1+9erVq1qwpm82m++67TxEREVbZvn371KRJE9lsNgUGBmry5MlW2dmzZ9WjRw8VL15c1apVU0xMjN33XKtt3H333Zo1a5bd9HXq1MkXr7C5VfXq1dPcuXOtz61bt1bz5s2tz++++65CQkJ08uRJPfroo7LZbKpcubImTZqkixcvWtOtXr1a1apVk7e3t4YMGWJX1rt3b40YMULdunWTzWZThQoV9OGHH1rl1+rzSdJbb72lSpUqydPTUw0bNlRkZKRV9s0336h+/fry8vLSE088oZSUFKvMGKPXXntNVapUkbu7u8qVK6dJkyZJurQ9uLm56ddff7Wm3717t2w2W7599dLNuLx9ZrXD+fPnKzAwUMWKFVOfPn2Unp4uKftz0cvP91q0aGH9AWXFihX1119/6eDBg1a7e/DBB/Xbb7/Zzb9w4ULdc889cnd3V6lSpTR48GBdvHhRJ0+elKurq/bs2WNNe+bMGbm5ueno0aO37ffIr7LOjTZs2KDKlSurWLFiGjp0qH744Qc1bNhQ3t7e6tChg7VtL168WDVq1JCXl5caNmyor7/+2qqrcuXKmjdvnoKDg+Xp6al7771Xu3fvtspZp85TuXJlHT9+XH379rWOp6+88oruuOMODRky5Ko2eq39cl6+TgDAXk59sOxeeXblay2ut7+//DrCtm3bVL58eb311lvy8/NT2bJlNWXKFLv6FyxYoCpVqqhYsWJq0aIFf+COPCGn87wLFy6oX79+KlWqlIoVK6ZHH31U8fHxkq7u1+bUfwEcLaftOet63pQpU3THHXfI399fH374oVauXKlKlSrJ19dXY8aMseq5kbzKtfqR2V1Ll659jo3cQZIe/9jy5cvVvn17ubq66tFHH9UHH3xwQyduGRkZ6tChg3x9fRUbG6tx48blmwa9c+dOHT58WDt27NDcuXM1Z84chz8iuU6dOgoMDNQXX3xhjVu9erU6duxoN93UqVO1YcMGhYeH6/Dhw+rVq5eGDBmi06dP67HHHlNqaqrdI89XrFihbt26OeRR20OHDtXbb79tJanDw8OVmpqqmjVrqmjRonrppZcUExOjzz//XNu2bVNycrIef/xxuzomTZqkTz75RKtXr1Z4eLgmTJhw2+POzvXawYQJEzR69GhFR0crJSVFXbp0scp++eUXpaWlaffu3erRo4fDYg4MDNSkSZM0ZcoUxcXFXVV+/vx5Pfjggzp37pwiIiK0YsUKbdiwQaNHj5arq6sef/xxu8fgREdHKykpSY899phD4t+zZ4+MMWrUqFG25SEhIdq3b5/27dunRx55RJ07d9a+ffvUo0cPPfbYYypatKjCw8MlXXqvfZMmTRwS9+Vyox1n+eijj7R582YtXrzY6Y/Knzt3rj766CN9/PHHio6OVtmyZdWmTRtduHDBmuadd97RW2+9pW+++UaHDx/W8OHDnRjxJTVr1pR06eJzaGiokpOTtWPHDq1Zs0YxMTHWEw/OnDmj1q1b695779XevXv10ksvqVevXtq3b58zw5d06e6q9u3bq02bNjpw4IA2b96so0ePaurUqdY0eeEYhsJl1apVKl++vGbPnq05c+Zcc9p9+/apV69e+s9//qP9+/fr6aefVrt27awEzjPPPKP69evrwIEDev/99/X666/r888/lyQNHDhQP/74oyIiIvT2229r5syZVr3Xaxs9evTQypUrrekPHTqkI0eOqHPnzrn9c+Q5bdu2tf5Q7cKFC4qOjlZMTIy1z/7yyy/Vtm1bde7cWWXKlNHevXu1ePFiffzxx3rttdckXdpvPvHEExo0aJB2796tCxcu2CXSpUvHhgYNGuiHH35Qly5dNGDAACUnJ0vSNft8e/fu1ahRozRv3jz9+OOPatq0qR5//HFlZmbq119/VYcOHdS6dWt99913qlmzpj799FPrOz/44APNnj1bCxcu1JEjR/Tyyy9r4sSJ2rNnj5o0aaLAwECtXr3amn7FihVq37693R/KFXTZtc+VK1dq06ZNWr16tT799FO7P8q8nrCwMC1dulSrV6+Wu7u72rdvrzvvvFN79uxR165dtWDBAmvaiIgIvfDCC3rttdd05MgRzZ8/X++//77Wrl2rChUqKCQkxK5dhoeHq379+qpatWru/QAFzLRp07Ru3Tq99957euutt9SpUydNnTpVmzdvVlRUlBYuXKjFixdryJAhGjdunL777ju1atVKDz/8sHXRWrp07jJ27Fjt379fPj4+euGFFyRdutjHOnWemJgYq71m7et27Nih2NhYDR061G7a6+2X8/J1AgD/Y4y5Zh/sWm5kf3/ldYTTp0/rgw8+0JdffqkFCxbojTfesG5+WL9+vSZOnKi3335be/fuVdOmTdWyZcs88Qf3KLyudZ43d+5cRUREaPPmzYqNjdVff/2V7bWna/VfAEe63nWLqKgoHTt2TDExMerRo4cGDhyoOXPmaP369Zo1a5beeOMN7d27V9K1z7Gz5NSPPHDgQLbX0hMTE695jo1cYuB0YWFhplKlSiYuLs5IMnFxcVbZhAkTTPPmze2mc6YTJ04YFxcXs2rVKmOMMV9++aWRZL7++mtjjDGVKlUyYWFh1vTbtm0zWZvZpk2bTLFixUxycrJVPnbsWKct0z/53V1dXe3irl+/vpkyZYrDYpVktm3bZoYNG2aeeuopY4wxaWlpxsfHx5w+fdo0b97cTJgwwRhjzOrVq80333xjzZuWlma3jp544gnz7LPPGmOMOXfunPH29jaxsbEOW5alS5eaJk2aGFdXVyPJFC9e3CxatMicO3fOuLu7m/3791vT/vHHH8bV1dXs37/fWk9r1qyxyhctWmRKly5tMjMzHRa/MTfWDoYNG2ZNf+zYMSPJfP/991abOHTokENjztqGMjIyTN26dU2HDh2MMfb7lbVr1xqbzWZ+//13a76NGzcaNzc389dff5moqCjj4eFhzp49a4wxZsSIEaZz584OW4alS5caSebChQvZlm/atMlIMr1797bab5b//Oc/5tChQ3b7JEfLzXZcqVIlM2bMGIfGX6lSJePh4WG8vb3thr///tuUL1/erFu3zpo2IyPDlC5d2honycydO9cq3759u3Fzc7O2JUfEfvmxKcuFCxeMJPPqq68aV1dX8+eff1pl+/fvt8bNmTPHVKlSxVy8eNEqnzlzpomKinJE+NnKarsJCQlmxowZdvvBsWPHmgcffNCaztnHMBROWe0uu/1ur169TK9evYwxxjz99NNmxIgRduWdO3e2xpUoUcKMHz/ean87d+40CQkJ5s8//zRFihSx9ovGGPPOO+9Y33W9tnHw4EHj4uJiTp48aYwxZuLEidaxsaD78ssvrf5TVFSUqVevnilXrpyJjo42Fy9eNH5+fmbatGmmdOnSdvu9devWmZIlSxpjjBk5cqT1WxpjzPnz5025cuWs41ivXr1Mw4YNrfLk5GQjyezYseO6fb5Vq1YZDw8P8/333xtjjPn777/NV199ZS5cuGDmzp1r7rrrLrv12qhRI2t72rp1q/nss8/sltff39988MEHxhhjRo8ebVq1amWVValSxaxcufJWfs586cr2efjwYausY8eOZuDAgcYY+3OiK+c1xpjmzZubbt26WWWfffaZKV68uPn777+tcY8//rhVR2xsrPn444/t6gsODjaTJ082xhgzb948U7VqVausRYsWZsaMGbe8vAVR1rnRpk2brHFlypQx48ePtz4/8cQTpn///qZ+/fpm3LhxdvMHBwebsWPHGmMurdORI0daZWvXrjVFixY1xrBO84KsNpe1zjdu3GiVXd5Gr7dfzuvXCQBc8tVXX+XYB8vuuvDl1xFuZH9/+XWErH7Ad999Z417+eWXTYMGDYwxxoSEhJi33nrLrr6goKCrxgGOdK3zvBdeeMHUrVvXJCUlGWOMOX78uNm9e7cxxv6Yeb3+C+Ao19qew8LCjJubm9UPP3jwoJFktmzZYk1bpkwZ8/HHH99wXiWnfuTw4cNzvJZ+vXNs3DrupMc/snz5cnl6eqpt27aSLj1W6Y477tCSJUuuO+/+/ftVrVo1lShRwhrXuHHj2xZrbipbtqxd3CVKlLC7Q9RRHnvsMW3cuFEZGRnasmWL6tSpozJlythN07FjR6WmpurFF19U+/btrUdhZT2yp0ePHlqzZo0yMjK0YcMGlStXTg0aNHDYMjz11FPasWOHzpw5o48++ki1atVSaGioYmJidP78eTVu3FjFihVTsWLFVL58eWVmZurIkSPW/A888ID1/4YNG+rXX3+96pGLt9uNtIPL46xSpYpKliypQ4cOWeOc9ZqHIkWK6L///a82bNigNWvW2JUdOnRI1apV0x133GGNa9KkiTIyMnT06FEFBwcrICBAGzZskHTpTqzu3bs7LPaSJUtKkvXqgCv93//9n1V+5Tb9yiuv6J577rm9Ad6g3GjHknO2ocmTJ+u7776zGzIzM3Xq1Cl169bNars+Pj5KSkqya7v33Xef9f+goCBru3KmrNcO1K1b13qlQ9YyNG7cWJmZmTp69KgOHz6s+vXry9X1f92mESNGKDg42FmhW/z9/dWrVy+9+eabeuaZZ9SwYUPNmDHDblvJK8cwIDuHDh3S3LlzrbZXrFgxrV+/3tp/vPTSS3r11VcVEBCg0NBQpaeny9/fX0eOHNHFixd17733WnVd/qSV67WNGjVqqG7dutYdnitWrHDoMc2ZmjZtqnPnzunAgQP6+uuv1bRpUwUHBysyMlJ79+6Vq6urbDabkpKSVKJECWu9dOvWTb///ruSkpJ08OBBu9++aNGidp+lS68UyJK1D7pw4YKOHTt2zT5f27ZtVadOHdWpU0dBQUGaMWOGatSoITc3Nx08eFD16tWzu7Pz8vXesmVLlSpVSuPGjVPHjh1VqVIlJSYm2vWDt2/frqSkJMXExOi3335T+/btb8OvnL/cdddd1v99fHyUlpZ2w/Ne3h85ePCg7r77bnl7e1vjLl8/DRo0UL169TRhwgR17dpV1atX165du6z18/jjj+v48eP67rvvdPr0aUVGRqpbt263sGQF35133mn938vLy259eHl5KT09XYcOHdL9999vN1/jxo3tzk2ubK9Z/QTWad6T0znA9fbLef06AYBLDh06dM0+2PXmvd7+/sp9SLFixVSvXj3rc8OGDa3pDx06pNGjR9v10/ft22d3ng842rXO8/r376+EhAT5+/urTZs2+vzzz1WjRo2r6rhe/wVwlOtdtyhbtqzVD/fy8pKkbPv71zvHzpJTP/Lw4cM5Xku/3jk2bh1JeidITEy0axzGGLm5uWX7GDFnvW87J8uWLVNqaqpKlCghNzc3eXp66o8//tCnn36q1NTUq5bh8vjd3Nyueiz+lZ9vp1v53d3d3a+axpGxZwkJCZEkRUZGas2aNerUqdNV0/znP//R008/raJFi+qZZ55RdHS0XXm7du2UkZGhiIgIrVy50mEXSfbv368XX3zR+uzn56cnn3xSERERKl++vL799ltJl5bt8gTgTz/9pDZt2ljzFS1a1Pp/1sHg8sSZI1yvHVwZZ1asl8fp6enp0Jgv16RJE/Xt21dDhw7VuXPnrhlT1m+c9W+3bt0UHh6u3bt369dff3Xohe2GDRuqSJEidu/IvFxsbKzq1q0rDw8Ph8V0M3KjHUvO2YbKlCmjqlWr2g1Z28ann35q13YPHz6sPn36WPMWKVLE+n9mZqak7PetjrR//35J0tGjR+Xj43PVHyD89NNP1us4nC2nY1h8fLzq1KmjrVu3qkGDBnrzzTft9rVS3jmGoXC6Xj8rIyNDY8aMsWt7Bw8e1Pz58yVJY8aM0c8//6wxY8bo2LFjevDBB7Vw4UJr/su35cu39RtpGz169FB4eLgOHTqkuLg4h72+xdk8PDzUrFkzbd++XV9//bVCQkIUEhKiHTt2aMuWLWrTpo0uXryoe+65x2697N+/Xz/99JN8fHwkXb0fuXJfk9O+J2v959Tns9ls2rVrl7Zu3aoWLVooLCxMQUFB1qNar/W9CxcuVKtWrZSWlqYuXbpoy5YtKl++vFV+7733qmrVqlqzZo1Wrlypxx57zKl9srzi8mO09L/f+EbOk678/a61fjZt2qQGDRooMTFR7dq108qVK+3+sLVUqVJq1aqVwsPDtWrVKgUHB9utP1zNzc3N7nN250U59fEvv7B2rT4Z6zRvudY+61rrKq9eJwBgLyMjI8c+WKlSpbKdPsuN7O+vnObK48jl164yMjI0e/Zsu1h+/PFHjR8//paWEbgV1zrPq1Wrlo4fP66PPvpIAQEBGjdunNq0aXPV8fF6/RfAUa533eLKfbSUfX//eufYWXLqR17ruuf1zrFx60jSO8GMGTM0YsQI63NycrJKlSplnUD99ddfVtmxY8ccHl9Ojhw5or179+qtt96ya+zLly/X2bNnrfcQ5hR/rVq19NNPP9mV55Rsux3y6+9+OTc3N7Vv317r1q3T+vXrs03uzZ8/X3PnztW0adPUrVs3Kwmb1SHx8PBQ586dtXr1am3evNlhd41lZGRo1qxZ1ntSsri7u8tms8nT01NFihRRUlKSlfwrUaKEhg8fbvce7u+++876f2xsrMqVKyc/Pz+HLIN0Y+3gyjiPHj2q5ORk1a1b12FxXs/rr7+uc+fOacaMGda46tWr68iRI/r999+tcVFRUXJzc7PusOrevbs2b96slStX6tFHH5XNZnNYzKVLl1anTp30yiuvXPXXeidPntT777+vfv366e67777qXeFNmjTR8uXL88Q7FXOjHeclvr6+KlOmjBITE622W7FiRY0ePVqHDx+2pvv++++t/3/77bdyd3dXlSpVnBGyZdGiRWrQoIH+9a9/KTk5WS4uLtYypKamatSoUUpPT9fdd9+t/fv32/3+3bp10/Tp0x0Wa07HsNWrV6tkyZL67LPPNHToUDVt2lTHjh3Lk9sKCpes/e31+lnVq1dXXFyc3R//vPvuu9q4caPS0tI0dOhQubu7a8SIEdq2bZv69++v8PBwVa9eXUWLFlVMTIxV1+V9jBtpGz169FB0dLQ++OADtW/fXsWKFbttv0dek/Ve+qioKDVt2lRNmzbVjh07tGnTJv3rX/9S9erVdeLECZUuXdpaL3FxcZowYYJcXFxUu3Ztu98+MzPzqmNvTu66665r9vmioqI0depUtWzZUrNmzdLhw4eVlpamyMhI1a5dW3v27LHrB1y+3ufPn6+XX35Zb775pnr27KlSpUrp9OnTduv9ySef1Pr167Vhw4ZC8/SEK91of+jKc7u///5bZ86cyXH62rVr68iRI0pOTrbGXb5+3nvvPfXt21cLFixQaGioatSooZ9//pn1c5tVr179qoRsdHS0qlevft15Waf5x/X2y3n1OgEAe9fqg7m5udkdl40xiouLs5v3n+7v//zzTx0/ftz6nHXzQ1Z9p06dsuunT5kyJdubCABHudZ53gcffKD169fr8ccf15IlS/TFF18oMjLyqv7rjfRfAEfIrWt61zvHvp5rXUu/kXNs3BqS9E7QrFkzbd26VV999ZX279+vd955R61bt1bZsmVVoUIFTZ8+XceOHdPixYutx0rnBcuWLVPJkiXVv39/1a5d2xq6deummjVrasmSJWrUqJHef/99/fDDD9q+fbtmzpxpzf/QQw+pQoUK6tevnw4dOqSVK1dqzpw5Dkua5dff/UqPPfaYFi5cqLJly2ab4PLz89P69et17NgxRUZGqmfPnpKk9PR0a5oePXro/fffV/ny5VWrVi2HxB0UFKT27dvrscce08cff6zjx48rOjpagwYNUlpamnr37q1+/fpp0KBB2r59uw4ePKhnnnlGR48etVvOoUOHKjY2Vl999ZVefvllDR482CHxZ7mRdiBJc+bM0bp167R//3717dtXrVu3tnuMpLP5+fnp9ddftzsZa926te6880717NlT33//vbZt26bnn39eTz75pHx9fSVdugOtXLlymjt3rlPurpgzZ45+//13tWvXTpGRkTpx4oRWr16tli1bqkWLFnruuec0cOBAffPNN5o1a5aOHj2qqVOn6sCBA2rWrJn1iKDdu3f/o0e55rbcaMd5yYgRI/Tvf/9b69ev108//aRnn31WO3bssHvFwL///W9t2bJF0dHReuGFFzRgwACH/pFHcnKyEhMTlZCQoO+//17Dhg3T8uXLNXPmTNWoUUP/+te/9NRTTykmJkZ79uxR79699ffff8vX11dPPfWUkpKSNHr0aP30009avHix1q5dq9atWzss/pyOYX5+fjpx4oS2bNmiY8eO6fXXX1d4eHie3VZQeHh7e+vHH39UYGCgvLy8NGXKFMXFxWn69Ol2CZ7hw4dr+fLleuutt/Tzzz9r9uzZmjVrlqpVqyZPT09FRkbq+eef1+HDhxUbG6uvv/5a9evXV4kSJfTMM8/o+eef165du7R9+3ZNnDjRqvdG2kbFihV1//33a/bs2YUuGdGmTRutX79ePj4+KleunOrXr6+UlBRFRESobdu2atOmjSpVqqSnn35a33//vb755hv1799fNptNRYoUUb9+/RQbG6spU6bo8OHDGjlypH755Zcb+u7ixYtfs8/n5eWlSZMmaeHChTp+/LiWL1+uv//+W3Xr1lX37t2VkpKioUOH6vDhw5o+fboiIyOtuv38/PTVV1/pyJEj2r17t7p166YLFy5c1Q/etGmTEhIS7O4qKEyy2uflf5iZnUaNGmnfvn369NNPdeTIEfXv3/+qu+4v16pVK1WsWFGhoaE6dOiQFi9erE8++cQq9/Pz086dO/X999/rwIED6t27txISEuzWT8eOHXXkyBFt375djz/++K0vLDRixAi9/fbb+vDDD3XkyBGNHTtW+/bt07PPPnvdeVmn+cf19st59ToBAHvX6oPdd999+v333/X222/r2LFjGjFihN2x/Gb39/369dMPP/yg8PBwvfXWW9Z1thEjRmj27Nn68MMPrSdbrVixItvHhwOOcq3zvOTkZA0dOlRbtmxRXFycPvroI5UvX/6qp1DcSP8FcITcuqZ3vXPs67nWtfQbOcfGLXLEi+9xtf/85z/G39/fFC9e3PTu3ducO3fOGGPM5s2bTfXq1Y2Hh4d5+OGHzeuvv26aN29ujDEmLCzMVKpUyWkx33PPPeaFF17Ituztt982rq6uJjIy0jRv3ty4u7ubunXrmk8++cRcvpkdOnTIhISEWOVDhw411apVc9Qi5Nrv3rx5czNhwgSHxS3JbNu2zRhjzF9//WU8PT3tvv/yeCIjI02dOnWMp6enueuuu8y0adPMfffdZ1577TVr+oyMDFO6dGnz6quvOmwZjDHm3Llz5qWXXjJ333238fDwMCVLljQ9evQwv/zyi1U+aNAgU7JkSVO8eHHTvn17c+zYMWOMMXFxcUaSee2110yZMmVMqVKlzPjx483Fixcdugw30g7c3NzM8OHDTc2aNY23t7d54oknzO+//26MMWbbtm3GGbvey7ehLJmZmaZJkyZ22/exY8fMww8/bLy8vEyZMmXM8OHDTWpqqt18EyZMMD4+PiYtLc0BkV/t9OnTZsiQIaZChQrG09PT1KxZ00yfPt1cuHDBmmb9+vWmVq1axsPDwwQFBZmIiAhjjDFpaWmmdevWxt3d3YSHhzs07txsx5UqVTJhYWEOjf9a35mRkWH+/e9/G39/f2Oz2UyzZs3M3r17rXJJZubMmaZSpUrG29vb9O3b16SkpDgmcHMpdklGknFxcTFlypQx//rXv8w333xjTfPrr7+a7t27m+LFi5s77rjD9OjRw/z2229W+c6dO819991n3N3dzT333OPw7ceY7I9hGRkZZuDAgcbX19fccccdpk2bNubNN980JUqUMGlpaXniGIbC6Z133jHe3t6mU6dOZunSpaZixYrGy8vLPPXUU2bkyJGmV69e1rTLli0z1atXN+7u7qZGjRpmxYoVVtlPP/1k2rRpY7XNAQMGWPuPlJQUExoaaooXL24qVqxoZsyYYR1jr9c2srz11lumePHiVx3rCoPy5cubnj17Wp9bt25tGjRoYH3++eefrT5B6dKlzXPPPWe37968ebOpVauW8fT0NN27dzcdOnSw9i29evWyW8fG2B8Hr9XnM8aYDz/80FSrVs14eHiYatWqmWXLllllu3fvNvfdd5/x8PAwrVu3Nn369LG+69ChQyY4ONh4enqaihUrmlGjRplOnTqZ/v3728USFBRknn322Vv5+fK1rPZ5xx13XNUvvXzdZWZmmlGjRhlfX1/j5+dnpkyZYpo3b271B7I7nhw7dsw8+OCDxtPT09x3333mxRdftM6r/u///s+0adPG2Gw2ExAQYEJDQ82gQYNMmzZt7Oro3LmzadWq1e1Y9AIj69woLi7OGndlX+3ydTlnzhxTqVIl4+HhYe6//36rb5zdfFeer7BOnStr/WS3zidMmGCtC2OuvV/Oy9cJANi7Vh9sxowZpkyZMqZEiRJm6NCh5umnn7Y7Ft/M/n7mzJnGx8fHBAYGmrffftsulqz6PD09TYMGDcyWLVtu67ID13O987zRo0ebgIAA4+HhYR544AGzZ88eY4z9MfNG+y/A7Xat7Xn+/Pl21/Ou1/+/kbzKtfqROV1Lv9FzbNw8F2N4LgEc48yZM9q7d6/atm1rjZs+fbo2bNig7du3Oy+wQujs2bPy9/fXDz/8oDvvvNPZ4dyQ48ePq0qVKoqLi1PlypWdHc41Va5cWRMnTlTv3r2dHQoAALiGf//73zp16pT1JBwUfJmZmapUqZI++OADtWzZ0tnhIBsPPPCAnn32WfXp08fZoSCXsE7zh/x4nQDAzdu+fbtatmzJI4sBAHAiN2cHgMLl0Ucf1ezZs/Xwww/rp59+0uzZs/XSSy85O6xCwxij8PBwhYeHq0mTJpx4AwCAQmn//v3au3ev5s2bp/Xr1zs7HDjIhg0btGnTJnl5eal58+bODgdX2LZtm3bs2KGDBw/yWPQCgnWaP3CdAAAAAHAOkvRwmDJlymjFihUaP368hg8frrJly2rIkCF67rnnnB1aoeHi4qLRo0erSJEiXJAGAACFVmxsrJ5//nkNHjxYISEhzg4HDjJjxgwdPnxYn3zyiVxdXZ0dDq7wwQcfaO3atXr33XdVrFgxZ4eDXMA6zR+4TgAAAAA4B4+7BwAAAAAAAAAAAADAQbh9AAAAAAAAAAAAAAAAByFJDwAAAAAAAAAAAACAg5CkBwAAAAAAAAAAAADAQUjSAwAAAAAAAAAAAADgICTpASCPi4+PV9euXVWyZEkFBgZqxIgRSktLs8p3796txo0bq1ixYgoODlZ0dLQTowUAAEBhcPToUbVt21bFihVTxYoVNX36dLvyuLg4tWrVSt7e3qpZs6Y2b97spEgBAABQGFzvGmqW5ORkBQYGavHixY4PEgAuQ5IeAPIwY4y6du2qlJQUffPNN1q+fLnWr1+v8ePHS5LOnDmjhx56SHXq1FFsbKy6deum1q1b68SJE06OHAAAAAVVZmam2rdvr9KlS2vv3r2aP3++Xn31VX388ceSLvVhO3bsKH9/f8XGxqpnz57q1KkTfVQAAADcFte7hnq5MWPG6P/+7/+cECUA2HMxxhhnBwEAyN6PP/6oGjVqKDExUWXLlpUkLVu2TCNHjlR8fLxmzJih//73vzpy5IiKFCkiSWrXrp3uvfdeTZ061ZmhAwAAoIBKSEjQsGHDtHDhQhUvXlyS1LlzZ/n7+2vevHnaunWrHn30UZ0+fVre3t6SpFatWikkJEQTJ050YuQAAAAoiK53DTVLZGSk+vTpo7///ltTp05V7969nRQxAHAnPQDkCe+//748PDx09OhRSZc6lp6entq1a5e++OILq3OZJTk5WZJ07NgxNWjQwErQS1LdunUVFRXluOABAABQIOXUR/3222/1ySefqHjx4jLGaMeOHfr666/VokULSVJ0dLSCgoKsBL0khYSE0EcFAADALbnZa6iSlJ6ern79+umdd96Rh4eHQ+MGgOyQpAeAPKBv375q3Lixhg8fLmOM+vfvr86dO6tXr15q27atNV1mZqbmzp2rhx56SJJUtmxZu78GlaSTJ0/qt99+c2j8AAAAKHhy6qM+9thj1jSVK1dWSEiIGjdurC5duki6dKd9uXLl7OoqW7asTp065dD4AQAAULDc7DVUSXrttddUv359tWnTxhmhA8BV3JwdAABAcnFx0bvvvqt69erp6aef1uHDh7Vq1aqrphs9erT27NmjmJgYSVKXLl30yiuv6L333lOfPn20ZcsWrV27VoGBgY5eBAAAABQwN9JHDQ8PV2JiogYNGqThw4frrbfeUkpKylV3J3l4eCg9Pd2R4QMAAKCAudlrqAcPHtT8+fO1f/9+R4cMADniTnoAyCOqVaumsWPH6uOPP9aMGTNUqlQpu/IxY8Zo9uzZWrp0qWrXri1Jql27tt577z2NGDFCHh4eeumll/Tcc8+pRIkSzlgEAAAAFDDX66M2bNhQHTp00JtvvqkFCxbo/Pnz8vT0vCohn56eLpvN5sjQAQAAUAD902uoxhj169dPkydPvupx+ADgTCTpASAP2bdvn4oUKaKtW7fajX/++ec1c+ZMLV261HqMaJY+ffrozz//1KlTp7R79265uLiocuXKDowaAAAABdmVfdTTp09rzZo1dtPUrFlT58+f19mzZxUYGKjExES78sTERAUEBDgqZAAAABRg/+Qa6okTJ7Rz5069+OKLKlasmIoVK6YTJ05o4MCBateunTPCBwBJJOkBIM9Yu3atNm3apM8++0wfffSR1cmcNGmS5s+fr+XLl6t79+5282zbtk3du3dXkSJFFBAQIGOMNm7cqJYtWzpjEQAAAFDAZNdHjYuLU+fOnRUfH29Nt3v3bpUuXVqlSpVScHCw9uzZo9TUVKs8MjJSwcHBzlgEAAAAFCD/9BpqYGCgfvrpJ3333XfWUK5cOU2ePFkLFy501mIAgFyMMcbZQQBAYffXX3+pZs2aeu655zRu3Di9+OKLWrdundatW6c6depo3LhxGjx4sN08/v7+io+PV7Vq1TRjxgy1bdtWM2bM0Lp16/Tjjz+qWLFiTloaAAAAFAQ59VG/++47tWjRQiVLltSbb76p48ePq2/fvho3bpyGDh2qixcvqm7duqpTp47Gjx+v9evXa8qUKTpw4IAqVqzo7MUCAABAPnWz11CvVLlyZU2cOFG9e/d2UOQAcDWS9ACQBzz//PPatGmTfvjhB7m7u+uvv/5S9erVlZiYqJx201njN2zYoJEjR+rEiRMKDg7WO++8o3vuuceR4QMAAKAAyqmP2rt3bw0ZMkRDhgzRli1b5O3trSFDhmjcuHFycXGRJB09elShoaHatWuXqlatqtmzZ6tVq1ZOXiIAAADkZ7dyDfVyJOkB5AUk6QEAAAAAAAAAAAAAcBDeSQ8AAAAAAAAAAAAAgIOQpAcAAAAAAAAAAAAAwEFI0gMAAAAAAAAAAAAA4CAk6QEAAAAAAAAAAAAAcBCS9AAAAAAAAAAAAAAAOAhJegAAAAAAAAAAAAAAHIQkPQAAAAAAAAAAAAAADkKSHgAAAAAAAAAAAAAAByFJDwAAAAAAAAAAAACAg5CkBwAAAAAAAAAAAADAQUjSAwAAAAAAAAAAAADgICTpAQAAAAAAAAAAAABwkP8HPFXTlMQ7y+UAAAAASUVORK5CYII="
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['x30'].value_counts()"
      ],
      "metadata": {
        "id": "_1LSKgy80ENF",
        "outputId": "9410f986-e61a-449f-877f-e5cebb6e0865",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "x30\n",
              "wednesday    101535\n",
              "thurday       29429\n",
              "tuesday       27954\n",
              "friday          564\n",
              "monday          488\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# thursday is incorrect\n",
        "df['x30'].replace(to_replace = 'thurday',value='thursday')\n",
        "days = ['monday','tuesday','wednesday','thursday','friday']\n",
        "d_heights = []\n",
        "for i in days:\n",
        "    x = df['x30'].to_list().count(i)\n",
        "    d_heights.append(x)\n",
        "plt.bar(x=days,height = d_heights)"
      ],
      "metadata": {
        "id": "3hFwgArL0GAB",
        "outputId": "9d285065-1381-461e-e962-cdb4be7a3332",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 5 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 550x600 with 1 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['x32'].value_counts()"
      ],
      "metadata": {
        "id": "WErTHaJ70Ia2",
        "outputId": "522a194e-184a-4a12-ba97-34bf410dfca1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "x32\n",
              "0.01%     40767\n",
              "-0.01%    34094\n",
              "0.0%      33923\n",
              "-0.0%     30492\n",
              "-0.02%     9924\n",
              "0.02%      7987\n",
              "-0.03%     1727\n",
              "0.03%       855\n",
              "-0.04%      138\n",
              "0.04%        55\n",
              "-0.05%        6\n",
              "0.05%         1\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['x37'].value_counts()\n"
      ],
      "metadata": {
        "id": "r98Zehw50LS1",
        "outputId": "d95f782c-8102-4810-8b25-f3fab1f1d37e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "x37\n",
              "$-311.26     6\n",
              "$-336.77     6\n",
              "$237.4       6\n",
              "$72.42       6\n",
              "$341.26      6\n",
              "            ..\n",
              "$-505.21     1\n",
              "$770.07      1\n",
              "$74.62       1\n",
              "$-1082.96    1\n",
              "$-1229.34    1\n",
              "Name: count, Length: 129198, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### x32 and x37 are actually numeric with string format (even though x32 has few \"levels\" or possible values)\n",
        "### x32 is in percentage, but don't think it needs to be transformed to proportion since data will be scaled later (will double check, but should make no difference)\n",
        "\n",
        "df['x32'] = df['x32'].transform(lambda x: float(str(x).replace('%','')))\n",
        "df['x37'] = df['x37'].transform(lambda x: float(str(x).replace('$','')))"
      ],
      "metadata": {
        "id": "-8HSIli70VDX"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#all significanlty less than 5%, should be no issue imputing,\n",
        "#imputing categorical features with modes\n",
        "# imputing continent with mode, then dates by mode grouped by continent\n",
        "\n",
        "print('imputing continent with mode: {}'.format(df['x24'].aggregate(pd.Series.mode)))\n",
        "df['x24'] = df['x24'].transform(lambda x: x.fillna(pd.Series.mode(x)[0]))\n",
        "\n",
        "print('imputing month with mode by cont: {}'.format(df[['x24','x29']].groupby(by='x24').aggregate(pd.Series.mode)))\n",
        "idx_29 = df.loc[df['x29'].isna(),:].index #saving NAs indices to quick check what they've been imputed with\n",
        "df['x29'] = df[['x24','x29']].groupby(by='x24').transform(lambda grp: grp.fillna(pd.Series.mode(grp)[0]))\n",
        "\n",
        "# will fix index showing on print later\n"
      ],
      "metadata": {
        "id": "qyAc5R1u209T",
        "outputId": "d0098395-8a4b-4609-9bf7-f00928856d4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "imputing continent with mode: 0    asia\n",
            "Name: x24, dtype: object\n",
            "imputing month with mode by cont:          x29\n",
            "x24         \n",
            "america  Jul\n",
            "asia     Jul\n",
            "euorpe   Jul\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[['x24','x29','x30']].groupby(by=['x24','x29']).aggregate(pd.Series.mode)\n",
        "# could just impute with wednesday since Wed is mode per month, but adding continent gives more context and different days for some months"
      ],
      "metadata": {
        "id": "2iV02zDI3Emu",
        "outputId": "73e9b689-966b-4109-e2d0-fd9d744e73da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   x30\n",
              "x24     x29           \n",
              "america Apr  wednesday\n",
              "        Aug  wednesday\n",
              "        Feb    tuesday\n",
              "        Jul  wednesday\n",
              "        Jun  wednesday\n",
              "        Mar  wednesday\n",
              "        May  wednesday\n",
              "        Nov  wednesday\n",
              "        Oct  wednesday\n",
              "        Sep  wednesday\n",
              "asia    Apr  wednesday\n",
              "        Aug  wednesday\n",
              "        Dec  wednesday\n",
              "        Feb  wednesday\n",
              "        Jan  wednesday\n",
              "        Jul  wednesday\n",
              "        Jun  wednesday\n",
              "        Mar  wednesday\n",
              "        May  wednesday\n",
              "        Nov  wednesday\n",
              "        Oct  wednesday\n",
              "        Sep  wednesday\n",
              "euorpe  Apr  wednesday\n",
              "        Aug  wednesday\n",
              "        Dec  wednesday\n",
              "        Feb    tuesday\n",
              "        Jul  wednesday\n",
              "        Jun  wednesday\n",
              "        Mar  wednesday\n",
              "        May  wednesday\n",
              "        Nov  wednesday\n",
              "        Oct  wednesday\n",
              "        Sep  wednesday"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>x30</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x24</th>\n",
              "      <th>x29</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"10\" valign=\"top\">america</th>\n",
              "      <th>Apr</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Aug</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feb</th>\n",
              "      <td>tuesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jul</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jun</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mar</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>May</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nov</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Oct</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sep</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"12\" valign=\"top\">asia</th>\n",
              "      <th>Apr</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Aug</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dec</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feb</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jan</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jul</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jun</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mar</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>May</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nov</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Oct</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sep</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"11\" valign=\"top\">euorpe</th>\n",
              "      <th>Apr</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Aug</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dec</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feb</th>\n",
              "      <td>tuesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jul</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jun</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mar</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>May</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nov</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Oct</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sep</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# impute day\n",
        "df['x30'] = df[['x24','x29','x30']].groupby(by=['x24','x29']).transform(lambda grp: grp.fillna(pd.Series.mode(grp)[0]))"
      ],
      "metadata": {
        "id": "HVQavir8IV9m"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.loc[:,df.columns != 'y']\n",
        "y = df['y'].values.flatten()\n",
        "\n",
        "df_num = X.select_dtypes(exclude='object')\n",
        "num_cols = df_num.columns\n",
        "\n",
        "# impute numeric with median\n",
        "for i in num_cols:\n",
        "    df_num[i] = df_num[i].transform(lambda x: x.fillna(pd.Series.mode(x)[0]))\n",
        "df_num.info()\n",
        "\n",
        "df_cat = X.select_dtypes(include='object')\n",
        "cat_cols = df_cat.columns\n",
        "\n",
        "# scale numerical data\n",
        "scaler = StandardScaler()\n",
        "df_num = scaler.fit_transform(df_num)\n",
        "\n",
        "#one hot encode cat data\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "df_cat = encoder.fit_transform(df_cat)"
      ],
      "metadata": {
        "id": "w8Uy9xG3Iern",
        "outputId": "3aed46a3-8379-47d4-cd0c-82f38e3e182f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 160000 entries, 0 to 159999\n",
            "Data columns (total 47 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   x0      160000 non-null  float64\n",
            " 1   x1      160000 non-null  float64\n",
            " 2   x2      160000 non-null  float64\n",
            " 3   x3      160000 non-null  float64\n",
            " 4   x4      160000 non-null  float64\n",
            " 5   x5      160000 non-null  float64\n",
            " 6   x6      160000 non-null  float64\n",
            " 7   x7      160000 non-null  float64\n",
            " 8   x8      160000 non-null  float64\n",
            " 9   x9      160000 non-null  float64\n",
            " 10  x10     160000 non-null  float64\n",
            " 11  x11     160000 non-null  float64\n",
            " 12  x12     160000 non-null  float64\n",
            " 13  x13     160000 non-null  float64\n",
            " 14  x14     160000 non-null  float64\n",
            " 15  x15     160000 non-null  float64\n",
            " 16  x16     160000 non-null  float64\n",
            " 17  x17     160000 non-null  float64\n",
            " 18  x18     160000 non-null  float64\n",
            " 19  x19     160000 non-null  float64\n",
            " 20  x20     160000 non-null  float64\n",
            " 21  x21     160000 non-null  float64\n",
            " 22  x22     160000 non-null  float64\n",
            " 23  x23     160000 non-null  float64\n",
            " 24  x25     160000 non-null  float64\n",
            " 25  x26     160000 non-null  float64\n",
            " 26  x27     160000 non-null  float64\n",
            " 27  x28     160000 non-null  float64\n",
            " 28  x31     160000 non-null  float64\n",
            " 29  x32     160000 non-null  float64\n",
            " 30  x33     160000 non-null  float64\n",
            " 31  x34     160000 non-null  float64\n",
            " 32  x35     160000 non-null  float64\n",
            " 33  x36     160000 non-null  float64\n",
            " 34  x37     160000 non-null  float64\n",
            " 35  x38     160000 non-null  float64\n",
            " 36  x39     160000 non-null  float64\n",
            " 37  x40     160000 non-null  float64\n",
            " 38  x41     160000 non-null  float64\n",
            " 39  x42     160000 non-null  float64\n",
            " 40  x43     160000 non-null  float64\n",
            " 41  x44     160000 non-null  float64\n",
            " 42  x45     160000 non-null  float64\n",
            " 43  x46     160000 non-null  float64\n",
            " 44  x47     160000 non-null  float64\n",
            " 45  x48     160000 non-null  float64\n",
            " 46  x49     160000 non-null  float64\n",
            "dtypes: float64(47)\n",
            "memory usage: 57.4 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.hstack([df_num,df_cat])"
      ],
      "metadata": {
        "id": "R4oaw8CgIkXV"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1zPG-Q7z7U3",
        "outputId": "640c15d2-1dff-487b-c225-3db1d9f3bfca"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(160000, 67)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['y'].value_counts() # not balanced"
      ],
      "metadata": {
        "id": "xbzdACUdImVy",
        "outputId": "77c2f5dc-a171-40e4-ba49-433965287e64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "y\n",
              "0    95803\n",
              "1    64197\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## define cost function\n",
        "def cost_func(y_pred,y_true):\n",
        "    diff = y_pred - y_true\n",
        "    x = 0\n",
        "    for i in diff:\n",
        "        #false pos (y_pred -y_true == 1)\n",
        "        if i == 1:\n",
        "            x += 100\n",
        "        #false neg (y_pred -y_true ==-1)\n",
        "        elif i == -1:\n",
        "            x += 150\n",
        "    return(x)"
      ],
      "metadata": {
        "id": "HRJz__nu_bxm"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skf = StratifiedKFold(n_splits=10,random_state=807,shuffle=True)\n",
        "skf.get_n_splits(X,y)"
      ],
      "metadata": {
        "id": "qIgBnSnHIqjU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2881078-9712-44df-ceae-cc62b50f7192"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression"
      ],
      "metadata": {
        "id": "gpPJ9Gb95HXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#logR = LogisticRegression(random_state=807,penalty='elasticnet',class_weight='balanced',solver='saga')\n",
        "#params = {'C':[0.00001,0.0001,0.001,0.01,0.1,1,2,5,10],'l1_ratio':[0,0.001,0.01,0.1,0.25,0.5,0.75,0.9,0.99,1],'max_iter':[25,50,75]}\n",
        "\n",
        "#lr_clf = GridSearchCV(estimator=logR,param_grid=params,n_jobs=-1,cv=skf)\n",
        "#lr_clf.fit(X,y)"
      ],
      "metadata": {
        "id": "AcpquSzJO6SF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lr_params = lr_clf.best_params_\n",
        "lr_params ={'C': 0.001, 'l1_ratio': 0.5, 'max_iter': 50}"
      ],
      "metadata": {
        "id": "Eb5e2xOvO8pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "{'C': 0.001, 'l1_ratio': 0.5, 'max_iter': 50}"
      ],
      "metadata": {
        "id": "gfllGKF4pUMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = LogisticRegression(random_state=807,penalty='elasticnet',class_weight='balanced',solver='saga')\n",
        "model1.set_params(**lr_params)\n",
        "model1.fit(X,y)\n",
        "\n",
        "preds_m1 = cross_val_predict(model1,X,y,cv=skf)"
      ],
      "metadata": {
        "id": "RHUkzlw2PATu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cr_m1 = classification_report(y,preds_m1,output_dict=True)\n",
        "cr_m1"
      ],
      "metadata": {
        "id": "3katCHeBPQB-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebf8318a-733e-4dfe-a99c-c387e0f38fef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': {'precision': 0.7707924178564336,\n",
              "  'recall': 0.7292047221903281,\n",
              "  'f1-score': 0.7494220567805746,\n",
              "  'support': 95803},\n",
              " '1': {'precision': 0.6259983277109823,\n",
              "  'recall': 0.6764023240961415,\n",
              "  'f1-score': 0.6502249874591017,\n",
              "  'support': 64197},\n",
              " 'accuracy': 0.70801875,\n",
              " 'macro avg': {'precision': 0.698395372783708,\n",
              "  'recall': 0.7028035231432348,\n",
              "  'f1-score': 0.6998235221198381,\n",
              "  'support': 160000},\n",
              " 'weighted avg': {'precision': 0.7126965040747615,\n",
              "  'recall': 0.70801875,\n",
              "  'f1-score': 0.7096210926603833,\n",
              "  'support': 160000}}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ConfusionMatrixDisplay.from_predictions(y,preds_m1)"
      ],
      "metadata": {
        "id": "ent8XHdUPayB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "outputId": "7b29cb60-2c16-4502-cf3c-5c991f3e8001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7cd8252c5e70>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 550x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cost_m1 = cost_func(preds_m1,y)\n",
        "cost_m1"
      ],
      "metadata": {
        "id": "zawbBlwk_fbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41eb76c9-4ac5-47ed-e1c2-0ebc467e257a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5710400"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ],
      "metadata": {
        "id": "gWPF0EgN5Mw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(random_state=807,criterion='gini',class_weight='balanced')\n",
        "params = {'n_estimators':[100, 200],'max_features':['sqrt','log2',20]}\n",
        "rf_clf = GridSearchCV(rf,param_grid=params,cv=skf,n_jobs = -1)"
      ],
      "metadata": {
        "id": "4HWotr_VPhhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_clf.fit(X,y)"
      ],
      "metadata": {
        "id": "soQp5nQ8PkUl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "12f4caae-9c96-47f7-87f9-ac547e74cf61"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=807, shuffle=True),\n",
              "             estimator=RandomForestClassifier(class_weight=&#x27;balanced&#x27;,\n",
              "                                              random_state=807),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, 20],\n",
              "                         &#x27;n_estimators&#x27;: [100, 200]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=807, shuffle=True),\n",
              "             estimator=RandomForestClassifier(class_weight=&#x27;balanced&#x27;,\n",
              "                                              random_state=807),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, 20],\n",
              "                         &#x27;n_estimators&#x27;: [100, 200]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, random_state=807)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, random_state=807)</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=807, shuffle=True),\n",
              "             estimator=RandomForestClassifier(class_weight='balanced',\n",
              "                                              random_state=807),\n",
              "             n_jobs=-1,\n",
              "             param_grid={'max_features': ['sqrt', 'log2', 20],\n",
              "                         'n_estimators': [100, 200]})"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf_clf.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3jhHtsE6rFk",
        "outputId": "268d129a-e1f6-430c-d247-a7a524d48ea1"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'max_features': 20, 'n_estimators': 200}"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf_params = rf_clf.best_params_\n",
        "rf_params"
      ],
      "metadata": {
        "id": "Hz6owkMTPlOF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "207a18c1-62ab-4f41-8327-6158aafca873"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'max_features': 20, 'n_estimators': 200}"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = RandomForestClassifier(random_state=807,criterion='gini',class_weight='balanced')\n",
        "model2.set_params(**rf_params)\n",
        "preds_m2 = cross_val_predict(model2,X,y,cv=skf)"
      ],
      "metadata": {
        "id": "hvIbks5bPnfm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "cd42f3e3-d5ad-4807-da28-b61400c7725f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-331-c2093db50b55>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m807\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gini'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mrf_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpreds_m2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_predict\u001b[0;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[1;32m    984\u001b[0m     \u001b[0;31m# independent, and that it is pickle-able.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m     predictions = parallel(\n\u001b[0m\u001b[1;32m    987\u001b[0m         delayed(_fit_and_predict)(\n\u001b[1;32m    988\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1853\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1855\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1784\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_predict\u001b[0;34m(estimator, X, y, train, test, verbose, fit_params, method)\u001b[0m\n\u001b[1;32m   1066\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    474\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1853\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1855\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1784\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \"\"\"\n\u001b[1;32m    888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    890\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    377\u001b[0m             )\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cr_m2 = classification_report(y,preds_m2,output_dict=True)\n",
        "cr_m2"
      ],
      "metadata": {
        "id": "Aaw8aFI7PpCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ConfusionMatrixDisplay.from_predictions(y,preds_m2 ,cmap='Blues', colorbar=False)"
      ],
      "metadata": {
        "id": "BK6zSOo4Pq_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cost_m2 = cost_func(preds_m2,y)\n",
        "cost_m2"
      ],
      "metadata": {
        "id": "XqmhfmAx9Ge2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Neural Network"
      ],
      "metadata": {
        "id": "qA5qTJxP5amW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### define a cost function used in validation with keras and backend\n",
        "### returns the average cost (total cost divided by array tensor size)\n",
        "def cost(y_true,y_pred):\n",
        "  bin_p = tf.where(tf.greater_equal(y_pred,0.5),tf.constant(1,dtype='float32'),tf.constant(0,dtype='float32'))\n",
        "\n",
        "  diff = bin_p - y_true\n",
        "\n",
        "  error = tf.where(\n",
        "      tf.equal(diff,1),100,\n",
        "      tf.where(\n",
        "          tf.equal(diff,-1),150,\n",
        "          0\n",
        "      )\n",
        "  )\n",
        "  return(K.sum(error)/tf.size(bin_p))"
      ],
      "metadata": {
        "id": "EV-gIgK12n02"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "now = datetime.datetime.now"
      ],
      "metadata": {
        "id": "b04x7Mf5dBDd"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor='val_cost', mode='min',patience=50,restore_best_weights=True,start_from_epoch=100)\n",
        "fold_results = {}\n",
        "t_tot = now()\n",
        "for i, (train_index, test_index) in enumerate(skf.split(X,y)):\n",
        "  # building model within loop to reset weights each time\n",
        "  tf.keras.backend.clear_session()\n",
        "  tf.keras.utils.set_random_seed(807)\n",
        "  model4 = tf.keras.Sequential()\n",
        "  model4.add(tf.keras.Input(shape=(X.shape[1],)))\n",
        "  model4.add(tf.keras.layers.Dense(64, activation='relu',name=\"Relu1\"))\n",
        "  model4.add(tf.keras.layers.Dense(64, activation='relu', name=\"Relu2\"))\n",
        "  model4.add(tf.keras.layers.Dropout(0.2))\n",
        "  model4.add(tf.keras.layers.Dense(1, activation='sigmoid', name=\"Activation\"))\n",
        "  model4.compile(optimizer='adam',\n",
        "                loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "                metrics = [tf.keras.metrics.AUC(from_logits=False), 'accuracy',cost])\n",
        "  t_fold = now()\n",
        "  print('x_train shape:', X[train_index].shape)\n",
        "  model4.fit(X[train_index],y[train_index],epochs=1000,batch_size=1080,validation_split=0.10,callbacks=[es])\n",
        "  score = model4.evaluate(X[test_index],y[test_index])\n",
        "  fold_results.update({i:{'predictions':model4.predict(X[test_index]).flatten(),'index':test_index,'y_true':y[test_index]}})\n",
        "  print('fold train/predict time: %s' % (now()-t_fold))\n",
        "  print('fold accuracy: {} - fold cost: {}'.format(score[2],score[3]))\n",
        "print('total train/predict time: %s' % (now()-t_tot))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEjPIqNtVPF1",
        "outputId": "7d37b9cc-a1d3-40ee-cc5f-cc89d7a27717"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-08-05 18:24:48.463919: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-05 18:24:48.471943: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-05 18:24:48.472365: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-05 18:24:48.473798: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-05 18:24:48.474263: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-05 18:24:48.474553: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-05 18:24:49.066887: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-05 18:24:49.067197: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-05 18:24:49.067442: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-05 18:24:49.067652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3326 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050 Ti with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (144000, 67)\n",
            "Epoch 1/1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-08-05 18:24:50.181745: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f878367c6c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2023-08-05 18:24:50.181766: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce GTX 1050 Ti with Max-Q Design, Compute Capability 6.1\n",
            "2023-08-05 18:24:50.185418: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2023-08-05 18:24:50.333423: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
            "2023-08-05 18:24:50.455142: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120/120 [==============================] - 2s 5ms/step - loss: 0.5321 - auc: 0.7954 - accuracy: 0.7260 - cost: 36.5748 - val_loss: 0.4003 - val_auc: 0.8976 - val_accuracy: 0.8232 - val_cost: 22.5231\n",
            "Epoch 2/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.3524 - auc: 0.9212 - accuracy: 0.8483 - cost: 19.3557 - val_loss: 0.3178 - val_auc: 0.9358 - val_accuracy: 0.8656 - val_cost: 16.9940\n",
            "Epoch 3/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.3031 - auc: 0.9418 - accuracy: 0.8744 - cost: 15.9012 - val_loss: 0.2909 - val_auc: 0.9469 - val_accuracy: 0.8783 - val_cost: 15.7507\n",
            "Epoch 4/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2755 - auc: 0.9521 - accuracy: 0.8883 - cost: 14.1628 - val_loss: 0.2647 - val_auc: 0.9560 - val_accuracy: 0.8920 - val_cost: 13.2771\n",
            "Epoch 5/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2531 - auc: 0.9596 - accuracy: 0.8980 - cost: 12.9136 - val_loss: 0.2447 - val_auc: 0.9622 - val_accuracy: 0.9024 - val_cost: 12.2189\n",
            "Epoch 6/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2345 - auc: 0.9652 - accuracy: 0.9081 - cost: 11.6169 - val_loss: 0.2292 - val_auc: 0.9673 - val_accuracy: 0.9099 - val_cost: 10.9061\n",
            "Epoch 7/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2183 - auc: 0.9698 - accuracy: 0.9160 - cost: 10.6292 - val_loss: 0.2129 - val_auc: 0.9713 - val_accuracy: 0.9213 - val_cost: 9.7950\n",
            "Epoch 8/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2035 - auc: 0.9737 - accuracy: 0.9224 - cost: 9.8287 - val_loss: 0.2006 - val_auc: 0.9742 - val_accuracy: 0.9279 - val_cost: 9.0807\n",
            "Epoch 9/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1929 - auc: 0.9763 - accuracy: 0.9264 - cost: 9.2975 - val_loss: 0.1913 - val_auc: 0.9763 - val_accuracy: 0.9300 - val_cost: 8.8492\n",
            "Epoch 10/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1832 - auc: 0.9784 - accuracy: 0.9312 - cost: 8.6956 - val_loss: 0.1829 - val_auc: 0.9782 - val_accuracy: 0.9347 - val_cost: 8.1250\n",
            "Epoch 11/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1755 - auc: 0.9800 - accuracy: 0.9348 - cost: 8.2531 - val_loss: 0.1771 - val_auc: 0.9796 - val_accuracy: 0.9387 - val_cost: 7.5066\n",
            "Epoch 12/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1688 - auc: 0.9813 - accuracy: 0.9379 - cost: 7.8542 - val_loss: 0.1713 - val_auc: 0.9806 - val_accuracy: 0.9407 - val_cost: 7.3743\n",
            "Epoch 13/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1622 - auc: 0.9827 - accuracy: 0.9410 - cost: 7.4672 - val_loss: 0.1647 - val_auc: 0.9819 - val_accuracy: 0.9436 - val_cost: 7.0370\n",
            "Epoch 14/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1575 - auc: 0.9836 - accuracy: 0.9429 - cost: 7.2245 - val_loss: 0.1626 - val_auc: 0.9823 - val_accuracy: 0.9433 - val_cost: 7.0635\n",
            "Epoch 15/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1534 - auc: 0.9844 - accuracy: 0.9446 - cost: 7.0046 - val_loss: 0.1567 - val_auc: 0.9834 - val_accuracy: 0.9465 - val_cost: 6.7725\n",
            "Epoch 16/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1486 - auc: 0.9853 - accuracy: 0.9476 - cost: 6.6397 - val_loss: 0.1543 - val_auc: 0.9838 - val_accuracy: 0.9472 - val_cost: 6.5278\n",
            "Epoch 17/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1458 - auc: 0.9857 - accuracy: 0.9483 - cost: 6.5463 - val_loss: 0.1524 - val_auc: 0.9841 - val_accuracy: 0.9477 - val_cost: 6.4120\n",
            "Epoch 18/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1430 - auc: 0.9862 - accuracy: 0.9500 - cost: 6.3329 - val_loss: 0.1493 - val_auc: 0.9846 - val_accuracy: 0.9481 - val_cost: 6.6534\n",
            "Epoch 19/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1407 - auc: 0.9866 - accuracy: 0.9508 - cost: 6.2149 - val_loss: 0.1477 - val_auc: 0.9850 - val_accuracy: 0.9498 - val_cost: 6.3062\n",
            "Epoch 20/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1362 - auc: 0.9873 - accuracy: 0.9523 - cost: 6.0482 - val_loss: 0.1461 - val_auc: 0.9851 - val_accuracy: 0.9500 - val_cost: 6.1971\n",
            "Epoch 21/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1338 - auc: 0.9876 - accuracy: 0.9534 - cost: 5.8904 - val_loss: 0.1444 - val_auc: 0.9854 - val_accuracy: 0.9513 - val_cost: 6.2070\n",
            "Epoch 22/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1319 - auc: 0.9879 - accuracy: 0.9551 - cost: 5.6925 - val_loss: 0.1428 - val_auc: 0.9856 - val_accuracy: 0.9515 - val_cost: 6.1640\n",
            "Epoch 23/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1301 - auc: 0.9882 - accuracy: 0.9551 - cost: 5.6941 - val_loss: 0.1413 - val_auc: 0.9858 - val_accuracy: 0.9523 - val_cost: 5.9358\n",
            "Epoch 24/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1282 - auc: 0.9886 - accuracy: 0.9553 - cost: 5.6632 - val_loss: 0.1395 - val_auc: 0.9860 - val_accuracy: 0.9538 - val_cost: 5.6944\n",
            "Epoch 25/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1257 - auc: 0.9888 - accuracy: 0.9571 - cost: 5.4309 - val_loss: 0.1394 - val_auc: 0.9861 - val_accuracy: 0.9543 - val_cost: 5.6911\n",
            "Epoch 26/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1245 - auc: 0.9891 - accuracy: 0.9572 - cost: 5.4329 - val_loss: 0.1375 - val_auc: 0.9865 - val_accuracy: 0.9552 - val_cost: 5.5423\n",
            "Epoch 27/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1226 - auc: 0.9892 - accuracy: 0.9584 - cost: 5.2747 - val_loss: 0.1371 - val_auc: 0.9865 - val_accuracy: 0.9550 - val_cost: 5.5423\n",
            "Epoch 28/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1202 - auc: 0.9896 - accuracy: 0.9592 - cost: 5.1821 - val_loss: 0.1350 - val_auc: 0.9868 - val_accuracy: 0.9566 - val_cost: 5.3902\n",
            "Epoch 29/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1193 - auc: 0.9897 - accuracy: 0.9601 - cost: 5.0575 - val_loss: 0.1347 - val_auc: 0.9869 - val_accuracy: 0.9566 - val_cost: 5.3737\n",
            "Epoch 30/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1171 - auc: 0.9901 - accuracy: 0.9613 - cost: 4.9097 - val_loss: 0.1321 - val_auc: 0.9871 - val_accuracy: 0.9572 - val_cost: 5.3604\n",
            "Epoch 31/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1166 - auc: 0.9900 - accuracy: 0.9615 - cost: 4.8943 - val_loss: 0.1318 - val_auc: 0.9871 - val_accuracy: 0.9572 - val_cost: 5.3704\n",
            "Epoch 32/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1142 - auc: 0.9905 - accuracy: 0.9624 - cost: 4.7785 - val_loss: 0.1304 - val_auc: 0.9874 - val_accuracy: 0.9585 - val_cost: 5.2447\n",
            "Epoch 33/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1126 - auc: 0.9906 - accuracy: 0.9631 - cost: 4.6779 - val_loss: 0.1295 - val_auc: 0.9873 - val_accuracy: 0.9590 - val_cost: 5.1521\n",
            "Epoch 34/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1118 - auc: 0.9907 - accuracy: 0.9633 - cost: 4.6551 - val_loss: 0.1294 - val_auc: 0.9873 - val_accuracy: 0.9595 - val_cost: 5.0595\n",
            "Epoch 35/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1107 - auc: 0.9909 - accuracy: 0.9638 - cost: 4.5907 - val_loss: 0.1282 - val_auc: 0.9875 - val_accuracy: 0.9596 - val_cost: 5.1091\n",
            "Epoch 36/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1084 - auc: 0.9911 - accuracy: 0.9649 - cost: 4.4506 - val_loss: 0.1271 - val_auc: 0.9878 - val_accuracy: 0.9592 - val_cost: 5.1389\n",
            "Epoch 37/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1082 - auc: 0.9912 - accuracy: 0.9646 - cost: 4.4780 - val_loss: 0.1272 - val_auc: 0.9877 - val_accuracy: 0.9600 - val_cost: 5.0661\n",
            "Epoch 38/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1064 - auc: 0.9914 - accuracy: 0.9657 - cost: 4.3480 - val_loss: 0.1274 - val_auc: 0.9877 - val_accuracy: 0.9601 - val_cost: 5.0099\n",
            "Epoch 39/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1057 - auc: 0.9914 - accuracy: 0.9655 - cost: 4.3611 - val_loss: 0.1249 - val_auc: 0.9879 - val_accuracy: 0.9604 - val_cost: 5.0099\n",
            "Epoch 40/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1036 - auc: 0.9917 - accuracy: 0.9667 - cost: 4.2238 - val_loss: 0.1244 - val_auc: 0.9881 - val_accuracy: 0.9622 - val_cost: 4.7255\n",
            "Epoch 41/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1030 - auc: 0.9918 - accuracy: 0.9670 - cost: 4.1829 - val_loss: 0.1247 - val_auc: 0.9880 - val_accuracy: 0.9618 - val_cost: 4.6892\n",
            "Epoch 42/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1024 - auc: 0.9919 - accuracy: 0.9671 - cost: 4.1852 - val_loss: 0.1225 - val_auc: 0.9884 - val_accuracy: 0.9623 - val_cost: 4.6825\n",
            "Epoch 43/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1014 - auc: 0.9920 - accuracy: 0.9677 - cost: 4.1019 - val_loss: 0.1226 - val_auc: 0.9882 - val_accuracy: 0.9626 - val_cost: 4.7024\n",
            "Epoch 44/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1007 - auc: 0.9920 - accuracy: 0.9673 - cost: 4.1582 - val_loss: 0.1223 - val_auc: 0.9885 - val_accuracy: 0.9619 - val_cost: 4.7421\n",
            "Epoch 45/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1001 - auc: 0.9921 - accuracy: 0.9681 - cost: 4.0529 - val_loss: 0.1201 - val_auc: 0.9885 - val_accuracy: 0.9632 - val_cost: 4.6131\n",
            "Epoch 46/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0980 - auc: 0.9923 - accuracy: 0.9684 - cost: 4.0131 - val_loss: 0.1194 - val_auc: 0.9888 - val_accuracy: 0.9627 - val_cost: 4.6958\n",
            "Epoch 47/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0975 - auc: 0.9924 - accuracy: 0.9689 - cost: 3.9568 - val_loss: 0.1207 - val_auc: 0.9887 - val_accuracy: 0.9637 - val_cost: 4.4511\n",
            "Epoch 48/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0973 - auc: 0.9924 - accuracy: 0.9693 - cost: 3.8974 - val_loss: 0.1199 - val_auc: 0.9886 - val_accuracy: 0.9634 - val_cost: 4.6164\n",
            "Epoch 49/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0963 - auc: 0.9924 - accuracy: 0.9694 - cost: 3.8954 - val_loss: 0.1182 - val_auc: 0.9889 - val_accuracy: 0.9639 - val_cost: 4.5172\n",
            "Epoch 50/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0959 - auc: 0.9925 - accuracy: 0.9701 - cost: 3.8067 - val_loss: 0.1184 - val_auc: 0.9887 - val_accuracy: 0.9637 - val_cost: 4.5899\n",
            "Epoch 51/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0949 - auc: 0.9926 - accuracy: 0.9705 - cost: 3.7569 - val_loss: 0.1190 - val_auc: 0.9887 - val_accuracy: 0.9642 - val_cost: 4.3882\n",
            "Epoch 52/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0943 - auc: 0.9927 - accuracy: 0.9703 - cost: 3.7820 - val_loss: 0.1172 - val_auc: 0.9889 - val_accuracy: 0.9646 - val_cost: 4.4643\n",
            "Epoch 53/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0930 - auc: 0.9928 - accuracy: 0.9711 - cost: 3.6736 - val_loss: 0.1165 - val_auc: 0.9890 - val_accuracy: 0.9655 - val_cost: 4.3353\n",
            "Epoch 54/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0928 - auc: 0.9929 - accuracy: 0.9708 - cost: 3.7187 - val_loss: 0.1171 - val_auc: 0.9887 - val_accuracy: 0.9651 - val_cost: 4.3519\n",
            "Epoch 55/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0922 - auc: 0.9929 - accuracy: 0.9712 - cost: 3.6759 - val_loss: 0.1166 - val_auc: 0.9889 - val_accuracy: 0.9649 - val_cost: 4.3948\n",
            "Epoch 56/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0915 - auc: 0.9929 - accuracy: 0.9718 - cost: 3.6030 - val_loss: 0.1154 - val_auc: 0.9891 - val_accuracy: 0.9655 - val_cost: 4.3353\n",
            "Epoch 57/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0900 - auc: 0.9931 - accuracy: 0.9722 - cost: 3.5374 - val_loss: 0.1149 - val_auc: 0.9892 - val_accuracy: 0.9653 - val_cost: 4.2725\n",
            "Epoch 58/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0912 - auc: 0.9930 - accuracy: 0.9718 - cost: 3.5810 - val_loss: 0.1171 - val_auc: 0.9889 - val_accuracy: 0.9651 - val_cost: 4.2295\n",
            "Epoch 59/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0894 - auc: 0.9932 - accuracy: 0.9722 - cost: 3.5305 - val_loss: 0.1151 - val_auc: 0.9892 - val_accuracy: 0.9660 - val_cost: 4.2791\n",
            "Epoch 60/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0903 - auc: 0.9931 - accuracy: 0.9716 - cost: 3.6142 - val_loss: 0.1164 - val_auc: 0.9890 - val_accuracy: 0.9644 - val_cost: 4.3452\n",
            "Epoch 61/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0888 - auc: 0.9933 - accuracy: 0.9720 - cost: 3.5575 - val_loss: 0.1147 - val_auc: 0.9892 - val_accuracy: 0.9664 - val_cost: 4.1369\n",
            "Epoch 62/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0890 - auc: 0.9932 - accuracy: 0.9721 - cost: 3.5529 - val_loss: 0.1152 - val_auc: 0.9893 - val_accuracy: 0.9658 - val_cost: 4.2063\n",
            "Epoch 63/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0871 - auc: 0.9934 - accuracy: 0.9730 - cost: 3.4340 - val_loss: 0.1136 - val_auc: 0.9893 - val_accuracy: 0.9664 - val_cost: 4.1997\n",
            "Epoch 64/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0873 - auc: 0.9934 - accuracy: 0.9732 - cost: 3.4217 - val_loss: 0.1150 - val_auc: 0.9891 - val_accuracy: 0.9665 - val_cost: 4.1071\n",
            "Epoch 65/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0864 - auc: 0.9936 - accuracy: 0.9733 - cost: 3.3981 - val_loss: 0.1135 - val_auc: 0.9895 - val_accuracy: 0.9669 - val_cost: 4.1865\n",
            "Epoch 66/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0861 - auc: 0.9936 - accuracy: 0.9730 - cost: 3.4421 - val_loss: 0.1124 - val_auc: 0.9893 - val_accuracy: 0.9663 - val_cost: 4.1898\n",
            "Epoch 67/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0856 - auc: 0.9936 - accuracy: 0.9737 - cost: 3.3600 - val_loss: 0.1142 - val_auc: 0.9894 - val_accuracy: 0.9677 - val_cost: 3.9187\n",
            "Epoch 68/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0864 - auc: 0.9934 - accuracy: 0.9734 - cost: 3.3873 - val_loss: 0.1144 - val_auc: 0.9893 - val_accuracy: 0.9667 - val_cost: 4.1303\n",
            "Epoch 69/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0853 - auc: 0.9936 - accuracy: 0.9739 - cost: 3.3368 - val_loss: 0.1132 - val_auc: 0.9894 - val_accuracy: 0.9674 - val_cost: 4.0013\n",
            "Epoch 70/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0848 - auc: 0.9937 - accuracy: 0.9740 - cost: 3.3183 - val_loss: 0.1116 - val_auc: 0.9896 - val_accuracy: 0.9674 - val_cost: 4.0939\n",
            "Epoch 71/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0834 - auc: 0.9937 - accuracy: 0.9745 - cost: 3.2546 - val_loss: 0.1116 - val_auc: 0.9897 - val_accuracy: 0.9681 - val_cost: 3.9881\n",
            "Epoch 72/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0828 - auc: 0.9938 - accuracy: 0.9746 - cost: 3.2438 - val_loss: 0.1121 - val_auc: 0.9896 - val_accuracy: 0.9674 - val_cost: 4.1766\n",
            "Epoch 73/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0828 - auc: 0.9939 - accuracy: 0.9745 - cost: 3.2508 - val_loss: 0.1120 - val_auc: 0.9895 - val_accuracy: 0.9674 - val_cost: 4.0774\n",
            "Epoch 74/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0826 - auc: 0.9939 - accuracy: 0.9747 - cost: 3.2269 - val_loss: 0.1111 - val_auc: 0.9897 - val_accuracy: 0.9685 - val_cost: 3.8724\n",
            "Epoch 75/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0815 - auc: 0.9941 - accuracy: 0.9747 - cost: 3.2234 - val_loss: 0.1119 - val_auc: 0.9896 - val_accuracy: 0.9678 - val_cost: 4.0840\n",
            "Epoch 76/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0818 - auc: 0.9940 - accuracy: 0.9748 - cost: 3.2133 - val_loss: 0.1118 - val_auc: 0.9895 - val_accuracy: 0.9676 - val_cost: 4.0046\n",
            "Epoch 77/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0815 - auc: 0.9939 - accuracy: 0.9750 - cost: 3.1925 - val_loss: 0.1131 - val_auc: 0.9895 - val_accuracy: 0.9673 - val_cost: 4.0939\n",
            "Epoch 78/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0809 - auc: 0.9941 - accuracy: 0.9755 - cost: 3.1389 - val_loss: 0.1104 - val_auc: 0.9897 - val_accuracy: 0.9691 - val_cost: 3.9087\n",
            "Epoch 79/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0809 - auc: 0.9941 - accuracy: 0.9752 - cost: 3.1624 - val_loss: 0.1108 - val_auc: 0.9895 - val_accuracy: 0.9688 - val_cost: 3.8790\n",
            "Epoch 80/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0806 - auc: 0.9940 - accuracy: 0.9754 - cost: 3.1316 - val_loss: 0.1114 - val_auc: 0.9898 - val_accuracy: 0.9685 - val_cost: 3.8856\n",
            "Epoch 81/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0794 - auc: 0.9942 - accuracy: 0.9759 - cost: 3.0698 - val_loss: 0.1098 - val_auc: 0.9896 - val_accuracy: 0.9690 - val_cost: 3.8558\n",
            "Epoch 82/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0794 - auc: 0.9941 - accuracy: 0.9762 - cost: 3.0285 - val_loss: 0.1099 - val_auc: 0.9894 - val_accuracy: 0.9688 - val_cost: 3.9054\n",
            "Epoch 83/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0789 - auc: 0.9943 - accuracy: 0.9756 - cost: 3.1142 - val_loss: 0.1113 - val_auc: 0.9894 - val_accuracy: 0.9689 - val_cost: 3.8955\n",
            "Epoch 84/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0782 - auc: 0.9943 - accuracy: 0.9765 - cost: 2.9958 - val_loss: 0.1092 - val_auc: 0.9899 - val_accuracy: 0.9691 - val_cost: 3.8724\n",
            "Epoch 85/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0784 - auc: 0.9944 - accuracy: 0.9761 - cost: 3.0478 - val_loss: 0.1100 - val_auc: 0.9895 - val_accuracy: 0.9694 - val_cost: 3.8856\n",
            "Epoch 86/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0789 - auc: 0.9941 - accuracy: 0.9761 - cost: 3.0451 - val_loss: 0.1089 - val_auc: 0.9898 - val_accuracy: 0.9692 - val_cost: 3.8955\n",
            "Epoch 87/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0770 - auc: 0.9944 - accuracy: 0.9770 - cost: 2.9387 - val_loss: 0.1113 - val_auc: 0.9896 - val_accuracy: 0.9685 - val_cost: 3.8261\n",
            "Epoch 88/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0776 - auc: 0.9944 - accuracy: 0.9766 - cost: 2.9826 - val_loss: 0.1098 - val_auc: 0.9896 - val_accuracy: 0.9699 - val_cost: 3.7566\n",
            "Epoch 89/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0767 - auc: 0.9945 - accuracy: 0.9770 - cost: 2.9321 - val_loss: 0.1101 - val_auc: 0.9897 - val_accuracy: 0.9703 - val_cost: 3.7632\n",
            "Epoch 90/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0771 - auc: 0.9942 - accuracy: 0.9772 - cost: 2.9124 - val_loss: 0.1117 - val_auc: 0.9896 - val_accuracy: 0.9690 - val_cost: 3.9319\n",
            "Epoch 91/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0771 - auc: 0.9945 - accuracy: 0.9767 - cost: 2.9568 - val_loss: 0.1091 - val_auc: 0.9897 - val_accuracy: 0.9698 - val_cost: 3.8062\n",
            "Epoch 92/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0773 - auc: 0.9943 - accuracy: 0.9765 - cost: 2.9981 - val_loss: 0.1104 - val_auc: 0.9895 - val_accuracy: 0.9697 - val_cost: 3.8360\n",
            "Epoch 93/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0756 - auc: 0.9946 - accuracy: 0.9770 - cost: 2.9302 - val_loss: 0.1087 - val_auc: 0.9898 - val_accuracy: 0.9697 - val_cost: 3.8558\n",
            "Epoch 94/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0752 - auc: 0.9946 - accuracy: 0.9772 - cost: 2.9124 - val_loss: 0.1113 - val_auc: 0.9896 - val_accuracy: 0.9700 - val_cost: 3.8194\n",
            "Epoch 95/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0754 - auc: 0.9945 - accuracy: 0.9774 - cost: 2.8785 - val_loss: 0.1104 - val_auc: 0.9899 - val_accuracy: 0.9709 - val_cost: 3.5681\n",
            "Epoch 96/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0748 - auc: 0.9946 - accuracy: 0.9774 - cost: 2.8862 - val_loss: 0.1097 - val_auc: 0.9898 - val_accuracy: 0.9704 - val_cost: 3.6971\n",
            "Epoch 97/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0749 - auc: 0.9947 - accuracy: 0.9771 - cost: 2.9105 - val_loss: 0.1098 - val_auc: 0.9897 - val_accuracy: 0.9695 - val_cost: 3.8327\n",
            "Epoch 98/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0748 - auc: 0.9946 - accuracy: 0.9775 - cost: 2.8735 - val_loss: 0.1087 - val_auc: 0.9896 - val_accuracy: 0.9701 - val_cost: 3.6971\n",
            "Epoch 99/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0745 - auc: 0.9946 - accuracy: 0.9774 - cost: 2.8924 - val_loss: 0.1102 - val_auc: 0.9899 - val_accuracy: 0.9690 - val_cost: 3.8261\n",
            "Epoch 100/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0749 - auc: 0.9947 - accuracy: 0.9776 - cost: 2.8484 - val_loss: 0.1091 - val_auc: 0.9898 - val_accuracy: 0.9701 - val_cost: 3.8525\n",
            "Epoch 101/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0734 - auc: 0.9948 - accuracy: 0.9779 - cost: 2.8314 - val_loss: 0.1079 - val_auc: 0.9899 - val_accuracy: 0.9708 - val_cost: 3.7070\n",
            "Epoch 102/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0743 - auc: 0.9947 - accuracy: 0.9776 - cost: 2.8569 - val_loss: 0.1093 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.7798\n",
            "Epoch 103/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0732 - auc: 0.9948 - accuracy: 0.9785 - cost: 2.7380 - val_loss: 0.1097 - val_auc: 0.9896 - val_accuracy: 0.9699 - val_cost: 3.7302\n",
            "Epoch 104/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0730 - auc: 0.9949 - accuracy: 0.9783 - cost: 2.7712 - val_loss: 0.1080 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.5946\n",
            "Epoch 105/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0734 - auc: 0.9947 - accuracy: 0.9781 - cost: 2.7905 - val_loss: 0.1092 - val_auc: 0.9894 - val_accuracy: 0.9705 - val_cost: 3.7037\n",
            "Epoch 106/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0730 - auc: 0.9948 - accuracy: 0.9781 - cost: 2.7975 - val_loss: 0.1090 - val_auc: 0.9896 - val_accuracy: 0.9703 - val_cost: 3.7831\n",
            "Epoch 107/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0730 - auc: 0.9948 - accuracy: 0.9784 - cost: 2.7616 - val_loss: 0.1062 - val_auc: 0.9900 - val_accuracy: 0.9706 - val_cost: 3.7831\n",
            "Epoch 108/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0726 - auc: 0.9949 - accuracy: 0.9783 - cost: 2.7739 - val_loss: 0.1087 - val_auc: 0.9898 - val_accuracy: 0.9705 - val_cost: 3.7599\n",
            "Epoch 109/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0716 - auc: 0.9949 - accuracy: 0.9786 - cost: 2.7407 - val_loss: 0.1081 - val_auc: 0.9897 - val_accuracy: 0.9710 - val_cost: 3.6276\n",
            "Epoch 110/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0726 - auc: 0.9949 - accuracy: 0.9784 - cost: 2.7569 - val_loss: 0.1073 - val_auc: 0.9902 - val_accuracy: 0.9710 - val_cost: 3.6772\n",
            "Epoch 111/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0719 - auc: 0.9950 - accuracy: 0.9786 - cost: 2.7249 - val_loss: 0.1085 - val_auc: 0.9899 - val_accuracy: 0.9713 - val_cost: 3.6475\n",
            "Epoch 112/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0717 - auc: 0.9950 - accuracy: 0.9784 - cost: 2.7604 - val_loss: 0.1085 - val_auc: 0.9900 - val_accuracy: 0.9706 - val_cost: 3.7202\n",
            "Epoch 113/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0714 - auc: 0.9949 - accuracy: 0.9789 - cost: 2.6844 - val_loss: 0.1071 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.5615\n",
            "Epoch 114/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0714 - auc: 0.9950 - accuracy: 0.9788 - cost: 2.7164 - val_loss: 0.1083 - val_auc: 0.9898 - val_accuracy: 0.9703 - val_cost: 3.7269\n",
            "Epoch 115/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0711 - auc: 0.9950 - accuracy: 0.9786 - cost: 2.7450 - val_loss: 0.1083 - val_auc: 0.9896 - val_accuracy: 0.9714 - val_cost: 3.6111\n",
            "Epoch 116/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0702 - auc: 0.9951 - accuracy: 0.9794 - cost: 2.6427 - val_loss: 0.1098 - val_auc: 0.9900 - val_accuracy: 0.9703 - val_cost: 3.6706\n",
            "Epoch 117/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0709 - auc: 0.9950 - accuracy: 0.9791 - cost: 2.6609 - val_loss: 0.1098 - val_auc: 0.9899 - val_accuracy: 0.9703 - val_cost: 3.6376\n",
            "Epoch 118/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0703 - auc: 0.9949 - accuracy: 0.9792 - cost: 2.6597 - val_loss: 0.1071 - val_auc: 0.9900 - val_accuracy: 0.9714 - val_cost: 3.4987\n",
            "Epoch 119/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0708 - auc: 0.9949 - accuracy: 0.9792 - cost: 2.6578 - val_loss: 0.1074 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.6607\n",
            "Epoch 120/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0708 - auc: 0.9949 - accuracy: 0.9789 - cost: 2.6964 - val_loss: 0.1075 - val_auc: 0.9901 - val_accuracy: 0.9717 - val_cost: 3.6045\n",
            "Epoch 121/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0691 - auc: 0.9952 - accuracy: 0.9796 - cost: 2.6007 - val_loss: 0.1091 - val_auc: 0.9898 - val_accuracy: 0.9707 - val_cost: 3.6574\n",
            "Epoch 122/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0698 - auc: 0.9951 - accuracy: 0.9791 - cost: 2.6601 - val_loss: 0.1081 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 3.6541\n",
            "Epoch 123/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0707 - auc: 0.9951 - accuracy: 0.9788 - cost: 2.7133 - val_loss: 0.1076 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.5681\n",
            "Epoch 124/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0697 - auc: 0.9951 - accuracy: 0.9792 - cost: 2.6566 - val_loss: 0.1088 - val_auc: 0.9900 - val_accuracy: 0.9705 - val_cost: 3.7831\n",
            "Epoch 125/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0691 - auc: 0.9951 - accuracy: 0.9797 - cost: 2.5995 - val_loss: 0.1088 - val_auc: 0.9897 - val_accuracy: 0.9713 - val_cost: 3.5780\n",
            "Epoch 126/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0692 - auc: 0.9952 - accuracy: 0.9798 - cost: 2.5810 - val_loss: 0.1090 - val_auc: 0.9899 - val_accuracy: 0.9715 - val_cost: 3.6310\n",
            "Epoch 127/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0692 - auc: 0.9952 - accuracy: 0.9793 - cost: 2.6539 - val_loss: 0.1087 - val_auc: 0.9899 - val_accuracy: 0.9717 - val_cost: 3.5384\n",
            "Epoch 128/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0696 - auc: 0.9951 - accuracy: 0.9790 - cost: 2.6860 - val_loss: 0.1084 - val_auc: 0.9898 - val_accuracy: 0.9710 - val_cost: 3.6310\n",
            "Epoch 129/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0690 - auc: 0.9951 - accuracy: 0.9797 - cost: 2.6111 - val_loss: 0.1086 - val_auc: 0.9899 - val_accuracy: 0.9711 - val_cost: 3.6508\n",
            "Epoch 130/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0684 - auc: 0.9953 - accuracy: 0.9794 - cost: 2.6393 - val_loss: 0.1094 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.5780\n",
            "Epoch 131/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0688 - auc: 0.9951 - accuracy: 0.9799 - cost: 2.5710 - val_loss: 0.1083 - val_auc: 0.9898 - val_accuracy: 0.9712 - val_cost: 3.6177\n",
            "Epoch 132/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0691 - auc: 0.9953 - accuracy: 0.9791 - cost: 2.6817 - val_loss: 0.1067 - val_auc: 0.9897 - val_accuracy: 0.9715 - val_cost: 3.6177\n",
            "Epoch 133/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0676 - auc: 0.9954 - accuracy: 0.9799 - cost: 2.5733 - val_loss: 0.1080 - val_auc: 0.9899 - val_accuracy: 0.9708 - val_cost: 3.7467\n",
            "Epoch 134/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0678 - auc: 0.9954 - accuracy: 0.9797 - cost: 2.6042 - val_loss: 0.1076 - val_auc: 0.9898 - val_accuracy: 0.9710 - val_cost: 3.6409\n",
            "Epoch 135/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0675 - auc: 0.9953 - accuracy: 0.9800 - cost: 2.5579 - val_loss: 0.1099 - val_auc: 0.9896 - val_accuracy: 0.9706 - val_cost: 3.7533\n",
            "Epoch 136/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0682 - auc: 0.9953 - accuracy: 0.9800 - cost: 2.5633 - val_loss: 0.1075 - val_auc: 0.9902 - val_accuracy: 0.9714 - val_cost: 3.5813\n",
            "Epoch 137/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0679 - auc: 0.9953 - accuracy: 0.9800 - cost: 2.5590 - val_loss: 0.1104 - val_auc: 0.9898 - val_accuracy: 0.9705 - val_cost: 3.6177\n",
            "Epoch 138/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0677 - auc: 0.9953 - accuracy: 0.9798 - cost: 2.5810 - val_loss: 0.1087 - val_auc: 0.9896 - val_accuracy: 0.9719 - val_cost: 3.4557\n",
            "Epoch 139/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0678 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.5675 - val_loss: 0.1075 - val_auc: 0.9898 - val_accuracy: 0.9717 - val_cost: 3.5218\n",
            "Epoch 140/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0672 - auc: 0.9954 - accuracy: 0.9801 - cost: 2.5482 - val_loss: 0.1096 - val_auc: 0.9898 - val_accuracy: 0.9711 - val_cost: 3.5979\n",
            "Epoch 141/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0662 - auc: 0.9955 - accuracy: 0.9803 - cost: 2.5285 - val_loss: 0.1087 - val_auc: 0.9895 - val_accuracy: 0.9710 - val_cost: 3.6706\n",
            "Epoch 142/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0673 - auc: 0.9954 - accuracy: 0.9799 - cost: 2.5856 - val_loss: 0.1092 - val_auc: 0.9900 - val_accuracy: 0.9717 - val_cost: 3.5747\n",
            "Epoch 143/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0671 - auc: 0.9953 - accuracy: 0.9804 - cost: 2.5039 - val_loss: 0.1110 - val_auc: 0.9893 - val_accuracy: 0.9710 - val_cost: 3.7235\n",
            "Epoch 144/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0666 - auc: 0.9954 - accuracy: 0.9804 - cost: 2.5243 - val_loss: 0.1102 - val_auc: 0.9894 - val_accuracy: 0.9715 - val_cost: 3.4855\n",
            "Epoch 145/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0671 - auc: 0.9953 - accuracy: 0.9805 - cost: 2.5031 - val_loss: 0.1089 - val_auc: 0.9893 - val_accuracy: 0.9718 - val_cost: 3.5582\n",
            "Epoch 146/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0664 - auc: 0.9954 - accuracy: 0.9803 - cost: 2.5174 - val_loss: 0.1091 - val_auc: 0.9897 - val_accuracy: 0.9712 - val_cost: 3.5351\n",
            "Epoch 147/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0653 - auc: 0.9956 - accuracy: 0.9804 - cost: 2.5131 - val_loss: 0.1082 - val_auc: 0.9897 - val_accuracy: 0.9715 - val_cost: 3.5813\n",
            "Epoch 148/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0663 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4846 - val_loss: 0.1100 - val_auc: 0.9899 - val_accuracy: 0.9703 - val_cost: 3.6739\n",
            "Epoch 149/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0659 - auc: 0.9955 - accuracy: 0.9802 - cost: 2.5278 - val_loss: 0.1105 - val_auc: 0.9893 - val_accuracy: 0.9706 - val_cost: 3.6739\n",
            "Epoch 150/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0663 - auc: 0.9954 - accuracy: 0.9802 - cost: 2.5421 - val_loss: 0.1103 - val_auc: 0.9896 - val_accuracy: 0.9715 - val_cost: 3.5284\n",
            "Epoch 151/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0660 - auc: 0.9954 - accuracy: 0.9804 - cost: 2.5197 - val_loss: 0.1094 - val_auc: 0.9892 - val_accuracy: 0.9711 - val_cost: 3.5979\n",
            "Epoch 152/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0658 - auc: 0.9954 - accuracy: 0.9803 - cost: 2.5258 - val_loss: 0.1108 - val_auc: 0.9896 - val_accuracy: 0.9713 - val_cost: 3.5780\n",
            "Epoch 153/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0658 - auc: 0.9955 - accuracy: 0.9804 - cost: 2.5039 - val_loss: 0.1110 - val_auc: 0.9892 - val_accuracy: 0.9705 - val_cost: 3.7269\n",
            "Epoch 154/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0656 - auc: 0.9956 - accuracy: 0.9804 - cost: 2.5077 - val_loss: 0.1107 - val_auc: 0.9894 - val_accuracy: 0.9707 - val_cost: 3.6012\n",
            "Epoch 155/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0655 - auc: 0.9954 - accuracy: 0.9809 - cost: 2.4414 - val_loss: 0.1122 - val_auc: 0.9896 - val_accuracy: 0.9701 - val_cost: 3.8228\n",
            "Epoch 156/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0640 - auc: 0.9956 - accuracy: 0.9815 - cost: 2.3723 - val_loss: 0.1099 - val_auc: 0.9895 - val_accuracy: 0.9715 - val_cost: 3.5483\n",
            "Epoch 157/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0653 - auc: 0.9956 - accuracy: 0.9808 - cost: 2.4579 - val_loss: 0.1114 - val_auc: 0.9893 - val_accuracy: 0.9706 - val_cost: 3.6905\n",
            "Epoch 158/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0652 - auc: 0.9956 - accuracy: 0.9807 - cost: 2.4549 - val_loss: 0.1104 - val_auc: 0.9896 - val_accuracy: 0.9702 - val_cost: 3.7632\n",
            "Epoch 159/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0647 - auc: 0.9956 - accuracy: 0.9806 - cost: 2.4865 - val_loss: 0.1104 - val_auc: 0.9897 - val_accuracy: 0.9706 - val_cost: 3.6243\n",
            "Epoch 160/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0645 - auc: 0.9957 - accuracy: 0.9809 - cost: 2.4464 - val_loss: 0.1112 - val_auc: 0.9895 - val_accuracy: 0.9717 - val_cost: 3.5615\n",
            "Epoch 161/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0652 - auc: 0.9955 - accuracy: 0.9810 - cost: 2.4275 - val_loss: 0.1101 - val_auc: 0.9897 - val_accuracy: 0.9715 - val_cost: 3.5747\n",
            "Epoch 162/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0646 - auc: 0.9957 - accuracy: 0.9809 - cost: 2.4340 - val_loss: 0.1110 - val_auc: 0.9895 - val_accuracy: 0.9706 - val_cost: 3.6971\n",
            "Epoch 163/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0645 - auc: 0.9956 - accuracy: 0.9810 - cost: 2.4309 - val_loss: 0.1087 - val_auc: 0.9897 - val_accuracy: 0.9707 - val_cost: 3.7665\n",
            "Epoch 164/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0639 - auc: 0.9957 - accuracy: 0.9810 - cost: 2.4371 - val_loss: 0.1102 - val_auc: 0.9896 - val_accuracy: 0.9706 - val_cost: 3.7004\n",
            "Epoch 165/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0643 - auc: 0.9957 - accuracy: 0.9811 - cost: 2.4124 - val_loss: 0.1104 - val_auc: 0.9895 - val_accuracy: 0.9708 - val_cost: 3.6673\n",
            "Epoch 166/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0641 - auc: 0.9957 - accuracy: 0.9810 - cost: 2.4282 - val_loss: 0.1118 - val_auc: 0.9891 - val_accuracy: 0.9701 - val_cost: 3.7335\n",
            "Epoch 167/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0640 - auc: 0.9957 - accuracy: 0.9810 - cost: 2.4371 - val_loss: 0.1113 - val_auc: 0.9897 - val_accuracy: 0.9713 - val_cost: 3.6111\n",
            "Epoch 168/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0633 - auc: 0.9958 - accuracy: 0.9811 - cost: 2.4225 - val_loss: 0.1108 - val_auc: 0.9896 - val_accuracy: 0.9719 - val_cost: 3.5615\n",
            "Epoch 169/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0631 - auc: 0.9958 - accuracy: 0.9810 - cost: 2.4240 - val_loss: 0.1098 - val_auc: 0.9897 - val_accuracy: 0.9713 - val_cost: 3.7368\n",
            "Epoch 170/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0635 - auc: 0.9957 - accuracy: 0.9812 - cost: 2.4144 - val_loss: 0.1117 - val_auc: 0.9894 - val_accuracy: 0.9710 - val_cost: 3.6012\n",
            "Epoch 171/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0634 - auc: 0.9959 - accuracy: 0.9809 - cost: 2.4437 - val_loss: 0.1134 - val_auc: 0.9896 - val_accuracy: 0.9701 - val_cost: 3.7434\n",
            "Epoch 172/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0633 - auc: 0.9957 - accuracy: 0.9814 - cost: 2.3808 - val_loss: 0.1123 - val_auc: 0.9893 - val_accuracy: 0.9707 - val_cost: 3.7070\n",
            "Epoch 173/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0622 - auc: 0.9960 - accuracy: 0.9813 - cost: 2.3927 - val_loss: 0.1108 - val_auc: 0.9896 - val_accuracy: 0.9708 - val_cost: 3.7235\n",
            "Epoch 174/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0626 - auc: 0.9958 - accuracy: 0.9817 - cost: 2.3329 - val_loss: 0.1117 - val_auc: 0.9892 - val_accuracy: 0.9710 - val_cost: 3.7070\n",
            "Epoch 175/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0636 - auc: 0.9958 - accuracy: 0.9813 - cost: 2.3916 - val_loss: 0.1101 - val_auc: 0.9898 - val_accuracy: 0.9717 - val_cost: 3.6210\n",
            "Epoch 176/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0634 - auc: 0.9957 - accuracy: 0.9809 - cost: 2.4525 - val_loss: 0.1117 - val_auc: 0.9895 - val_accuracy: 0.9706 - val_cost: 3.6938\n",
            "Epoch 177/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0634 - auc: 0.9958 - accuracy: 0.9815 - cost: 2.3650 - val_loss: 0.1117 - val_auc: 0.9894 - val_accuracy: 0.9706 - val_cost: 3.6706\n",
            "Epoch 178/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0639 - auc: 0.9958 - accuracy: 0.9805 - cost: 2.4977 - val_loss: 0.1114 - val_auc: 0.9899 - val_accuracy: 0.9719 - val_cost: 3.5450\n",
            "Epoch 179/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0619 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3553 - val_loss: 0.1131 - val_auc: 0.9897 - val_accuracy: 0.9711 - val_cost: 3.6177\n",
            "Epoch 180/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0621 - auc: 0.9958 - accuracy: 0.9820 - cost: 2.2994 - val_loss: 0.1121 - val_auc: 0.9896 - val_accuracy: 0.9701 - val_cost: 3.7169\n",
            "Epoch 181/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0623 - auc: 0.9959 - accuracy: 0.9815 - cost: 2.3661 - val_loss: 0.1113 - val_auc: 0.9893 - val_accuracy: 0.9710 - val_cost: 3.7897\n",
            "Epoch 182/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0621 - auc: 0.9959 - accuracy: 0.9820 - cost: 2.3113 - val_loss: 0.1133 - val_auc: 0.9894 - val_accuracy: 0.9708 - val_cost: 3.7202\n",
            "Epoch 183/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0630 - auc: 0.9958 - accuracy: 0.9814 - cost: 2.3804 - val_loss: 0.1138 - val_auc: 0.9894 - val_accuracy: 0.9710 - val_cost: 3.7467\n",
            "Epoch 184/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0613 - auc: 0.9960 - accuracy: 0.9820 - cost: 2.3056 - val_loss: 0.1136 - val_auc: 0.9894 - val_accuracy: 0.9706 - val_cost: 3.8327\n",
            "Epoch 185/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0617 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3499 - val_loss: 0.1139 - val_auc: 0.9894 - val_accuracy: 0.9708 - val_cost: 3.7765\n",
            "Epoch 186/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0627 - auc: 0.9959 - accuracy: 0.9815 - cost: 2.3719 - val_loss: 0.1133 - val_auc: 0.9892 - val_accuracy: 0.9724 - val_cost: 3.5615\n",
            "Epoch 187/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0613 - auc: 0.9959 - accuracy: 0.9818 - cost: 2.3233 - val_loss: 0.1136 - val_auc: 0.9893 - val_accuracy: 0.9707 - val_cost: 3.7698\n",
            "Epoch 188/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0618 - auc: 0.9960 - accuracy: 0.9814 - cost: 2.3831 - val_loss: 0.1135 - val_auc: 0.9893 - val_accuracy: 0.9697 - val_cost: 3.8856\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.1074 - auc: 0.9908 - accuracy: 0.9709 - cost: 3.5906\n",
            "500/500 [==============================] - 1s 994us/step\n",
            "fold train/predict time: 0:01:17.749013\n",
            "fold accuracy: 0.9709374904632568 - fold cost: 3.590625047683716\n",
            "x_train shape: (144000, 67)\n",
            "Epoch 1/1000\n",
            "120/120 [==============================] - 2s 5ms/step - loss: 0.5333 - auc: 0.7947 - accuracy: 0.7271 - cost: 36.3997 - val_loss: 0.4027 - val_auc: 0.8969 - val_accuracy: 0.8235 - val_cost: 23.0423\n",
            "Epoch 2/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.3527 - auc: 0.9209 - accuracy: 0.8479 - cost: 19.4020 - val_loss: 0.3177 - val_auc: 0.9359 - val_accuracy: 0.8650 - val_cost: 16.9213\n",
            "Epoch 3/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.3028 - auc: 0.9419 - accuracy: 0.8752 - cost: 15.7909 - val_loss: 0.2890 - val_auc: 0.9475 - val_accuracy: 0.8792 - val_cost: 15.4729\n",
            "Epoch 4/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2740 - auc: 0.9525 - accuracy: 0.8884 - cost: 14.1358 - val_loss: 0.2635 - val_auc: 0.9561 - val_accuracy: 0.8938 - val_cost: 13.3796\n",
            "Epoch 5/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2506 - auc: 0.9604 - accuracy: 0.8993 - cost: 12.7488 - val_loss: 0.2435 - val_auc: 0.9626 - val_accuracy: 0.9040 - val_cost: 11.9676\n",
            "Epoch 6/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2320 - auc: 0.9659 - accuracy: 0.9086 - cost: 11.5648 - val_loss: 0.2277 - val_auc: 0.9673 - val_accuracy: 0.9121 - val_cost: 11.2731\n",
            "Epoch 7/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2168 - auc: 0.9701 - accuracy: 0.9166 - cost: 10.5451 - val_loss: 0.2139 - val_auc: 0.9710 - val_accuracy: 0.9191 - val_cost: 10.1323\n",
            "Epoch 8/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2030 - auc: 0.9737 - accuracy: 0.9224 - cost: 9.8021 - val_loss: 0.2010 - val_auc: 0.9743 - val_accuracy: 0.9260 - val_cost: 9.3585\n",
            "Epoch 9/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1919 - auc: 0.9765 - accuracy: 0.9271 - cost: 9.2215 - val_loss: 0.1915 - val_auc: 0.9765 - val_accuracy: 0.9309 - val_cost: 8.7930\n",
            "Epoch 10/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1826 - auc: 0.9785 - accuracy: 0.9319 - cost: 8.6215 - val_loss: 0.1851 - val_auc: 0.9779 - val_accuracy: 0.9330 - val_cost: 8.3697\n",
            "Epoch 11/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1756 - auc: 0.9800 - accuracy: 0.9350 - cost: 8.2392 - val_loss: 0.1771 - val_auc: 0.9796 - val_accuracy: 0.9372 - val_cost: 7.8274\n",
            "Epoch 12/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1680 - auc: 0.9816 - accuracy: 0.9382 - cost: 7.8345 - val_loss: 0.1716 - val_auc: 0.9806 - val_accuracy: 0.9392 - val_cost: 7.7116\n",
            "Epoch 13/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1631 - auc: 0.9825 - accuracy: 0.9407 - cost: 7.5166 - val_loss: 0.1664 - val_auc: 0.9818 - val_accuracy: 0.9407 - val_cost: 7.4372\n",
            "Epoch 14/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1572 - auc: 0.9836 - accuracy: 0.9434 - cost: 7.1628 - val_loss: 0.1611 - val_auc: 0.9828 - val_accuracy: 0.9433 - val_cost: 7.1792\n",
            "Epoch 15/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1526 - auc: 0.9845 - accuracy: 0.9453 - cost: 6.9174 - val_loss: 0.1576 - val_auc: 0.9835 - val_accuracy: 0.9458 - val_cost: 6.8915\n",
            "Epoch 16/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1495 - auc: 0.9849 - accuracy: 0.9467 - cost: 6.7481 - val_loss: 0.1552 - val_auc: 0.9838 - val_accuracy: 0.9458 - val_cost: 6.6634\n",
            "Epoch 17/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1450 - auc: 0.9859 - accuracy: 0.9490 - cost: 6.4695 - val_loss: 0.1526 - val_auc: 0.9842 - val_accuracy: 0.9472 - val_cost: 6.6667\n",
            "Epoch 18/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1412 - auc: 0.9864 - accuracy: 0.9499 - cost: 6.3445 - val_loss: 0.1497 - val_auc: 0.9849 - val_accuracy: 0.9474 - val_cost: 6.4649\n",
            "Epoch 19/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1388 - auc: 0.9868 - accuracy: 0.9517 - cost: 6.1285 - val_loss: 0.1490 - val_auc: 0.9849 - val_accuracy: 0.9481 - val_cost: 6.6700\n",
            "Epoch 20/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1364 - auc: 0.9872 - accuracy: 0.9525 - cost: 6.0293 - val_loss: 0.1455 - val_auc: 0.9856 - val_accuracy: 0.9504 - val_cost: 6.1475\n",
            "Epoch 21/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1324 - auc: 0.9879 - accuracy: 0.9541 - cost: 5.8171 - val_loss: 0.1447 - val_auc: 0.9856 - val_accuracy: 0.9506 - val_cost: 6.2533\n",
            "Epoch 22/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1296 - auc: 0.9882 - accuracy: 0.9557 - cost: 5.6146 - val_loss: 0.1416 - val_auc: 0.9861 - val_accuracy: 0.9517 - val_cost: 5.9755\n",
            "Epoch 23/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1279 - auc: 0.9884 - accuracy: 0.9564 - cost: 5.5062 - val_loss: 0.1406 - val_auc: 0.9862 - val_accuracy: 0.9530 - val_cost: 5.9888\n",
            "Epoch 24/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1262 - auc: 0.9887 - accuracy: 0.9570 - cost: 5.4444 - val_loss: 0.1387 - val_auc: 0.9864 - val_accuracy: 0.9547 - val_cost: 5.5423\n",
            "Epoch 25/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1230 - auc: 0.9892 - accuracy: 0.9583 - cost: 5.3036 - val_loss: 0.1356 - val_auc: 0.9867 - val_accuracy: 0.9557 - val_cost: 5.6283\n",
            "Epoch 26/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1211 - auc: 0.9895 - accuracy: 0.9587 - cost: 5.2373 - val_loss: 0.1350 - val_auc: 0.9869 - val_accuracy: 0.9561 - val_cost: 5.5026\n",
            "Epoch 27/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1193 - auc: 0.9897 - accuracy: 0.9598 - cost: 5.1046 - val_loss: 0.1340 - val_auc: 0.9870 - val_accuracy: 0.9561 - val_cost: 5.4696\n",
            "Epoch 28/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1171 - auc: 0.9900 - accuracy: 0.9607 - cost: 4.9776 - val_loss: 0.1335 - val_auc: 0.9871 - val_accuracy: 0.9568 - val_cost: 5.4101\n",
            "Epoch 29/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1152 - auc: 0.9902 - accuracy: 0.9617 - cost: 4.8603 - val_loss: 0.1311 - val_auc: 0.9874 - val_accuracy: 0.9576 - val_cost: 5.4332\n",
            "Epoch 30/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1144 - auc: 0.9903 - accuracy: 0.9619 - cost: 4.8434 - val_loss: 0.1290 - val_auc: 0.9876 - val_accuracy: 0.9592 - val_cost: 5.1124\n",
            "Epoch 31/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1128 - auc: 0.9905 - accuracy: 0.9626 - cost: 4.7423 - val_loss: 0.1290 - val_auc: 0.9876 - val_accuracy: 0.9592 - val_cost: 5.3208\n",
            "Epoch 32/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1107 - auc: 0.9908 - accuracy: 0.9635 - cost: 4.6431 - val_loss: 0.1287 - val_auc: 0.9877 - val_accuracy: 0.9585 - val_cost: 5.1257\n",
            "Epoch 33/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1093 - auc: 0.9910 - accuracy: 0.9638 - cost: 4.6030 - val_loss: 0.1265 - val_auc: 0.9879 - val_accuracy: 0.9594 - val_cost: 5.1753\n",
            "Epoch 34/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1076 - auc: 0.9912 - accuracy: 0.9646 - cost: 4.5012 - val_loss: 0.1259 - val_auc: 0.9880 - val_accuracy: 0.9595 - val_cost: 5.0198\n",
            "Epoch 35/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1063 - auc: 0.9913 - accuracy: 0.9653 - cost: 4.4201 - val_loss: 0.1253 - val_auc: 0.9883 - val_accuracy: 0.9608 - val_cost: 4.8776\n",
            "Epoch 36/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1041 - auc: 0.9915 - accuracy: 0.9662 - cost: 4.2785 - val_loss: 0.1241 - val_auc: 0.9883 - val_accuracy: 0.9599 - val_cost: 5.1521\n",
            "Epoch 37/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1040 - auc: 0.9916 - accuracy: 0.9660 - cost: 4.3345 - val_loss: 0.1235 - val_auc: 0.9884 - val_accuracy: 0.9606 - val_cost: 4.8743\n",
            "Epoch 38/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1026 - auc: 0.9917 - accuracy: 0.9672 - cost: 4.1551 - val_loss: 0.1232 - val_auc: 0.9884 - val_accuracy: 0.9607 - val_cost: 4.8545\n",
            "Epoch 39/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1018 - auc: 0.9918 - accuracy: 0.9669 - cost: 4.1948 - val_loss: 0.1226 - val_auc: 0.9886 - val_accuracy: 0.9619 - val_cost: 4.8347\n",
            "Epoch 40/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1007 - auc: 0.9919 - accuracy: 0.9681 - cost: 4.0513 - val_loss: 0.1207 - val_auc: 0.9888 - val_accuracy: 0.9619 - val_cost: 4.8810\n",
            "Epoch 41/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0992 - auc: 0.9922 - accuracy: 0.9679 - cost: 4.0779 - val_loss: 0.1219 - val_auc: 0.9887 - val_accuracy: 0.9626 - val_cost: 4.5899\n",
            "Epoch 42/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0989 - auc: 0.9921 - accuracy: 0.9686 - cost: 3.9838 - val_loss: 0.1210 - val_auc: 0.9885 - val_accuracy: 0.9615 - val_cost: 4.7817\n",
            "Epoch 43/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0973 - auc: 0.9924 - accuracy: 0.9689 - cost: 3.9522 - val_loss: 0.1197 - val_auc: 0.9888 - val_accuracy: 0.9625 - val_cost: 4.7652\n",
            "Epoch 44/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0967 - auc: 0.9924 - accuracy: 0.9692 - cost: 3.9240 - val_loss: 0.1217 - val_auc: 0.9887 - val_accuracy: 0.9632 - val_cost: 4.4577\n",
            "Epoch 45/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0956 - auc: 0.9926 - accuracy: 0.9693 - cost: 3.9086 - val_loss: 0.1195 - val_auc: 0.9892 - val_accuracy: 0.9629 - val_cost: 4.5470\n",
            "Epoch 46/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0955 - auc: 0.9926 - accuracy: 0.9693 - cost: 3.9074 - val_loss: 0.1177 - val_auc: 0.9893 - val_accuracy: 0.9642 - val_cost: 4.4544\n",
            "Epoch 47/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0941 - auc: 0.9928 - accuracy: 0.9702 - cost: 3.7955 - val_loss: 0.1168 - val_auc: 0.9890 - val_accuracy: 0.9648 - val_cost: 4.4048\n",
            "Epoch 48/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0929 - auc: 0.9928 - accuracy: 0.9709 - cost: 3.6987 - val_loss: 0.1184 - val_auc: 0.9891 - val_accuracy: 0.9647 - val_cost: 4.3221\n",
            "Epoch 49/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0927 - auc: 0.9929 - accuracy: 0.9707 - cost: 3.7307 - val_loss: 0.1196 - val_auc: 0.9890 - val_accuracy: 0.9635 - val_cost: 4.4213\n",
            "Epoch 50/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0916 - auc: 0.9930 - accuracy: 0.9709 - cost: 3.6898 - val_loss: 0.1177 - val_auc: 0.9893 - val_accuracy: 0.9648 - val_cost: 4.5073\n",
            "Epoch 51/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0912 - auc: 0.9930 - accuracy: 0.9715 - cost: 3.6238 - val_loss: 0.1180 - val_auc: 0.9891 - val_accuracy: 0.9641 - val_cost: 4.5205\n",
            "Epoch 52/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0900 - auc: 0.9932 - accuracy: 0.9716 - cost: 3.6103 - val_loss: 0.1169 - val_auc: 0.9893 - val_accuracy: 0.9648 - val_cost: 4.4345\n",
            "Epoch 53/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0899 - auc: 0.9932 - accuracy: 0.9723 - cost: 3.5324 - val_loss: 0.1154 - val_auc: 0.9894 - val_accuracy: 0.9649 - val_cost: 4.3585\n",
            "Epoch 54/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0886 - auc: 0.9932 - accuracy: 0.9725 - cost: 3.4954 - val_loss: 0.1147 - val_auc: 0.9896 - val_accuracy: 0.9658 - val_cost: 4.3221\n",
            "Epoch 55/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0885 - auc: 0.9932 - accuracy: 0.9724 - cost: 3.5015 - val_loss: 0.1140 - val_auc: 0.9897 - val_accuracy: 0.9656 - val_cost: 4.4676\n",
            "Epoch 56/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0874 - auc: 0.9934 - accuracy: 0.9730 - cost: 3.4344 - val_loss: 0.1149 - val_auc: 0.9897 - val_accuracy: 0.9655 - val_cost: 4.4246\n",
            "Epoch 57/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0870 - auc: 0.9934 - accuracy: 0.9730 - cost: 3.4514 - val_loss: 0.1157 - val_auc: 0.9894 - val_accuracy: 0.9658 - val_cost: 4.2229\n",
            "Epoch 58/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0866 - auc: 0.9934 - accuracy: 0.9727 - cost: 3.4645 - val_loss: 0.1136 - val_auc: 0.9898 - val_accuracy: 0.9658 - val_cost: 4.2890\n",
            "Epoch 59/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0866 - auc: 0.9934 - accuracy: 0.9726 - cost: 3.4846 - val_loss: 0.1146 - val_auc: 0.9895 - val_accuracy: 0.9652 - val_cost: 4.4147\n",
            "Epoch 60/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0857 - auc: 0.9936 - accuracy: 0.9737 - cost: 3.3549 - val_loss: 0.1147 - val_auc: 0.9896 - val_accuracy: 0.9666 - val_cost: 4.0807\n",
            "Epoch 61/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0855 - auc: 0.9937 - accuracy: 0.9734 - cost: 3.3916 - val_loss: 0.1145 - val_auc: 0.9898 - val_accuracy: 0.9660 - val_cost: 4.1931\n",
            "Epoch 62/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0852 - auc: 0.9937 - accuracy: 0.9735 - cost: 3.3746 - val_loss: 0.1141 - val_auc: 0.9897 - val_accuracy: 0.9658 - val_cost: 4.2725\n",
            "Epoch 63/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0841 - auc: 0.9937 - accuracy: 0.9737 - cost: 3.3511 - val_loss: 0.1135 - val_auc: 0.9896 - val_accuracy: 0.9660 - val_cost: 4.1766\n",
            "Epoch 64/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0837 - auc: 0.9938 - accuracy: 0.9744 - cost: 3.2662 - val_loss: 0.1146 - val_auc: 0.9898 - val_accuracy: 0.9662 - val_cost: 4.1402\n",
            "Epoch 65/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0833 - auc: 0.9938 - accuracy: 0.9742 - cost: 3.3029 - val_loss: 0.1116 - val_auc: 0.9902 - val_accuracy: 0.9667 - val_cost: 4.1997\n",
            "Epoch 66/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0832 - auc: 0.9938 - accuracy: 0.9744 - cost: 3.2627 - val_loss: 0.1132 - val_auc: 0.9899 - val_accuracy: 0.9659 - val_cost: 4.4015\n",
            "Epoch 67/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0822 - auc: 0.9939 - accuracy: 0.9743 - cost: 3.2704 - val_loss: 0.1143 - val_auc: 0.9898 - val_accuracy: 0.9663 - val_cost: 4.1071\n",
            "Epoch 68/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0817 - auc: 0.9940 - accuracy: 0.9749 - cost: 3.1952 - val_loss: 0.1119 - val_auc: 0.9897 - val_accuracy: 0.9671 - val_cost: 4.0840\n",
            "Epoch 69/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0815 - auc: 0.9939 - accuracy: 0.9752 - cost: 3.1532 - val_loss: 0.1117 - val_auc: 0.9899 - val_accuracy: 0.9672 - val_cost: 4.1832\n",
            "Epoch 70/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0816 - auc: 0.9940 - accuracy: 0.9748 - cost: 3.2245 - val_loss: 0.1134 - val_auc: 0.9897 - val_accuracy: 0.9667 - val_cost: 4.1369\n",
            "Epoch 71/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0820 - auc: 0.9940 - accuracy: 0.9746 - cost: 3.2473 - val_loss: 0.1110 - val_auc: 0.9901 - val_accuracy: 0.9674 - val_cost: 4.1667\n",
            "Epoch 72/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0804 - auc: 0.9940 - accuracy: 0.9752 - cost: 3.1601 - val_loss: 0.1103 - val_auc: 0.9900 - val_accuracy: 0.9679 - val_cost: 4.0708\n",
            "Epoch 73/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0801 - auc: 0.9940 - accuracy: 0.9753 - cost: 3.1551 - val_loss: 0.1102 - val_auc: 0.9900 - val_accuracy: 0.9675 - val_cost: 4.1567\n",
            "Epoch 74/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0792 - auc: 0.9942 - accuracy: 0.9757 - cost: 3.0907 - val_loss: 0.1105 - val_auc: 0.9900 - val_accuracy: 0.9685 - val_cost: 3.8922\n",
            "Epoch 75/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0794 - auc: 0.9941 - accuracy: 0.9760 - cost: 3.0671 - val_loss: 0.1102 - val_auc: 0.9902 - val_accuracy: 0.9680 - val_cost: 4.0046\n",
            "Epoch 76/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0794 - auc: 0.9942 - accuracy: 0.9759 - cost: 3.0806 - val_loss: 0.1110 - val_auc: 0.9900 - val_accuracy: 0.9686 - val_cost: 3.8591\n",
            "Epoch 77/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0793 - auc: 0.9942 - accuracy: 0.9758 - cost: 3.0783 - val_loss: 0.1111 - val_auc: 0.9900 - val_accuracy: 0.9682 - val_cost: 3.9683\n",
            "Epoch 78/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0785 - auc: 0.9943 - accuracy: 0.9762 - cost: 3.0343 - val_loss: 0.1102 - val_auc: 0.9901 - val_accuracy: 0.9683 - val_cost: 3.9120\n",
            "Epoch 79/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0779 - auc: 0.9943 - accuracy: 0.9764 - cost: 3.0054 - val_loss: 0.1111 - val_auc: 0.9900 - val_accuracy: 0.9692 - val_cost: 3.8062\n",
            "Epoch 80/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0783 - auc: 0.9943 - accuracy: 0.9766 - cost: 2.9969 - val_loss: 0.1092 - val_auc: 0.9902 - val_accuracy: 0.9688 - val_cost: 3.9153\n",
            "Epoch 81/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0764 - auc: 0.9945 - accuracy: 0.9767 - cost: 2.9672 - val_loss: 0.1096 - val_auc: 0.9902 - val_accuracy: 0.9678 - val_cost: 4.0311\n",
            "Epoch 82/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0776 - auc: 0.9944 - accuracy: 0.9768 - cost: 2.9618 - val_loss: 0.1092 - val_auc: 0.9899 - val_accuracy: 0.9698 - val_cost: 3.8856\n",
            "Epoch 83/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0763 - auc: 0.9945 - accuracy: 0.9768 - cost: 2.9657 - val_loss: 0.1105 - val_auc: 0.9901 - val_accuracy: 0.9676 - val_cost: 3.9385\n",
            "Epoch 84/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0763 - auc: 0.9945 - accuracy: 0.9769 - cost: 2.9576 - val_loss: 0.1108 - val_auc: 0.9902 - val_accuracy: 0.9694 - val_cost: 3.7831\n",
            "Epoch 85/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0768 - auc: 0.9944 - accuracy: 0.9770 - cost: 2.9441 - val_loss: 0.1096 - val_auc: 0.9903 - val_accuracy: 0.9693 - val_cost: 3.7368\n",
            "Epoch 86/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0758 - auc: 0.9945 - accuracy: 0.9774 - cost: 2.8800 - val_loss: 0.1086 - val_auc: 0.9903 - val_accuracy: 0.9697 - val_cost: 3.8591\n",
            "Epoch 87/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0759 - auc: 0.9945 - accuracy: 0.9773 - cost: 2.8943 - val_loss: 0.1100 - val_auc: 0.9900 - val_accuracy: 0.9686 - val_cost: 3.9220\n",
            "Epoch 88/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0755 - auc: 0.9946 - accuracy: 0.9772 - cost: 2.9190 - val_loss: 0.1113 - val_auc: 0.9899 - val_accuracy: 0.9697 - val_cost: 3.7665\n",
            "Epoch 89/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0757 - auc: 0.9945 - accuracy: 0.9771 - cost: 2.9225 - val_loss: 0.1096 - val_auc: 0.9904 - val_accuracy: 0.9688 - val_cost: 3.9484\n",
            "Epoch 90/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0745 - auc: 0.9946 - accuracy: 0.9778 - cost: 2.8322 - val_loss: 0.1107 - val_auc: 0.9902 - val_accuracy: 0.9690 - val_cost: 3.8492\n",
            "Epoch 91/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0745 - auc: 0.9946 - accuracy: 0.9775 - cost: 2.8796 - val_loss: 0.1101 - val_auc: 0.9898 - val_accuracy: 0.9693 - val_cost: 3.7765\n",
            "Epoch 92/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0745 - auc: 0.9947 - accuracy: 0.9775 - cost: 2.8812 - val_loss: 0.1086 - val_auc: 0.9903 - val_accuracy: 0.9699 - val_cost: 3.7202\n",
            "Epoch 93/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0744 - auc: 0.9947 - accuracy: 0.9774 - cost: 2.8885 - val_loss: 0.1082 - val_auc: 0.9903 - val_accuracy: 0.9692 - val_cost: 3.8558\n",
            "Epoch 94/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0743 - auc: 0.9947 - accuracy: 0.9781 - cost: 2.8098 - val_loss: 0.1099 - val_auc: 0.9901 - val_accuracy: 0.9688 - val_cost: 3.9517\n",
            "Epoch 95/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0739 - auc: 0.9947 - accuracy: 0.9777 - cost: 2.8569 - val_loss: 0.1095 - val_auc: 0.9905 - val_accuracy: 0.9692 - val_cost: 3.7963\n",
            "Epoch 96/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0732 - auc: 0.9948 - accuracy: 0.9780 - cost: 2.8140 - val_loss: 0.1087 - val_auc: 0.9902 - val_accuracy: 0.9686 - val_cost: 3.9848\n",
            "Epoch 97/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0739 - auc: 0.9947 - accuracy: 0.9778 - cost: 2.8353 - val_loss: 0.1094 - val_auc: 0.9902 - val_accuracy: 0.9701 - val_cost: 3.7169\n",
            "Epoch 98/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0736 - auc: 0.9948 - accuracy: 0.9779 - cost: 2.8318 - val_loss: 0.1083 - val_auc: 0.9904 - val_accuracy: 0.9692 - val_cost: 3.8591\n",
            "Epoch 99/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0730 - auc: 0.9948 - accuracy: 0.9782 - cost: 2.7867 - val_loss: 0.1118 - val_auc: 0.9902 - val_accuracy: 0.9684 - val_cost: 3.8459\n",
            "Epoch 100/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0727 - auc: 0.9949 - accuracy: 0.9781 - cost: 2.7975 - val_loss: 0.1095 - val_auc: 0.9901 - val_accuracy: 0.9694 - val_cost: 3.8690\n",
            "Epoch 101/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0733 - auc: 0.9947 - accuracy: 0.9781 - cost: 2.7905 - val_loss: 0.1070 - val_auc: 0.9904 - val_accuracy: 0.9703 - val_cost: 3.7004\n",
            "Epoch 102/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0719 - auc: 0.9948 - accuracy: 0.9786 - cost: 2.7357 - val_loss: 0.1079 - val_auc: 0.9904 - val_accuracy: 0.9707 - val_cost: 3.6806\n",
            "Epoch 103/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0719 - auc: 0.9949 - accuracy: 0.9785 - cost: 2.7515 - val_loss: 0.1089 - val_auc: 0.9902 - val_accuracy: 0.9707 - val_cost: 3.6078\n",
            "Epoch 104/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0718 - auc: 0.9950 - accuracy: 0.9782 - cost: 2.7801 - val_loss: 0.1104 - val_auc: 0.9902 - val_accuracy: 0.9699 - val_cost: 3.7004\n",
            "Epoch 105/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0716 - auc: 0.9949 - accuracy: 0.9788 - cost: 2.7103 - val_loss: 0.1087 - val_auc: 0.9904 - val_accuracy: 0.9708 - val_cost: 3.6276\n",
            "Epoch 106/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0712 - auc: 0.9949 - accuracy: 0.9792 - cost: 2.6721 - val_loss: 0.1082 - val_auc: 0.9903 - val_accuracy: 0.9706 - val_cost: 3.6177\n",
            "Epoch 107/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0706 - auc: 0.9951 - accuracy: 0.9790 - cost: 2.6821 - val_loss: 0.1098 - val_auc: 0.9906 - val_accuracy: 0.9702 - val_cost: 3.6541\n",
            "Epoch 108/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0719 - auc: 0.9949 - accuracy: 0.9787 - cost: 2.7222 - val_loss: 0.1093 - val_auc: 0.9902 - val_accuracy: 0.9701 - val_cost: 3.7698\n",
            "Epoch 109/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0706 - auc: 0.9950 - accuracy: 0.9789 - cost: 2.6998 - val_loss: 0.1078 - val_auc: 0.9900 - val_accuracy: 0.9707 - val_cost: 3.6739\n",
            "Epoch 110/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0711 - auc: 0.9949 - accuracy: 0.9790 - cost: 2.6944 - val_loss: 0.1088 - val_auc: 0.9902 - val_accuracy: 0.9710 - val_cost: 3.5747\n",
            "Epoch 111/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0706 - auc: 0.9950 - accuracy: 0.9788 - cost: 2.7106 - val_loss: 0.1099 - val_auc: 0.9903 - val_accuracy: 0.9697 - val_cost: 3.7533\n",
            "Epoch 112/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0705 - auc: 0.9950 - accuracy: 0.9789 - cost: 2.7022 - val_loss: 0.1086 - val_auc: 0.9904 - val_accuracy: 0.9706 - val_cost: 3.6508\n",
            "Epoch 113/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0705 - auc: 0.9951 - accuracy: 0.9792 - cost: 2.6617 - val_loss: 0.1094 - val_auc: 0.9903 - val_accuracy: 0.9704 - val_cost: 3.5913\n",
            "Epoch 114/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0696 - auc: 0.9952 - accuracy: 0.9791 - cost: 2.6752 - val_loss: 0.1093 - val_auc: 0.9904 - val_accuracy: 0.9700 - val_cost: 3.8360\n",
            "Epoch 115/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0692 - auc: 0.9952 - accuracy: 0.9797 - cost: 2.6026 - val_loss: 0.1092 - val_auc: 0.9903 - val_accuracy: 0.9697 - val_cost: 3.8327\n",
            "Epoch 116/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0695 - auc: 0.9951 - accuracy: 0.9796 - cost: 2.6204 - val_loss: 0.1088 - val_auc: 0.9904 - val_accuracy: 0.9694 - val_cost: 3.8790\n",
            "Epoch 117/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0698 - auc: 0.9951 - accuracy: 0.9795 - cost: 2.6254 - val_loss: 0.1104 - val_auc: 0.9898 - val_accuracy: 0.9696 - val_cost: 3.8856\n",
            "Epoch 118/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0695 - auc: 0.9951 - accuracy: 0.9792 - cost: 2.6609 - val_loss: 0.1100 - val_auc: 0.9901 - val_accuracy: 0.9703 - val_cost: 3.7037\n",
            "Epoch 119/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0694 - auc: 0.9951 - accuracy: 0.9792 - cost: 2.6705 - val_loss: 0.1101 - val_auc: 0.9902 - val_accuracy: 0.9708 - val_cost: 3.6607\n",
            "Epoch 120/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0688 - auc: 0.9952 - accuracy: 0.9798 - cost: 2.5872 - val_loss: 0.1092 - val_auc: 0.9903 - val_accuracy: 0.9714 - val_cost: 3.6045\n",
            "Epoch 121/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0689 - auc: 0.9953 - accuracy: 0.9796 - cost: 2.6157 - val_loss: 0.1115 - val_auc: 0.9901 - val_accuracy: 0.9701 - val_cost: 3.7169\n",
            "Epoch 122/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0691 - auc: 0.9953 - accuracy: 0.9791 - cost: 2.6790 - val_loss: 0.1074 - val_auc: 0.9903 - val_accuracy: 0.9714 - val_cost: 3.5516\n",
            "Epoch 123/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0678 - auc: 0.9954 - accuracy: 0.9797 - cost: 2.5953 - val_loss: 0.1092 - val_auc: 0.9905 - val_accuracy: 0.9694 - val_cost: 3.8128\n",
            "Epoch 124/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0677 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.5640 - val_loss: 0.1075 - val_auc: 0.9905 - val_accuracy: 0.9703 - val_cost: 3.7434\n",
            "Epoch 125/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0681 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.5718 - val_loss: 0.1076 - val_auc: 0.9905 - val_accuracy: 0.9707 - val_cost: 3.6144\n",
            "Epoch 126/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0683 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.5718 - val_loss: 0.1080 - val_auc: 0.9902 - val_accuracy: 0.9706 - val_cost: 3.6508\n",
            "Epoch 127/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0689 - auc: 0.9952 - accuracy: 0.9797 - cost: 2.6034 - val_loss: 0.1089 - val_auc: 0.9905 - val_accuracy: 0.9707 - val_cost: 3.6376\n",
            "Epoch 128/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0673 - auc: 0.9954 - accuracy: 0.9799 - cost: 2.5760 - val_loss: 0.1086 - val_auc: 0.9902 - val_accuracy: 0.9707 - val_cost: 3.6640\n",
            "Epoch 129/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0686 - auc: 0.9951 - accuracy: 0.9801 - cost: 2.5525 - val_loss: 0.1104 - val_auc: 0.9902 - val_accuracy: 0.9701 - val_cost: 3.7335\n",
            "Epoch 130/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0674 - auc: 0.9954 - accuracy: 0.9800 - cost: 2.5617 - val_loss: 0.1088 - val_auc: 0.9904 - val_accuracy: 0.9706 - val_cost: 3.6475\n",
            "Epoch 131/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0677 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.5787 - val_loss: 0.1086 - val_auc: 0.9905 - val_accuracy: 0.9701 - val_cost: 3.8062\n",
            "Epoch 132/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0661 - auc: 0.9955 - accuracy: 0.9804 - cost: 2.5035 - val_loss: 0.1100 - val_auc: 0.9899 - val_accuracy: 0.9709 - val_cost: 3.6640\n",
            "Epoch 133/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0656 - auc: 0.9955 - accuracy: 0.9807 - cost: 2.4672 - val_loss: 0.1098 - val_auc: 0.9903 - val_accuracy: 0.9700 - val_cost: 3.7368\n",
            "Epoch 134/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0669 - auc: 0.9954 - accuracy: 0.9797 - cost: 2.5887 - val_loss: 0.1082 - val_auc: 0.9906 - val_accuracy: 0.9715 - val_cost: 3.5549\n",
            "Epoch 135/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0673 - auc: 0.9953 - accuracy: 0.9801 - cost: 2.5602 - val_loss: 0.1105 - val_auc: 0.9903 - val_accuracy: 0.9702 - val_cost: 3.6409\n",
            "Epoch 136/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0665 - auc: 0.9954 - accuracy: 0.9800 - cost: 2.5498 - val_loss: 0.1073 - val_auc: 0.9908 - val_accuracy: 0.9713 - val_cost: 3.4888\n",
            "Epoch 137/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0669 - auc: 0.9954 - accuracy: 0.9806 - cost: 2.4765 - val_loss: 0.1092 - val_auc: 0.9908 - val_accuracy: 0.9697 - val_cost: 3.8393\n",
            "Epoch 138/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0668 - auc: 0.9955 - accuracy: 0.9800 - cost: 2.5617 - val_loss: 0.1102 - val_auc: 0.9906 - val_accuracy: 0.9705 - val_cost: 3.6607\n",
            "Epoch 139/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0662 - auc: 0.9953 - accuracy: 0.9806 - cost: 2.4830 - val_loss: 0.1087 - val_auc: 0.9902 - val_accuracy: 0.9712 - val_cost: 3.6276\n",
            "Epoch 140/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0655 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4745 - val_loss: 0.1110 - val_auc: 0.9903 - val_accuracy: 0.9709 - val_cost: 3.6376\n",
            "Epoch 141/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0654 - auc: 0.9956 - accuracy: 0.9806 - cost: 2.4830 - val_loss: 0.1109 - val_auc: 0.9901 - val_accuracy: 0.9700 - val_cost: 3.7533\n",
            "Epoch 142/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0659 - auc: 0.9955 - accuracy: 0.9811 - cost: 2.4217 - val_loss: 0.1107 - val_auc: 0.9904 - val_accuracy: 0.9705 - val_cost: 3.7434\n",
            "Epoch 143/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0650 - auc: 0.9956 - accuracy: 0.9810 - cost: 2.4452 - val_loss: 0.1090 - val_auc: 0.9906 - val_accuracy: 0.9708 - val_cost: 3.6276\n",
            "Epoch 144/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0649 - auc: 0.9956 - accuracy: 0.9812 - cost: 2.4016 - val_loss: 0.1077 - val_auc: 0.9907 - val_accuracy: 0.9701 - val_cost: 3.7434\n",
            "Epoch 145/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0658 - auc: 0.9956 - accuracy: 0.9802 - cost: 2.5316 - val_loss: 0.1098 - val_auc: 0.9903 - val_accuracy: 0.9710 - val_cost: 3.5913\n",
            "Epoch 146/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0657 - auc: 0.9954 - accuracy: 0.9807 - cost: 2.4603 - val_loss: 0.1109 - val_auc: 0.9904 - val_accuracy: 0.9695 - val_cost: 3.8062\n",
            "Epoch 147/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0650 - auc: 0.9955 - accuracy: 0.9809 - cost: 2.4410 - val_loss: 0.1096 - val_auc: 0.9906 - val_accuracy: 0.9702 - val_cost: 3.7070\n",
            "Epoch 148/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0643 - auc: 0.9956 - accuracy: 0.9806 - cost: 2.4842 - val_loss: 0.1112 - val_auc: 0.9904 - val_accuracy: 0.9706 - val_cost: 3.6409\n",
            "Epoch 149/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0654 - auc: 0.9955 - accuracy: 0.9808 - cost: 2.4579 - val_loss: 0.1095 - val_auc: 0.9906 - val_accuracy: 0.9717 - val_cost: 3.5020\n",
            "Epoch 150/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0649 - auc: 0.9956 - accuracy: 0.9808 - cost: 2.4529 - val_loss: 0.1088 - val_auc: 0.9909 - val_accuracy: 0.9701 - val_cost: 3.7765\n",
            "Epoch 151/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0647 - auc: 0.9956 - accuracy: 0.9812 - cost: 2.4124 - val_loss: 0.1072 - val_auc: 0.9910 - val_accuracy: 0.9714 - val_cost: 3.6310\n",
            "Epoch 152/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0641 - auc: 0.9956 - accuracy: 0.9815 - cost: 2.3708 - val_loss: 0.1109 - val_auc: 0.9904 - val_accuracy: 0.9697 - val_cost: 3.8095\n",
            "Epoch 153/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0652 - auc: 0.9956 - accuracy: 0.9807 - cost: 2.4680 - val_loss: 0.1127 - val_auc: 0.9902 - val_accuracy: 0.9710 - val_cost: 3.5714\n",
            "Epoch 154/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0644 - auc: 0.9956 - accuracy: 0.9810 - cost: 2.4294 - val_loss: 0.1105 - val_auc: 0.9902 - val_accuracy: 0.9703 - val_cost: 3.7235\n",
            "Epoch 155/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0643 - auc: 0.9955 - accuracy: 0.9809 - cost: 2.4483 - val_loss: 0.1113 - val_auc: 0.9903 - val_accuracy: 0.9707 - val_cost: 3.6310\n",
            "Epoch 156/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0645 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4387 - val_loss: 0.1142 - val_auc: 0.9900 - val_accuracy: 0.9695 - val_cost: 3.7533\n",
            "Epoch 157/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0647 - auc: 0.9955 - accuracy: 0.9812 - cost: 2.4128 - val_loss: 0.1106 - val_auc: 0.9903 - val_accuracy: 0.9709 - val_cost: 3.5979\n",
            "Epoch 158/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0641 - auc: 0.9957 - accuracy: 0.9811 - cost: 2.4194 - val_loss: 0.1125 - val_auc: 0.9903 - val_accuracy: 0.9702 - val_cost: 3.6574\n",
            "Epoch 159/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0641 - auc: 0.9958 - accuracy: 0.9814 - cost: 2.3854 - val_loss: 0.1097 - val_auc: 0.9905 - val_accuracy: 0.9706 - val_cost: 3.6442\n",
            "Epoch 160/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0637 - auc: 0.9956 - accuracy: 0.9818 - cost: 2.3353 - val_loss: 0.1111 - val_auc: 0.9904 - val_accuracy: 0.9703 - val_cost: 3.7004\n",
            "Epoch 161/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0638 - auc: 0.9957 - accuracy: 0.9812 - cost: 2.4205 - val_loss: 0.1101 - val_auc: 0.9904 - val_accuracy: 0.9703 - val_cost: 3.6310\n",
            "Epoch 162/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0640 - auc: 0.9957 - accuracy: 0.9813 - cost: 2.3904 - val_loss: 0.1100 - val_auc: 0.9902 - val_accuracy: 0.9712 - val_cost: 3.5648\n",
            "Epoch 163/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0633 - auc: 0.9957 - accuracy: 0.9815 - cost: 2.3696 - val_loss: 0.1112 - val_auc: 0.9904 - val_accuracy: 0.9710 - val_cost: 3.6607\n",
            "Epoch 164/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0631 - auc: 0.9957 - accuracy: 0.9814 - cost: 2.3866 - val_loss: 0.1085 - val_auc: 0.9905 - val_accuracy: 0.9712 - val_cost: 3.5946\n",
            "Epoch 165/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0626 - auc: 0.9958 - accuracy: 0.9814 - cost: 2.3812 - val_loss: 0.1110 - val_auc: 0.9903 - val_accuracy: 0.9706 - val_cost: 3.7169\n",
            "Epoch 166/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0636 - auc: 0.9957 - accuracy: 0.9812 - cost: 2.4078 - val_loss: 0.1115 - val_auc: 0.9902 - val_accuracy: 0.9709 - val_cost: 3.6640\n",
            "Epoch 167/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0630 - auc: 0.9957 - accuracy: 0.9817 - cost: 2.3430 - val_loss: 0.1140 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.5384\n",
            "Epoch 168/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0632 - auc: 0.9957 - accuracy: 0.9814 - cost: 2.3897 - val_loss: 0.1116 - val_auc: 0.9903 - val_accuracy: 0.9712 - val_cost: 3.5516\n",
            "Epoch 169/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0628 - auc: 0.9958 - accuracy: 0.9818 - cost: 2.3395 - val_loss: 0.1118 - val_auc: 0.9901 - val_accuracy: 0.9717 - val_cost: 3.4689\n",
            "Epoch 170/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0628 - auc: 0.9958 - accuracy: 0.9818 - cost: 2.3326 - val_loss: 0.1115 - val_auc: 0.9904 - val_accuracy: 0.9712 - val_cost: 3.4888\n",
            "Epoch 171/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0630 - auc: 0.9957 - accuracy: 0.9815 - cost: 2.3615 - val_loss: 0.1106 - val_auc: 0.9904 - val_accuracy: 0.9715 - val_cost: 3.6078\n",
            "Epoch 172/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0618 - auc: 0.9959 - accuracy: 0.9816 - cost: 2.3692 - val_loss: 0.1110 - val_auc: 0.9902 - val_accuracy: 0.9717 - val_cost: 3.4755\n",
            "Epoch 173/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0621 - auc: 0.9958 - accuracy: 0.9817 - cost: 2.3488 - val_loss: 0.1152 - val_auc: 0.9900 - val_accuracy: 0.9710 - val_cost: 3.4921\n",
            "Epoch 174/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0627 - auc: 0.9958 - accuracy: 0.9816 - cost: 2.3515 - val_loss: 0.1111 - val_auc: 0.9903 - val_accuracy: 0.9705 - val_cost: 3.7070\n",
            "Epoch 175/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0629 - auc: 0.9958 - accuracy: 0.9817 - cost: 2.3422 - val_loss: 0.1145 - val_auc: 0.9900 - val_accuracy: 0.9714 - val_cost: 3.4656\n",
            "Epoch 176/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0628 - auc: 0.9958 - accuracy: 0.9814 - cost: 2.3885 - val_loss: 0.1105 - val_auc: 0.9905 - val_accuracy: 0.9713 - val_cost: 3.5020\n",
            "Epoch 177/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0623 - auc: 0.9959 - accuracy: 0.9820 - cost: 2.3083 - val_loss: 0.1112 - val_auc: 0.9901 - val_accuracy: 0.9708 - val_cost: 3.6243\n",
            "Epoch 178/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0632 - auc: 0.9957 - accuracy: 0.9814 - cost: 2.3781 - val_loss: 0.1111 - val_auc: 0.9904 - val_accuracy: 0.9711 - val_cost: 3.6210\n",
            "Epoch 179/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0619 - auc: 0.9959 - accuracy: 0.9818 - cost: 2.3391 - val_loss: 0.1104 - val_auc: 0.9901 - val_accuracy: 0.9718 - val_cost: 3.5251\n",
            "Epoch 180/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0611 - auc: 0.9959 - accuracy: 0.9824 - cost: 2.2581 - val_loss: 0.1122 - val_auc: 0.9900 - val_accuracy: 0.9708 - val_cost: 3.6409\n",
            "Epoch 181/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0615 - auc: 0.9960 - accuracy: 0.9818 - cost: 2.3372 - val_loss: 0.1132 - val_auc: 0.9901 - val_accuracy: 0.9709 - val_cost: 3.5747\n",
            "Epoch 182/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0619 - auc: 0.9958 - accuracy: 0.9820 - cost: 2.3175 - val_loss: 0.1121 - val_auc: 0.9898 - val_accuracy: 0.9710 - val_cost: 3.6673\n",
            "Epoch 183/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0611 - auc: 0.9959 - accuracy: 0.9824 - cost: 2.2654 - val_loss: 0.1115 - val_auc: 0.9902 - val_accuracy: 0.9715 - val_cost: 3.5648\n",
            "Epoch 184/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0614 - auc: 0.9960 - accuracy: 0.9819 - cost: 2.3252 - val_loss: 0.1160 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.6442\n",
            "Epoch 185/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0614 - auc: 0.9959 - accuracy: 0.9816 - cost: 2.3557 - val_loss: 0.1124 - val_auc: 0.9904 - val_accuracy: 0.9710 - val_cost: 3.6243\n",
            "Epoch 186/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0620 - auc: 0.9959 - accuracy: 0.9818 - cost: 2.3295 - val_loss: 0.1144 - val_auc: 0.9896 - val_accuracy: 0.9699 - val_cost: 3.7798\n",
            "Epoch 187/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0614 - auc: 0.9959 - accuracy: 0.9816 - cost: 2.3499 - val_loss: 0.1134 - val_auc: 0.9899 - val_accuracy: 0.9706 - val_cost: 3.6905\n",
            "Epoch 188/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0609 - auc: 0.9960 - accuracy: 0.9824 - cost: 2.2562 - val_loss: 0.1136 - val_auc: 0.9897 - val_accuracy: 0.9723 - val_cost: 3.5747\n",
            "Epoch 189/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0608 - auc: 0.9960 - accuracy: 0.9820 - cost: 2.3090 - val_loss: 0.1122 - val_auc: 0.9904 - val_accuracy: 0.9725 - val_cost: 3.4425\n",
            "Epoch 190/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0613 - auc: 0.9960 - accuracy: 0.9824 - cost: 2.2681 - val_loss: 0.1147 - val_auc: 0.9902 - val_accuracy: 0.9709 - val_cost: 3.5549\n",
            "Epoch 191/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0618 - auc: 0.9958 - accuracy: 0.9816 - cost: 2.3549 - val_loss: 0.1130 - val_auc: 0.9896 - val_accuracy: 0.9717 - val_cost: 3.5747\n",
            "Epoch 192/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0612 - auc: 0.9960 - accuracy: 0.9822 - cost: 2.2762 - val_loss: 0.1136 - val_auc: 0.9901 - val_accuracy: 0.9718 - val_cost: 3.4854\n",
            "Epoch 193/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0606 - auc: 0.9960 - accuracy: 0.9825 - cost: 2.2388 - val_loss: 0.1142 - val_auc: 0.9901 - val_accuracy: 0.9702 - val_cost: 3.7500\n",
            "Epoch 194/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0606 - auc: 0.9960 - accuracy: 0.9823 - cost: 2.2685 - val_loss: 0.1161 - val_auc: 0.9898 - val_accuracy: 0.9697 - val_cost: 3.7665\n",
            "Epoch 195/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0606 - auc: 0.9961 - accuracy: 0.9821 - cost: 2.3009 - val_loss: 0.1150 - val_auc: 0.9900 - val_accuracy: 0.9715 - val_cost: 3.5119\n",
            "Epoch 196/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0609 - auc: 0.9960 - accuracy: 0.9820 - cost: 2.3160 - val_loss: 0.1136 - val_auc: 0.9899 - val_accuracy: 0.9713 - val_cost: 3.6012\n",
            "Epoch 197/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0612 - auc: 0.9960 - accuracy: 0.9819 - cost: 2.3183 - val_loss: 0.1144 - val_auc: 0.9898 - val_accuracy: 0.9710 - val_cost: 3.5516\n",
            "Epoch 198/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0599 - auc: 0.9962 - accuracy: 0.9822 - cost: 2.2812 - val_loss: 0.1136 - val_auc: 0.9898 - val_accuracy: 0.9722 - val_cost: 3.4491\n",
            "Epoch 199/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0611 - auc: 0.9960 - accuracy: 0.9820 - cost: 2.3221 - val_loss: 0.1160 - val_auc: 0.9901 - val_accuracy: 0.9712 - val_cost: 3.5615\n",
            "Epoch 200/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0603 - auc: 0.9960 - accuracy: 0.9821 - cost: 2.2990 - val_loss: 0.1125 - val_auc: 0.9900 - val_accuracy: 0.9721 - val_cost: 3.4788\n",
            "Epoch 201/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0602 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2720 - val_loss: 0.1135 - val_auc: 0.9900 - val_accuracy: 0.9715 - val_cost: 3.6012\n",
            "Epoch 202/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0600 - auc: 0.9961 - accuracy: 0.9827 - cost: 2.2253 - val_loss: 0.1129 - val_auc: 0.9901 - val_accuracy: 0.9723 - val_cost: 3.4392\n",
            "Epoch 203/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0601 - auc: 0.9960 - accuracy: 0.9821 - cost: 2.2959 - val_loss: 0.1125 - val_auc: 0.9903 - val_accuracy: 0.9713 - val_cost: 3.5317\n",
            "Epoch 204/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0603 - auc: 0.9960 - accuracy: 0.9821 - cost: 2.2959 - val_loss: 0.1127 - val_auc: 0.9903 - val_accuracy: 0.9717 - val_cost: 3.4921\n",
            "Epoch 205/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0595 - auc: 0.9961 - accuracy: 0.9825 - cost: 2.2469 - val_loss: 0.1159 - val_auc: 0.9897 - val_accuracy: 0.9715 - val_cost: 3.5780\n",
            "Epoch 206/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0606 - auc: 0.9960 - accuracy: 0.9820 - cost: 2.3040 - val_loss: 0.1142 - val_auc: 0.9901 - val_accuracy: 0.9716 - val_cost: 3.4921\n",
            "Epoch 207/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0602 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2666 - val_loss: 0.1144 - val_auc: 0.9900 - val_accuracy: 0.9717 - val_cost: 3.4722\n",
            "Epoch 208/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0602 - auc: 0.9961 - accuracy: 0.9821 - cost: 2.2905 - val_loss: 0.1158 - val_auc: 0.9895 - val_accuracy: 0.9714 - val_cost: 3.5714\n",
            "Epoch 209/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0600 - auc: 0.9961 - accuracy: 0.9822 - cost: 2.2735 - val_loss: 0.1147 - val_auc: 0.9900 - val_accuracy: 0.9715 - val_cost: 3.5152\n",
            "Epoch 210/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0601 - auc: 0.9962 - accuracy: 0.9822 - cost: 2.2948 - val_loss: 0.1148 - val_auc: 0.9897 - val_accuracy: 0.9715 - val_cost: 3.5417\n",
            "Epoch 211/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0595 - auc: 0.9963 - accuracy: 0.9825 - cost: 2.2377 - val_loss: 0.1160 - val_auc: 0.9896 - val_accuracy: 0.9718 - val_cost: 3.5714\n",
            "Epoch 212/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0598 - auc: 0.9962 - accuracy: 0.9824 - cost: 2.2589 - val_loss: 0.1147 - val_auc: 0.9899 - val_accuracy: 0.9722 - val_cost: 3.4292\n",
            "Epoch 213/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0596 - auc: 0.9962 - accuracy: 0.9824 - cost: 2.2689 - val_loss: 0.1154 - val_auc: 0.9899 - val_accuracy: 0.9704 - val_cost: 3.7599\n",
            "Epoch 214/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0593 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2539 - val_loss: 0.1135 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.5119\n",
            "Epoch 215/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0588 - auc: 0.9962 - accuracy: 0.9827 - cost: 2.2234 - val_loss: 0.1160 - val_auc: 0.9895 - val_accuracy: 0.9708 - val_cost: 3.6243\n",
            "Epoch 216/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0595 - auc: 0.9962 - accuracy: 0.9822 - cost: 2.2824 - val_loss: 0.1162 - val_auc: 0.9898 - val_accuracy: 0.9714 - val_cost: 3.5780\n",
            "Epoch 217/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0598 - auc: 0.9961 - accuracy: 0.9825 - cost: 2.2485 - val_loss: 0.1171 - val_auc: 0.9899 - val_accuracy: 0.9712 - val_cost: 3.5351\n",
            "Epoch 218/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0596 - auc: 0.9962 - accuracy: 0.9823 - cost: 2.2697 - val_loss: 0.1155 - val_auc: 0.9896 - val_accuracy: 0.9709 - val_cost: 3.6078\n",
            "Epoch 219/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0590 - auc: 0.9962 - accuracy: 0.9827 - cost: 2.2226 - val_loss: 0.1170 - val_auc: 0.9899 - val_accuracy: 0.9699 - val_cost: 3.6839\n",
            "Epoch 220/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0592 - auc: 0.9962 - accuracy: 0.9823 - cost: 2.2681 - val_loss: 0.1177 - val_auc: 0.9900 - val_accuracy: 0.9708 - val_cost: 3.5979\n",
            "Epoch 221/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0592 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2369 - val_loss: 0.1155 - val_auc: 0.9896 - val_accuracy: 0.9722 - val_cost: 3.5020\n",
            "Epoch 222/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0596 - auc: 0.9961 - accuracy: 0.9825 - cost: 2.2515 - val_loss: 0.1187 - val_auc: 0.9891 - val_accuracy: 0.9723 - val_cost: 3.4590\n",
            "Epoch 223/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0595 - auc: 0.9961 - accuracy: 0.9825 - cost: 2.2407 - val_loss: 0.1195 - val_auc: 0.9897 - val_accuracy: 0.9710 - val_cost: 3.4921\n",
            "Epoch 224/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0588 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2481 - val_loss: 0.1149 - val_auc: 0.9895 - val_accuracy: 0.9725 - val_cost: 3.4921\n",
            "Epoch 225/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0585 - auc: 0.9963 - accuracy: 0.9824 - cost: 2.2593 - val_loss: 0.1173 - val_auc: 0.9896 - val_accuracy: 0.9708 - val_cost: 3.5979\n",
            "Epoch 226/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0600 - auc: 0.9961 - accuracy: 0.9825 - cost: 2.2454 - val_loss: 0.1191 - val_auc: 0.9891 - val_accuracy: 0.9715 - val_cost: 3.4987\n",
            "Epoch 227/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0590 - auc: 0.9961 - accuracy: 0.9825 - cost: 2.2469 - val_loss: 0.1185 - val_auc: 0.9896 - val_accuracy: 0.9701 - val_cost: 3.6872\n",
            "Epoch 228/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0591 - auc: 0.9963 - accuracy: 0.9823 - cost: 2.2820 - val_loss: 0.1158 - val_auc: 0.9896 - val_accuracy: 0.9720 - val_cost: 3.4524\n",
            "Epoch 229/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0585 - auc: 0.9962 - accuracy: 0.9828 - cost: 2.1979 - val_loss: 0.1169 - val_auc: 0.9896 - val_accuracy: 0.9718 - val_cost: 3.5946\n",
            "Epoch 230/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0593 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2539 - val_loss: 0.1190 - val_auc: 0.9895 - val_accuracy: 0.9710 - val_cost: 3.4954\n",
            "Epoch 231/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0591 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2473 - val_loss: 0.1171 - val_auc: 0.9898 - val_accuracy: 0.9715 - val_cost: 3.5648\n",
            "Epoch 232/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0584 - auc: 0.9962 - accuracy: 0.9828 - cost: 2.2079 - val_loss: 0.1164 - val_auc: 0.9892 - val_accuracy: 0.9708 - val_cost: 3.6442\n",
            "Epoch 233/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0590 - auc: 0.9963 - accuracy: 0.9827 - cost: 2.2311 - val_loss: 0.1159 - val_auc: 0.9898 - val_accuracy: 0.9713 - val_cost: 3.5714\n",
            "Epoch 234/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0582 - auc: 0.9964 - accuracy: 0.9828 - cost: 2.2095 - val_loss: 0.1161 - val_auc: 0.9898 - val_accuracy: 0.9712 - val_cost: 3.5847\n",
            "Epoch 235/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0587 - auc: 0.9963 - accuracy: 0.9828 - cost: 2.2168 - val_loss: 0.1169 - val_auc: 0.9895 - val_accuracy: 0.9706 - val_cost: 3.6607\n",
            "Epoch 236/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0581 - auc: 0.9963 - accuracy: 0.9829 - cost: 2.1998 - val_loss: 0.1189 - val_auc: 0.9895 - val_accuracy: 0.9699 - val_cost: 3.7235\n",
            "Epoch 237/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0591 - auc: 0.9962 - accuracy: 0.9823 - cost: 2.2650 - val_loss: 0.1170 - val_auc: 0.9894 - val_accuracy: 0.9707 - val_cost: 3.6574\n",
            "Epoch 238/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0579 - auc: 0.9963 - accuracy: 0.9829 - cost: 2.1825 - val_loss: 0.1179 - val_auc: 0.9894 - val_accuracy: 0.9708 - val_cost: 3.6276\n",
            "Epoch 239/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0575 - auc: 0.9963 - accuracy: 0.9829 - cost: 2.1914 - val_loss: 0.1175 - val_auc: 0.9895 - val_accuracy: 0.9714 - val_cost: 3.5847\n",
            "Epoch 240/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0580 - auc: 0.9963 - accuracy: 0.9828 - cost: 2.2099 - val_loss: 0.1184 - val_auc: 0.9897 - val_accuracy: 0.9714 - val_cost: 3.5185\n",
            "Epoch 241/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0573 - auc: 0.9964 - accuracy: 0.9829 - cost: 2.1863 - val_loss: 0.1156 - val_auc: 0.9896 - val_accuracy: 0.9709 - val_cost: 3.5549\n",
            "Epoch 242/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0578 - auc: 0.9963 - accuracy: 0.9828 - cost: 2.2137 - val_loss: 0.1176 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.5946\n",
            "Epoch 243/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0582 - auc: 0.9963 - accuracy: 0.9828 - cost: 2.1968 - val_loss: 0.1160 - val_auc: 0.9896 - val_accuracy: 0.9705 - val_cost: 3.7037\n",
            "Epoch 244/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0582 - auc: 0.9962 - accuracy: 0.9828 - cost: 2.2133 - val_loss: 0.1164 - val_auc: 0.9897 - val_accuracy: 0.9717 - val_cost: 3.6343\n",
            "Epoch 245/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0579 - auc: 0.9962 - accuracy: 0.9829 - cost: 2.1840 - val_loss: 0.1160 - val_auc: 0.9893 - val_accuracy: 0.9722 - val_cost: 3.4755\n",
            "Epoch 246/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0587 - auc: 0.9963 - accuracy: 0.9828 - cost: 2.2103 - val_loss: 0.1176 - val_auc: 0.9896 - val_accuracy: 0.9711 - val_cost: 3.5714\n",
            "Epoch 247/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0572 - auc: 0.9965 - accuracy: 0.9829 - cost: 2.1871 - val_loss: 0.1155 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.6574\n",
            "Epoch 248/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0571 - auc: 0.9965 - accuracy: 0.9832 - cost: 2.1624 - val_loss: 0.1188 - val_auc: 0.9895 - val_accuracy: 0.9703 - val_cost: 3.5681\n",
            "Epoch 249/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0575 - auc: 0.9963 - accuracy: 0.9831 - cost: 2.1682 - val_loss: 0.1184 - val_auc: 0.9895 - val_accuracy: 0.9706 - val_cost: 3.6739\n",
            "Epoch 250/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0572 - auc: 0.9964 - accuracy: 0.9830 - cost: 2.1933 - val_loss: 0.1167 - val_auc: 0.9895 - val_accuracy: 0.9712 - val_cost: 3.5681\n",
            "Epoch 251/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0579 - auc: 0.9964 - accuracy: 0.9825 - cost: 2.2469 - val_loss: 0.1183 - val_auc: 0.9894 - val_accuracy: 0.9715 - val_cost: 3.4954\n",
            "Epoch 252/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0580 - auc: 0.9963 - accuracy: 0.9831 - cost: 2.1779 - val_loss: 0.1201 - val_auc: 0.9890 - val_accuracy: 0.9712 - val_cost: 3.5317\n",
            "Epoch 253/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0579 - auc: 0.9964 - accuracy: 0.9827 - cost: 2.2133 - val_loss: 0.1169 - val_auc: 0.9894 - val_accuracy: 0.9717 - val_cost: 3.4788\n",
            "Epoch 254/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0575 - auc: 0.9963 - accuracy: 0.9834 - cost: 2.1277 - val_loss: 0.1186 - val_auc: 0.9895 - val_accuracy: 0.9703 - val_cost: 3.6905\n",
            "Epoch 255/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0574 - auc: 0.9964 - accuracy: 0.9832 - cost: 2.1574 - val_loss: 0.1208 - val_auc: 0.9893 - val_accuracy: 0.9711 - val_cost: 3.5417\n",
            "Epoch 256/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0570 - auc: 0.9964 - accuracy: 0.9832 - cost: 2.1578 - val_loss: 0.1189 - val_auc: 0.9895 - val_accuracy: 0.9722 - val_cost: 3.4226\n",
            "Epoch 257/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0572 - auc: 0.9964 - accuracy: 0.9830 - cost: 2.1809 - val_loss: 0.1201 - val_auc: 0.9894 - val_accuracy: 0.9712 - val_cost: 3.5119\n",
            "Epoch 258/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0573 - auc: 0.9964 - accuracy: 0.9830 - cost: 2.1875 - val_loss: 0.1171 - val_auc: 0.9894 - val_accuracy: 0.9712 - val_cost: 3.5417\n",
            "Epoch 259/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0568 - auc: 0.9964 - accuracy: 0.9831 - cost: 2.1586 - val_loss: 0.1164 - val_auc: 0.9898 - val_accuracy: 0.9720 - val_cost: 3.5185\n",
            "Epoch 260/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0581 - auc: 0.9963 - accuracy: 0.9829 - cost: 2.1898 - val_loss: 0.1190 - val_auc: 0.9894 - val_accuracy: 0.9717 - val_cost: 3.5185\n",
            "Epoch 261/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0573 - auc: 0.9964 - accuracy: 0.9832 - cost: 2.1617 - val_loss: 0.1214 - val_auc: 0.9890 - val_accuracy: 0.9715 - val_cost: 3.5417\n",
            "Epoch 262/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0575 - auc: 0.9963 - accuracy: 0.9828 - cost: 2.2052 - val_loss: 0.1190 - val_auc: 0.9895 - val_accuracy: 0.9708 - val_cost: 3.6376\n",
            "Epoch 263/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0571 - auc: 0.9965 - accuracy: 0.9829 - cost: 2.1894 - val_loss: 0.1172 - val_auc: 0.9897 - val_accuracy: 0.9706 - val_cost: 3.6541\n",
            "Epoch 264/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0569 - auc: 0.9964 - accuracy: 0.9830 - cost: 2.1817 - val_loss: 0.1186 - val_auc: 0.9898 - val_accuracy: 0.9712 - val_cost: 3.5880\n",
            "Epoch 265/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0568 - auc: 0.9964 - accuracy: 0.9830 - cost: 2.1852 - val_loss: 0.1194 - val_auc: 0.9895 - val_accuracy: 0.9711 - val_cost: 3.6243\n",
            "Epoch 266/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0565 - auc: 0.9965 - accuracy: 0.9831 - cost: 2.1728 - val_loss: 0.1176 - val_auc: 0.9898 - val_accuracy: 0.9720 - val_cost: 3.4854\n",
            "Epoch 267/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0578 - auc: 0.9963 - accuracy: 0.9829 - cost: 2.1948 - val_loss: 0.1176 - val_auc: 0.9892 - val_accuracy: 0.9713 - val_cost: 3.6409\n",
            "Epoch 268/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0574 - auc: 0.9963 - accuracy: 0.9830 - cost: 2.1775 - val_loss: 0.1185 - val_auc: 0.9894 - val_accuracy: 0.9713 - val_cost: 3.6376\n",
            "Epoch 269/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0578 - auc: 0.9962 - accuracy: 0.9829 - cost: 2.1929 - val_loss: 0.1187 - val_auc: 0.9896 - val_accuracy: 0.9724 - val_cost: 3.5053\n",
            "Epoch 270/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0563 - auc: 0.9964 - accuracy: 0.9836 - cost: 2.1130 - val_loss: 0.1181 - val_auc: 0.9896 - val_accuracy: 0.9706 - val_cost: 3.6541\n",
            "Epoch 271/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0566 - auc: 0.9964 - accuracy: 0.9830 - cost: 2.1852 - val_loss: 0.1194 - val_auc: 0.9894 - val_accuracy: 0.9711 - val_cost: 3.6111\n",
            "Epoch 272/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0569 - auc: 0.9964 - accuracy: 0.9832 - cost: 2.1539 - val_loss: 0.1188 - val_auc: 0.9891 - val_accuracy: 0.9708 - val_cost: 3.6673\n",
            "Epoch 273/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0574 - auc: 0.9964 - accuracy: 0.9831 - cost: 2.1632 - val_loss: 0.1192 - val_auc: 0.9894 - val_accuracy: 0.9710 - val_cost: 3.5582\n",
            "Epoch 274/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0571 - auc: 0.9964 - accuracy: 0.9831 - cost: 2.1717 - val_loss: 0.1188 - val_auc: 0.9892 - val_accuracy: 0.9710 - val_cost: 3.6144\n",
            "Epoch 275/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0568 - auc: 0.9965 - accuracy: 0.9828 - cost: 2.2103 - val_loss: 0.1185 - val_auc: 0.9894 - val_accuracy: 0.9703 - val_cost: 3.6045\n",
            "Epoch 276/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0559 - auc: 0.9965 - accuracy: 0.9834 - cost: 2.1265 - val_loss: 0.1221 - val_auc: 0.9893 - val_accuracy: 0.9703 - val_cost: 3.5979\n",
            "Epoch 277/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0564 - auc: 0.9964 - accuracy: 0.9832 - cost: 2.1590 - val_loss: 0.1182 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.6276\n",
            "Epoch 278/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0560 - auc: 0.9966 - accuracy: 0.9832 - cost: 2.1408 - val_loss: 0.1192 - val_auc: 0.9895 - val_accuracy: 0.9708 - val_cost: 3.6045\n",
            "Epoch 279/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0568 - auc: 0.9965 - accuracy: 0.9827 - cost: 2.2238 - val_loss: 0.1193 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.5714\n",
            "Epoch 280/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0568 - auc: 0.9965 - accuracy: 0.9826 - cost: 2.2346 - val_loss: 0.1211 - val_auc: 0.9893 - val_accuracy: 0.9715 - val_cost: 3.4392\n",
            "Epoch 281/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0567 - auc: 0.9964 - accuracy: 0.9830 - cost: 2.1829 - val_loss: 0.1169 - val_auc: 0.9898 - val_accuracy: 0.9710 - val_cost: 3.5847\n",
            "Epoch 282/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0565 - auc: 0.9965 - accuracy: 0.9833 - cost: 2.1408 - val_loss: 0.1193 - val_auc: 0.9894 - val_accuracy: 0.9715 - val_cost: 3.5813\n",
            "Epoch 283/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0570 - auc: 0.9963 - accuracy: 0.9832 - cost: 2.1609 - val_loss: 0.1195 - val_auc: 0.9895 - val_accuracy: 0.9710 - val_cost: 3.5813\n",
            "Epoch 284/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0567 - auc: 0.9964 - accuracy: 0.9833 - cost: 2.1431 - val_loss: 0.1195 - val_auc: 0.9891 - val_accuracy: 0.9716 - val_cost: 3.5615\n",
            "Epoch 285/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0555 - auc: 0.9965 - accuracy: 0.9836 - cost: 2.1065 - val_loss: 0.1199 - val_auc: 0.9893 - val_accuracy: 0.9707 - val_cost: 3.6607\n",
            "Epoch 286/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0561 - auc: 0.9965 - accuracy: 0.9831 - cost: 2.1786 - val_loss: 0.1213 - val_auc: 0.9896 - val_accuracy: 0.9707 - val_cost: 3.5780\n",
            "Epoch 287/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0566 - auc: 0.9964 - accuracy: 0.9834 - cost: 2.1265 - val_loss: 0.1193 - val_auc: 0.9897 - val_accuracy: 0.9712 - val_cost: 3.5847\n",
            "Epoch 288/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0562 - auc: 0.9965 - accuracy: 0.9833 - cost: 2.1416 - val_loss: 0.1202 - val_auc: 0.9895 - val_accuracy: 0.9708 - val_cost: 3.5847\n",
            "Epoch 289/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0558 - auc: 0.9966 - accuracy: 0.9835 - cost: 2.1204 - val_loss: 0.1213 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.5582\n",
            "Epoch 290/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0564 - auc: 0.9965 - accuracy: 0.9833 - cost: 2.1478 - val_loss: 0.1205 - val_auc: 0.9890 - val_accuracy: 0.9710 - val_cost: 3.6409\n",
            "Epoch 291/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0560 - auc: 0.9965 - accuracy: 0.9832 - cost: 2.1593 - val_loss: 0.1205 - val_auc: 0.9895 - val_accuracy: 0.9715 - val_cost: 3.5119\n",
            "Epoch 292/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0558 - auc: 0.9965 - accuracy: 0.9835 - cost: 2.1262 - val_loss: 0.1213 - val_auc: 0.9894 - val_accuracy: 0.9712 - val_cost: 3.5615\n",
            "Epoch 293/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0558 - auc: 0.9967 - accuracy: 0.9833 - cost: 2.1416 - val_loss: 0.1218 - val_auc: 0.9893 - val_accuracy: 0.9709 - val_cost: 3.6045\n",
            "Epoch 294/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0561 - auc: 0.9964 - accuracy: 0.9834 - cost: 2.1312 - val_loss: 0.1214 - val_auc: 0.9892 - val_accuracy: 0.9710 - val_cost: 3.5582\n",
            "Epoch 295/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0561 - auc: 0.9964 - accuracy: 0.9832 - cost: 2.1524 - val_loss: 0.1194 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.7302\n",
            "Epoch 296/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0550 - auc: 0.9966 - accuracy: 0.9832 - cost: 2.1570 - val_loss: 0.1249 - val_auc: 0.9891 - val_accuracy: 0.9703 - val_cost: 3.7235\n",
            "Epoch 297/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0556 - auc: 0.9965 - accuracy: 0.9834 - cost: 2.1300 - val_loss: 0.1205 - val_auc: 0.9892 - val_accuracy: 0.9710 - val_cost: 3.6210\n",
            "Epoch 298/1000\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.0550 - auc: 0.9966 - accuracy: 0.9835 - cost: 2.1154 - val_loss: 0.1191 - val_auc: 0.9894 - val_accuracy: 0.9704 - val_cost: 3.6343\n",
            "Epoch 299/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0557 - auc: 0.9966 - accuracy: 0.9831 - cost: 2.1667 - val_loss: 0.1194 - val_auc: 0.9897 - val_accuracy: 0.9722 - val_cost: 3.5384\n",
            "Epoch 300/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0552 - auc: 0.9966 - accuracy: 0.9838 - cost: 2.0756 - val_loss: 0.1201 - val_auc: 0.9894 - val_accuracy: 0.9702 - val_cost: 3.7169\n",
            "Epoch 301/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0556 - auc: 0.9966 - accuracy: 0.9835 - cost: 2.1219 - val_loss: 0.1206 - val_auc: 0.9896 - val_accuracy: 0.9715 - val_cost: 3.6045\n",
            "Epoch 302/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0557 - auc: 0.9966 - accuracy: 0.9834 - cost: 2.1285 - val_loss: 0.1224 - val_auc: 0.9892 - val_accuracy: 0.9716 - val_cost: 3.6045\n",
            "Epoch 303/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0561 - auc: 0.9966 - accuracy: 0.9835 - cost: 2.1335 - val_loss: 0.1200 - val_auc: 0.9894 - val_accuracy: 0.9717 - val_cost: 3.4788\n",
            "Epoch 304/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0555 - auc: 0.9965 - accuracy: 0.9836 - cost: 2.0980 - val_loss: 0.1228 - val_auc: 0.9894 - val_accuracy: 0.9716 - val_cost: 3.4788\n",
            "Epoch 305/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0553 - auc: 0.9965 - accuracy: 0.9832 - cost: 2.1570 - val_loss: 0.1220 - val_auc: 0.9891 - val_accuracy: 0.9712 - val_cost: 3.5582\n",
            "Epoch 306/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0547 - auc: 0.9966 - accuracy: 0.9837 - cost: 2.1042 - val_loss: 0.1235 - val_auc: 0.9890 - val_accuracy: 0.9704 - val_cost: 3.6508\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.1192 - auc: 0.9899 - accuracy: 0.9712 - cost: 3.6031\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:02:07.215817\n",
            "fold accuracy: 0.9711874723434448 - fold cost: 3.6031250953674316\n",
            "x_train shape: (144000, 67)\n",
            "Epoch 1/1000\n",
            "120/120 [==============================] - 2s 6ms/step - loss: 0.5321 - auc: 0.7960 - accuracy: 0.7264 - cost: 36.4738 - val_loss: 0.3994 - val_auc: 0.8983 - val_accuracy: 0.8247 - val_cost: 22.2685\n",
            "Epoch 2/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.3521 - auc: 0.9212 - accuracy: 0.8492 - cost: 19.2191 - val_loss: 0.3194 - val_auc: 0.9348 - val_accuracy: 0.8668 - val_cost: 16.8684\n",
            "Epoch 3/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.3032 - auc: 0.9417 - accuracy: 0.8738 - cost: 15.9911 - val_loss: 0.2892 - val_auc: 0.9470 - val_accuracy: 0.8812 - val_cost: 14.7421\n",
            "Epoch 4/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2749 - auc: 0.9522 - accuracy: 0.8886 - cost: 14.0945 - val_loss: 0.2649 - val_auc: 0.9559 - val_accuracy: 0.8943 - val_cost: 13.5251\n",
            "Epoch 5/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2525 - auc: 0.9597 - accuracy: 0.8986 - cost: 12.8434 - val_loss: 0.2442 - val_auc: 0.9625 - val_accuracy: 0.9053 - val_cost: 11.9147\n",
            "Epoch 6/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.2327 - auc: 0.9659 - accuracy: 0.9080 - cost: 11.6227 - val_loss: 0.2272 - val_auc: 0.9672 - val_accuracy: 0.9132 - val_cost: 10.9325\n",
            "Epoch 7/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2167 - auc: 0.9702 - accuracy: 0.9163 - cost: 10.5914 - val_loss: 0.2140 - val_auc: 0.9709 - val_accuracy: 0.9195 - val_cost: 10.0529\n",
            "Epoch 8/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2026 - auc: 0.9739 - accuracy: 0.9221 - cost: 9.8414 - val_loss: 0.2022 - val_auc: 0.9737 - val_accuracy: 0.9244 - val_cost: 9.5701\n",
            "Epoch 9/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1918 - auc: 0.9765 - accuracy: 0.9274 - cost: 9.1821 - val_loss: 0.1916 - val_auc: 0.9763 - val_accuracy: 0.9302 - val_cost: 8.7434\n",
            "Epoch 10/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1818 - auc: 0.9787 - accuracy: 0.9325 - cost: 8.5255 - val_loss: 0.1874 - val_auc: 0.9774 - val_accuracy: 0.9315 - val_cost: 8.8624\n",
            "Epoch 11/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1749 - auc: 0.9801 - accuracy: 0.9352 - cost: 8.2002 - val_loss: 0.1783 - val_auc: 0.9791 - val_accuracy: 0.9356 - val_cost: 8.1647\n",
            "Epoch 12/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1680 - auc: 0.9815 - accuracy: 0.9383 - cost: 7.8144 - val_loss: 0.1733 - val_auc: 0.9802 - val_accuracy: 0.9370 - val_cost: 7.8968\n",
            "Epoch 13/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1624 - auc: 0.9825 - accuracy: 0.9408 - cost: 7.4830 - val_loss: 0.1691 - val_auc: 0.9809 - val_accuracy: 0.9395 - val_cost: 7.6422\n",
            "Epoch 14/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1580 - auc: 0.9835 - accuracy: 0.9425 - cost: 7.2874 - val_loss: 0.1657 - val_auc: 0.9816 - val_accuracy: 0.9407 - val_cost: 7.3545\n",
            "Epoch 15/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1537 - auc: 0.9842 - accuracy: 0.9449 - cost: 6.9788 - val_loss: 0.1611 - val_auc: 0.9827 - val_accuracy: 0.9431 - val_cost: 7.1660\n",
            "Epoch 16/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1499 - auc: 0.9849 - accuracy: 0.9464 - cost: 6.7890 - val_loss: 0.1589 - val_auc: 0.9831 - val_accuracy: 0.9434 - val_cost: 7.1925\n",
            "Epoch 17/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1462 - auc: 0.9855 - accuracy: 0.9482 - cost: 6.5613 - val_loss: 0.1591 - val_auc: 0.9832 - val_accuracy: 0.9443 - val_cost: 6.8056\n",
            "Epoch 18/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1434 - auc: 0.9860 - accuracy: 0.9491 - cost: 6.4529 - val_loss: 0.1542 - val_auc: 0.9839 - val_accuracy: 0.9467 - val_cost: 6.6501\n",
            "Epoch 19/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1410 - auc: 0.9865 - accuracy: 0.9502 - cost: 6.3086 - val_loss: 0.1532 - val_auc: 0.9842 - val_accuracy: 0.9465 - val_cost: 6.6733\n",
            "Epoch 20/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1380 - auc: 0.9869 - accuracy: 0.9516 - cost: 6.1254 - val_loss: 0.1509 - val_auc: 0.9845 - val_accuracy: 0.9469 - val_cost: 6.7394\n",
            "Epoch 21/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1361 - auc: 0.9873 - accuracy: 0.9525 - cost: 6.0208 - val_loss: 0.1500 - val_auc: 0.9848 - val_accuracy: 0.9484 - val_cost: 6.3757\n",
            "Epoch 22/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1333 - auc: 0.9877 - accuracy: 0.9537 - cost: 5.8688 - val_loss: 0.1488 - val_auc: 0.9850 - val_accuracy: 0.9474 - val_cost: 6.4418\n",
            "Epoch 23/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1312 - auc: 0.9881 - accuracy: 0.9542 - cost: 5.7990 - val_loss: 0.1451 - val_auc: 0.9855 - val_accuracy: 0.9498 - val_cost: 6.2136\n",
            "Epoch 24/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1292 - auc: 0.9883 - accuracy: 0.9555 - cost: 5.6254 - val_loss: 0.1448 - val_auc: 0.9856 - val_accuracy: 0.9498 - val_cost: 6.2996\n",
            "Epoch 25/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1274 - auc: 0.9885 - accuracy: 0.9565 - cost: 5.5212 - val_loss: 0.1437 - val_auc: 0.9857 - val_accuracy: 0.9500 - val_cost: 6.2070\n",
            "Epoch 26/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1253 - auc: 0.9888 - accuracy: 0.9572 - cost: 5.4105 - val_loss: 0.1428 - val_auc: 0.9860 - val_accuracy: 0.9519 - val_cost: 5.9292\n",
            "Epoch 27/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1235 - auc: 0.9891 - accuracy: 0.9580 - cost: 5.3106 - val_loss: 0.1433 - val_auc: 0.9860 - val_accuracy: 0.9513 - val_cost: 6.3294\n",
            "Epoch 28/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1222 - auc: 0.9893 - accuracy: 0.9587 - cost: 5.2272 - val_loss: 0.1401 - val_auc: 0.9862 - val_accuracy: 0.9525 - val_cost: 6.0119\n",
            "Epoch 29/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1209 - auc: 0.9895 - accuracy: 0.9590 - cost: 5.1991 - val_loss: 0.1394 - val_auc: 0.9864 - val_accuracy: 0.9528 - val_cost: 6.0483\n",
            "Epoch 30/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1189 - auc: 0.9897 - accuracy: 0.9600 - cost: 5.0671 - val_loss: 0.1390 - val_auc: 0.9866 - val_accuracy: 0.9533 - val_cost: 5.9127\n",
            "Epoch 31/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1176 - auc: 0.9899 - accuracy: 0.9608 - cost: 4.9726 - val_loss: 0.1372 - val_auc: 0.9868 - val_accuracy: 0.9542 - val_cost: 5.7275\n",
            "Epoch 32/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1169 - auc: 0.9900 - accuracy: 0.9608 - cost: 4.9495 - val_loss: 0.1374 - val_auc: 0.9867 - val_accuracy: 0.9541 - val_cost: 5.8399\n",
            "Epoch 33/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1149 - auc: 0.9902 - accuracy: 0.9623 - cost: 4.7805 - val_loss: 0.1366 - val_auc: 0.9869 - val_accuracy: 0.9562 - val_cost: 5.4663\n",
            "Epoch 34/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1138 - auc: 0.9904 - accuracy: 0.9620 - cost: 4.8125 - val_loss: 0.1351 - val_auc: 0.9872 - val_accuracy: 0.9563 - val_cost: 5.4729\n",
            "Epoch 35/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1127 - auc: 0.9906 - accuracy: 0.9630 - cost: 4.6848 - val_loss: 0.1336 - val_auc: 0.9871 - val_accuracy: 0.9574 - val_cost: 5.3968\n",
            "Epoch 36/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1108 - auc: 0.9908 - accuracy: 0.9633 - cost: 4.6620 - val_loss: 0.1343 - val_auc: 0.9872 - val_accuracy: 0.9573 - val_cost: 5.4101\n",
            "Epoch 37/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1107 - auc: 0.9908 - accuracy: 0.9635 - cost: 4.6335 - val_loss: 0.1336 - val_auc: 0.9872 - val_accuracy: 0.9577 - val_cost: 5.2017\n",
            "Epoch 38/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1101 - auc: 0.9909 - accuracy: 0.9638 - cost: 4.5922 - val_loss: 0.1328 - val_auc: 0.9873 - val_accuracy: 0.9574 - val_cost: 5.2778\n",
            "Epoch 39/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1072 - auc: 0.9913 - accuracy: 0.9648 - cost: 4.4568 - val_loss: 0.1319 - val_auc: 0.9873 - val_accuracy: 0.9571 - val_cost: 5.4828\n",
            "Epoch 40/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1072 - auc: 0.9911 - accuracy: 0.9651 - cost: 4.4344 - val_loss: 0.1319 - val_auc: 0.9872 - val_accuracy: 0.9580 - val_cost: 5.2679\n",
            "Epoch 41/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1069 - auc: 0.9912 - accuracy: 0.9654 - cost: 4.3900 - val_loss: 0.1307 - val_auc: 0.9874 - val_accuracy: 0.9587 - val_cost: 5.1852\n",
            "Epoch 42/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1046 - auc: 0.9915 - accuracy: 0.9668 - cost: 4.2133 - val_loss: 0.1311 - val_auc: 0.9875 - val_accuracy: 0.9577 - val_cost: 5.2083\n",
            "Epoch 43/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1029 - auc: 0.9918 - accuracy: 0.9664 - cost: 4.2654 - val_loss: 0.1292 - val_auc: 0.9877 - val_accuracy: 0.9590 - val_cost: 5.0893\n",
            "Epoch 44/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1029 - auc: 0.9917 - accuracy: 0.9668 - cost: 4.2242 - val_loss: 0.1287 - val_auc: 0.9876 - val_accuracy: 0.9591 - val_cost: 5.1422\n",
            "Epoch 45/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1016 - auc: 0.9919 - accuracy: 0.9670 - cost: 4.1887 - val_loss: 0.1286 - val_auc: 0.9876 - val_accuracy: 0.9607 - val_cost: 4.9603\n",
            "Epoch 46/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1017 - auc: 0.9919 - accuracy: 0.9673 - cost: 4.1566 - val_loss: 0.1283 - val_auc: 0.9877 - val_accuracy: 0.9603 - val_cost: 4.8776\n",
            "Epoch 47/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0999 - auc: 0.9920 - accuracy: 0.9682 - cost: 4.0293 - val_loss: 0.1266 - val_auc: 0.9877 - val_accuracy: 0.9591 - val_cost: 5.1323\n",
            "Epoch 48/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1002 - auc: 0.9919 - accuracy: 0.9681 - cost: 4.0502 - val_loss: 0.1243 - val_auc: 0.9881 - val_accuracy: 0.9618 - val_cost: 4.8512\n",
            "Epoch 49/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0978 - auc: 0.9923 - accuracy: 0.9692 - cost: 3.9178 - val_loss: 0.1249 - val_auc: 0.9882 - val_accuracy: 0.9601 - val_cost: 5.1455\n",
            "Epoch 50/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0970 - auc: 0.9924 - accuracy: 0.9692 - cost: 3.9198 - val_loss: 0.1246 - val_auc: 0.9885 - val_accuracy: 0.9618 - val_cost: 4.7553\n",
            "Epoch 51/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0970 - auc: 0.9924 - accuracy: 0.9691 - cost: 3.9333 - val_loss: 0.1238 - val_auc: 0.9883 - val_accuracy: 0.9617 - val_cost: 4.9339\n",
            "Epoch 52/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0959 - auc: 0.9925 - accuracy: 0.9701 - cost: 3.8171 - val_loss: 0.1245 - val_auc: 0.9882 - val_accuracy: 0.9621 - val_cost: 4.6329\n",
            "Epoch 53/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0952 - auc: 0.9925 - accuracy: 0.9703 - cost: 3.7731 - val_loss: 0.1237 - val_auc: 0.9882 - val_accuracy: 0.9617 - val_cost: 4.8710\n",
            "Epoch 54/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0945 - auc: 0.9926 - accuracy: 0.9706 - cost: 3.7299 - val_loss: 0.1237 - val_auc: 0.9884 - val_accuracy: 0.9633 - val_cost: 4.4808\n",
            "Epoch 55/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0931 - auc: 0.9928 - accuracy: 0.9709 - cost: 3.6991 - val_loss: 0.1217 - val_auc: 0.9885 - val_accuracy: 0.9636 - val_cost: 4.6329\n",
            "Epoch 56/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0927 - auc: 0.9928 - accuracy: 0.9708 - cost: 3.7010 - val_loss: 0.1207 - val_auc: 0.9886 - val_accuracy: 0.9628 - val_cost: 4.6693\n",
            "Epoch 57/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0926 - auc: 0.9927 - accuracy: 0.9709 - cost: 3.6894 - val_loss: 0.1207 - val_auc: 0.9886 - val_accuracy: 0.9632 - val_cost: 4.6263\n",
            "Epoch 58/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0908 - auc: 0.9931 - accuracy: 0.9714 - cost: 3.6308 - val_loss: 0.1226 - val_auc: 0.9887 - val_accuracy: 0.9638 - val_cost: 4.5007\n",
            "Epoch 59/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0911 - auc: 0.9930 - accuracy: 0.9714 - cost: 3.6196 - val_loss: 0.1185 - val_auc: 0.9889 - val_accuracy: 0.9631 - val_cost: 4.6627\n",
            "Epoch 60/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0896 - auc: 0.9932 - accuracy: 0.9727 - cost: 3.4726 - val_loss: 0.1177 - val_auc: 0.9890 - val_accuracy: 0.9645 - val_cost: 4.4874\n",
            "Epoch 61/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0890 - auc: 0.9931 - accuracy: 0.9726 - cost: 3.4792 - val_loss: 0.1178 - val_auc: 0.9890 - val_accuracy: 0.9640 - val_cost: 4.5205\n",
            "Epoch 62/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0890 - auc: 0.9931 - accuracy: 0.9725 - cost: 3.5120 - val_loss: 0.1183 - val_auc: 0.9888 - val_accuracy: 0.9641 - val_cost: 4.4312\n",
            "Epoch 63/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0877 - auc: 0.9933 - accuracy: 0.9730 - cost: 3.4333 - val_loss: 0.1171 - val_auc: 0.9889 - val_accuracy: 0.9648 - val_cost: 4.4081\n",
            "Epoch 64/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0878 - auc: 0.9932 - accuracy: 0.9734 - cost: 3.3758 - val_loss: 0.1167 - val_auc: 0.9893 - val_accuracy: 0.9649 - val_cost: 4.5139\n",
            "Epoch 65/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0863 - auc: 0.9934 - accuracy: 0.9734 - cost: 3.3754 - val_loss: 0.1154 - val_auc: 0.9894 - val_accuracy: 0.9641 - val_cost: 4.5767\n",
            "Epoch 66/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0866 - auc: 0.9934 - accuracy: 0.9734 - cost: 3.3785 - val_loss: 0.1159 - val_auc: 0.9889 - val_accuracy: 0.9635 - val_cost: 4.5635\n",
            "Epoch 67/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0855 - auc: 0.9935 - accuracy: 0.9740 - cost: 3.3029 - val_loss: 0.1165 - val_auc: 0.9891 - val_accuracy: 0.9643 - val_cost: 4.5470\n",
            "Epoch 68/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0850 - auc: 0.9936 - accuracy: 0.9738 - cost: 3.3314 - val_loss: 0.1148 - val_auc: 0.9891 - val_accuracy: 0.9663 - val_cost: 4.1799\n",
            "Epoch 69/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0854 - auc: 0.9936 - accuracy: 0.9739 - cost: 3.3164 - val_loss: 0.1151 - val_auc: 0.9893 - val_accuracy: 0.9656 - val_cost: 4.3485\n",
            "Epoch 70/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0840 - auc: 0.9937 - accuracy: 0.9745 - cost: 3.2604 - val_loss: 0.1151 - val_auc: 0.9894 - val_accuracy: 0.9648 - val_cost: 4.3783\n",
            "Epoch 71/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0827 - auc: 0.9938 - accuracy: 0.9747 - cost: 3.2110 - val_loss: 0.1148 - val_auc: 0.9893 - val_accuracy: 0.9654 - val_cost: 4.2725\n",
            "Epoch 72/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0836 - auc: 0.9937 - accuracy: 0.9747 - cost: 3.2133 - val_loss: 0.1145 - val_auc: 0.9892 - val_accuracy: 0.9653 - val_cost: 4.3783\n",
            "Epoch 73/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0841 - auc: 0.9937 - accuracy: 0.9743 - cost: 3.2654 - val_loss: 0.1157 - val_auc: 0.9894 - val_accuracy: 0.9654 - val_cost: 4.1799\n",
            "Epoch 74/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0817 - auc: 0.9939 - accuracy: 0.9753 - cost: 3.1412 - val_loss: 0.1133 - val_auc: 0.9896 - val_accuracy: 0.9672 - val_cost: 4.0675\n",
            "Epoch 75/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0819 - auc: 0.9939 - accuracy: 0.9748 - cost: 3.2091 - val_loss: 0.1144 - val_auc: 0.9896 - val_accuracy: 0.9654 - val_cost: 4.2857\n",
            "Epoch 76/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0812 - auc: 0.9939 - accuracy: 0.9754 - cost: 3.1316 - val_loss: 0.1132 - val_auc: 0.9896 - val_accuracy: 0.9667 - val_cost: 4.2593\n",
            "Epoch 77/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0806 - auc: 0.9941 - accuracy: 0.9754 - cost: 3.1346 - val_loss: 0.1131 - val_auc: 0.9893 - val_accuracy: 0.9660 - val_cost: 4.3022\n",
            "Epoch 78/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0811 - auc: 0.9939 - accuracy: 0.9754 - cost: 3.1350 - val_loss: 0.1132 - val_auc: 0.9894 - val_accuracy: 0.9655 - val_cost: 4.3816\n",
            "Epoch 79/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0808 - auc: 0.9939 - accuracy: 0.9756 - cost: 3.1046 - val_loss: 0.1129 - val_auc: 0.9895 - val_accuracy: 0.9667 - val_cost: 4.2196\n",
            "Epoch 80/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0800 - auc: 0.9941 - accuracy: 0.9762 - cost: 3.0274 - val_loss: 0.1142 - val_auc: 0.9895 - val_accuracy: 0.9666 - val_cost: 4.1138\n",
            "Epoch 81/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0796 - auc: 0.9941 - accuracy: 0.9760 - cost: 3.0502 - val_loss: 0.1133 - val_auc: 0.9895 - val_accuracy: 0.9676 - val_cost: 4.0410\n",
            "Epoch 82/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0801 - auc: 0.9940 - accuracy: 0.9756 - cost: 3.1030 - val_loss: 0.1127 - val_auc: 0.9895 - val_accuracy: 0.9669 - val_cost: 4.2063\n",
            "Epoch 83/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0784 - auc: 0.9942 - accuracy: 0.9768 - cost: 2.9498 - val_loss: 0.1120 - val_auc: 0.9893 - val_accuracy: 0.9668 - val_cost: 4.2163\n",
            "Epoch 84/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0779 - auc: 0.9943 - accuracy: 0.9764 - cost: 3.0050 - val_loss: 0.1113 - val_auc: 0.9896 - val_accuracy: 0.9660 - val_cost: 4.2361\n",
            "Epoch 85/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0787 - auc: 0.9942 - accuracy: 0.9765 - cost: 2.9942 - val_loss: 0.1111 - val_auc: 0.9895 - val_accuracy: 0.9661 - val_cost: 4.2857\n",
            "Epoch 86/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0775 - auc: 0.9943 - accuracy: 0.9763 - cost: 3.0181 - val_loss: 0.1112 - val_auc: 0.9896 - val_accuracy: 0.9676 - val_cost: 3.9021\n",
            "Epoch 87/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0782 - auc: 0.9943 - accuracy: 0.9760 - cost: 3.0571 - val_loss: 0.1114 - val_auc: 0.9896 - val_accuracy: 0.9672 - val_cost: 4.1038\n",
            "Epoch 88/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0769 - auc: 0.9944 - accuracy: 0.9772 - cost: 2.9062 - val_loss: 0.1112 - val_auc: 0.9896 - val_accuracy: 0.9686 - val_cost: 3.8724\n",
            "Epoch 89/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0764 - auc: 0.9943 - accuracy: 0.9774 - cost: 2.8812 - val_loss: 0.1142 - val_auc: 0.9893 - val_accuracy: 0.9667 - val_cost: 4.0675\n",
            "Epoch 90/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0769 - auc: 0.9943 - accuracy: 0.9772 - cost: 2.9066 - val_loss: 0.1126 - val_auc: 0.9894 - val_accuracy: 0.9667 - val_cost: 4.1634\n",
            "Epoch 91/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0758 - auc: 0.9944 - accuracy: 0.9773 - cost: 2.8873 - val_loss: 0.1124 - val_auc: 0.9896 - val_accuracy: 0.9669 - val_cost: 4.1270\n",
            "Epoch 92/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0754 - auc: 0.9945 - accuracy: 0.9772 - cost: 2.9051 - val_loss: 0.1102 - val_auc: 0.9896 - val_accuracy: 0.9679 - val_cost: 4.0377\n",
            "Epoch 93/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0762 - auc: 0.9944 - accuracy: 0.9772 - cost: 2.8893 - val_loss: 0.1104 - val_auc: 0.9896 - val_accuracy: 0.9683 - val_cost: 4.0046\n",
            "Epoch 94/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0752 - auc: 0.9945 - accuracy: 0.9780 - cost: 2.8059 - val_loss: 0.1101 - val_auc: 0.9897 - val_accuracy: 0.9674 - val_cost: 4.1369\n",
            "Epoch 95/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0738 - auc: 0.9946 - accuracy: 0.9780 - cost: 2.8036 - val_loss: 0.1117 - val_auc: 0.9895 - val_accuracy: 0.9679 - val_cost: 4.0575\n",
            "Epoch 96/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0749 - auc: 0.9946 - accuracy: 0.9776 - cost: 2.8480 - val_loss: 0.1116 - val_auc: 0.9893 - val_accuracy: 0.9686 - val_cost: 3.9385\n",
            "Epoch 97/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0740 - auc: 0.9947 - accuracy: 0.9780 - cost: 2.7936 - val_loss: 0.1101 - val_auc: 0.9897 - val_accuracy: 0.9685 - val_cost: 3.9187\n",
            "Epoch 98/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0742 - auc: 0.9946 - accuracy: 0.9781 - cost: 2.7886 - val_loss: 0.1107 - val_auc: 0.9895 - val_accuracy: 0.9680 - val_cost: 4.0146\n",
            "Epoch 99/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0731 - auc: 0.9948 - accuracy: 0.9781 - cost: 2.7870 - val_loss: 0.1115 - val_auc: 0.9897 - val_accuracy: 0.9678 - val_cost: 4.0046\n",
            "Epoch 100/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0732 - auc: 0.9946 - accuracy: 0.9786 - cost: 2.7307 - val_loss: 0.1091 - val_auc: 0.9896 - val_accuracy: 0.9691 - val_cost: 3.9550\n",
            "Epoch 101/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0742 - auc: 0.9946 - accuracy: 0.9781 - cost: 2.7948 - val_loss: 0.1105 - val_auc: 0.9897 - val_accuracy: 0.9674 - val_cost: 3.9947\n",
            "Epoch 102/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0737 - auc: 0.9946 - accuracy: 0.9782 - cost: 2.7890 - val_loss: 0.1097 - val_auc: 0.9898 - val_accuracy: 0.9690 - val_cost: 3.8823\n",
            "Epoch 103/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0726 - auc: 0.9947 - accuracy: 0.9782 - cost: 2.7751 - val_loss: 0.1113 - val_auc: 0.9897 - val_accuracy: 0.9674 - val_cost: 4.1567\n",
            "Epoch 104/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0724 - auc: 0.9947 - accuracy: 0.9790 - cost: 2.6836 - val_loss: 0.1103 - val_auc: 0.9898 - val_accuracy: 0.9687 - val_cost: 3.9616\n",
            "Epoch 105/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0720 - auc: 0.9948 - accuracy: 0.9790 - cost: 2.6690 - val_loss: 0.1096 - val_auc: 0.9896 - val_accuracy: 0.9690 - val_cost: 3.9683\n",
            "Epoch 106/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0730 - auc: 0.9947 - accuracy: 0.9786 - cost: 2.7380 - val_loss: 0.1120 - val_auc: 0.9897 - val_accuracy: 0.9682 - val_cost: 4.0079\n",
            "Epoch 107/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0723 - auc: 0.9949 - accuracy: 0.9790 - cost: 2.6782 - val_loss: 0.1101 - val_auc: 0.9896 - val_accuracy: 0.9683 - val_cost: 3.9220\n",
            "Epoch 108/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0717 - auc: 0.9949 - accuracy: 0.9789 - cost: 2.6991 - val_loss: 0.1113 - val_auc: 0.9895 - val_accuracy: 0.9690 - val_cost: 3.9418\n",
            "Epoch 109/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0713 - auc: 0.9949 - accuracy: 0.9794 - cost: 2.6385 - val_loss: 0.1108 - val_auc: 0.9896 - val_accuracy: 0.9690 - val_cost: 3.8558\n",
            "Epoch 110/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0711 - auc: 0.9950 - accuracy: 0.9794 - cost: 2.6443 - val_loss: 0.1105 - val_auc: 0.9900 - val_accuracy: 0.9688 - val_cost: 3.9220\n",
            "Epoch 111/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9949 - accuracy: 0.9791 - cost: 2.6694 - val_loss: 0.1109 - val_auc: 0.9899 - val_accuracy: 0.9694 - val_cost: 3.8624\n",
            "Epoch 112/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0713 - auc: 0.9949 - accuracy: 0.9790 - cost: 2.6852 - val_loss: 0.1092 - val_auc: 0.9899 - val_accuracy: 0.9691 - val_cost: 4.0079\n",
            "Epoch 113/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0717 - auc: 0.9949 - accuracy: 0.9788 - cost: 2.6995 - val_loss: 0.1094 - val_auc: 0.9895 - val_accuracy: 0.9701 - val_cost: 3.7401\n",
            "Epoch 114/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0708 - auc: 0.9950 - accuracy: 0.9792 - cost: 2.6644 - val_loss: 0.1102 - val_auc: 0.9897 - val_accuracy: 0.9697 - val_cost: 3.8525\n",
            "Epoch 115/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0696 - auc: 0.9950 - accuracy: 0.9792 - cost: 2.6701 - val_loss: 0.1100 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.7665\n",
            "Epoch 116/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0703 - auc: 0.9950 - accuracy: 0.9794 - cost: 2.6281 - val_loss: 0.1088 - val_auc: 0.9898 - val_accuracy: 0.9696 - val_cost: 3.8988\n",
            "Epoch 117/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0702 - auc: 0.9950 - accuracy: 0.9791 - cost: 2.6617 - val_loss: 0.1098 - val_auc: 0.9897 - val_accuracy: 0.9697 - val_cost: 3.7599\n",
            "Epoch 118/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0707 - auc: 0.9950 - accuracy: 0.9792 - cost: 2.6574 - val_loss: 0.1096 - val_auc: 0.9897 - val_accuracy: 0.9696 - val_cost: 3.7831\n",
            "Epoch 119/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0704 - auc: 0.9950 - accuracy: 0.9793 - cost: 2.6481 - val_loss: 0.1099 - val_auc: 0.9897 - val_accuracy: 0.9697 - val_cost: 3.7070\n",
            "Epoch 120/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9949 - accuracy: 0.9795 - cost: 2.6231 - val_loss: 0.1093 - val_auc: 0.9896 - val_accuracy: 0.9699 - val_cost: 3.7632\n",
            "Epoch 121/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0688 - auc: 0.9950 - accuracy: 0.9797 - cost: 2.5945 - val_loss: 0.1095 - val_auc: 0.9893 - val_accuracy: 0.9698 - val_cost: 3.8327\n",
            "Epoch 122/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0688 - auc: 0.9952 - accuracy: 0.9797 - cost: 2.5880 - val_loss: 0.1092 - val_auc: 0.9895 - val_accuracy: 0.9696 - val_cost: 3.8095\n",
            "Epoch 123/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0690 - auc: 0.9951 - accuracy: 0.9801 - cost: 2.5421 - val_loss: 0.1104 - val_auc: 0.9895 - val_accuracy: 0.9699 - val_cost: 3.7765\n",
            "Epoch 124/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0686 - auc: 0.9952 - accuracy: 0.9798 - cost: 2.5891 - val_loss: 0.1107 - val_auc: 0.9897 - val_accuracy: 0.9687 - val_cost: 3.9187\n",
            "Epoch 125/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0693 - auc: 0.9951 - accuracy: 0.9797 - cost: 2.6073 - val_loss: 0.1100 - val_auc: 0.9898 - val_accuracy: 0.9694 - val_cost: 3.8657\n",
            "Epoch 126/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0679 - auc: 0.9952 - accuracy: 0.9800 - cost: 2.5718 - val_loss: 0.1099 - val_auc: 0.9894 - val_accuracy: 0.9700 - val_cost: 3.6839\n",
            "Epoch 127/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0684 - auc: 0.9952 - accuracy: 0.9799 - cost: 2.5613 - val_loss: 0.1090 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.7269\n",
            "Epoch 128/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0684 - auc: 0.9953 - accuracy: 0.9797 - cost: 2.5910 - val_loss: 0.1103 - val_auc: 0.9898 - val_accuracy: 0.9686 - val_cost: 3.9517\n",
            "Epoch 129/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0679 - auc: 0.9953 - accuracy: 0.9800 - cost: 2.5640 - val_loss: 0.1096 - val_auc: 0.9894 - val_accuracy: 0.9701 - val_cost: 3.6839\n",
            "Epoch 130/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0671 - auc: 0.9953 - accuracy: 0.9806 - cost: 2.4788 - val_loss: 0.1098 - val_auc: 0.9899 - val_accuracy: 0.9698 - val_cost: 3.7996\n",
            "Epoch 131/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0679 - auc: 0.9953 - accuracy: 0.9802 - cost: 2.5316 - val_loss: 0.1077 - val_auc: 0.9899 - val_accuracy: 0.9694 - val_cost: 3.7698\n",
            "Epoch 132/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0677 - auc: 0.9952 - accuracy: 0.9802 - cost: 2.5328 - val_loss: 0.1092 - val_auc: 0.9895 - val_accuracy: 0.9710 - val_cost: 3.6607\n",
            "Epoch 133/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0673 - auc: 0.9953 - accuracy: 0.9807 - cost: 2.4688 - val_loss: 0.1077 - val_auc: 0.9899 - val_accuracy: 0.9699 - val_cost: 3.8161\n",
            "Epoch 134/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0675 - auc: 0.9952 - accuracy: 0.9803 - cost: 2.5112 - val_loss: 0.1091 - val_auc: 0.9898 - val_accuracy: 0.9698 - val_cost: 3.7765\n",
            "Epoch 135/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0674 - auc: 0.9953 - accuracy: 0.9803 - cost: 2.5131 - val_loss: 0.1093 - val_auc: 0.9900 - val_accuracy: 0.9710 - val_cost: 3.8062\n",
            "Epoch 136/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0671 - auc: 0.9954 - accuracy: 0.9804 - cost: 2.4985 - val_loss: 0.1091 - val_auc: 0.9897 - val_accuracy: 0.9710 - val_cost: 3.6541\n",
            "Epoch 137/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0671 - auc: 0.9952 - accuracy: 0.9804 - cost: 2.5039 - val_loss: 0.1113 - val_auc: 0.9899 - val_accuracy: 0.9695 - val_cost: 3.7368\n",
            "Epoch 138/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0669 - auc: 0.9953 - accuracy: 0.9805 - cost: 2.4938 - val_loss: 0.1095 - val_auc: 0.9900 - val_accuracy: 0.9708 - val_cost: 3.7004\n",
            "Epoch 139/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0664 - auc: 0.9955 - accuracy: 0.9805 - cost: 2.4826 - val_loss: 0.1117 - val_auc: 0.9897 - val_accuracy: 0.9691 - val_cost: 3.8161\n",
            "Epoch 140/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0666 - auc: 0.9954 - accuracy: 0.9808 - cost: 2.4564 - val_loss: 0.1096 - val_auc: 0.9895 - val_accuracy: 0.9706 - val_cost: 3.7136\n",
            "Epoch 141/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0661 - auc: 0.9956 - accuracy: 0.9806 - cost: 2.4784 - val_loss: 0.1112 - val_auc: 0.9895 - val_accuracy: 0.9697 - val_cost: 3.8624\n",
            "Epoch 142/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0660 - auc: 0.9955 - accuracy: 0.9808 - cost: 2.4533 - val_loss: 0.1087 - val_auc: 0.9897 - val_accuracy: 0.9699 - val_cost: 3.8029\n",
            "Epoch 143/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0665 - auc: 0.9953 - accuracy: 0.9810 - cost: 2.4367 - val_loss: 0.1102 - val_auc: 0.9896 - val_accuracy: 0.9695 - val_cost: 3.8228\n",
            "Epoch 144/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0651 - auc: 0.9956 - accuracy: 0.9810 - cost: 2.4294 - val_loss: 0.1097 - val_auc: 0.9894 - val_accuracy: 0.9699 - val_cost: 3.8261\n",
            "Epoch 145/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0659 - auc: 0.9955 - accuracy: 0.9807 - cost: 2.4722 - val_loss: 0.1101 - val_auc: 0.9894 - val_accuracy: 0.9708 - val_cost: 3.5747\n",
            "Epoch 146/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0656 - auc: 0.9955 - accuracy: 0.9811 - cost: 2.4201 - val_loss: 0.1117 - val_auc: 0.9899 - val_accuracy: 0.9699 - val_cost: 3.6772\n",
            "Epoch 147/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0660 - auc: 0.9955 - accuracy: 0.9807 - cost: 2.4699 - val_loss: 0.1093 - val_auc: 0.9894 - val_accuracy: 0.9703 - val_cost: 3.7004\n",
            "Epoch 148/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0653 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4491 - val_loss: 0.1105 - val_auc: 0.9894 - val_accuracy: 0.9710 - val_cost: 3.6409\n",
            "Epoch 149/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0649 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4371 - val_loss: 0.1085 - val_auc: 0.9898 - val_accuracy: 0.9714 - val_cost: 3.5218\n",
            "Epoch 150/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0647 - auc: 0.9957 - accuracy: 0.9809 - cost: 2.4417 - val_loss: 0.1115 - val_auc: 0.9895 - val_accuracy: 0.9703 - val_cost: 3.7269\n",
            "Epoch 151/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0649 - auc: 0.9955 - accuracy: 0.9814 - cost: 2.3715 - val_loss: 0.1097 - val_auc: 0.9898 - val_accuracy: 0.9715 - val_cost: 3.6012\n",
            "Epoch 152/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0643 - auc: 0.9956 - accuracy: 0.9814 - cost: 2.3785 - val_loss: 0.1102 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.7434\n",
            "Epoch 153/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0636 - auc: 0.9957 - accuracy: 0.9816 - cost: 2.3542 - val_loss: 0.1080 - val_auc: 0.9897 - val_accuracy: 0.9710 - val_cost: 3.6839\n",
            "Epoch 154/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0641 - auc: 0.9956 - accuracy: 0.9814 - cost: 2.3862 - val_loss: 0.1096 - val_auc: 0.9897 - val_accuracy: 0.9705 - val_cost: 3.7235\n",
            "Epoch 155/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0643 - auc: 0.9956 - accuracy: 0.9813 - cost: 2.3870 - val_loss: 0.1094 - val_auc: 0.9897 - val_accuracy: 0.9711 - val_cost: 3.6078\n",
            "Epoch 156/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0639 - auc: 0.9956 - accuracy: 0.9810 - cost: 2.4117 - val_loss: 0.1103 - val_auc: 0.9897 - val_accuracy: 0.9710 - val_cost: 3.8062\n",
            "Epoch 157/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0639 - auc: 0.9956 - accuracy: 0.9813 - cost: 2.3862 - val_loss: 0.1096 - val_auc: 0.9895 - val_accuracy: 0.9712 - val_cost: 3.6177\n",
            "Epoch 158/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0639 - auc: 0.9957 - accuracy: 0.9815 - cost: 2.3681 - val_loss: 0.1105 - val_auc: 0.9896 - val_accuracy: 0.9703 - val_cost: 3.7269\n",
            "Epoch 159/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0640 - auc: 0.9956 - accuracy: 0.9815 - cost: 2.3669 - val_loss: 0.1101 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.6706\n",
            "Epoch 160/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0637 - auc: 0.9957 - accuracy: 0.9816 - cost: 2.3588 - val_loss: 0.1085 - val_auc: 0.9897 - val_accuracy: 0.9699 - val_cost: 3.8029\n",
            "Epoch 161/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0639 - auc: 0.9957 - accuracy: 0.9815 - cost: 2.3742 - val_loss: 0.1098 - val_auc: 0.9896 - val_accuracy: 0.9703 - val_cost: 3.7037\n",
            "Epoch 162/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0631 - auc: 0.9958 - accuracy: 0.9816 - cost: 2.3549 - val_loss: 0.1105 - val_auc: 0.9899 - val_accuracy: 0.9715 - val_cost: 3.5351\n",
            "Epoch 163/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0634 - auc: 0.9957 - accuracy: 0.9817 - cost: 2.3407 - val_loss: 0.1105 - val_auc: 0.9896 - val_accuracy: 0.9704 - val_cost: 3.7930\n",
            "Epoch 164/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0630 - auc: 0.9957 - accuracy: 0.9815 - cost: 2.3738 - val_loss: 0.1093 - val_auc: 0.9898 - val_accuracy: 0.9708 - val_cost: 3.7202\n",
            "Epoch 165/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0635 - auc: 0.9957 - accuracy: 0.9813 - cost: 2.3947 - val_loss: 0.1095 - val_auc: 0.9894 - val_accuracy: 0.9719 - val_cost: 3.4921\n",
            "Epoch 166/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0634 - auc: 0.9958 - accuracy: 0.9815 - cost: 2.3692 - val_loss: 0.1112 - val_auc: 0.9897 - val_accuracy: 0.9706 - val_cost: 3.7533\n",
            "Epoch 167/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0633 - auc: 0.9957 - accuracy: 0.9816 - cost: 2.3453 - val_loss: 0.1136 - val_auc: 0.9892 - val_accuracy: 0.9699 - val_cost: 3.9253\n",
            "Epoch 168/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0636 - auc: 0.9957 - accuracy: 0.9814 - cost: 2.3762 - val_loss: 0.1099 - val_auc: 0.9896 - val_accuracy: 0.9712 - val_cost: 3.5351\n",
            "Epoch 169/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0630 - auc: 0.9957 - accuracy: 0.9819 - cost: 2.3079 - val_loss: 0.1096 - val_auc: 0.9897 - val_accuracy: 0.9711 - val_cost: 3.5582\n",
            "Epoch 170/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0622 - auc: 0.9958 - accuracy: 0.9820 - cost: 2.3063 - val_loss: 0.1116 - val_auc: 0.9893 - val_accuracy: 0.9701 - val_cost: 3.7235\n",
            "Epoch 171/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0628 - auc: 0.9959 - accuracy: 0.9820 - cost: 2.2940 - val_loss: 0.1097 - val_auc: 0.9896 - val_accuracy: 0.9712 - val_cost: 3.6144\n",
            "Epoch 172/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0635 - auc: 0.9957 - accuracy: 0.9816 - cost: 2.3603 - val_loss: 0.1093 - val_auc: 0.9896 - val_accuracy: 0.9706 - val_cost: 3.6409\n",
            "Epoch 173/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0621 - auc: 0.9959 - accuracy: 0.9818 - cost: 2.3268 - val_loss: 0.1084 - val_auc: 0.9900 - val_accuracy: 0.9711 - val_cost: 3.7500\n",
            "Epoch 174/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0628 - auc: 0.9958 - accuracy: 0.9815 - cost: 2.3592 - val_loss: 0.1084 - val_auc: 0.9898 - val_accuracy: 0.9708 - val_cost: 3.6607\n",
            "Epoch 175/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0622 - auc: 0.9959 - accuracy: 0.9816 - cost: 2.3565 - val_loss: 0.1087 - val_auc: 0.9898 - val_accuracy: 0.9712 - val_cost: 3.6310\n",
            "Epoch 176/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0621 - auc: 0.9959 - accuracy: 0.9823 - cost: 2.2693 - val_loss: 0.1094 - val_auc: 0.9898 - val_accuracy: 0.9713 - val_cost: 3.6409\n",
            "Epoch 177/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0621 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3164 - val_loss: 0.1109 - val_auc: 0.9898 - val_accuracy: 0.9708 - val_cost: 3.5979\n",
            "Epoch 178/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0623 - auc: 0.9958 - accuracy: 0.9817 - cost: 2.3407 - val_loss: 0.1109 - val_auc: 0.9894 - val_accuracy: 0.9715 - val_cost: 3.5813\n",
            "Epoch 179/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0622 - auc: 0.9959 - accuracy: 0.9815 - cost: 2.3592 - val_loss: 0.1135 - val_auc: 0.9892 - val_accuracy: 0.9703 - val_cost: 3.6276\n",
            "Epoch 180/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0613 - auc: 0.9959 - accuracy: 0.9822 - cost: 2.2843 - val_loss: 0.1104 - val_auc: 0.9895 - val_accuracy: 0.9709 - val_cost: 3.8261\n",
            "Epoch 181/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0622 - auc: 0.9960 - accuracy: 0.9822 - cost: 2.2762 - val_loss: 0.1115 - val_auc: 0.9895 - val_accuracy: 0.9697 - val_cost: 3.7401\n",
            "Epoch 182/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0607 - auc: 0.9960 - accuracy: 0.9825 - cost: 2.2427 - val_loss: 0.1094 - val_auc: 0.9895 - val_accuracy: 0.9712 - val_cost: 3.6210\n",
            "Epoch 183/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0616 - auc: 0.9959 - accuracy: 0.9820 - cost: 2.3005 - val_loss: 0.1101 - val_auc: 0.9895 - val_accuracy: 0.9712 - val_cost: 3.6376\n",
            "Epoch 184/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0610 - auc: 0.9959 - accuracy: 0.9825 - cost: 2.2334 - val_loss: 0.1112 - val_auc: 0.9897 - val_accuracy: 0.9715 - val_cost: 3.6177\n",
            "Epoch 185/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0611 - auc: 0.9959 - accuracy: 0.9822 - cost: 2.2681 - val_loss: 0.1120 - val_auc: 0.9896 - val_accuracy: 0.9714 - val_cost: 3.5317\n",
            "Epoch 186/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0621 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3160 - val_loss: 0.1099 - val_auc: 0.9896 - val_accuracy: 0.9714 - val_cost: 3.5284\n",
            "Epoch 187/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0614 - auc: 0.9958 - accuracy: 0.9822 - cost: 2.2758 - val_loss: 0.1108 - val_auc: 0.9896 - val_accuracy: 0.9722 - val_cost: 3.5880\n",
            "Epoch 188/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0618 - auc: 0.9958 - accuracy: 0.9822 - cost: 2.2693 - val_loss: 0.1105 - val_auc: 0.9896 - val_accuracy: 0.9713 - val_cost: 3.5847\n",
            "Epoch 189/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0603 - auc: 0.9960 - accuracy: 0.9824 - cost: 2.2461 - val_loss: 0.1098 - val_auc: 0.9897 - val_accuracy: 0.9714 - val_cost: 3.5714\n",
            "Epoch 190/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0606 - auc: 0.9960 - accuracy: 0.9828 - cost: 2.2076 - val_loss: 0.1122 - val_auc: 0.9894 - val_accuracy: 0.9718 - val_cost: 3.5218\n",
            "Epoch 191/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0610 - auc: 0.9960 - accuracy: 0.9819 - cost: 2.3113 - val_loss: 0.1127 - val_auc: 0.9893 - val_accuracy: 0.9714 - val_cost: 3.6177\n",
            "Epoch 192/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0610 - auc: 0.9960 - accuracy: 0.9824 - cost: 2.2608 - val_loss: 0.1104 - val_auc: 0.9897 - val_accuracy: 0.9714 - val_cost: 3.5351\n",
            "Epoch 193/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0609 - auc: 0.9959 - accuracy: 0.9820 - cost: 2.3083 - val_loss: 0.1105 - val_auc: 0.9895 - val_accuracy: 0.9724 - val_cost: 3.4888\n",
            "Epoch 194/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0608 - auc: 0.9960 - accuracy: 0.9823 - cost: 2.2512 - val_loss: 0.1112 - val_auc: 0.9894 - val_accuracy: 0.9722 - val_cost: 3.6210\n",
            "Epoch 195/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0610 - auc: 0.9960 - accuracy: 0.9820 - cost: 2.2982 - val_loss: 0.1123 - val_auc: 0.9896 - val_accuracy: 0.9722 - val_cost: 3.4755\n",
            "Epoch 196/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0615 - auc: 0.9959 - accuracy: 0.9820 - cost: 2.3032 - val_loss: 0.1101 - val_auc: 0.9899 - val_accuracy: 0.9722 - val_cost: 3.5020\n",
            "Epoch 197/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0599 - auc: 0.9961 - accuracy: 0.9827 - cost: 2.2149 - val_loss: 0.1093 - val_auc: 0.9895 - val_accuracy: 0.9716 - val_cost: 3.5351\n",
            "Epoch 198/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0607 - auc: 0.9961 - accuracy: 0.9824 - cost: 2.2531 - val_loss: 0.1107 - val_auc: 0.9896 - val_accuracy: 0.9719 - val_cost: 3.4987\n",
            "Epoch 199/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0600 - auc: 0.9961 - accuracy: 0.9826 - cost: 2.2276 - val_loss: 0.1104 - val_auc: 0.9895 - val_accuracy: 0.9713 - val_cost: 3.6971\n",
            "Epoch 200/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0600 - auc: 0.9960 - accuracy: 0.9825 - cost: 2.2369 - val_loss: 0.1104 - val_auc: 0.9895 - val_accuracy: 0.9722 - val_cost: 3.5847\n",
            "Epoch 201/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0607 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2654 - val_loss: 0.1141 - val_auc: 0.9893 - val_accuracy: 0.9706 - val_cost: 3.6243\n",
            "Epoch 202/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0604 - auc: 0.9959 - accuracy: 0.9824 - cost: 2.2461 - val_loss: 0.1105 - val_auc: 0.9896 - val_accuracy: 0.9713 - val_cost: 3.6541\n",
            "Epoch 203/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0600 - auc: 0.9960 - accuracy: 0.9826 - cost: 2.2276 - val_loss: 0.1141 - val_auc: 0.9892 - val_accuracy: 0.9711 - val_cost: 3.6739\n",
            "Epoch 204/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0607 - auc: 0.9960 - accuracy: 0.9819 - cost: 2.3156 - val_loss: 0.1122 - val_auc: 0.9898 - val_accuracy: 0.9718 - val_cost: 3.5152\n",
            "Epoch 205/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0600 - auc: 0.9960 - accuracy: 0.9825 - cost: 2.2461 - val_loss: 0.1108 - val_auc: 0.9895 - val_accuracy: 0.9721 - val_cost: 3.5516\n",
            "Epoch 206/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0600 - auc: 0.9962 - accuracy: 0.9821 - cost: 2.2967 - val_loss: 0.1122 - val_auc: 0.9894 - val_accuracy: 0.9707 - val_cost: 3.7930\n",
            "Epoch 207/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0595 - auc: 0.9960 - accuracy: 0.9830 - cost: 2.1821 - val_loss: 0.1150 - val_auc: 0.9892 - val_accuracy: 0.9706 - val_cost: 3.6012\n",
            "Epoch 208/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0600 - auc: 0.9960 - accuracy: 0.9827 - cost: 2.2091 - val_loss: 0.1124 - val_auc: 0.9894 - val_accuracy: 0.9712 - val_cost: 3.7599\n",
            "Epoch 209/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0597 - auc: 0.9960 - accuracy: 0.9826 - cost: 2.2326 - val_loss: 0.1134 - val_auc: 0.9895 - val_accuracy: 0.9712 - val_cost: 3.6078\n",
            "Epoch 210/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0592 - auc: 0.9963 - accuracy: 0.9828 - cost: 2.2049 - val_loss: 0.1140 - val_auc: 0.9895 - val_accuracy: 0.9715 - val_cost: 3.7004\n",
            "Epoch 211/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0597 - auc: 0.9959 - accuracy: 0.9826 - cost: 2.2346 - val_loss: 0.1136 - val_auc: 0.9894 - val_accuracy: 0.9714 - val_cost: 3.5549\n",
            "Epoch 212/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0591 - auc: 0.9961 - accuracy: 0.9830 - cost: 2.1651 - val_loss: 0.1142 - val_auc: 0.9891 - val_accuracy: 0.9712 - val_cost: 3.7235\n",
            "Epoch 213/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0594 - auc: 0.9962 - accuracy: 0.9826 - cost: 2.2292 - val_loss: 0.1130 - val_auc: 0.9894 - val_accuracy: 0.9718 - val_cost: 3.5847\n",
            "Epoch 214/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0606 - auc: 0.9960 - accuracy: 0.9824 - cost: 2.2473 - val_loss: 0.1132 - val_auc: 0.9894 - val_accuracy: 0.9716 - val_cost: 3.5714\n",
            "Epoch 215/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0597 - auc: 0.9961 - accuracy: 0.9829 - cost: 2.1802 - val_loss: 0.1120 - val_auc: 0.9895 - val_accuracy: 0.9717 - val_cost: 3.5681\n",
            "Epoch 216/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0592 - auc: 0.9962 - accuracy: 0.9824 - cost: 2.2519 - val_loss: 0.1157 - val_auc: 0.9894 - val_accuracy: 0.9710 - val_cost: 3.7831\n",
            "Epoch 217/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0594 - auc: 0.9961 - accuracy: 0.9824 - cost: 2.2589 - val_loss: 0.1136 - val_auc: 0.9894 - val_accuracy: 0.9715 - val_cost: 3.5317\n",
            "Epoch 218/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0591 - auc: 0.9961 - accuracy: 0.9829 - cost: 2.1906 - val_loss: 0.1151 - val_auc: 0.9891 - val_accuracy: 0.9716 - val_cost: 3.6706\n",
            "Epoch 219/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0592 - auc: 0.9961 - accuracy: 0.9829 - cost: 2.1744 - val_loss: 0.1121 - val_auc: 0.9896 - val_accuracy: 0.9719 - val_cost: 3.5020\n",
            "Epoch 220/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0583 - auc: 0.9962 - accuracy: 0.9829 - cost: 2.1802 - val_loss: 0.1153 - val_auc: 0.9894 - val_accuracy: 0.9713 - val_cost: 3.6144\n",
            "Epoch 221/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0586 - auc: 0.9962 - accuracy: 0.9828 - cost: 2.2025 - val_loss: 0.1133 - val_auc: 0.9892 - val_accuracy: 0.9703 - val_cost: 3.7897\n",
            "Epoch 222/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0583 - auc: 0.9963 - accuracy: 0.9829 - cost: 2.1879 - val_loss: 0.1147 - val_auc: 0.9894 - val_accuracy: 0.9720 - val_cost: 3.5714\n",
            "Epoch 223/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0582 - auc: 0.9962 - accuracy: 0.9832 - cost: 2.1524 - val_loss: 0.1158 - val_auc: 0.9892 - val_accuracy: 0.9708 - val_cost: 3.5946\n",
            "Epoch 224/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0588 - auc: 0.9962 - accuracy: 0.9831 - cost: 2.1559 - val_loss: 0.1156 - val_auc: 0.9893 - val_accuracy: 0.9708 - val_cost: 3.6111\n",
            "Epoch 225/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0590 - auc: 0.9962 - accuracy: 0.9830 - cost: 2.1840 - val_loss: 0.1142 - val_auc: 0.9896 - val_accuracy: 0.9718 - val_cost: 3.6310\n",
            "Epoch 226/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0591 - auc: 0.9961 - accuracy: 0.9828 - cost: 2.2064 - val_loss: 0.1149 - val_auc: 0.9893 - val_accuracy: 0.9715 - val_cost: 3.5747\n",
            "Epoch 227/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0602 - auc: 0.9961 - accuracy: 0.9825 - cost: 2.2303 - val_loss: 0.1131 - val_auc: 0.9895 - val_accuracy: 0.9710 - val_cost: 3.7269\n",
            "Epoch 228/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0589 - auc: 0.9962 - accuracy: 0.9833 - cost: 2.1439 - val_loss: 0.1155 - val_auc: 0.9893 - val_accuracy: 0.9705 - val_cost: 3.7599\n",
            "Epoch 229/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0593 - auc: 0.9961 - accuracy: 0.9830 - cost: 2.1833 - val_loss: 0.1151 - val_auc: 0.9892 - val_accuracy: 0.9708 - val_cost: 3.7103\n",
            "Epoch 230/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0587 - auc: 0.9963 - accuracy: 0.9828 - cost: 2.2049 - val_loss: 0.1145 - val_auc: 0.9895 - val_accuracy: 0.9713 - val_cost: 3.6012\n",
            "Epoch 231/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0586 - auc: 0.9962 - accuracy: 0.9829 - cost: 2.1941 - val_loss: 0.1134 - val_auc: 0.9893 - val_accuracy: 0.9715 - val_cost: 3.6541\n",
            "Epoch 232/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0582 - auc: 0.9962 - accuracy: 0.9833 - cost: 2.1377 - val_loss: 0.1121 - val_auc: 0.9890 - val_accuracy: 0.9703 - val_cost: 3.7930\n",
            "Epoch 233/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0585 - auc: 0.9962 - accuracy: 0.9830 - cost: 2.1709 - val_loss: 0.1150 - val_auc: 0.9890 - val_accuracy: 0.9705 - val_cost: 3.7731\n",
            "Epoch 234/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0581 - auc: 0.9963 - accuracy: 0.9828 - cost: 2.2002 - val_loss: 0.1131 - val_auc: 0.9894 - val_accuracy: 0.9715 - val_cost: 3.6276\n",
            "Epoch 235/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0586 - auc: 0.9962 - accuracy: 0.9827 - cost: 2.2103 - val_loss: 0.1159 - val_auc: 0.9892 - val_accuracy: 0.9703 - val_cost: 3.6673\n",
            "Epoch 236/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0574 - auc: 0.9964 - accuracy: 0.9829 - cost: 2.1782 - val_loss: 0.1142 - val_auc: 0.9895 - val_accuracy: 0.9710 - val_cost: 3.6508\n",
            "Epoch 237/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0584 - auc: 0.9963 - accuracy: 0.9828 - cost: 2.2137 - val_loss: 0.1146 - val_auc: 0.9895 - val_accuracy: 0.9717 - val_cost: 3.6078\n",
            "Epoch 238/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0575 - auc: 0.9963 - accuracy: 0.9829 - cost: 2.1848 - val_loss: 0.1153 - val_auc: 0.9893 - val_accuracy: 0.9708 - val_cost: 3.6806\n",
            "Epoch 239/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0580 - auc: 0.9963 - accuracy: 0.9835 - cost: 2.1080 - val_loss: 0.1145 - val_auc: 0.9895 - val_accuracy: 0.9707 - val_cost: 3.6673\n",
            "Epoch 240/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0577 - auc: 0.9963 - accuracy: 0.9831 - cost: 2.1698 - val_loss: 0.1156 - val_auc: 0.9894 - val_accuracy: 0.9708 - val_cost: 3.7599\n",
            "Epoch 241/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0579 - auc: 0.9963 - accuracy: 0.9830 - cost: 2.1690 - val_loss: 0.1158 - val_auc: 0.9894 - val_accuracy: 0.9714 - val_cost: 3.5384\n",
            "Epoch 242/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0581 - auc: 0.9962 - accuracy: 0.9832 - cost: 2.1501 - val_loss: 0.1142 - val_auc: 0.9896 - val_accuracy: 0.9713 - val_cost: 3.6442\n",
            "Epoch 243/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0576 - auc: 0.9963 - accuracy: 0.9835 - cost: 2.1080 - val_loss: 0.1165 - val_auc: 0.9895 - val_accuracy: 0.9710 - val_cost: 3.6640\n",
            "Epoch 244/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0579 - auc: 0.9963 - accuracy: 0.9830 - cost: 2.1725 - val_loss: 0.1152 - val_auc: 0.9898 - val_accuracy: 0.9709 - val_cost: 3.6938\n",
            "Epoch 245/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0577 - auc: 0.9962 - accuracy: 0.9833 - cost: 2.1346 - val_loss: 0.1143 - val_auc: 0.9897 - val_accuracy: 0.9709 - val_cost: 3.7401\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0938 - auc: 0.9922 - accuracy: 0.9743 - cost: 3.2750\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:01:55.079632\n",
            "fold accuracy: 0.9742500185966492 - fold cost: 3.2750000953674316\n",
            "x_train shape: (144000, 67)\n",
            "Epoch 1/1000\n",
            "120/120 [==============================] - 2s 5ms/step - loss: 0.5308 - auc: 0.7975 - accuracy: 0.7283 - cost: 36.1543 - val_loss: 0.3956 - val_auc: 0.9004 - val_accuracy: 0.8267 - val_cost: 22.2090\n",
            "Epoch 2/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.3517 - auc: 0.9214 - accuracy: 0.8492 - cost: 19.2052 - val_loss: 0.3157 - val_auc: 0.9366 - val_accuracy: 0.8684 - val_cost: 16.4120\n",
            "Epoch 3/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.3027 - auc: 0.9420 - accuracy: 0.8741 - cost: 15.9352 - val_loss: 0.2841 - val_auc: 0.9489 - val_accuracy: 0.8836 - val_cost: 14.5966\n",
            "Epoch 4/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2736 - auc: 0.9528 - accuracy: 0.8880 - cost: 14.1478 - val_loss: 0.2600 - val_auc: 0.9571 - val_accuracy: 0.8933 - val_cost: 13.4425\n",
            "Epoch 5/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2503 - auc: 0.9605 - accuracy: 0.8998 - cost: 12.6995 - val_loss: 0.2396 - val_auc: 0.9639 - val_accuracy: 0.9062 - val_cost: 11.5542\n",
            "Epoch 6/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.2301 - auc: 0.9666 - accuracy: 0.9096 - cost: 11.4348 - val_loss: 0.2223 - val_auc: 0.9686 - val_accuracy: 0.9144 - val_cost: 10.7044\n",
            "Epoch 7/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2138 - auc: 0.9710 - accuracy: 0.9176 - cost: 10.4113 - val_loss: 0.2091 - val_auc: 0.9726 - val_accuracy: 0.9219 - val_cost: 9.5040\n",
            "Epoch 8/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2008 - auc: 0.9744 - accuracy: 0.9239 - cost: 9.6281 - val_loss: 0.1959 - val_auc: 0.9755 - val_accuracy: 0.9286 - val_cost: 8.8393\n",
            "Epoch 9/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1892 - auc: 0.9771 - accuracy: 0.9284 - cost: 9.0440 - val_loss: 0.1879 - val_auc: 0.9775 - val_accuracy: 0.9312 - val_cost: 8.4325\n",
            "Epoch 10/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1804 - auc: 0.9790 - accuracy: 0.9329 - cost: 8.4653 - val_loss: 0.1811 - val_auc: 0.9788 - val_accuracy: 0.9356 - val_cost: 8.2606\n",
            "Epoch 11/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1723 - auc: 0.9808 - accuracy: 0.9361 - cost: 8.0976 - val_loss: 0.1730 - val_auc: 0.9803 - val_accuracy: 0.9390 - val_cost: 7.6422\n",
            "Epoch 12/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1664 - auc: 0.9819 - accuracy: 0.9397 - cost: 7.6385 - val_loss: 0.1683 - val_auc: 0.9813 - val_accuracy: 0.9412 - val_cost: 7.4603\n",
            "Epoch 13/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1612 - auc: 0.9829 - accuracy: 0.9422 - cost: 7.3468 - val_loss: 0.1636 - val_auc: 0.9821 - val_accuracy: 0.9423 - val_cost: 7.2751\n",
            "Epoch 14/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1561 - auc: 0.9839 - accuracy: 0.9439 - cost: 7.1103 - val_loss: 0.1602 - val_auc: 0.9829 - val_accuracy: 0.9440 - val_cost: 6.9378\n",
            "Epoch 15/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1519 - auc: 0.9847 - accuracy: 0.9458 - cost: 6.8754 - val_loss: 0.1585 - val_auc: 0.9832 - val_accuracy: 0.9444 - val_cost: 6.7890\n",
            "Epoch 16/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1478 - auc: 0.9853 - accuracy: 0.9479 - cost: 6.6169 - val_loss: 0.1540 - val_auc: 0.9839 - val_accuracy: 0.9466 - val_cost: 6.6303\n",
            "Epoch 17/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1450 - auc: 0.9858 - accuracy: 0.9491 - cost: 6.4452 - val_loss: 0.1524 - val_auc: 0.9841 - val_accuracy: 0.9486 - val_cost: 6.3988\n",
            "Epoch 18/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1425 - auc: 0.9862 - accuracy: 0.9506 - cost: 6.2774 - val_loss: 0.1498 - val_auc: 0.9846 - val_accuracy: 0.9494 - val_cost: 6.3823\n",
            "Epoch 19/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1382 - auc: 0.9869 - accuracy: 0.9520 - cost: 6.0856 - val_loss: 0.1466 - val_auc: 0.9851 - val_accuracy: 0.9513 - val_cost: 6.0747\n",
            "Epoch 20/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1365 - auc: 0.9871 - accuracy: 0.9528 - cost: 5.9877 - val_loss: 0.1459 - val_auc: 0.9851 - val_accuracy: 0.9512 - val_cost: 6.2070\n",
            "Epoch 21/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1336 - auc: 0.9877 - accuracy: 0.9545 - cost: 5.7712 - val_loss: 0.1434 - val_auc: 0.9857 - val_accuracy: 0.9522 - val_cost: 6.0880\n",
            "Epoch 22/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1309 - auc: 0.9880 - accuracy: 0.9547 - cost: 5.7620 - val_loss: 0.1424 - val_auc: 0.9859 - val_accuracy: 0.9523 - val_cost: 5.8366\n",
            "Epoch 23/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1287 - auc: 0.9884 - accuracy: 0.9559 - cost: 5.5937 - val_loss: 0.1400 - val_auc: 0.9861 - val_accuracy: 0.9542 - val_cost: 5.6779\n",
            "Epoch 24/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1270 - auc: 0.9886 - accuracy: 0.9568 - cost: 5.5069 - val_loss: 0.1386 - val_auc: 0.9864 - val_accuracy: 0.9548 - val_cost: 5.6911\n",
            "Epoch 25/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1241 - auc: 0.9890 - accuracy: 0.9581 - cost: 5.3302 - val_loss: 0.1382 - val_auc: 0.9864 - val_accuracy: 0.9563 - val_cost: 5.4630\n",
            "Epoch 26/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1228 - auc: 0.9892 - accuracy: 0.9584 - cost: 5.2944 - val_loss: 0.1368 - val_auc: 0.9865 - val_accuracy: 0.9565 - val_cost: 5.5357\n",
            "Epoch 27/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1214 - auc: 0.9893 - accuracy: 0.9594 - cost: 5.1439 - val_loss: 0.1352 - val_auc: 0.9867 - val_accuracy: 0.9567 - val_cost: 5.6019\n",
            "Epoch 28/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1189 - auc: 0.9897 - accuracy: 0.9603 - cost: 5.0409 - val_loss: 0.1351 - val_auc: 0.9867 - val_accuracy: 0.9576 - val_cost: 5.2712\n",
            "Epoch 29/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1178 - auc: 0.9899 - accuracy: 0.9607 - cost: 4.9900 - val_loss: 0.1339 - val_auc: 0.9869 - val_accuracy: 0.9565 - val_cost: 5.3737\n",
            "Epoch 30/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1161 - auc: 0.9900 - accuracy: 0.9615 - cost: 4.8877 - val_loss: 0.1327 - val_auc: 0.9871 - val_accuracy: 0.9583 - val_cost: 5.1819\n",
            "Epoch 31/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1147 - auc: 0.9903 - accuracy: 0.9624 - cost: 4.7782 - val_loss: 0.1323 - val_auc: 0.9871 - val_accuracy: 0.9584 - val_cost: 5.2976\n",
            "Epoch 32/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1135 - auc: 0.9904 - accuracy: 0.9621 - cost: 4.8098 - val_loss: 0.1305 - val_auc: 0.9874 - val_accuracy: 0.9604 - val_cost: 5.0496\n",
            "Epoch 33/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1114 - auc: 0.9907 - accuracy: 0.9632 - cost: 4.6782 - val_loss: 0.1300 - val_auc: 0.9875 - val_accuracy: 0.9589 - val_cost: 5.0562\n",
            "Epoch 34/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1103 - auc: 0.9908 - accuracy: 0.9635 - cost: 4.6323 - val_loss: 0.1290 - val_auc: 0.9875 - val_accuracy: 0.9603 - val_cost: 4.9008\n",
            "Epoch 35/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1098 - auc: 0.9910 - accuracy: 0.9639 - cost: 4.5787 - val_loss: 0.1273 - val_auc: 0.9876 - val_accuracy: 0.9608 - val_cost: 4.9008\n",
            "Epoch 36/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1075 - auc: 0.9912 - accuracy: 0.9644 - cost: 4.5390 - val_loss: 0.1276 - val_auc: 0.9878 - val_accuracy: 0.9612 - val_cost: 4.9140\n",
            "Epoch 37/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1076 - auc: 0.9912 - accuracy: 0.9648 - cost: 4.4695 - val_loss: 0.1266 - val_auc: 0.9879 - val_accuracy: 0.9615 - val_cost: 4.9173\n",
            "Epoch 38/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1061 - auc: 0.9913 - accuracy: 0.9650 - cost: 4.4394 - val_loss: 0.1246 - val_auc: 0.9881 - val_accuracy: 0.9608 - val_cost: 4.9934\n",
            "Epoch 39/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1050 - auc: 0.9915 - accuracy: 0.9657 - cost: 4.3557 - val_loss: 0.1253 - val_auc: 0.9879 - val_accuracy: 0.9619 - val_cost: 4.8677\n",
            "Epoch 40/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1031 - auc: 0.9917 - accuracy: 0.9668 - cost: 4.2218 - val_loss: 0.1234 - val_auc: 0.9884 - val_accuracy: 0.9622 - val_cost: 4.6726\n",
            "Epoch 41/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1031 - auc: 0.9917 - accuracy: 0.9665 - cost: 4.2728 - val_loss: 0.1238 - val_auc: 0.9881 - val_accuracy: 0.9624 - val_cost: 4.6792\n",
            "Epoch 42/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1020 - auc: 0.9918 - accuracy: 0.9670 - cost: 4.2010 - val_loss: 0.1219 - val_auc: 0.9886 - val_accuracy: 0.9630 - val_cost: 4.6131\n",
            "Epoch 43/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1013 - auc: 0.9919 - accuracy: 0.9673 - cost: 4.1528 - val_loss: 0.1225 - val_auc: 0.9884 - val_accuracy: 0.9631 - val_cost: 4.6825\n",
            "Epoch 44/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0999 - auc: 0.9921 - accuracy: 0.9679 - cost: 4.0891 - val_loss: 0.1215 - val_auc: 0.9886 - val_accuracy: 0.9631 - val_cost: 4.5701\n",
            "Epoch 45/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0991 - auc: 0.9922 - accuracy: 0.9679 - cost: 4.0810 - val_loss: 0.1210 - val_auc: 0.9886 - val_accuracy: 0.9649 - val_cost: 4.2758\n",
            "Epoch 46/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0981 - auc: 0.9922 - accuracy: 0.9684 - cost: 4.0162 - val_loss: 0.1196 - val_auc: 0.9887 - val_accuracy: 0.9642 - val_cost: 4.4940\n",
            "Epoch 47/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0964 - auc: 0.9925 - accuracy: 0.9687 - cost: 3.9865 - val_loss: 0.1193 - val_auc: 0.9888 - val_accuracy: 0.9642 - val_cost: 4.5337\n",
            "Epoch 48/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0964 - auc: 0.9925 - accuracy: 0.9690 - cost: 3.9433 - val_loss: 0.1191 - val_auc: 0.9887 - val_accuracy: 0.9642 - val_cost: 4.5767\n",
            "Epoch 49/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0957 - auc: 0.9925 - accuracy: 0.9693 - cost: 3.8985 - val_loss: 0.1200 - val_auc: 0.9886 - val_accuracy: 0.9638 - val_cost: 4.4180\n",
            "Epoch 50/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0953 - auc: 0.9926 - accuracy: 0.9695 - cost: 3.8835 - val_loss: 0.1164 - val_auc: 0.9890 - val_accuracy: 0.9655 - val_cost: 4.3155\n",
            "Epoch 51/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0941 - auc: 0.9927 - accuracy: 0.9703 - cost: 3.7855 - val_loss: 0.1166 - val_auc: 0.9892 - val_accuracy: 0.9664 - val_cost: 4.2163\n",
            "Epoch 52/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0932 - auc: 0.9928 - accuracy: 0.9706 - cost: 3.7373 - val_loss: 0.1174 - val_auc: 0.9892 - val_accuracy: 0.9647 - val_cost: 4.3684\n",
            "Epoch 53/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0926 - auc: 0.9929 - accuracy: 0.9706 - cost: 3.7431 - val_loss: 0.1160 - val_auc: 0.9890 - val_accuracy: 0.9660 - val_cost: 4.3585\n",
            "Epoch 54/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0914 - auc: 0.9929 - accuracy: 0.9711 - cost: 3.6755 - val_loss: 0.1158 - val_auc: 0.9892 - val_accuracy: 0.9660 - val_cost: 4.1766\n",
            "Epoch 55/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0919 - auc: 0.9929 - accuracy: 0.9710 - cost: 3.6840 - val_loss: 0.1174 - val_auc: 0.9892 - val_accuracy: 0.9653 - val_cost: 4.2229\n",
            "Epoch 56/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0907 - auc: 0.9931 - accuracy: 0.9716 - cost: 3.6123 - val_loss: 0.1142 - val_auc: 0.9894 - val_accuracy: 0.9660 - val_cost: 4.2262\n",
            "Epoch 57/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0903 - auc: 0.9931 - accuracy: 0.9713 - cost: 3.6520 - val_loss: 0.1140 - val_auc: 0.9895 - val_accuracy: 0.9669 - val_cost: 4.1601\n",
            "Epoch 58/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0892 - auc: 0.9932 - accuracy: 0.9721 - cost: 3.5324 - val_loss: 0.1145 - val_auc: 0.9893 - val_accuracy: 0.9664 - val_cost: 4.3585\n",
            "Epoch 59/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0899 - auc: 0.9931 - accuracy: 0.9717 - cost: 3.6042 - val_loss: 0.1138 - val_auc: 0.9895 - val_accuracy: 0.9675 - val_cost: 4.0013\n",
            "Epoch 60/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0886 - auc: 0.9932 - accuracy: 0.9720 - cost: 3.5583 - val_loss: 0.1140 - val_auc: 0.9892 - val_accuracy: 0.9658 - val_cost: 4.3022\n",
            "Epoch 61/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0878 - auc: 0.9934 - accuracy: 0.9726 - cost: 3.4950 - val_loss: 0.1139 - val_auc: 0.9894 - val_accuracy: 0.9665 - val_cost: 4.0906\n",
            "Epoch 62/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0885 - auc: 0.9933 - accuracy: 0.9725 - cost: 3.4969 - val_loss: 0.1148 - val_auc: 0.9894 - val_accuracy: 0.9670 - val_cost: 4.0179\n",
            "Epoch 63/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0871 - auc: 0.9934 - accuracy: 0.9729 - cost: 3.4537 - val_loss: 0.1121 - val_auc: 0.9897 - val_accuracy: 0.9673 - val_cost: 4.2626\n",
            "Epoch 64/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0872 - auc: 0.9935 - accuracy: 0.9731 - cost: 3.4263 - val_loss: 0.1119 - val_auc: 0.9895 - val_accuracy: 0.9679 - val_cost: 3.9418\n",
            "Epoch 65/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0866 - auc: 0.9934 - accuracy: 0.9732 - cost: 3.4205 - val_loss: 0.1105 - val_auc: 0.9896 - val_accuracy: 0.9684 - val_cost: 3.9550\n",
            "Epoch 66/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0856 - auc: 0.9935 - accuracy: 0.9733 - cost: 3.3951 - val_loss: 0.1124 - val_auc: 0.9894 - val_accuracy: 0.9671 - val_cost: 4.0311\n",
            "Epoch 67/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0844 - auc: 0.9938 - accuracy: 0.9737 - cost: 3.3511 - val_loss: 0.1119 - val_auc: 0.9894 - val_accuracy: 0.9681 - val_cost: 4.0145\n",
            "Epoch 68/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0848 - auc: 0.9936 - accuracy: 0.9738 - cost: 3.3225 - val_loss: 0.1124 - val_auc: 0.9895 - val_accuracy: 0.9681 - val_cost: 4.0212\n",
            "Epoch 69/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0838 - auc: 0.9938 - accuracy: 0.9741 - cost: 3.2982 - val_loss: 0.1104 - val_auc: 0.9896 - val_accuracy: 0.9695 - val_cost: 3.8161\n",
            "Epoch 70/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0838 - auc: 0.9938 - accuracy: 0.9743 - cost: 3.2751 - val_loss: 0.1116 - val_auc: 0.9894 - val_accuracy: 0.9691 - val_cost: 3.8988\n",
            "Epoch 71/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0828 - auc: 0.9939 - accuracy: 0.9743 - cost: 3.2674 - val_loss: 0.1117 - val_auc: 0.9896 - val_accuracy: 0.9688 - val_cost: 3.8228\n",
            "Epoch 72/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0829 - auc: 0.9939 - accuracy: 0.9741 - cost: 3.2948 - val_loss: 0.1114 - val_auc: 0.9895 - val_accuracy: 0.9681 - val_cost: 3.9649\n",
            "Epoch 73/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0823 - auc: 0.9940 - accuracy: 0.9748 - cost: 3.2076 - val_loss: 0.1125 - val_auc: 0.9894 - val_accuracy: 0.9673 - val_cost: 4.0939\n",
            "Epoch 74/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0822 - auc: 0.9939 - accuracy: 0.9748 - cost: 3.2068 - val_loss: 0.1107 - val_auc: 0.9896 - val_accuracy: 0.9687 - val_cost: 3.9087\n",
            "Epoch 75/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0817 - auc: 0.9941 - accuracy: 0.9747 - cost: 3.2253 - val_loss: 0.1117 - val_auc: 0.9895 - val_accuracy: 0.9682 - val_cost: 3.9352\n",
            "Epoch 76/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0821 - auc: 0.9940 - accuracy: 0.9747 - cost: 3.2149 - val_loss: 0.1119 - val_auc: 0.9894 - val_accuracy: 0.9690 - val_cost: 3.8823\n",
            "Epoch 77/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0810 - auc: 0.9941 - accuracy: 0.9747 - cost: 3.2249 - val_loss: 0.1130 - val_auc: 0.9897 - val_accuracy: 0.9691 - val_cost: 3.7996\n",
            "Epoch 78/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0800 - auc: 0.9942 - accuracy: 0.9755 - cost: 3.1254 - val_loss: 0.1116 - val_auc: 0.9897 - val_accuracy: 0.9689 - val_cost: 3.9484\n",
            "Epoch 79/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0800 - auc: 0.9941 - accuracy: 0.9757 - cost: 3.1007 - val_loss: 0.1096 - val_auc: 0.9899 - val_accuracy: 0.9687 - val_cost: 3.8955\n",
            "Epoch 80/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0798 - auc: 0.9942 - accuracy: 0.9759 - cost: 3.0721 - val_loss: 0.1120 - val_auc: 0.9897 - val_accuracy: 0.9680 - val_cost: 4.0013\n",
            "Epoch 81/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0795 - auc: 0.9943 - accuracy: 0.9752 - cost: 3.1566 - val_loss: 0.1103 - val_auc: 0.9897 - val_accuracy: 0.9688 - val_cost: 3.8657\n",
            "Epoch 82/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0789 - auc: 0.9944 - accuracy: 0.9757 - cost: 3.0887 - val_loss: 0.1117 - val_auc: 0.9897 - val_accuracy: 0.9680 - val_cost: 3.9484\n",
            "Epoch 83/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0797 - auc: 0.9942 - accuracy: 0.9755 - cost: 3.1142 - val_loss: 0.1099 - val_auc: 0.9898 - val_accuracy: 0.9688 - val_cost: 3.9583\n",
            "Epoch 84/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0790 - auc: 0.9943 - accuracy: 0.9757 - cost: 3.0999 - val_loss: 0.1106 - val_auc: 0.9897 - val_accuracy: 0.9690 - val_cost: 3.8393\n",
            "Epoch 85/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0785 - auc: 0.9943 - accuracy: 0.9759 - cost: 3.0849 - val_loss: 0.1087 - val_auc: 0.9899 - val_accuracy: 0.9690 - val_cost: 4.0377\n",
            "Epoch 86/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0780 - auc: 0.9943 - accuracy: 0.9759 - cost: 3.0814 - val_loss: 0.1093 - val_auc: 0.9900 - val_accuracy: 0.9693 - val_cost: 3.8261\n",
            "Epoch 87/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0774 - auc: 0.9944 - accuracy: 0.9763 - cost: 3.0405 - val_loss: 0.1098 - val_auc: 0.9896 - val_accuracy: 0.9694 - val_cost: 3.7930\n",
            "Epoch 88/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0770 - auc: 0.9944 - accuracy: 0.9765 - cost: 2.9988 - val_loss: 0.1108 - val_auc: 0.9897 - val_accuracy: 0.9697 - val_cost: 3.7665\n",
            "Epoch 89/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0768 - auc: 0.9945 - accuracy: 0.9770 - cost: 2.9298 - val_loss: 0.1101 - val_auc: 0.9897 - val_accuracy: 0.9699 - val_cost: 3.7731\n",
            "Epoch 90/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0760 - auc: 0.9945 - accuracy: 0.9767 - cost: 2.9668 - val_loss: 0.1103 - val_auc: 0.9897 - val_accuracy: 0.9691 - val_cost: 3.9484\n",
            "Epoch 91/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0759 - auc: 0.9947 - accuracy: 0.9763 - cost: 3.0154 - val_loss: 0.1090 - val_auc: 0.9900 - val_accuracy: 0.9689 - val_cost: 3.9319\n",
            "Epoch 92/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0764 - auc: 0.9945 - accuracy: 0.9763 - cost: 3.0239 - val_loss: 0.1119 - val_auc: 0.9894 - val_accuracy: 0.9694 - val_cost: 3.7136\n",
            "Epoch 93/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0757 - auc: 0.9946 - accuracy: 0.9765 - cost: 2.9981 - val_loss: 0.1109 - val_auc: 0.9899 - val_accuracy: 0.9705 - val_cost: 3.6872\n",
            "Epoch 94/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0755 - auc: 0.9946 - accuracy: 0.9770 - cost: 2.9329 - val_loss: 0.1100 - val_auc: 0.9900 - val_accuracy: 0.9705 - val_cost: 3.6772\n",
            "Epoch 95/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0751 - auc: 0.9946 - accuracy: 0.9775 - cost: 2.8819 - val_loss: 0.1094 - val_auc: 0.9897 - val_accuracy: 0.9700 - val_cost: 3.6872\n",
            "Epoch 96/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0754 - auc: 0.9946 - accuracy: 0.9769 - cost: 2.9460 - val_loss: 0.1073 - val_auc: 0.9900 - val_accuracy: 0.9709 - val_cost: 3.6971\n",
            "Epoch 97/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0747 - auc: 0.9946 - accuracy: 0.9777 - cost: 2.8588 - val_loss: 0.1114 - val_auc: 0.9898 - val_accuracy: 0.9694 - val_cost: 3.7235\n",
            "Epoch 98/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0751 - auc: 0.9946 - accuracy: 0.9774 - cost: 2.8769 - val_loss: 0.1101 - val_auc: 0.9897 - val_accuracy: 0.9697 - val_cost: 3.7765\n",
            "Epoch 99/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0745 - auc: 0.9946 - accuracy: 0.9776 - cost: 2.8580 - val_loss: 0.1105 - val_auc: 0.9899 - val_accuracy: 0.9699 - val_cost: 3.8492\n",
            "Epoch 100/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0740 - auc: 0.9948 - accuracy: 0.9772 - cost: 2.9086 - val_loss: 0.1109 - val_auc: 0.9899 - val_accuracy: 0.9697 - val_cost: 3.7698\n",
            "Epoch 101/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0736 - auc: 0.9947 - accuracy: 0.9777 - cost: 2.8461 - val_loss: 0.1098 - val_auc: 0.9900 - val_accuracy: 0.9688 - val_cost: 3.9484\n",
            "Epoch 102/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0737 - auc: 0.9949 - accuracy: 0.9774 - cost: 2.8931 - val_loss: 0.1103 - val_auc: 0.9898 - val_accuracy: 0.9701 - val_cost: 3.8591\n",
            "Epoch 103/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0740 - auc: 0.9947 - accuracy: 0.9776 - cost: 2.8650 - val_loss: 0.1111 - val_auc: 0.9899 - val_accuracy: 0.9703 - val_cost: 3.6376\n",
            "Epoch 104/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0735 - auc: 0.9949 - accuracy: 0.9775 - cost: 2.8796 - val_loss: 0.1114 - val_auc: 0.9901 - val_accuracy: 0.9709 - val_cost: 3.5317\n",
            "Epoch 105/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0729 - auc: 0.9948 - accuracy: 0.9782 - cost: 2.7782 - val_loss: 0.1113 - val_auc: 0.9897 - val_accuracy: 0.9710 - val_cost: 3.5185\n",
            "Epoch 106/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0726 - auc: 0.9949 - accuracy: 0.9783 - cost: 2.7755 - val_loss: 0.1111 - val_auc: 0.9899 - val_accuracy: 0.9712 - val_cost: 3.6276\n",
            "Epoch 107/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0735 - auc: 0.9948 - accuracy: 0.9778 - cost: 2.8245 - val_loss: 0.1122 - val_auc: 0.9897 - val_accuracy: 0.9700 - val_cost: 3.8228\n",
            "Epoch 108/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0723 - auc: 0.9949 - accuracy: 0.9782 - cost: 2.7828 - val_loss: 0.1109 - val_auc: 0.9899 - val_accuracy: 0.9702 - val_cost: 3.7368\n",
            "Epoch 109/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0714 - auc: 0.9950 - accuracy: 0.9784 - cost: 2.7608 - val_loss: 0.1102 - val_auc: 0.9900 - val_accuracy: 0.9706 - val_cost: 3.6144\n",
            "Epoch 110/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0720 - auc: 0.9950 - accuracy: 0.9782 - cost: 2.7840 - val_loss: 0.1101 - val_auc: 0.9901 - val_accuracy: 0.9706 - val_cost: 3.6772\n",
            "Epoch 111/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0727 - auc: 0.9949 - accuracy: 0.9779 - cost: 2.8256 - val_loss: 0.1117 - val_auc: 0.9897 - val_accuracy: 0.9710 - val_cost: 3.5714\n",
            "Epoch 112/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0717 - auc: 0.9950 - accuracy: 0.9785 - cost: 2.7276 - val_loss: 0.1107 - val_auc: 0.9899 - val_accuracy: 0.9709 - val_cost: 3.7004\n",
            "Epoch 113/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0712 - auc: 0.9951 - accuracy: 0.9787 - cost: 2.7222 - val_loss: 0.1125 - val_auc: 0.9898 - val_accuracy: 0.9701 - val_cost: 3.6343\n",
            "Epoch 114/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0714 - auc: 0.9949 - accuracy: 0.9786 - cost: 2.7338 - val_loss: 0.1104 - val_auc: 0.9899 - val_accuracy: 0.9708 - val_cost: 3.6243\n",
            "Epoch 115/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0711 - auc: 0.9951 - accuracy: 0.9785 - cost: 2.7465 - val_loss: 0.1104 - val_auc: 0.9898 - val_accuracy: 0.9710 - val_cost: 3.6177\n",
            "Epoch 116/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0713 - auc: 0.9950 - accuracy: 0.9785 - cost: 2.7461 - val_loss: 0.1110 - val_auc: 0.9897 - val_accuracy: 0.9704 - val_cost: 3.7269\n",
            "Epoch 117/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0702 - auc: 0.9951 - accuracy: 0.9794 - cost: 2.6304 - val_loss: 0.1126 - val_auc: 0.9897 - val_accuracy: 0.9713 - val_cost: 3.4491\n",
            "Epoch 118/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0707 - auc: 0.9950 - accuracy: 0.9792 - cost: 2.6539 - val_loss: 0.1109 - val_auc: 0.9898 - val_accuracy: 0.9703 - val_cost: 3.6343\n",
            "Epoch 119/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0702 - auc: 0.9951 - accuracy: 0.9785 - cost: 2.7431 - val_loss: 0.1100 - val_auc: 0.9899 - val_accuracy: 0.9712 - val_cost: 3.6409\n",
            "Epoch 120/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0705 - auc: 0.9951 - accuracy: 0.9791 - cost: 2.6705 - val_loss: 0.1113 - val_auc: 0.9900 - val_accuracy: 0.9701 - val_cost: 3.6640\n",
            "Epoch 121/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0703 - auc: 0.9951 - accuracy: 0.9789 - cost: 2.6902 - val_loss: 0.1103 - val_auc: 0.9899 - val_accuracy: 0.9707 - val_cost: 3.6276\n",
            "Epoch 122/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0700 - auc: 0.9951 - accuracy: 0.9789 - cost: 2.6941 - val_loss: 0.1114 - val_auc: 0.9897 - val_accuracy: 0.9700 - val_cost: 3.7202\n",
            "Epoch 123/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0703 - auc: 0.9952 - accuracy: 0.9789 - cost: 2.7018 - val_loss: 0.1114 - val_auc: 0.9896 - val_accuracy: 0.9699 - val_cost: 3.7235\n",
            "Epoch 124/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0703 - auc: 0.9950 - accuracy: 0.9788 - cost: 2.7018 - val_loss: 0.1112 - val_auc: 0.9896 - val_accuracy: 0.9704 - val_cost: 3.6376\n",
            "Epoch 125/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0693 - auc: 0.9951 - accuracy: 0.9796 - cost: 2.6046 - val_loss: 0.1114 - val_auc: 0.9901 - val_accuracy: 0.9705 - val_cost: 3.6376\n",
            "Epoch 126/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0696 - auc: 0.9951 - accuracy: 0.9793 - cost: 2.6400 - val_loss: 0.1123 - val_auc: 0.9898 - val_accuracy: 0.9697 - val_cost: 3.6673\n",
            "Epoch 127/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0701 - auc: 0.9952 - accuracy: 0.9788 - cost: 2.7145 - val_loss: 0.1127 - val_auc: 0.9900 - val_accuracy: 0.9697 - val_cost: 3.8690\n",
            "Epoch 128/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0701 - auc: 0.9950 - accuracy: 0.9791 - cost: 2.6717 - val_loss: 0.1095 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 3.5747\n",
            "Epoch 129/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0692 - auc: 0.9952 - accuracy: 0.9792 - cost: 2.6644 - val_loss: 0.1097 - val_auc: 0.9900 - val_accuracy: 0.9711 - val_cost: 3.5714\n",
            "Epoch 130/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0697 - auc: 0.9952 - accuracy: 0.9788 - cost: 2.7133 - val_loss: 0.1126 - val_auc: 0.9901 - val_accuracy: 0.9705 - val_cost: 3.6144\n",
            "Epoch 131/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0694 - auc: 0.9952 - accuracy: 0.9790 - cost: 2.6794 - val_loss: 0.1110 - val_auc: 0.9898 - val_accuracy: 0.9710 - val_cost: 3.6276\n",
            "Epoch 132/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0679 - auc: 0.9954 - accuracy: 0.9795 - cost: 2.6200 - val_loss: 0.1120 - val_auc: 0.9900 - val_accuracy: 0.9703 - val_cost: 3.7930\n",
            "Epoch 133/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0677 - auc: 0.9954 - accuracy: 0.9798 - cost: 2.5837 - val_loss: 0.1110 - val_auc: 0.9898 - val_accuracy: 0.9711 - val_cost: 3.5880\n",
            "Epoch 134/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0683 - auc: 0.9953 - accuracy: 0.9795 - cost: 2.6181 - val_loss: 0.1092 - val_auc: 0.9900 - val_accuracy: 0.9714 - val_cost: 3.5979\n",
            "Epoch 135/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0690 - auc: 0.9953 - accuracy: 0.9793 - cost: 2.6489 - val_loss: 0.1119 - val_auc: 0.9901 - val_accuracy: 0.9711 - val_cost: 3.5251\n",
            "Epoch 136/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0682 - auc: 0.9954 - accuracy: 0.9795 - cost: 2.6146 - val_loss: 0.1118 - val_auc: 0.9900 - val_accuracy: 0.9706 - val_cost: 3.5913\n",
            "Epoch 137/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0672 - auc: 0.9954 - accuracy: 0.9801 - cost: 2.5540 - val_loss: 0.1119 - val_auc: 0.9899 - val_accuracy: 0.9703 - val_cost: 3.6310\n",
            "Epoch 138/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0677 - auc: 0.9953 - accuracy: 0.9798 - cost: 2.5787 - val_loss: 0.1118 - val_auc: 0.9900 - val_accuracy: 0.9705 - val_cost: 3.7335\n",
            "Epoch 139/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0674 - auc: 0.9955 - accuracy: 0.9797 - cost: 2.6049 - val_loss: 0.1117 - val_auc: 0.9898 - val_accuracy: 0.9703 - val_cost: 3.6376\n",
            "Epoch 140/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0667 - auc: 0.9955 - accuracy: 0.9802 - cost: 2.5301 - val_loss: 0.1131 - val_auc: 0.9897 - val_accuracy: 0.9706 - val_cost: 3.6442\n",
            "Epoch 141/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0666 - auc: 0.9956 - accuracy: 0.9800 - cost: 2.5540 - val_loss: 0.1131 - val_auc: 0.9896 - val_accuracy: 0.9707 - val_cost: 3.5813\n",
            "Epoch 142/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0668 - auc: 0.9955 - accuracy: 0.9802 - cost: 2.5231 - val_loss: 0.1133 - val_auc: 0.9896 - val_accuracy: 0.9708 - val_cost: 3.6508\n",
            "Epoch 143/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0673 - auc: 0.9954 - accuracy: 0.9800 - cost: 2.5563 - val_loss: 0.1144 - val_auc: 0.9897 - val_accuracy: 0.9717 - val_cost: 3.5317\n",
            "Epoch 144/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0668 - auc: 0.9955 - accuracy: 0.9801 - cost: 2.5409 - val_loss: 0.1130 - val_auc: 0.9896 - val_accuracy: 0.9705 - val_cost: 3.6276\n",
            "Epoch 145/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0670 - auc: 0.9954 - accuracy: 0.9800 - cost: 2.5532 - val_loss: 0.1132 - val_auc: 0.9899 - val_accuracy: 0.9706 - val_cost: 3.7037\n",
            "Epoch 146/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0664 - auc: 0.9955 - accuracy: 0.9803 - cost: 2.5104 - val_loss: 0.1115 - val_auc: 0.9899 - val_accuracy: 0.9716 - val_cost: 3.5351\n",
            "Epoch 147/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0662 - auc: 0.9956 - accuracy: 0.9803 - cost: 2.5081 - val_loss: 0.1132 - val_auc: 0.9896 - val_accuracy: 0.9703 - val_cost: 3.7136\n",
            "Epoch 148/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0666 - auc: 0.9955 - accuracy: 0.9804 - cost: 2.5189 - val_loss: 0.1145 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.5218\n",
            "Epoch 149/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0662 - auc: 0.9955 - accuracy: 0.9804 - cost: 2.5093 - val_loss: 0.1125 - val_auc: 0.9899 - val_accuracy: 0.9715 - val_cost: 3.5417\n",
            "Epoch 150/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0668 - auc: 0.9956 - accuracy: 0.9796 - cost: 2.6184 - val_loss: 0.1152 - val_auc: 0.9893 - val_accuracy: 0.9705 - val_cost: 3.6012\n",
            "Epoch 151/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0653 - auc: 0.9956 - accuracy: 0.9806 - cost: 2.4834 - val_loss: 0.1137 - val_auc: 0.9899 - val_accuracy: 0.9708 - val_cost: 3.5582\n",
            "Epoch 152/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0665 - auc: 0.9956 - accuracy: 0.9799 - cost: 2.5610 - val_loss: 0.1133 - val_auc: 0.9895 - val_accuracy: 0.9706 - val_cost: 3.6210\n",
            "Epoch 153/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0653 - auc: 0.9957 - accuracy: 0.9811 - cost: 2.4213 - val_loss: 0.1135 - val_auc: 0.9896 - val_accuracy: 0.9715 - val_cost: 3.5284\n",
            "Epoch 154/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0654 - auc: 0.9956 - accuracy: 0.9807 - cost: 2.4583 - val_loss: 0.1131 - val_auc: 0.9898 - val_accuracy: 0.9716 - val_cost: 3.5384\n",
            "Epoch 155/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0654 - auc: 0.9956 - accuracy: 0.9807 - cost: 2.4695 - val_loss: 0.1142 - val_auc: 0.9899 - val_accuracy: 0.9710 - val_cost: 3.5946\n",
            "Epoch 156/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0654 - auc: 0.9955 - accuracy: 0.9805 - cost: 2.4857 - val_loss: 0.1177 - val_auc: 0.9893 - val_accuracy: 0.9702 - val_cost: 3.6607\n",
            "Epoch 157/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0656 - auc: 0.9956 - accuracy: 0.9805 - cost: 2.4973 - val_loss: 0.1157 - val_auc: 0.9892 - val_accuracy: 0.9702 - val_cost: 3.6475\n",
            "Epoch 158/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0650 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4414 - val_loss: 0.1146 - val_auc: 0.9895 - val_accuracy: 0.9713 - val_cost: 3.5516\n",
            "Epoch 159/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0654 - auc: 0.9956 - accuracy: 0.9808 - cost: 2.4576 - val_loss: 0.1168 - val_auc: 0.9892 - val_accuracy: 0.9701 - val_cost: 3.7401\n",
            "Epoch 160/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0652 - auc: 0.9957 - accuracy: 0.9804 - cost: 2.5004 - val_loss: 0.1152 - val_auc: 0.9892 - val_accuracy: 0.9709 - val_cost: 3.6905\n",
            "Epoch 161/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0645 - auc: 0.9957 - accuracy: 0.9808 - cost: 2.4633 - val_loss: 0.1132 - val_auc: 0.9893 - val_accuracy: 0.9709 - val_cost: 3.6078\n",
            "Epoch 162/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0648 - auc: 0.9957 - accuracy: 0.9807 - cost: 2.4653 - val_loss: 0.1153 - val_auc: 0.9895 - val_accuracy: 0.9706 - val_cost: 3.7632\n",
            "Epoch 163/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0648 - auc: 0.9957 - accuracy: 0.9808 - cost: 2.4560 - val_loss: 0.1184 - val_auc: 0.9895 - val_accuracy: 0.9701 - val_cost: 3.6872\n",
            "Epoch 164/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0651 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4525 - val_loss: 0.1153 - val_auc: 0.9894 - val_accuracy: 0.9715 - val_cost: 3.5714\n",
            "Epoch 165/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0651 - auc: 0.9956 - accuracy: 0.9805 - cost: 2.4807 - val_loss: 0.1143 - val_auc: 0.9896 - val_accuracy: 0.9714 - val_cost: 3.6310\n",
            "Epoch 166/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0647 - auc: 0.9956 - accuracy: 0.9812 - cost: 2.4020 - val_loss: 0.1146 - val_auc: 0.9894 - val_accuracy: 0.9712 - val_cost: 3.5185\n",
            "Epoch 167/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0645 - auc: 0.9958 - accuracy: 0.9811 - cost: 2.4151 - val_loss: 0.1159 - val_auc: 0.9893 - val_accuracy: 0.9712 - val_cost: 3.5946\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0999 - auc: 0.9909 - accuracy: 0.9708 - cost: 3.6500\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:01:25.251856\n",
            "fold accuracy: 0.9708124995231628 - fold cost: 3.6500000953674316\n",
            "x_train shape: (144000, 67)\n",
            "Epoch 1/1000\n",
            "120/120 [==============================] - 2s 5ms/step - loss: 0.5332 - auc: 0.7947 - accuracy: 0.7271 - cost: 36.4279 - val_loss: 0.4019 - val_auc: 0.8971 - val_accuracy: 0.8231 - val_cost: 22.8373\n",
            "Epoch 2/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.3547 - auc: 0.9200 - accuracy: 0.8476 - cost: 19.4402 - val_loss: 0.3194 - val_auc: 0.9350 - val_accuracy: 0.8638 - val_cost: 17.2950\n",
            "Epoch 3/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.3044 - auc: 0.9413 - accuracy: 0.8734 - cost: 16.0525 - val_loss: 0.2890 - val_auc: 0.9472 - val_accuracy: 0.8808 - val_cost: 14.7156\n",
            "Epoch 4/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2759 - auc: 0.9519 - accuracy: 0.8872 - cost: 14.3056 - val_loss: 0.2641 - val_auc: 0.9557 - val_accuracy: 0.8903 - val_cost: 13.8459\n",
            "Epoch 5/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2527 - auc: 0.9597 - accuracy: 0.8990 - cost: 12.7832 - val_loss: 0.2442 - val_auc: 0.9625 - val_accuracy: 0.9034 - val_cost: 12.0800\n",
            "Epoch 6/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2328 - auc: 0.9658 - accuracy: 0.9090 - cost: 11.4954 - val_loss: 0.2261 - val_auc: 0.9678 - val_accuracy: 0.9131 - val_cost: 10.9491\n",
            "Epoch 7/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2177 - auc: 0.9701 - accuracy: 0.9152 - cost: 10.7257 - val_loss: 0.2126 - val_auc: 0.9715 - val_accuracy: 0.9197 - val_cost: 10.1190\n",
            "Epoch 8/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2044 - auc: 0.9735 - accuracy: 0.9219 - cost: 9.8750 - val_loss: 0.2013 - val_auc: 0.9743 - val_accuracy: 0.9242 - val_cost: 9.4411\n",
            "Epoch 9/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1931 - auc: 0.9761 - accuracy: 0.9270 - cost: 9.2311 - val_loss: 0.1917 - val_auc: 0.9766 - val_accuracy: 0.9289 - val_cost: 8.9616\n",
            "Epoch 10/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1834 - auc: 0.9783 - accuracy: 0.9312 - cost: 8.7122 - val_loss: 0.1848 - val_auc: 0.9780 - val_accuracy: 0.9324 - val_cost: 8.6243\n",
            "Epoch 11/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1765 - auc: 0.9798 - accuracy: 0.9351 - cost: 8.2326 - val_loss: 0.1777 - val_auc: 0.9798 - val_accuracy: 0.9358 - val_cost: 7.9563\n",
            "Epoch 12/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1695 - auc: 0.9814 - accuracy: 0.9380 - cost: 7.8542 - val_loss: 0.1729 - val_auc: 0.9805 - val_accuracy: 0.9388 - val_cost: 7.6488\n",
            "Epoch 13/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1641 - auc: 0.9824 - accuracy: 0.9400 - cost: 7.6165 - val_loss: 0.1683 - val_auc: 0.9815 - val_accuracy: 0.9418 - val_cost: 7.3876\n",
            "Epoch 14/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1585 - auc: 0.9834 - accuracy: 0.9432 - cost: 7.2199 - val_loss: 0.1634 - val_auc: 0.9825 - val_accuracy: 0.9423 - val_cost: 7.2685\n",
            "Epoch 15/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1544 - auc: 0.9841 - accuracy: 0.9449 - cost: 6.9896 - val_loss: 0.1610 - val_auc: 0.9828 - val_accuracy: 0.9435 - val_cost: 7.1032\n",
            "Epoch 16/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1487 - auc: 0.9853 - accuracy: 0.9474 - cost: 6.6806 - val_loss: 0.1564 - val_auc: 0.9837 - val_accuracy: 0.9446 - val_cost: 6.9180\n",
            "Epoch 17/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1460 - auc: 0.9856 - accuracy: 0.9483 - cost: 6.5563 - val_loss: 0.1525 - val_auc: 0.9845 - val_accuracy: 0.9465 - val_cost: 6.8684\n",
            "Epoch 18/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1436 - auc: 0.9860 - accuracy: 0.9499 - cost: 6.3507 - val_loss: 0.1502 - val_auc: 0.9848 - val_accuracy: 0.9472 - val_cost: 6.7295\n",
            "Epoch 19/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1406 - auc: 0.9865 - accuracy: 0.9506 - cost: 6.2820 - val_loss: 0.1491 - val_auc: 0.9850 - val_accuracy: 0.9478 - val_cost: 6.4947\n",
            "Epoch 20/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1386 - auc: 0.9869 - accuracy: 0.9516 - cost: 6.1389 - val_loss: 0.1460 - val_auc: 0.9855 - val_accuracy: 0.9501 - val_cost: 6.2136\n",
            "Epoch 21/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1343 - auc: 0.9876 - accuracy: 0.9537 - cost: 5.8785 - val_loss: 0.1447 - val_auc: 0.9857 - val_accuracy: 0.9504 - val_cost: 6.2798\n",
            "Epoch 22/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1328 - auc: 0.9878 - accuracy: 0.9537 - cost: 5.8754 - val_loss: 0.1439 - val_auc: 0.9857 - val_accuracy: 0.9514 - val_cost: 6.1409\n",
            "Epoch 23/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1318 - auc: 0.9879 - accuracy: 0.9550 - cost: 5.7145 - val_loss: 0.1413 - val_auc: 0.9861 - val_accuracy: 0.9511 - val_cost: 6.2335\n",
            "Epoch 24/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1288 - auc: 0.9884 - accuracy: 0.9563 - cost: 5.5467 - val_loss: 0.1397 - val_auc: 0.9864 - val_accuracy: 0.9519 - val_cost: 6.0351\n",
            "Epoch 25/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1271 - auc: 0.9886 - accuracy: 0.9567 - cost: 5.4961 - val_loss: 0.1398 - val_auc: 0.9863 - val_accuracy: 0.9526 - val_cost: 5.8862\n",
            "Epoch 26/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1244 - auc: 0.9889 - accuracy: 0.9584 - cost: 5.2731 - val_loss: 0.1388 - val_auc: 0.9864 - val_accuracy: 0.9532 - val_cost: 5.8399\n",
            "Epoch 27/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1223 - auc: 0.9893 - accuracy: 0.9589 - cost: 5.2323 - val_loss: 0.1373 - val_auc: 0.9867 - val_accuracy: 0.9539 - val_cost: 5.8730\n",
            "Epoch 28/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1212 - auc: 0.9895 - accuracy: 0.9594 - cost: 5.1535 - val_loss: 0.1369 - val_auc: 0.9868 - val_accuracy: 0.9537 - val_cost: 5.8598\n",
            "Epoch 29/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1201 - auc: 0.9896 - accuracy: 0.9596 - cost: 5.1300 - val_loss: 0.1377 - val_auc: 0.9868 - val_accuracy: 0.9548 - val_cost: 5.5456\n",
            "Epoch 30/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1189 - auc: 0.9897 - accuracy: 0.9603 - cost: 5.0436 - val_loss: 0.1351 - val_auc: 0.9870 - val_accuracy: 0.9565 - val_cost: 5.4861\n",
            "Epoch 31/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1161 - auc: 0.9901 - accuracy: 0.9614 - cost: 4.9059 - val_loss: 0.1348 - val_auc: 0.9871 - val_accuracy: 0.9558 - val_cost: 5.6878\n",
            "Epoch 32/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1156 - auc: 0.9902 - accuracy: 0.9616 - cost: 4.8696 - val_loss: 0.1327 - val_auc: 0.9872 - val_accuracy: 0.9561 - val_cost: 5.5390\n",
            "Epoch 33/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1137 - auc: 0.9904 - accuracy: 0.9623 - cost: 4.7863 - val_loss: 0.1315 - val_auc: 0.9876 - val_accuracy: 0.9563 - val_cost: 5.6448\n",
            "Epoch 34/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1124 - auc: 0.9907 - accuracy: 0.9631 - cost: 4.7037 - val_loss: 0.1311 - val_auc: 0.9875 - val_accuracy: 0.9583 - val_cost: 5.2646\n",
            "Epoch 35/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1118 - auc: 0.9906 - accuracy: 0.9632 - cost: 4.6840 - val_loss: 0.1285 - val_auc: 0.9881 - val_accuracy: 0.9581 - val_cost: 5.2348\n",
            "Epoch 36/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1102 - auc: 0.9909 - accuracy: 0.9636 - cost: 4.6200 - val_loss: 0.1292 - val_auc: 0.9878 - val_accuracy: 0.9592 - val_cost: 5.2183\n",
            "Epoch 37/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1093 - auc: 0.9909 - accuracy: 0.9645 - cost: 4.5123 - val_loss: 0.1288 - val_auc: 0.9880 - val_accuracy: 0.9593 - val_cost: 5.1025\n",
            "Epoch 38/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1084 - auc: 0.9911 - accuracy: 0.9647 - cost: 4.4718 - val_loss: 0.1266 - val_auc: 0.9882 - val_accuracy: 0.9592 - val_cost: 5.1951\n",
            "Epoch 39/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1063 - auc: 0.9914 - accuracy: 0.9652 - cost: 4.4298 - val_loss: 0.1261 - val_auc: 0.9882 - val_accuracy: 0.9601 - val_cost: 4.9272\n",
            "Epoch 40/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1057 - auc: 0.9914 - accuracy: 0.9655 - cost: 4.3858 - val_loss: 0.1269 - val_auc: 0.9882 - val_accuracy: 0.9594 - val_cost: 5.0000\n",
            "Epoch 41/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1046 - auc: 0.9914 - accuracy: 0.9665 - cost: 4.2481 - val_loss: 0.1243 - val_auc: 0.9884 - val_accuracy: 0.9603 - val_cost: 5.0628\n",
            "Epoch 42/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1039 - auc: 0.9916 - accuracy: 0.9661 - cost: 4.3048 - val_loss: 0.1235 - val_auc: 0.9885 - val_accuracy: 0.9610 - val_cost: 4.9173\n",
            "Epoch 43/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1027 - auc: 0.9918 - accuracy: 0.9666 - cost: 4.2546 - val_loss: 0.1251 - val_auc: 0.9883 - val_accuracy: 0.9600 - val_cost: 4.9438\n",
            "Epoch 44/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1021 - auc: 0.9919 - accuracy: 0.9674 - cost: 4.1242 - val_loss: 0.1235 - val_auc: 0.9883 - val_accuracy: 0.9606 - val_cost: 4.9702\n",
            "Epoch 45/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1007 - auc: 0.9920 - accuracy: 0.9683 - cost: 4.0448 - val_loss: 0.1249 - val_auc: 0.9885 - val_accuracy: 0.9611 - val_cost: 4.7321\n",
            "Epoch 46/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1006 - auc: 0.9921 - accuracy: 0.9674 - cost: 4.1323 - val_loss: 0.1237 - val_auc: 0.9884 - val_accuracy: 0.9606 - val_cost: 4.9173\n",
            "Epoch 47/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0999 - auc: 0.9921 - accuracy: 0.9679 - cost: 4.0818 - val_loss: 0.1221 - val_auc: 0.9884 - val_accuracy: 0.9622 - val_cost: 4.8280\n",
            "Epoch 48/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0982 - auc: 0.9923 - accuracy: 0.9688 - cost: 3.9653 - val_loss: 0.1222 - val_auc: 0.9885 - val_accuracy: 0.9610 - val_cost: 4.8644\n",
            "Epoch 49/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0973 - auc: 0.9924 - accuracy: 0.9694 - cost: 3.8881 - val_loss: 0.1208 - val_auc: 0.9889 - val_accuracy: 0.9615 - val_cost: 4.9074\n",
            "Epoch 50/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0960 - auc: 0.9924 - accuracy: 0.9693 - cost: 3.9155 - val_loss: 0.1209 - val_auc: 0.9888 - val_accuracy: 0.9625 - val_cost: 4.7454\n",
            "Epoch 51/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0959 - auc: 0.9926 - accuracy: 0.9694 - cost: 3.8978 - val_loss: 0.1204 - val_auc: 0.9889 - val_accuracy: 0.9628 - val_cost: 4.8545\n",
            "Epoch 52/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0950 - auc: 0.9927 - accuracy: 0.9700 - cost: 3.8218 - val_loss: 0.1209 - val_auc: 0.9886 - val_accuracy: 0.9628 - val_cost: 4.6362\n",
            "Epoch 53/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0943 - auc: 0.9927 - accuracy: 0.9701 - cost: 3.8067 - val_loss: 0.1187 - val_auc: 0.9888 - val_accuracy: 0.9634 - val_cost: 4.6792\n",
            "Epoch 54/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0933 - auc: 0.9928 - accuracy: 0.9702 - cost: 3.7886 - val_loss: 0.1197 - val_auc: 0.9890 - val_accuracy: 0.9634 - val_cost: 4.3849\n",
            "Epoch 55/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0929 - auc: 0.9929 - accuracy: 0.9708 - cost: 3.7218 - val_loss: 0.1187 - val_auc: 0.9890 - val_accuracy: 0.9632 - val_cost: 4.5437\n",
            "Epoch 56/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0925 - auc: 0.9929 - accuracy: 0.9706 - cost: 3.7411 - val_loss: 0.1172 - val_auc: 0.9888 - val_accuracy: 0.9647 - val_cost: 4.4775\n",
            "Epoch 57/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0915 - auc: 0.9929 - accuracy: 0.9708 - cost: 3.7238 - val_loss: 0.1167 - val_auc: 0.9891 - val_accuracy: 0.9642 - val_cost: 4.4742\n",
            "Epoch 58/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0920 - auc: 0.9929 - accuracy: 0.9711 - cost: 3.6833 - val_loss: 0.1166 - val_auc: 0.9891 - val_accuracy: 0.9642 - val_cost: 4.4940\n",
            "Epoch 59/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0903 - auc: 0.9931 - accuracy: 0.9715 - cost: 3.6339 - val_loss: 0.1170 - val_auc: 0.9890 - val_accuracy: 0.9638 - val_cost: 4.5635\n",
            "Epoch 60/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0898 - auc: 0.9931 - accuracy: 0.9721 - cost: 3.5517 - val_loss: 0.1161 - val_auc: 0.9892 - val_accuracy: 0.9642 - val_cost: 4.5602\n",
            "Epoch 61/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0899 - auc: 0.9931 - accuracy: 0.9719 - cost: 3.5764 - val_loss: 0.1176 - val_auc: 0.9891 - val_accuracy: 0.9650 - val_cost: 4.4974\n",
            "Epoch 62/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0885 - auc: 0.9934 - accuracy: 0.9720 - cost: 3.5671 - val_loss: 0.1169 - val_auc: 0.9893 - val_accuracy: 0.9651 - val_cost: 4.3155\n",
            "Epoch 63/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0878 - auc: 0.9934 - accuracy: 0.9724 - cost: 3.5139 - val_loss: 0.1155 - val_auc: 0.9893 - val_accuracy: 0.9652 - val_cost: 4.3386\n",
            "Epoch 64/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0882 - auc: 0.9934 - accuracy: 0.9729 - cost: 3.4579 - val_loss: 0.1158 - val_auc: 0.9892 - val_accuracy: 0.9655 - val_cost: 4.3353\n",
            "Epoch 65/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0876 - auc: 0.9933 - accuracy: 0.9728 - cost: 3.4699 - val_loss: 0.1148 - val_auc: 0.9894 - val_accuracy: 0.9656 - val_cost: 4.3519\n",
            "Epoch 66/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0869 - auc: 0.9935 - accuracy: 0.9730 - cost: 3.4387 - val_loss: 0.1146 - val_auc: 0.9895 - val_accuracy: 0.9662 - val_cost: 4.2328\n",
            "Epoch 67/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0869 - auc: 0.9935 - accuracy: 0.9729 - cost: 3.4653 - val_loss: 0.1127 - val_auc: 0.9895 - val_accuracy: 0.9660 - val_cost: 4.2989\n",
            "Epoch 68/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0852 - auc: 0.9936 - accuracy: 0.9737 - cost: 3.3530 - val_loss: 0.1132 - val_auc: 0.9896 - val_accuracy: 0.9666 - val_cost: 4.1468\n",
            "Epoch 69/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0859 - auc: 0.9935 - accuracy: 0.9733 - cost: 3.3978 - val_loss: 0.1173 - val_auc: 0.9893 - val_accuracy: 0.9655 - val_cost: 4.2692\n",
            "Epoch 70/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0856 - auc: 0.9935 - accuracy: 0.9737 - cost: 3.3580 - val_loss: 0.1136 - val_auc: 0.9896 - val_accuracy: 0.9665 - val_cost: 4.1931\n",
            "Epoch 71/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0850 - auc: 0.9937 - accuracy: 0.9741 - cost: 3.2878 - val_loss: 0.1120 - val_auc: 0.9898 - val_accuracy: 0.9663 - val_cost: 4.2526\n",
            "Epoch 72/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0841 - auc: 0.9937 - accuracy: 0.9745 - cost: 3.2577 - val_loss: 0.1121 - val_auc: 0.9896 - val_accuracy: 0.9669 - val_cost: 4.1402\n",
            "Epoch 73/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0841 - auc: 0.9937 - accuracy: 0.9739 - cost: 3.3302 - val_loss: 0.1131 - val_auc: 0.9894 - val_accuracy: 0.9655 - val_cost: 4.4775\n",
            "Epoch 74/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0837 - auc: 0.9939 - accuracy: 0.9740 - cost: 3.3160 - val_loss: 0.1134 - val_auc: 0.9896 - val_accuracy: 0.9665 - val_cost: 4.1038\n",
            "Epoch 75/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0826 - auc: 0.9939 - accuracy: 0.9748 - cost: 3.2218 - val_loss: 0.1138 - val_auc: 0.9895 - val_accuracy: 0.9656 - val_cost: 4.3188\n",
            "Epoch 76/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0838 - auc: 0.9937 - accuracy: 0.9742 - cost: 3.2832 - val_loss: 0.1128 - val_auc: 0.9897 - val_accuracy: 0.9665 - val_cost: 4.2824\n",
            "Epoch 77/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0814 - auc: 0.9941 - accuracy: 0.9749 - cost: 3.2130 - val_loss: 0.1113 - val_auc: 0.9899 - val_accuracy: 0.9662 - val_cost: 4.2626\n",
            "Epoch 78/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0825 - auc: 0.9939 - accuracy: 0.9749 - cost: 3.2083 - val_loss: 0.1120 - val_auc: 0.9896 - val_accuracy: 0.9672 - val_cost: 4.0675\n",
            "Epoch 79/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0804 - auc: 0.9942 - accuracy: 0.9753 - cost: 3.1339 - val_loss: 0.1113 - val_auc: 0.9900 - val_accuracy: 0.9672 - val_cost: 4.0542\n",
            "Epoch 80/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0808 - auc: 0.9940 - accuracy: 0.9755 - cost: 3.1327 - val_loss: 0.1122 - val_auc: 0.9896 - val_accuracy: 0.9668 - val_cost: 4.1204\n",
            "Epoch 81/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0810 - auc: 0.9941 - accuracy: 0.9753 - cost: 3.1566 - val_loss: 0.1123 - val_auc: 0.9895 - val_accuracy: 0.9665 - val_cost: 4.2063\n",
            "Epoch 82/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0812 - auc: 0.9940 - accuracy: 0.9752 - cost: 3.1686 - val_loss: 0.1133 - val_auc: 0.9897 - val_accuracy: 0.9671 - val_cost: 3.9914\n",
            "Epoch 83/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0802 - auc: 0.9942 - accuracy: 0.9755 - cost: 3.1285 - val_loss: 0.1113 - val_auc: 0.9897 - val_accuracy: 0.9679 - val_cost: 4.0774\n",
            "Epoch 84/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0795 - auc: 0.9942 - accuracy: 0.9758 - cost: 3.0953 - val_loss: 0.1108 - val_auc: 0.9897 - val_accuracy: 0.9681 - val_cost: 3.9980\n",
            "Epoch 85/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0800 - auc: 0.9941 - accuracy: 0.9758 - cost: 3.0965 - val_loss: 0.1109 - val_auc: 0.9898 - val_accuracy: 0.9675 - val_cost: 3.9683\n",
            "Epoch 86/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0794 - auc: 0.9942 - accuracy: 0.9755 - cost: 3.1238 - val_loss: 0.1118 - val_auc: 0.9899 - val_accuracy: 0.9670 - val_cost: 4.1534\n",
            "Epoch 87/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0787 - auc: 0.9943 - accuracy: 0.9762 - cost: 3.0312 - val_loss: 0.1122 - val_auc: 0.9897 - val_accuracy: 0.9674 - val_cost: 3.9352\n",
            "Epoch 88/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0789 - auc: 0.9942 - accuracy: 0.9760 - cost: 3.0779 - val_loss: 0.1121 - val_auc: 0.9897 - val_accuracy: 0.9665 - val_cost: 4.1435\n",
            "Epoch 89/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0777 - auc: 0.9943 - accuracy: 0.9764 - cost: 3.0116 - val_loss: 0.1112 - val_auc: 0.9897 - val_accuracy: 0.9679 - val_cost: 4.0079\n",
            "Epoch 90/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0771 - auc: 0.9943 - accuracy: 0.9766 - cost: 2.9857 - val_loss: 0.1120 - val_auc: 0.9894 - val_accuracy: 0.9672 - val_cost: 3.9947\n",
            "Epoch 91/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0779 - auc: 0.9943 - accuracy: 0.9764 - cost: 3.0046 - val_loss: 0.1122 - val_auc: 0.9898 - val_accuracy: 0.9664 - val_cost: 4.1931\n",
            "Epoch 92/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0776 - auc: 0.9943 - accuracy: 0.9769 - cost: 2.9479 - val_loss: 0.1119 - val_auc: 0.9900 - val_accuracy: 0.9672 - val_cost: 4.0410\n",
            "Epoch 93/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0783 - auc: 0.9943 - accuracy: 0.9760 - cost: 3.0679 - val_loss: 0.1112 - val_auc: 0.9899 - val_accuracy: 0.9681 - val_cost: 3.9649\n",
            "Epoch 94/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0761 - auc: 0.9945 - accuracy: 0.9766 - cost: 2.9911 - val_loss: 0.1151 - val_auc: 0.9891 - val_accuracy: 0.9672 - val_cost: 4.0575\n",
            "Epoch 95/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0773 - auc: 0.9943 - accuracy: 0.9768 - cost: 2.9541 - val_loss: 0.1107 - val_auc: 0.9898 - val_accuracy: 0.9691 - val_cost: 3.8757\n",
            "Epoch 96/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0769 - auc: 0.9944 - accuracy: 0.9769 - cost: 2.9614 - val_loss: 0.1125 - val_auc: 0.9896 - val_accuracy: 0.9674 - val_cost: 4.0344\n",
            "Epoch 97/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0766 - auc: 0.9944 - accuracy: 0.9767 - cost: 2.9788 - val_loss: 0.1119 - val_auc: 0.9899 - val_accuracy: 0.9678 - val_cost: 4.1005\n",
            "Epoch 98/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0754 - auc: 0.9946 - accuracy: 0.9769 - cost: 2.9421 - val_loss: 0.1122 - val_auc: 0.9898 - val_accuracy: 0.9684 - val_cost: 3.8128\n",
            "Epoch 99/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0752 - auc: 0.9945 - accuracy: 0.9776 - cost: 2.8700 - val_loss: 0.1114 - val_auc: 0.9897 - val_accuracy: 0.9692 - val_cost: 3.8261\n",
            "Epoch 100/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0754 - auc: 0.9946 - accuracy: 0.9768 - cost: 2.9595 - val_loss: 0.1124 - val_auc: 0.9898 - val_accuracy: 0.9674 - val_cost: 4.0476\n",
            "Epoch 101/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0750 - auc: 0.9947 - accuracy: 0.9772 - cost: 2.9178 - val_loss: 0.1097 - val_auc: 0.9898 - val_accuracy: 0.9683 - val_cost: 4.0278\n",
            "Epoch 102/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0744 - auc: 0.9947 - accuracy: 0.9776 - cost: 2.8634 - val_loss: 0.1118 - val_auc: 0.9899 - val_accuracy: 0.9688 - val_cost: 3.8988\n",
            "Epoch 103/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0745 - auc: 0.9947 - accuracy: 0.9776 - cost: 2.8619 - val_loss: 0.1119 - val_auc: 0.9900 - val_accuracy: 0.9680 - val_cost: 4.0278\n",
            "Epoch 104/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0740 - auc: 0.9947 - accuracy: 0.9776 - cost: 2.8534 - val_loss: 0.1108 - val_auc: 0.9899 - val_accuracy: 0.9688 - val_cost: 3.9484\n",
            "Epoch 105/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0747 - auc: 0.9947 - accuracy: 0.9773 - cost: 2.9128 - val_loss: 0.1131 - val_auc: 0.9894 - val_accuracy: 0.9667 - val_cost: 4.2692\n",
            "Epoch 106/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0737 - auc: 0.9948 - accuracy: 0.9781 - cost: 2.8059 - val_loss: 0.1118 - val_auc: 0.9900 - val_accuracy: 0.9685 - val_cost: 4.0112\n",
            "Epoch 107/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0735 - auc: 0.9947 - accuracy: 0.9776 - cost: 2.8630 - val_loss: 0.1132 - val_auc: 0.9897 - val_accuracy: 0.9680 - val_cost: 4.0410\n",
            "Epoch 108/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0732 - auc: 0.9948 - accuracy: 0.9782 - cost: 2.7894 - val_loss: 0.1130 - val_auc: 0.9896 - val_accuracy: 0.9677 - val_cost: 4.0774\n",
            "Epoch 109/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0734 - auc: 0.9948 - accuracy: 0.9783 - cost: 2.7785 - val_loss: 0.1129 - val_auc: 0.9896 - val_accuracy: 0.9678 - val_cost: 4.1270\n",
            "Epoch 110/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0734 - auc: 0.9948 - accuracy: 0.9779 - cost: 2.8206 - val_loss: 0.1136 - val_auc: 0.9895 - val_accuracy: 0.9677 - val_cost: 3.9484\n",
            "Epoch 111/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0728 - auc: 0.9949 - accuracy: 0.9780 - cost: 2.8187 - val_loss: 0.1118 - val_auc: 0.9898 - val_accuracy: 0.9686 - val_cost: 3.9616\n",
            "Epoch 112/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0728 - auc: 0.9949 - accuracy: 0.9780 - cost: 2.8137 - val_loss: 0.1108 - val_auc: 0.9900 - val_accuracy: 0.9687 - val_cost: 3.9451\n",
            "Epoch 113/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0728 - auc: 0.9947 - accuracy: 0.9779 - cost: 2.8241 - val_loss: 0.1124 - val_auc: 0.9898 - val_accuracy: 0.9684 - val_cost: 3.9220\n",
            "Epoch 114/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0719 - auc: 0.9949 - accuracy: 0.9784 - cost: 2.7554 - val_loss: 0.1134 - val_auc: 0.9898 - val_accuracy: 0.9677 - val_cost: 4.1468\n",
            "Epoch 115/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0732 - auc: 0.9948 - accuracy: 0.9781 - cost: 2.7936 - val_loss: 0.1129 - val_auc: 0.9897 - val_accuracy: 0.9681 - val_cost: 4.0013\n",
            "Epoch 116/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0725 - auc: 0.9948 - accuracy: 0.9782 - cost: 2.7878 - val_loss: 0.1127 - val_auc: 0.9898 - val_accuracy: 0.9690 - val_cost: 3.7831\n",
            "Epoch 117/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0712 - auc: 0.9950 - accuracy: 0.9786 - cost: 2.7377 - val_loss: 0.1096 - val_auc: 0.9898 - val_accuracy: 0.9697 - val_cost: 3.7632\n",
            "Epoch 118/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0713 - auc: 0.9949 - accuracy: 0.9788 - cost: 2.7122 - val_loss: 0.1129 - val_auc: 0.9899 - val_accuracy: 0.9690 - val_cost: 3.7302\n",
            "Epoch 119/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0717 - auc: 0.9949 - accuracy: 0.9785 - cost: 2.7492 - val_loss: 0.1125 - val_auc: 0.9898 - val_accuracy: 0.9683 - val_cost: 3.9517\n",
            "Epoch 120/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0715 - auc: 0.9949 - accuracy: 0.9786 - cost: 2.7280 - val_loss: 0.1121 - val_auc: 0.9897 - val_accuracy: 0.9683 - val_cost: 4.0642\n",
            "Epoch 121/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0709 - auc: 0.9951 - accuracy: 0.9787 - cost: 2.7230 - val_loss: 0.1123 - val_auc: 0.9896 - val_accuracy: 0.9690 - val_cost: 3.7996\n",
            "Epoch 122/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0700 - auc: 0.9951 - accuracy: 0.9791 - cost: 2.6755 - val_loss: 0.1108 - val_auc: 0.9900 - val_accuracy: 0.9688 - val_cost: 3.9087\n",
            "Epoch 123/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0706 - auc: 0.9950 - accuracy: 0.9790 - cost: 2.6968 - val_loss: 0.1126 - val_auc: 0.9899 - val_accuracy: 0.9686 - val_cost: 3.8856\n",
            "Epoch 124/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0712 - auc: 0.9949 - accuracy: 0.9786 - cost: 2.7415 - val_loss: 0.1117 - val_auc: 0.9898 - val_accuracy: 0.9687 - val_cost: 3.9385\n",
            "Epoch 125/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0706 - auc: 0.9951 - accuracy: 0.9787 - cost: 2.7284 - val_loss: 0.1140 - val_auc: 0.9894 - val_accuracy: 0.9690 - val_cost: 3.7996\n",
            "Epoch 126/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0704 - auc: 0.9951 - accuracy: 0.9790 - cost: 2.6813 - val_loss: 0.1120 - val_auc: 0.9898 - val_accuracy: 0.9694 - val_cost: 3.8393\n",
            "Epoch 127/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0696 - auc: 0.9952 - accuracy: 0.9790 - cost: 2.6833 - val_loss: 0.1144 - val_auc: 0.9895 - val_accuracy: 0.9681 - val_cost: 4.0013\n",
            "Epoch 128/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0701 - auc: 0.9950 - accuracy: 0.9793 - cost: 2.6613 - val_loss: 0.1144 - val_auc: 0.9894 - val_accuracy: 0.9685 - val_cost: 3.8624\n",
            "Epoch 129/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0701 - auc: 0.9951 - accuracy: 0.9795 - cost: 2.6258 - val_loss: 0.1120 - val_auc: 0.9896 - val_accuracy: 0.9692 - val_cost: 3.9319\n",
            "Epoch 130/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0694 - auc: 0.9951 - accuracy: 0.9793 - cost: 2.6536 - val_loss: 0.1107 - val_auc: 0.9899 - val_accuracy: 0.9701 - val_cost: 3.7368\n",
            "Epoch 131/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0693 - auc: 0.9951 - accuracy: 0.9793 - cost: 2.6397 - val_loss: 0.1110 - val_auc: 0.9895 - val_accuracy: 0.9686 - val_cost: 4.0509\n",
            "Epoch 132/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0693 - auc: 0.9952 - accuracy: 0.9796 - cost: 2.6227 - val_loss: 0.1121 - val_auc: 0.9899 - val_accuracy: 0.9695 - val_cost: 3.8558\n",
            "Epoch 133/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0696 - auc: 0.9952 - accuracy: 0.9790 - cost: 2.6952 - val_loss: 0.1105 - val_auc: 0.9899 - val_accuracy: 0.9694 - val_cost: 3.8624\n",
            "Epoch 134/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0691 - auc: 0.9952 - accuracy: 0.9797 - cost: 2.5988 - val_loss: 0.1115 - val_auc: 0.9897 - val_accuracy: 0.9696 - val_cost: 3.7467\n",
            "Epoch 135/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0697 - auc: 0.9952 - accuracy: 0.9794 - cost: 2.6516 - val_loss: 0.1118 - val_auc: 0.9895 - val_accuracy: 0.9709 - val_cost: 3.6376\n",
            "Epoch 136/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0685 - auc: 0.9953 - accuracy: 0.9795 - cost: 2.6323 - val_loss: 0.1124 - val_auc: 0.9899 - val_accuracy: 0.9696 - val_cost: 3.8856\n",
            "Epoch 137/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0695 - auc: 0.9952 - accuracy: 0.9793 - cost: 2.6370 - val_loss: 0.1100 - val_auc: 0.9898 - val_accuracy: 0.9703 - val_cost: 3.7599\n",
            "Epoch 138/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0679 - auc: 0.9953 - accuracy: 0.9802 - cost: 2.5224 - val_loss: 0.1151 - val_auc: 0.9894 - val_accuracy: 0.9695 - val_cost: 3.8624\n",
            "Epoch 139/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0689 - auc: 0.9952 - accuracy: 0.9796 - cost: 2.6123 - val_loss: 0.1094 - val_auc: 0.9901 - val_accuracy: 0.9697 - val_cost: 3.8624\n",
            "Epoch 140/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0689 - auc: 0.9952 - accuracy: 0.9793 - cost: 2.6555 - val_loss: 0.1128 - val_auc: 0.9897 - val_accuracy: 0.9699 - val_cost: 3.7500\n",
            "Epoch 141/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0680 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.5822 - val_loss: 0.1105 - val_auc: 0.9898 - val_accuracy: 0.9699 - val_cost: 3.7963\n",
            "Epoch 142/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0687 - auc: 0.9952 - accuracy: 0.9795 - cost: 2.6277 - val_loss: 0.1103 - val_auc: 0.9898 - val_accuracy: 0.9707 - val_cost: 3.6938\n",
            "Epoch 143/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0682 - auc: 0.9952 - accuracy: 0.9799 - cost: 2.5694 - val_loss: 0.1125 - val_auc: 0.9896 - val_accuracy: 0.9701 - val_cost: 3.8360\n",
            "Epoch 144/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0671 - auc: 0.9954 - accuracy: 0.9798 - cost: 2.5799 - val_loss: 0.1116 - val_auc: 0.9897 - val_accuracy: 0.9711 - val_cost: 3.6376\n",
            "Epoch 145/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0678 - auc: 0.9953 - accuracy: 0.9801 - cost: 2.5386 - val_loss: 0.1136 - val_auc: 0.9899 - val_accuracy: 0.9698 - val_cost: 3.7996\n",
            "Epoch 146/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0675 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.5779 - val_loss: 0.1096 - val_auc: 0.9899 - val_accuracy: 0.9699 - val_cost: 3.7434\n",
            "Epoch 147/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0668 - auc: 0.9953 - accuracy: 0.9806 - cost: 2.4907 - val_loss: 0.1119 - val_auc: 0.9898 - val_accuracy: 0.9697 - val_cost: 3.8955\n",
            "Epoch 148/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0674 - auc: 0.9953 - accuracy: 0.9798 - cost: 2.5860 - val_loss: 0.1119 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.7533\n",
            "Epoch 149/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0671 - auc: 0.9954 - accuracy: 0.9804 - cost: 2.5231 - val_loss: 0.1100 - val_auc: 0.9898 - val_accuracy: 0.9703 - val_cost: 3.8095\n",
            "Epoch 150/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0675 - auc: 0.9954 - accuracy: 0.9801 - cost: 2.5413 - val_loss: 0.1118 - val_auc: 0.9899 - val_accuracy: 0.9715 - val_cost: 3.6574\n",
            "Epoch 151/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0670 - auc: 0.9953 - accuracy: 0.9801 - cost: 2.5575 - val_loss: 0.1111 - val_auc: 0.9900 - val_accuracy: 0.9690 - val_cost: 3.7996\n",
            "Epoch 152/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0669 - auc: 0.9954 - accuracy: 0.9800 - cost: 2.5721 - val_loss: 0.1124 - val_auc: 0.9897 - val_accuracy: 0.9703 - val_cost: 3.7235\n",
            "Epoch 153/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0670 - auc: 0.9954 - accuracy: 0.9803 - cost: 2.5170 - val_loss: 0.1115 - val_auc: 0.9898 - val_accuracy: 0.9710 - val_cost: 3.6475\n",
            "Epoch 154/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0669 - auc: 0.9955 - accuracy: 0.9804 - cost: 2.5147 - val_loss: 0.1125 - val_auc: 0.9896 - val_accuracy: 0.9700 - val_cost: 3.8525\n",
            "Epoch 155/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0673 - auc: 0.9955 - accuracy: 0.9799 - cost: 2.5729 - val_loss: 0.1137 - val_auc: 0.9896 - val_accuracy: 0.9701 - val_cost: 3.7368\n",
            "Epoch 156/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0672 - auc: 0.9953 - accuracy: 0.9798 - cost: 2.5930 - val_loss: 0.1134 - val_auc: 0.9897 - val_accuracy: 0.9700 - val_cost: 3.6872\n",
            "Epoch 157/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0667 - auc: 0.9955 - accuracy: 0.9803 - cost: 2.5266 - val_loss: 0.1104 - val_auc: 0.9900 - val_accuracy: 0.9708 - val_cost: 3.7169\n",
            "Epoch 158/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0647 - auc: 0.9956 - accuracy: 0.9814 - cost: 2.3846 - val_loss: 0.1124 - val_auc: 0.9899 - val_accuracy: 0.9700 - val_cost: 3.8095\n",
            "Epoch 159/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0657 - auc: 0.9956 - accuracy: 0.9805 - cost: 2.5085 - val_loss: 0.1123 - val_auc: 0.9897 - val_accuracy: 0.9709 - val_cost: 3.6475\n",
            "Epoch 160/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0652 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4417 - val_loss: 0.1114 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.7731\n",
            "Epoch 161/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0656 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4919 - val_loss: 0.1127 - val_auc: 0.9898 - val_accuracy: 0.9704 - val_cost: 3.6574\n",
            "Epoch 162/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0651 - auc: 0.9955 - accuracy: 0.9808 - cost: 2.4657 - val_loss: 0.1128 - val_auc: 0.9895 - val_accuracy: 0.9702 - val_cost: 3.7467\n",
            "Epoch 163/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0659 - auc: 0.9954 - accuracy: 0.9808 - cost: 2.4545 - val_loss: 0.1117 - val_auc: 0.9898 - val_accuracy: 0.9711 - val_cost: 3.5946\n",
            "Epoch 164/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0652 - auc: 0.9956 - accuracy: 0.9811 - cost: 2.4171 - val_loss: 0.1111 - val_auc: 0.9898 - val_accuracy: 0.9716 - val_cost: 3.5417\n",
            "Epoch 165/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0654 - auc: 0.9956 - accuracy: 0.9808 - cost: 2.4614 - val_loss: 0.1127 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.6508\n",
            "Epoch 166/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0650 - auc: 0.9956 - accuracy: 0.9807 - cost: 2.4738 - val_loss: 0.1115 - val_auc: 0.9899 - val_accuracy: 0.9701 - val_cost: 3.8029\n",
            "Epoch 167/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0650 - auc: 0.9956 - accuracy: 0.9811 - cost: 2.4302 - val_loss: 0.1106 - val_auc: 0.9898 - val_accuracy: 0.9703 - val_cost: 3.7004\n",
            "Epoch 168/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0654 - auc: 0.9956 - accuracy: 0.9806 - cost: 2.4838 - val_loss: 0.1127 - val_auc: 0.9896 - val_accuracy: 0.9706 - val_cost: 3.6938\n",
            "Epoch 169/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0650 - auc: 0.9956 - accuracy: 0.9806 - cost: 2.4792 - val_loss: 0.1140 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.5847\n",
            "Epoch 170/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0655 - auc: 0.9955 - accuracy: 0.9807 - cost: 2.4715 - val_loss: 0.1147 - val_auc: 0.9899 - val_accuracy: 0.9697 - val_cost: 3.6938\n",
            "Epoch 171/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0658 - auc: 0.9956 - accuracy: 0.9803 - cost: 2.5147 - val_loss: 0.1151 - val_auc: 0.9898 - val_accuracy: 0.9692 - val_cost: 3.8327\n",
            "Epoch 172/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0636 - auc: 0.9958 - accuracy: 0.9814 - cost: 2.3812 - val_loss: 0.1140 - val_auc: 0.9896 - val_accuracy: 0.9705 - val_cost: 3.7798\n",
            "Epoch 173/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0645 - auc: 0.9957 - accuracy: 0.9807 - cost: 2.4637 - val_loss: 0.1150 - val_auc: 0.9895 - val_accuracy: 0.9703 - val_cost: 3.8426\n",
            "Epoch 174/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0647 - auc: 0.9957 - accuracy: 0.9810 - cost: 2.4321 - val_loss: 0.1118 - val_auc: 0.9897 - val_accuracy: 0.9712 - val_cost: 3.6541\n",
            "Epoch 175/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0645 - auc: 0.9956 - accuracy: 0.9807 - cost: 2.4826 - val_loss: 0.1142 - val_auc: 0.9898 - val_accuracy: 0.9710 - val_cost: 3.5582\n",
            "Epoch 176/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0636 - auc: 0.9958 - accuracy: 0.9809 - cost: 2.4591 - val_loss: 0.1128 - val_auc: 0.9899 - val_accuracy: 0.9703 - val_cost: 3.7004\n",
            "Epoch 177/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0640 - auc: 0.9956 - accuracy: 0.9811 - cost: 2.4194 - val_loss: 0.1139 - val_auc: 0.9896 - val_accuracy: 0.9699 - val_cost: 3.7368\n",
            "Epoch 178/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0646 - auc: 0.9957 - accuracy: 0.9812 - cost: 2.4074 - val_loss: 0.1125 - val_auc: 0.9897 - val_accuracy: 0.9714 - val_cost: 3.5086\n",
            "Epoch 179/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0640 - auc: 0.9957 - accuracy: 0.9811 - cost: 2.4240 - val_loss: 0.1159 - val_auc: 0.9892 - val_accuracy: 0.9707 - val_cost: 3.6739\n",
            "Epoch 180/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0634 - auc: 0.9959 - accuracy: 0.9811 - cost: 2.4255 - val_loss: 0.1143 - val_auc: 0.9898 - val_accuracy: 0.9699 - val_cost: 3.8558\n",
            "Epoch 181/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0640 - auc: 0.9957 - accuracy: 0.9812 - cost: 2.4147 - val_loss: 0.1139 - val_auc: 0.9895 - val_accuracy: 0.9706 - val_cost: 3.6872\n",
            "Epoch 182/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0640 - auc: 0.9958 - accuracy: 0.9811 - cost: 2.4228 - val_loss: 0.1146 - val_auc: 0.9900 - val_accuracy: 0.9705 - val_cost: 3.6706\n",
            "Epoch 183/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0635 - auc: 0.9958 - accuracy: 0.9812 - cost: 2.4032 - val_loss: 0.1128 - val_auc: 0.9899 - val_accuracy: 0.9713 - val_cost: 3.5979\n",
            "Epoch 184/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0631 - auc: 0.9958 - accuracy: 0.9812 - cost: 2.4035 - val_loss: 0.1128 - val_auc: 0.9898 - val_accuracy: 0.9711 - val_cost: 3.6078\n",
            "Epoch 185/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0636 - auc: 0.9958 - accuracy: 0.9812 - cost: 2.4005 - val_loss: 0.1127 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.6111\n",
            "Epoch 186/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0632 - auc: 0.9959 - accuracy: 0.9811 - cost: 2.4198 - val_loss: 0.1144 - val_auc: 0.9898 - val_accuracy: 0.9715 - val_cost: 3.5880\n",
            "Epoch 187/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0630 - auc: 0.9958 - accuracy: 0.9814 - cost: 2.3866 - val_loss: 0.1140 - val_auc: 0.9897 - val_accuracy: 0.9713 - val_cost: 3.6276\n",
            "Epoch 188/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0637 - auc: 0.9958 - accuracy: 0.9808 - cost: 2.4614 - val_loss: 0.1149 - val_auc: 0.9895 - val_accuracy: 0.9696 - val_cost: 3.8261\n",
            "Epoch 189/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0624 - auc: 0.9959 - accuracy: 0.9816 - cost: 2.3542 - val_loss: 0.1136 - val_auc: 0.9898 - val_accuracy: 0.9702 - val_cost: 3.7070\n",
            "Epoch 190/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0631 - auc: 0.9958 - accuracy: 0.9813 - cost: 2.3889 - val_loss: 0.1149 - val_auc: 0.9896 - val_accuracy: 0.9711 - val_cost: 3.6739\n",
            "Epoch 191/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0638 - auc: 0.9959 - accuracy: 0.9810 - cost: 2.4475 - val_loss: 0.1140 - val_auc: 0.9895 - val_accuracy: 0.9715 - val_cost: 3.5813\n",
            "Epoch 192/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0629 - auc: 0.9958 - accuracy: 0.9816 - cost: 2.3615 - val_loss: 0.1135 - val_auc: 0.9896 - val_accuracy: 0.9703 - val_cost: 3.7831\n",
            "Epoch 193/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0622 - auc: 0.9959 - accuracy: 0.9815 - cost: 2.3762 - val_loss: 0.1128 - val_auc: 0.9900 - val_accuracy: 0.9710 - val_cost: 3.6839\n",
            "Epoch 194/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0627 - auc: 0.9958 - accuracy: 0.9815 - cost: 2.3715 - val_loss: 0.1145 - val_auc: 0.9896 - val_accuracy: 0.9705 - val_cost: 3.6706\n",
            "Epoch 195/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0634 - auc: 0.9957 - accuracy: 0.9812 - cost: 2.4082 - val_loss: 0.1160 - val_auc: 0.9895 - val_accuracy: 0.9706 - val_cost: 3.6706\n",
            "Epoch 196/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0623 - auc: 0.9959 - accuracy: 0.9814 - cost: 2.3808 - val_loss: 0.1148 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.5880\n",
            "Epoch 197/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0630 - auc: 0.9958 - accuracy: 0.9815 - cost: 2.3673 - val_loss: 0.1154 - val_auc: 0.9893 - val_accuracy: 0.9706 - val_cost: 3.7269\n",
            "Epoch 198/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0621 - auc: 0.9960 - accuracy: 0.9816 - cost: 2.3492 - val_loss: 0.1150 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.7037\n",
            "Epoch 199/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0631 - auc: 0.9959 - accuracy: 0.9814 - cost: 2.3754 - val_loss: 0.1134 - val_auc: 0.9898 - val_accuracy: 0.9703 - val_cost: 3.7599\n",
            "Epoch 200/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0623 - auc: 0.9959 - accuracy: 0.9818 - cost: 2.3353 - val_loss: 0.1146 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.7103\n",
            "Epoch 201/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0627 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3333 - val_loss: 0.1135 - val_auc: 0.9896 - val_accuracy: 0.9704 - val_cost: 3.7202\n",
            "Epoch 202/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0625 - auc: 0.9959 - accuracy: 0.9815 - cost: 2.3723 - val_loss: 0.1132 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.5780\n",
            "Epoch 203/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0617 - auc: 0.9959 - accuracy: 0.9818 - cost: 2.3322 - val_loss: 0.1143 - val_auc: 0.9896 - val_accuracy: 0.9713 - val_cost: 3.5284\n",
            "Epoch 204/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0619 - auc: 0.9961 - accuracy: 0.9816 - cost: 2.3692 - val_loss: 0.1130 - val_auc: 0.9898 - val_accuracy: 0.9713 - val_cost: 3.5648\n",
            "Epoch 205/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0621 - auc: 0.9959 - accuracy: 0.9816 - cost: 2.3534 - val_loss: 0.1140 - val_auc: 0.9898 - val_accuracy: 0.9708 - val_cost: 3.6078\n",
            "Epoch 206/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0614 - auc: 0.9960 - accuracy: 0.9820 - cost: 2.3110 - val_loss: 0.1143 - val_auc: 0.9897 - val_accuracy: 0.9694 - val_cost: 3.8790\n",
            "Epoch 207/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0614 - auc: 0.9961 - accuracy: 0.9819 - cost: 2.3299 - val_loss: 0.1136 - val_auc: 0.9899 - val_accuracy: 0.9706 - val_cost: 3.7004\n",
            "Epoch 208/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0608 - auc: 0.9961 - accuracy: 0.9819 - cost: 2.3272 - val_loss: 0.1152 - val_auc: 0.9898 - val_accuracy: 0.9701 - val_cost: 3.7831\n",
            "Epoch 209/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0615 - auc: 0.9958 - accuracy: 0.9819 - cost: 2.3144 - val_loss: 0.1159 - val_auc: 0.9896 - val_accuracy: 0.9706 - val_cost: 3.6012\n",
            "Epoch 210/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0608 - auc: 0.9960 - accuracy: 0.9822 - cost: 2.2878 - val_loss: 0.1153 - val_auc: 0.9898 - val_accuracy: 0.9709 - val_cost: 3.6607\n",
            "Epoch 211/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0605 - auc: 0.9961 - accuracy: 0.9820 - cost: 2.3044 - val_loss: 0.1137 - val_auc: 0.9899 - val_accuracy: 0.9708 - val_cost: 3.6971\n",
            "Epoch 212/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0616 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3233 - val_loss: 0.1148 - val_auc: 0.9897 - val_accuracy: 0.9710 - val_cost: 3.6376\n",
            "Epoch 213/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0613 - auc: 0.9960 - accuracy: 0.9819 - cost: 2.3179 - val_loss: 0.1131 - val_auc: 0.9897 - val_accuracy: 0.9710 - val_cost: 3.7665\n",
            "Epoch 214/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0613 - auc: 0.9960 - accuracy: 0.9821 - cost: 2.2975 - val_loss: 0.1143 - val_auc: 0.9896 - val_accuracy: 0.9702 - val_cost: 3.7169\n",
            "Epoch 215/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0604 - auc: 0.9960 - accuracy: 0.9826 - cost: 2.2288 - val_loss: 0.1155 - val_auc: 0.9897 - val_accuracy: 0.9712 - val_cost: 3.5020\n",
            "Epoch 216/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0616 - auc: 0.9960 - accuracy: 0.9818 - cost: 2.3302 - val_loss: 0.1143 - val_auc: 0.9897 - val_accuracy: 0.9706 - val_cost: 3.7368\n",
            "Epoch 217/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0608 - auc: 0.9960 - accuracy: 0.9822 - cost: 2.2870 - val_loss: 0.1164 - val_auc: 0.9897 - val_accuracy: 0.9706 - val_cost: 3.6905\n",
            "Epoch 218/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0609 - auc: 0.9960 - accuracy: 0.9818 - cost: 2.3387 - val_loss: 0.1162 - val_auc: 0.9895 - val_accuracy: 0.9701 - val_cost: 3.7202\n",
            "Epoch 219/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0616 - auc: 0.9960 - accuracy: 0.9818 - cost: 2.3241 - val_loss: 0.1153 - val_auc: 0.9895 - val_accuracy: 0.9707 - val_cost: 3.6971\n",
            "Epoch 220/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0611 - auc: 0.9959 - accuracy: 0.9822 - cost: 2.2789 - val_loss: 0.1129 - val_auc: 0.9898 - val_accuracy: 0.9715 - val_cost: 3.6508\n",
            "Epoch 221/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0601 - auc: 0.9962 - accuracy: 0.9823 - cost: 2.2693 - val_loss: 0.1143 - val_auc: 0.9899 - val_accuracy: 0.9708 - val_cost: 3.6409\n",
            "Epoch 222/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0606 - auc: 0.9961 - accuracy: 0.9819 - cost: 2.3144 - val_loss: 0.1138 - val_auc: 0.9897 - val_accuracy: 0.9709 - val_cost: 3.6442\n",
            "Epoch 223/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0602 - auc: 0.9962 - accuracy: 0.9820 - cost: 2.3175 - val_loss: 0.1159 - val_auc: 0.9896 - val_accuracy: 0.9702 - val_cost: 3.6971\n",
            "Epoch 224/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0600 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2724 - val_loss: 0.1154 - val_auc: 0.9897 - val_accuracy: 0.9692 - val_cost: 3.8657\n",
            "Epoch 225/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0609 - auc: 0.9961 - accuracy: 0.9821 - cost: 2.2940 - val_loss: 0.1155 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.5152\n",
            "Epoch 226/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0607 - auc: 0.9961 - accuracy: 0.9824 - cost: 2.2589 - val_loss: 0.1144 - val_auc: 0.9897 - val_accuracy: 0.9712 - val_cost: 3.5417\n",
            "Epoch 227/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0607 - auc: 0.9961 - accuracy: 0.9822 - cost: 2.2816 - val_loss: 0.1146 - val_auc: 0.9896 - val_accuracy: 0.9708 - val_cost: 3.6673\n",
            "Epoch 228/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0601 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2805 - val_loss: 0.1137 - val_auc: 0.9899 - val_accuracy: 0.9713 - val_cost: 3.5549\n",
            "Epoch 229/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0603 - auc: 0.9961 - accuracy: 0.9821 - cost: 2.2932 - val_loss: 0.1166 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.5417\n",
            "Epoch 230/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0604 - auc: 0.9962 - accuracy: 0.9821 - cost: 2.2901 - val_loss: 0.1154 - val_auc: 0.9899 - val_accuracy: 0.9708 - val_cost: 3.6541\n",
            "Epoch 231/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0603 - auc: 0.9962 - accuracy: 0.9817 - cost: 2.3511 - val_loss: 0.1160 - val_auc: 0.9896 - val_accuracy: 0.9692 - val_cost: 3.8161\n",
            "Epoch 232/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0606 - auc: 0.9962 - accuracy: 0.9822 - cost: 2.2870 - val_loss: 0.1179 - val_auc: 0.9894 - val_accuracy: 0.9714 - val_cost: 3.6045\n",
            "Epoch 233/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0600 - auc: 0.9962 - accuracy: 0.9822 - cost: 2.2770 - val_loss: 0.1147 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.6343\n",
            "Epoch 234/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0604 - auc: 0.9961 - accuracy: 0.9821 - cost: 2.2882 - val_loss: 0.1154 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.5880\n",
            "Epoch 235/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0593 - auc: 0.9962 - accuracy: 0.9823 - cost: 2.2650 - val_loss: 0.1167 - val_auc: 0.9894 - val_accuracy: 0.9712 - val_cost: 3.6574\n",
            "Epoch 236/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0594 - auc: 0.9962 - accuracy: 0.9824 - cost: 2.2650 - val_loss: 0.1154 - val_auc: 0.9897 - val_accuracy: 0.9715 - val_cost: 3.5913\n",
            "Epoch 237/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0609 - auc: 0.9961 - accuracy: 0.9818 - cost: 2.3395 - val_loss: 0.1159 - val_auc: 0.9894 - val_accuracy: 0.9708 - val_cost: 3.6442\n",
            "Epoch 238/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0602 - auc: 0.9961 - accuracy: 0.9825 - cost: 2.2427 - val_loss: 0.1169 - val_auc: 0.9896 - val_accuracy: 0.9706 - val_cost: 3.6243\n",
            "Epoch 239/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0594 - auc: 0.9962 - accuracy: 0.9824 - cost: 2.2666 - val_loss: 0.1173 - val_auc: 0.9895 - val_accuracy: 0.9711 - val_cost: 3.5549\n",
            "Epoch 240/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0591 - auc: 0.9963 - accuracy: 0.9824 - cost: 2.2677 - val_loss: 0.1160 - val_auc: 0.9895 - val_accuracy: 0.9717 - val_cost: 3.5516\n",
            "Epoch 241/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0599 - auc: 0.9962 - accuracy: 0.9826 - cost: 2.2369 - val_loss: 0.1177 - val_auc: 0.9899 - val_accuracy: 0.9704 - val_cost: 3.5615\n",
            "Epoch 242/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0597 - auc: 0.9962 - accuracy: 0.9822 - cost: 2.2851 - val_loss: 0.1146 - val_auc: 0.9898 - val_accuracy: 0.9705 - val_cost: 3.6971\n",
            "Epoch 243/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0590 - auc: 0.9963 - accuracy: 0.9827 - cost: 2.2296 - val_loss: 0.1172 - val_auc: 0.9899 - val_accuracy: 0.9706 - val_cost: 3.5714\n",
            "Epoch 244/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0596 - auc: 0.9962 - accuracy: 0.9823 - cost: 2.2890 - val_loss: 0.1156 - val_auc: 0.9895 - val_accuracy: 0.9721 - val_cost: 3.4722\n",
            "Epoch 245/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0586 - auc: 0.9963 - accuracy: 0.9826 - cost: 2.2234 - val_loss: 0.1167 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.6243\n",
            "Epoch 246/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0594 - auc: 0.9961 - accuracy: 0.9822 - cost: 2.2809 - val_loss: 0.1176 - val_auc: 0.9896 - val_accuracy: 0.9708 - val_cost: 3.5119\n",
            "Epoch 247/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0590 - auc: 0.9963 - accuracy: 0.9827 - cost: 2.2226 - val_loss: 0.1166 - val_auc: 0.9900 - val_accuracy: 0.9718 - val_cost: 3.4590\n",
            "Epoch 248/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0595 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2396 - val_loss: 0.1156 - val_auc: 0.9895 - val_accuracy: 0.9715 - val_cost: 3.5516\n",
            "Epoch 249/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0590 - auc: 0.9963 - accuracy: 0.9825 - cost: 2.2431 - val_loss: 0.1185 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.5813\n",
            "Epoch 250/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0589 - auc: 0.9964 - accuracy: 0.9826 - cost: 2.2380 - val_loss: 0.1148 - val_auc: 0.9896 - val_accuracy: 0.9716 - val_cost: 3.5417\n",
            "Epoch 251/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0580 - auc: 0.9964 - accuracy: 0.9831 - cost: 2.1659 - val_loss: 0.1162 - val_auc: 0.9894 - val_accuracy: 0.9695 - val_cost: 3.7798\n",
            "Epoch 252/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0592 - auc: 0.9962 - accuracy: 0.9827 - cost: 2.2245 - val_loss: 0.1192 - val_auc: 0.9892 - val_accuracy: 0.9707 - val_cost: 3.6243\n",
            "Epoch 253/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0588 - auc: 0.9963 - accuracy: 0.9828 - cost: 2.2191 - val_loss: 0.1167 - val_auc: 0.9893 - val_accuracy: 0.9710 - val_cost: 3.6045\n",
            "Epoch 254/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0590 - auc: 0.9962 - accuracy: 0.9822 - cost: 2.2870 - val_loss: 0.1181 - val_auc: 0.9892 - val_accuracy: 0.9710 - val_cost: 3.7335\n",
            "Epoch 255/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0589 - auc: 0.9963 - accuracy: 0.9820 - cost: 2.3048 - val_loss: 0.1167 - val_auc: 0.9895 - val_accuracy: 0.9703 - val_cost: 3.7103\n",
            "Epoch 256/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0599 - auc: 0.9963 - accuracy: 0.9823 - cost: 2.2731 - val_loss: 0.1196 - val_auc: 0.9891 - val_accuracy: 0.9704 - val_cost: 3.6905\n",
            "Epoch 257/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0596 - auc: 0.9962 - accuracy: 0.9821 - cost: 2.2971 - val_loss: 0.1163 - val_auc: 0.9893 - val_accuracy: 0.9705 - val_cost: 3.7798\n",
            "Epoch 258/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0586 - auc: 0.9963 - accuracy: 0.9826 - cost: 2.2438 - val_loss: 0.1195 - val_auc: 0.9892 - val_accuracy: 0.9708 - val_cost: 3.5185\n",
            "Epoch 259/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0581 - auc: 0.9964 - accuracy: 0.9829 - cost: 2.1867 - val_loss: 0.1141 - val_auc: 0.9897 - val_accuracy: 0.9712 - val_cost: 3.5582\n",
            "Epoch 260/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0588 - auc: 0.9963 - accuracy: 0.9826 - cost: 2.2427 - val_loss: 0.1171 - val_auc: 0.9896 - val_accuracy: 0.9715 - val_cost: 3.5747\n",
            "Epoch 261/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0584 - auc: 0.9964 - accuracy: 0.9824 - cost: 2.2577 - val_loss: 0.1174 - val_auc: 0.9893 - val_accuracy: 0.9712 - val_cost: 3.6839\n",
            "Epoch 262/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0586 - auc: 0.9963 - accuracy: 0.9826 - cost: 2.2253 - val_loss: 0.1167 - val_auc: 0.9895 - val_accuracy: 0.9705 - val_cost: 3.7368\n",
            "Epoch 263/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0582 - auc: 0.9963 - accuracy: 0.9827 - cost: 2.2319 - val_loss: 0.1187 - val_auc: 0.9893 - val_accuracy: 0.9701 - val_cost: 3.6210\n",
            "Epoch 264/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0588 - auc: 0.9963 - accuracy: 0.9825 - cost: 2.2404 - val_loss: 0.1163 - val_auc: 0.9894 - val_accuracy: 0.9717 - val_cost: 3.5284\n",
            "Epoch 265/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0580 - auc: 0.9963 - accuracy: 0.9829 - cost: 2.2002 - val_loss: 0.1159 - val_auc: 0.9896 - val_accuracy: 0.9712 - val_cost: 3.6376\n",
            "Epoch 266/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0587 - auc: 0.9964 - accuracy: 0.9823 - cost: 2.2631 - val_loss: 0.1166 - val_auc: 0.9894 - val_accuracy: 0.9718 - val_cost: 3.5086\n",
            "Epoch 267/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0584 - auc: 0.9963 - accuracy: 0.9831 - cost: 2.1744 - val_loss: 0.1176 - val_auc: 0.9894 - val_accuracy: 0.9709 - val_cost: 3.6343\n",
            "Epoch 268/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0587 - auc: 0.9962 - accuracy: 0.9826 - cost: 2.2272 - val_loss: 0.1169 - val_auc: 0.9893 - val_accuracy: 0.9714 - val_cost: 3.6045\n",
            "Epoch 269/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0587 - auc: 0.9963 - accuracy: 0.9826 - cost: 2.2303 - val_loss: 0.1178 - val_auc: 0.9893 - val_accuracy: 0.9707 - val_cost: 3.6872\n",
            "Epoch 270/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0574 - auc: 0.9964 - accuracy: 0.9830 - cost: 2.1856 - val_loss: 0.1145 - val_auc: 0.9896 - val_accuracy: 0.9720 - val_cost: 3.5681\n",
            "Epoch 271/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0572 - auc: 0.9965 - accuracy: 0.9828 - cost: 2.2099 - val_loss: 0.1165 - val_auc: 0.9897 - val_accuracy: 0.9710 - val_cost: 3.6739\n",
            "Epoch 272/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0586 - auc: 0.9964 - accuracy: 0.9822 - cost: 2.2785 - val_loss: 0.1171 - val_auc: 0.9892 - val_accuracy: 0.9706 - val_cost: 3.7202\n",
            "Epoch 273/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0582 - auc: 0.9963 - accuracy: 0.9828 - cost: 2.2072 - val_loss: 0.1179 - val_auc: 0.9891 - val_accuracy: 0.9707 - val_cost: 3.6872\n",
            "Epoch 274/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0583 - auc: 0.9963 - accuracy: 0.9829 - cost: 2.1991 - val_loss: 0.1162 - val_auc: 0.9897 - val_accuracy: 0.9703 - val_cost: 3.6475\n",
            "Epoch 275/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0577 - auc: 0.9965 - accuracy: 0.9832 - cost: 2.1566 - val_loss: 0.1170 - val_auc: 0.9896 - val_accuracy: 0.9697 - val_cost: 3.7798\n",
            "Epoch 276/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0579 - auc: 0.9964 - accuracy: 0.9828 - cost: 2.2079 - val_loss: 0.1193 - val_auc: 0.9894 - val_accuracy: 0.9700 - val_cost: 3.7401\n",
            "Epoch 277/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0573 - auc: 0.9966 - accuracy: 0.9827 - cost: 2.2157 - val_loss: 0.1197 - val_auc: 0.9894 - val_accuracy: 0.9700 - val_cost: 3.7037\n",
            "Epoch 278/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0581 - auc: 0.9964 - accuracy: 0.9829 - cost: 2.1941 - val_loss: 0.1202 - val_auc: 0.9893 - val_accuracy: 0.9713 - val_cost: 3.6045\n",
            "Epoch 279/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0575 - auc: 0.9964 - accuracy: 0.9827 - cost: 2.2184 - val_loss: 0.1179 - val_auc: 0.9893 - val_accuracy: 0.9706 - val_cost: 3.6475\n",
            "Epoch 280/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0581 - auc: 0.9963 - accuracy: 0.9826 - cost: 2.2388 - val_loss: 0.1157 - val_auc: 0.9893 - val_accuracy: 0.9705 - val_cost: 3.7533\n",
            "Epoch 281/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0574 - auc: 0.9965 - accuracy: 0.9831 - cost: 2.1752 - val_loss: 0.1172 - val_auc: 0.9895 - val_accuracy: 0.9703 - val_cost: 3.6243\n",
            "Epoch 282/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0578 - auc: 0.9965 - accuracy: 0.9824 - cost: 2.2639 - val_loss: 0.1171 - val_auc: 0.9893 - val_accuracy: 0.9715 - val_cost: 3.5615\n",
            "Epoch 283/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0579 - auc: 0.9963 - accuracy: 0.9829 - cost: 2.1925 - val_loss: 0.1176 - val_auc: 0.9895 - val_accuracy: 0.9712 - val_cost: 3.5384\n",
            "Epoch 284/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0581 - auc: 0.9964 - accuracy: 0.9826 - cost: 2.2238 - val_loss: 0.1178 - val_auc: 0.9894 - val_accuracy: 0.9712 - val_cost: 3.5813\n",
            "Epoch 285/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0578 - auc: 0.9964 - accuracy: 0.9828 - cost: 2.2149 - val_loss: 0.1183 - val_auc: 0.9895 - val_accuracy: 0.9712 - val_cost: 3.5847\n",
            "Epoch 286/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0572 - auc: 0.9964 - accuracy: 0.9830 - cost: 2.1763 - val_loss: 0.1190 - val_auc: 0.9893 - val_accuracy: 0.9703 - val_cost: 3.7500\n",
            "Epoch 287/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0575 - auc: 0.9965 - accuracy: 0.9830 - cost: 2.1925 - val_loss: 0.1198 - val_auc: 0.9890 - val_accuracy: 0.9705 - val_cost: 3.7434\n",
            "Epoch 288/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0579 - auc: 0.9964 - accuracy: 0.9829 - cost: 2.2072 - val_loss: 0.1197 - val_auc: 0.9894 - val_accuracy: 0.9694 - val_cost: 3.7765\n",
            "Epoch 289/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0579 - auc: 0.9965 - accuracy: 0.9826 - cost: 2.2226 - val_loss: 0.1190 - val_auc: 0.9892 - val_accuracy: 0.9703 - val_cost: 3.7037\n",
            "Epoch 290/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0566 - auc: 0.9966 - accuracy: 0.9830 - cost: 2.1875 - val_loss: 0.1187 - val_auc: 0.9894 - val_accuracy: 0.9706 - val_cost: 3.6276\n",
            "Epoch 291/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0576 - auc: 0.9965 - accuracy: 0.9826 - cost: 2.2299 - val_loss: 0.1204 - val_auc: 0.9895 - val_accuracy: 0.9707 - val_cost: 3.5747\n",
            "Epoch 292/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0575 - auc: 0.9965 - accuracy: 0.9827 - cost: 2.2130 - val_loss: 0.1180 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.7169\n",
            "Epoch 293/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0569 - auc: 0.9967 - accuracy: 0.9826 - cost: 2.2284 - val_loss: 0.1184 - val_auc: 0.9892 - val_accuracy: 0.9714 - val_cost: 3.4987\n",
            "Epoch 294/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0572 - auc: 0.9965 - accuracy: 0.9832 - cost: 2.1690 - val_loss: 0.1187 - val_auc: 0.9893 - val_accuracy: 0.9714 - val_cost: 3.5946\n",
            "Epoch 295/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0567 - auc: 0.9965 - accuracy: 0.9832 - cost: 2.1516 - val_loss: 0.1165 - val_auc: 0.9896 - val_accuracy: 0.9712 - val_cost: 3.6276\n",
            "Epoch 296/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0568 - auc: 0.9966 - accuracy: 0.9829 - cost: 2.1948 - val_loss: 0.1203 - val_auc: 0.9897 - val_accuracy: 0.9710 - val_cost: 3.5780\n",
            "Epoch 297/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0577 - auc: 0.9965 - accuracy: 0.9825 - cost: 2.2415 - val_loss: 0.1181 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.6376\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.1096 - auc: 0.9906 - accuracy: 0.9720 - cost: 3.4688\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:02:22.337524\n",
            "fold accuracy: 0.972000002861023 - fold cost: 3.46875\n",
            "x_train shape: (144000, 67)\n",
            "Epoch 1/1000\n",
            "120/120 [==============================] - 2s 6ms/step - loss: 0.5302 - auc: 0.7974 - accuracy: 0.7280 - cost: 36.2701 - val_loss: 0.4010 - val_auc: 0.8972 - val_accuracy: 0.8259 - val_cost: 22.2156\n",
            "Epoch 2/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.3521 - auc: 0.9212 - accuracy: 0.8483 - cost: 19.3113 - val_loss: 0.3218 - val_auc: 0.9342 - val_accuracy: 0.8630 - val_cost: 16.9940\n",
            "Epoch 3/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.3027 - auc: 0.9419 - accuracy: 0.8752 - cost: 15.7971 - val_loss: 0.2904 - val_auc: 0.9467 - val_accuracy: 0.8799 - val_cost: 15.1554\n",
            "Epoch 4/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2740 - auc: 0.9526 - accuracy: 0.8879 - cost: 14.1740 - val_loss: 0.2655 - val_auc: 0.9554 - val_accuracy: 0.8921 - val_cost: 13.4954\n",
            "Epoch 5/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2500 - auc: 0.9605 - accuracy: 0.8996 - cost: 12.6975 - val_loss: 0.2448 - val_auc: 0.9621 - val_accuracy: 0.9038 - val_cost: 12.0106\n",
            "Epoch 6/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.2309 - auc: 0.9664 - accuracy: 0.9096 - cost: 11.4298 - val_loss: 0.2275 - val_auc: 0.9675 - val_accuracy: 0.9128 - val_cost: 10.8896\n",
            "Epoch 7/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2151 - auc: 0.9707 - accuracy: 0.9166 - cost: 10.5475 - val_loss: 0.2144 - val_auc: 0.9709 - val_accuracy: 0.9194 - val_cost: 9.9967\n",
            "Epoch 8/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.2006 - auc: 0.9745 - accuracy: 0.9235 - cost: 9.6640 - val_loss: 0.2018 - val_auc: 0.9741 - val_accuracy: 0.9253 - val_cost: 9.3287\n",
            "Epoch 9/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1900 - auc: 0.9769 - accuracy: 0.9280 - cost: 9.0833 - val_loss: 0.1925 - val_auc: 0.9765 - val_accuracy: 0.9308 - val_cost: 8.4557\n",
            "Epoch 10/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1811 - auc: 0.9788 - accuracy: 0.9325 - cost: 8.5324 - val_loss: 0.1830 - val_auc: 0.9782 - val_accuracy: 0.9347 - val_cost: 8.2507\n",
            "Epoch 11/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1741 - auc: 0.9804 - accuracy: 0.9359 - cost: 8.0903 - val_loss: 0.1762 - val_auc: 0.9797 - val_accuracy: 0.9369 - val_cost: 7.8175\n",
            "Epoch 12/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1675 - auc: 0.9818 - accuracy: 0.9388 - cost: 7.7431 - val_loss: 0.1712 - val_auc: 0.9810 - val_accuracy: 0.9390 - val_cost: 7.5231\n",
            "Epoch 13/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1611 - auc: 0.9829 - accuracy: 0.9418 - cost: 7.3646 - val_loss: 0.1650 - val_auc: 0.9820 - val_accuracy: 0.9413 - val_cost: 7.4272\n",
            "Epoch 14/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1555 - auc: 0.9840 - accuracy: 0.9452 - cost: 6.9441 - val_loss: 0.1616 - val_auc: 0.9826 - val_accuracy: 0.9422 - val_cost: 7.2090\n",
            "Epoch 15/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1517 - auc: 0.9846 - accuracy: 0.9463 - cost: 6.7836 - val_loss: 0.1577 - val_auc: 0.9833 - val_accuracy: 0.9438 - val_cost: 7.0536\n",
            "Epoch 16/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1474 - auc: 0.9854 - accuracy: 0.9477 - cost: 6.6265 - val_loss: 0.1545 - val_auc: 0.9840 - val_accuracy: 0.9464 - val_cost: 6.7956\n",
            "Epoch 17/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1438 - auc: 0.9859 - accuracy: 0.9494 - cost: 6.4167 - val_loss: 0.1517 - val_auc: 0.9845 - val_accuracy: 0.9460 - val_cost: 6.7229\n",
            "Epoch 18/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1410 - auc: 0.9865 - accuracy: 0.9503 - cost: 6.2901 - val_loss: 0.1488 - val_auc: 0.9850 - val_accuracy: 0.9495 - val_cost: 6.4484\n",
            "Epoch 19/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1380 - auc: 0.9869 - accuracy: 0.9520 - cost: 6.0795 - val_loss: 0.1465 - val_auc: 0.9851 - val_accuracy: 0.9491 - val_cost: 6.4782\n",
            "Epoch 20/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1352 - auc: 0.9875 - accuracy: 0.9532 - cost: 5.9336 - val_loss: 0.1470 - val_auc: 0.9853 - val_accuracy: 0.9504 - val_cost: 6.1012\n",
            "Epoch 21/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1331 - auc: 0.9877 - accuracy: 0.9541 - cost: 5.8052 - val_loss: 0.1427 - val_auc: 0.9858 - val_accuracy: 0.9531 - val_cost: 5.9590\n",
            "Epoch 22/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1306 - auc: 0.9881 - accuracy: 0.9558 - cost: 5.6092 - val_loss: 0.1430 - val_auc: 0.9858 - val_accuracy: 0.9512 - val_cost: 6.2599\n",
            "Epoch 23/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1283 - auc: 0.9884 - accuracy: 0.9563 - cost: 5.5312 - val_loss: 0.1395 - val_auc: 0.9862 - val_accuracy: 0.9534 - val_cost: 5.8862\n",
            "Epoch 24/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1269 - auc: 0.9886 - accuracy: 0.9567 - cost: 5.4799 - val_loss: 0.1391 - val_auc: 0.9862 - val_accuracy: 0.9547 - val_cost: 5.6647\n",
            "Epoch 25/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1241 - auc: 0.9891 - accuracy: 0.9578 - cost: 5.3422 - val_loss: 0.1374 - val_auc: 0.9867 - val_accuracy: 0.9551 - val_cost: 5.5258\n",
            "Epoch 26/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1224 - auc: 0.9892 - accuracy: 0.9586 - cost: 5.2361 - val_loss: 0.1352 - val_auc: 0.9869 - val_accuracy: 0.9556 - val_cost: 5.6316\n",
            "Epoch 27/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1208 - auc: 0.9895 - accuracy: 0.9595 - cost: 5.1331 - val_loss: 0.1350 - val_auc: 0.9871 - val_accuracy: 0.9557 - val_cost: 5.4563\n",
            "Epoch 28/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1200 - auc: 0.9895 - accuracy: 0.9602 - cost: 5.0305 - val_loss: 0.1338 - val_auc: 0.9869 - val_accuracy: 0.9567 - val_cost: 5.5126\n",
            "Epoch 29/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1177 - auc: 0.9899 - accuracy: 0.9607 - cost: 4.9853 - val_loss: 0.1331 - val_auc: 0.9871 - val_accuracy: 0.9569 - val_cost: 5.4663\n",
            "Epoch 30/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1158 - auc: 0.9902 - accuracy: 0.9613 - cost: 4.9128 - val_loss: 0.1331 - val_auc: 0.9871 - val_accuracy: 0.9558 - val_cost: 5.5985\n",
            "Epoch 31/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1146 - auc: 0.9903 - accuracy: 0.9619 - cost: 4.8029 - val_loss: 0.1302 - val_auc: 0.9874 - val_accuracy: 0.9583 - val_cost: 5.1918\n",
            "Epoch 32/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1139 - auc: 0.9904 - accuracy: 0.9624 - cost: 4.7620 - val_loss: 0.1305 - val_auc: 0.9875 - val_accuracy: 0.9572 - val_cost: 5.2811\n",
            "Epoch 33/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1125 - auc: 0.9905 - accuracy: 0.9630 - cost: 4.6740 - val_loss: 0.1280 - val_auc: 0.9875 - val_accuracy: 0.9592 - val_cost: 5.1323\n",
            "Epoch 34/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1104 - auc: 0.9908 - accuracy: 0.9637 - cost: 4.6111 - val_loss: 0.1270 - val_auc: 0.9878 - val_accuracy: 0.9595 - val_cost: 5.1720\n",
            "Epoch 35/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1101 - auc: 0.9908 - accuracy: 0.9639 - cost: 4.5937 - val_loss: 0.1261 - val_auc: 0.9879 - val_accuracy: 0.9589 - val_cost: 5.1885\n",
            "Epoch 36/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1079 - auc: 0.9909 - accuracy: 0.9651 - cost: 4.4209 - val_loss: 0.1259 - val_auc: 0.9880 - val_accuracy: 0.9603 - val_cost: 4.8644\n",
            "Epoch 37/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1070 - auc: 0.9912 - accuracy: 0.9651 - cost: 4.4275 - val_loss: 0.1250 - val_auc: 0.9881 - val_accuracy: 0.9603 - val_cost: 4.8975\n",
            "Epoch 38/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1057 - auc: 0.9913 - accuracy: 0.9660 - cost: 4.3125 - val_loss: 0.1238 - val_auc: 0.9883 - val_accuracy: 0.9606 - val_cost: 4.9603\n",
            "Epoch 39/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1043 - auc: 0.9915 - accuracy: 0.9661 - cost: 4.2951 - val_loss: 0.1226 - val_auc: 0.9884 - val_accuracy: 0.9618 - val_cost: 4.8016\n",
            "Epoch 40/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1036 - auc: 0.9915 - accuracy: 0.9666 - cost: 4.2315 - val_loss: 0.1229 - val_auc: 0.9883 - val_accuracy: 0.9614 - val_cost: 4.9636\n",
            "Epoch 41/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1027 - auc: 0.9916 - accuracy: 0.9670 - cost: 4.1902 - val_loss: 0.1211 - val_auc: 0.9884 - val_accuracy: 0.9624 - val_cost: 4.7817\n",
            "Epoch 42/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1016 - auc: 0.9917 - accuracy: 0.9674 - cost: 4.1350 - val_loss: 0.1201 - val_auc: 0.9887 - val_accuracy: 0.9625 - val_cost: 4.7057\n",
            "Epoch 43/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1006 - auc: 0.9919 - accuracy: 0.9677 - cost: 4.1011 - val_loss: 0.1203 - val_auc: 0.9887 - val_accuracy: 0.9621 - val_cost: 4.7851\n",
            "Epoch 44/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0982 - auc: 0.9921 - accuracy: 0.9692 - cost: 3.9001 - val_loss: 0.1177 - val_auc: 0.9891 - val_accuracy: 0.9638 - val_cost: 4.5635\n",
            "Epoch 45/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0983 - auc: 0.9921 - accuracy: 0.9687 - cost: 3.9780 - val_loss: 0.1183 - val_auc: 0.9889 - val_accuracy: 0.9640 - val_cost: 4.5370\n",
            "Epoch 46/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0965 - auc: 0.9924 - accuracy: 0.9696 - cost: 3.8553 - val_loss: 0.1179 - val_auc: 0.9891 - val_accuracy: 0.9647 - val_cost: 4.4345\n",
            "Epoch 47/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0965 - auc: 0.9924 - accuracy: 0.9692 - cost: 3.9159 - val_loss: 0.1179 - val_auc: 0.9890 - val_accuracy: 0.9641 - val_cost: 4.4114\n",
            "Epoch 48/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0959 - auc: 0.9924 - accuracy: 0.9699 - cost: 3.8225 - val_loss: 0.1163 - val_auc: 0.9891 - val_accuracy: 0.9652 - val_cost: 4.4048\n",
            "Epoch 49/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0943 - auc: 0.9926 - accuracy: 0.9707 - cost: 3.7168 - val_loss: 0.1156 - val_auc: 0.9892 - val_accuracy: 0.9650 - val_cost: 4.4874\n",
            "Epoch 50/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0938 - auc: 0.9926 - accuracy: 0.9705 - cost: 3.7512 - val_loss: 0.1150 - val_auc: 0.9891 - val_accuracy: 0.9656 - val_cost: 4.3915\n",
            "Epoch 51/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0938 - auc: 0.9927 - accuracy: 0.9704 - cost: 3.7581 - val_loss: 0.1147 - val_auc: 0.9894 - val_accuracy: 0.9663 - val_cost: 4.1832\n",
            "Epoch 52/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0924 - auc: 0.9927 - accuracy: 0.9717 - cost: 3.5965 - val_loss: 0.1131 - val_auc: 0.9895 - val_accuracy: 0.9663 - val_cost: 4.2725\n",
            "Epoch 53/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0916 - auc: 0.9928 - accuracy: 0.9716 - cost: 3.6127 - val_loss: 0.1133 - val_auc: 0.9894 - val_accuracy: 0.9684 - val_cost: 3.9616\n",
            "Epoch 54/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0916 - auc: 0.9929 - accuracy: 0.9713 - cost: 3.6559 - val_loss: 0.1134 - val_auc: 0.9894 - val_accuracy: 0.9667 - val_cost: 4.1402\n",
            "Epoch 55/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0896 - auc: 0.9931 - accuracy: 0.9723 - cost: 3.5340 - val_loss: 0.1129 - val_auc: 0.9894 - val_accuracy: 0.9653 - val_cost: 4.3816\n",
            "Epoch 56/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0902 - auc: 0.9930 - accuracy: 0.9724 - cost: 3.5231 - val_loss: 0.1111 - val_auc: 0.9897 - val_accuracy: 0.9683 - val_cost: 3.9484\n",
            "Epoch 57/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0898 - auc: 0.9930 - accuracy: 0.9723 - cost: 3.5231 - val_loss: 0.1103 - val_auc: 0.9898 - val_accuracy: 0.9680 - val_cost: 3.9385\n",
            "Epoch 58/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0881 - auc: 0.9932 - accuracy: 0.9731 - cost: 3.4228 - val_loss: 0.1106 - val_auc: 0.9895 - val_accuracy: 0.9684 - val_cost: 4.0311\n",
            "Epoch 59/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0877 - auc: 0.9932 - accuracy: 0.9729 - cost: 3.4456 - val_loss: 0.1102 - val_auc: 0.9898 - val_accuracy: 0.9685 - val_cost: 3.9153\n",
            "Epoch 60/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0883 - auc: 0.9931 - accuracy: 0.9730 - cost: 3.4410 - val_loss: 0.1107 - val_auc: 0.9896 - val_accuracy: 0.9681 - val_cost: 4.0708\n",
            "Epoch 61/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0862 - auc: 0.9935 - accuracy: 0.9740 - cost: 3.3175 - val_loss: 0.1098 - val_auc: 0.9897 - val_accuracy: 0.9686 - val_cost: 3.9220\n",
            "Epoch 62/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0868 - auc: 0.9934 - accuracy: 0.9732 - cost: 3.4217 - val_loss: 0.1094 - val_auc: 0.9899 - val_accuracy: 0.9685 - val_cost: 3.9749\n",
            "Epoch 63/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0861 - auc: 0.9934 - accuracy: 0.9739 - cost: 3.3329 - val_loss: 0.1106 - val_auc: 0.9901 - val_accuracy: 0.9685 - val_cost: 3.9153\n",
            "Epoch 64/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0852 - auc: 0.9935 - accuracy: 0.9736 - cost: 3.3573 - val_loss: 0.1077 - val_auc: 0.9899 - val_accuracy: 0.9684 - val_cost: 4.0079\n",
            "Epoch 65/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0845 - auc: 0.9936 - accuracy: 0.9740 - cost: 3.3144 - val_loss: 0.1100 - val_auc: 0.9898 - val_accuracy: 0.9685 - val_cost: 3.9286\n",
            "Epoch 66/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0847 - auc: 0.9936 - accuracy: 0.9741 - cost: 3.2940 - val_loss: 0.1090 - val_auc: 0.9901 - val_accuracy: 0.9681 - val_cost: 4.0146\n",
            "Epoch 67/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0843 - auc: 0.9936 - accuracy: 0.9741 - cost: 3.3063 - val_loss: 0.1073 - val_auc: 0.9901 - val_accuracy: 0.9694 - val_cost: 3.9385\n",
            "Epoch 68/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0832 - auc: 0.9938 - accuracy: 0.9746 - cost: 3.2365 - val_loss: 0.1068 - val_auc: 0.9901 - val_accuracy: 0.9704 - val_cost: 3.6905\n",
            "Epoch 69/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0827 - auc: 0.9938 - accuracy: 0.9748 - cost: 3.1917 - val_loss: 0.1077 - val_auc: 0.9899 - val_accuracy: 0.9690 - val_cost: 3.8922\n",
            "Epoch 70/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0830 - auc: 0.9937 - accuracy: 0.9747 - cost: 3.2130 - val_loss: 0.1072 - val_auc: 0.9900 - val_accuracy: 0.9690 - val_cost: 3.8790\n",
            "Epoch 71/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0824 - auc: 0.9938 - accuracy: 0.9755 - cost: 3.1250 - val_loss: 0.1068 - val_auc: 0.9902 - val_accuracy: 0.9692 - val_cost: 3.8690\n",
            "Epoch 72/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0808 - auc: 0.9940 - accuracy: 0.9751 - cost: 3.1721 - val_loss: 0.1078 - val_auc: 0.9902 - val_accuracy: 0.9685 - val_cost: 4.0708\n",
            "Epoch 73/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0811 - auc: 0.9940 - accuracy: 0.9752 - cost: 3.1551 - val_loss: 0.1068 - val_auc: 0.9900 - val_accuracy: 0.9692 - val_cost: 3.9517\n",
            "Epoch 74/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0805 - auc: 0.9941 - accuracy: 0.9756 - cost: 3.1215 - val_loss: 0.1076 - val_auc: 0.9902 - val_accuracy: 0.9689 - val_cost: 3.8757\n",
            "Epoch 75/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0808 - auc: 0.9939 - accuracy: 0.9761 - cost: 3.0482 - val_loss: 0.1073 - val_auc: 0.9899 - val_accuracy: 0.9697 - val_cost: 3.9716\n",
            "Epoch 76/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0802 - auc: 0.9940 - accuracy: 0.9759 - cost: 3.0729 - val_loss: 0.1062 - val_auc: 0.9902 - val_accuracy: 0.9698 - val_cost: 3.8459\n",
            "Epoch 77/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0803 - auc: 0.9940 - accuracy: 0.9756 - cost: 3.1119 - val_loss: 0.1076 - val_auc: 0.9902 - val_accuracy: 0.9678 - val_cost: 4.0344\n",
            "Epoch 78/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0792 - auc: 0.9941 - accuracy: 0.9765 - cost: 2.9988 - val_loss: 0.1065 - val_auc: 0.9902 - val_accuracy: 0.9688 - val_cost: 3.9517\n",
            "Epoch 79/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0791 - auc: 0.9941 - accuracy: 0.9765 - cost: 2.9965 - val_loss: 0.1060 - val_auc: 0.9902 - val_accuracy: 0.9699 - val_cost: 3.7434\n",
            "Epoch 80/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0789 - auc: 0.9942 - accuracy: 0.9756 - cost: 3.1165 - val_loss: 0.1056 - val_auc: 0.9904 - val_accuracy: 0.9697 - val_cost: 3.8029\n",
            "Epoch 81/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0784 - auc: 0.9942 - accuracy: 0.9762 - cost: 3.0243 - val_loss: 0.1067 - val_auc: 0.9901 - val_accuracy: 0.9703 - val_cost: 3.7335\n",
            "Epoch 82/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0782 - auc: 0.9943 - accuracy: 0.9767 - cost: 2.9718 - val_loss: 0.1054 - val_auc: 0.9903 - val_accuracy: 0.9697 - val_cost: 3.8459\n",
            "Epoch 83/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0778 - auc: 0.9942 - accuracy: 0.9765 - cost: 2.9850 - val_loss: 0.1082 - val_auc: 0.9900 - val_accuracy: 0.9688 - val_cost: 3.8525\n",
            "Epoch 84/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0768 - auc: 0.9943 - accuracy: 0.9773 - cost: 2.8943 - val_loss: 0.1051 - val_auc: 0.9904 - val_accuracy: 0.9695 - val_cost: 3.7169\n",
            "Epoch 85/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0771 - auc: 0.9944 - accuracy: 0.9770 - cost: 2.9309 - val_loss: 0.1064 - val_auc: 0.9902 - val_accuracy: 0.9688 - val_cost: 4.0509\n",
            "Epoch 86/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0775 - auc: 0.9943 - accuracy: 0.9767 - cost: 2.9726 - val_loss: 0.1062 - val_auc: 0.9902 - val_accuracy: 0.9692 - val_cost: 3.8988\n",
            "Epoch 87/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0768 - auc: 0.9945 - accuracy: 0.9769 - cost: 2.9560 - val_loss: 0.1068 - val_auc: 0.9903 - val_accuracy: 0.9692 - val_cost: 3.9021\n",
            "Epoch 88/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0762 - auc: 0.9945 - accuracy: 0.9768 - cost: 2.9622 - val_loss: 0.1067 - val_auc: 0.9902 - val_accuracy: 0.9685 - val_cost: 3.9153\n",
            "Epoch 89/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0764 - auc: 0.9944 - accuracy: 0.9771 - cost: 2.9174 - val_loss: 0.1056 - val_auc: 0.9904 - val_accuracy: 0.9694 - val_cost: 3.8922\n",
            "Epoch 90/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0761 - auc: 0.9944 - accuracy: 0.9774 - cost: 2.8762 - val_loss: 0.1067 - val_auc: 0.9904 - val_accuracy: 0.9683 - val_cost: 4.0179\n",
            "Epoch 91/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0750 - auc: 0.9946 - accuracy: 0.9780 - cost: 2.8017 - val_loss: 0.1058 - val_auc: 0.9902 - val_accuracy: 0.9694 - val_cost: 3.8393\n",
            "Epoch 92/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0757 - auc: 0.9944 - accuracy: 0.9775 - cost: 2.8692 - val_loss: 0.1043 - val_auc: 0.9907 - val_accuracy: 0.9694 - val_cost: 3.9087\n",
            "Epoch 93/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0756 - auc: 0.9945 - accuracy: 0.9776 - cost: 2.8654 - val_loss: 0.1046 - val_auc: 0.9906 - val_accuracy: 0.9690 - val_cost: 3.9716\n",
            "Epoch 94/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0752 - auc: 0.9945 - accuracy: 0.9776 - cost: 2.8704 - val_loss: 0.1042 - val_auc: 0.9903 - val_accuracy: 0.9697 - val_cost: 3.8062\n",
            "Epoch 95/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0747 - auc: 0.9945 - accuracy: 0.9775 - cost: 2.8603 - val_loss: 0.1065 - val_auc: 0.9903 - val_accuracy: 0.9688 - val_cost: 3.9253\n",
            "Epoch 96/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9946 - accuracy: 0.9780 - cost: 2.8098 - val_loss: 0.1057 - val_auc: 0.9903 - val_accuracy: 0.9685 - val_cost: 4.0112\n",
            "Epoch 97/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0740 - auc: 0.9946 - accuracy: 0.9779 - cost: 2.8106 - val_loss: 0.1062 - val_auc: 0.9903 - val_accuracy: 0.9688 - val_cost: 4.0509\n",
            "Epoch 98/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9947 - accuracy: 0.9778 - cost: 2.8268 - val_loss: 0.1048 - val_auc: 0.9904 - val_accuracy: 0.9694 - val_cost: 3.9616\n",
            "Epoch 99/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9947 - accuracy: 0.9782 - cost: 2.7751 - val_loss: 0.1065 - val_auc: 0.9902 - val_accuracy: 0.9691 - val_cost: 4.0146\n",
            "Epoch 100/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0734 - auc: 0.9948 - accuracy: 0.9783 - cost: 2.7712 - val_loss: 0.1060 - val_auc: 0.9903 - val_accuracy: 0.9703 - val_cost: 3.7500\n",
            "Epoch 101/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0734 - auc: 0.9948 - accuracy: 0.9783 - cost: 2.7758 - val_loss: 0.1062 - val_auc: 0.9906 - val_accuracy: 0.9697 - val_cost: 3.7632\n",
            "Epoch 102/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0732 - auc: 0.9947 - accuracy: 0.9784 - cost: 2.7650 - val_loss: 0.1084 - val_auc: 0.9902 - val_accuracy: 0.9695 - val_cost: 3.7368\n",
            "Epoch 103/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0736 - auc: 0.9947 - accuracy: 0.9782 - cost: 2.7724 - val_loss: 0.1072 - val_auc: 0.9903 - val_accuracy: 0.9688 - val_cost: 3.9749\n",
            "Epoch 104/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0735 - auc: 0.9947 - accuracy: 0.9782 - cost: 2.7863 - val_loss: 0.1063 - val_auc: 0.9905 - val_accuracy: 0.9699 - val_cost: 3.7930\n",
            "Epoch 105/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0719 - auc: 0.9948 - accuracy: 0.9787 - cost: 2.7068 - val_loss: 0.1056 - val_auc: 0.9905 - val_accuracy: 0.9700 - val_cost: 3.7599\n",
            "Epoch 106/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0729 - auc: 0.9947 - accuracy: 0.9789 - cost: 2.6914 - val_loss: 0.1060 - val_auc: 0.9904 - val_accuracy: 0.9698 - val_cost: 3.7831\n",
            "Epoch 107/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0724 - auc: 0.9949 - accuracy: 0.9788 - cost: 2.7141 - val_loss: 0.1059 - val_auc: 0.9906 - val_accuracy: 0.9692 - val_cost: 3.8922\n",
            "Epoch 108/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0727 - auc: 0.9948 - accuracy: 0.9786 - cost: 2.7245 - val_loss: 0.1049 - val_auc: 0.9907 - val_accuracy: 0.9703 - val_cost: 3.7202\n",
            "Epoch 109/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0722 - auc: 0.9949 - accuracy: 0.9787 - cost: 2.7172 - val_loss: 0.1074 - val_auc: 0.9903 - val_accuracy: 0.9694 - val_cost: 3.8029\n",
            "Epoch 110/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0719 - auc: 0.9949 - accuracy: 0.9789 - cost: 2.6914 - val_loss: 0.1068 - val_auc: 0.9906 - val_accuracy: 0.9706 - val_cost: 3.7004\n",
            "Epoch 111/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0715 - auc: 0.9949 - accuracy: 0.9789 - cost: 2.6921 - val_loss: 0.1059 - val_auc: 0.9905 - val_accuracy: 0.9708 - val_cost: 3.7103\n",
            "Epoch 112/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0712 - auc: 0.9950 - accuracy: 0.9794 - cost: 2.6211 - val_loss: 0.1047 - val_auc: 0.9905 - val_accuracy: 0.9709 - val_cost: 3.7500\n",
            "Epoch 113/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0717 - auc: 0.9949 - accuracy: 0.9790 - cost: 2.6860 - val_loss: 0.1052 - val_auc: 0.9908 - val_accuracy: 0.9699 - val_cost: 3.8062\n",
            "Epoch 114/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0705 - auc: 0.9950 - accuracy: 0.9791 - cost: 2.6698 - val_loss: 0.1050 - val_auc: 0.9905 - val_accuracy: 0.9703 - val_cost: 3.7864\n",
            "Epoch 115/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0709 - auc: 0.9949 - accuracy: 0.9793 - cost: 2.6462 - val_loss: 0.1081 - val_auc: 0.9906 - val_accuracy: 0.9695 - val_cost: 3.7632\n",
            "Epoch 116/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0712 - auc: 0.9950 - accuracy: 0.9789 - cost: 2.6929 - val_loss: 0.1060 - val_auc: 0.9905 - val_accuracy: 0.9699 - val_cost: 3.7930\n",
            "Epoch 117/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9949 - accuracy: 0.9794 - cost: 2.6370 - val_loss: 0.1056 - val_auc: 0.9904 - val_accuracy: 0.9697 - val_cost: 3.8790\n",
            "Epoch 118/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0707 - auc: 0.9949 - accuracy: 0.9794 - cost: 2.6412 - val_loss: 0.1058 - val_auc: 0.9905 - val_accuracy: 0.9696 - val_cost: 3.8194\n",
            "Epoch 119/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0702 - auc: 0.9951 - accuracy: 0.9794 - cost: 2.6150 - val_loss: 0.1061 - val_auc: 0.9907 - val_accuracy: 0.9694 - val_cost: 3.8624\n",
            "Epoch 120/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0712 - auc: 0.9950 - accuracy: 0.9791 - cost: 2.6597 - val_loss: 0.1066 - val_auc: 0.9906 - val_accuracy: 0.9705 - val_cost: 3.6872\n",
            "Epoch 121/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0705 - auc: 0.9950 - accuracy: 0.9792 - cost: 2.6512 - val_loss: 0.1067 - val_auc: 0.9907 - val_accuracy: 0.9718 - val_cost: 3.5384\n",
            "Epoch 122/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0692 - auc: 0.9951 - accuracy: 0.9801 - cost: 2.5390 - val_loss: 0.1048 - val_auc: 0.9906 - val_accuracy: 0.9705 - val_cost: 3.7798\n",
            "Epoch 123/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0697 - auc: 0.9951 - accuracy: 0.9794 - cost: 2.6370 - val_loss: 0.1057 - val_auc: 0.9907 - val_accuracy: 0.9700 - val_cost: 3.7665\n",
            "Epoch 124/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0691 - auc: 0.9952 - accuracy: 0.9800 - cost: 2.5556 - val_loss: 0.1058 - val_auc: 0.9907 - val_accuracy: 0.9712 - val_cost: 3.6640\n",
            "Epoch 125/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0698 - auc: 0.9950 - accuracy: 0.9794 - cost: 2.6327 - val_loss: 0.1064 - val_auc: 0.9904 - val_accuracy: 0.9702 - val_cost: 3.8228\n",
            "Epoch 126/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0692 - auc: 0.9952 - accuracy: 0.9798 - cost: 2.5853 - val_loss: 0.1080 - val_auc: 0.9904 - val_accuracy: 0.9707 - val_cost: 3.6475\n",
            "Epoch 127/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0694 - auc: 0.9952 - accuracy: 0.9792 - cost: 2.6632 - val_loss: 0.1066 - val_auc: 0.9907 - val_accuracy: 0.9699 - val_cost: 3.8261\n",
            "Epoch 128/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0694 - auc: 0.9951 - accuracy: 0.9800 - cost: 2.5559 - val_loss: 0.1057 - val_auc: 0.9906 - val_accuracy: 0.9712 - val_cost: 3.7169\n",
            "Epoch 129/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0690 - auc: 0.9951 - accuracy: 0.9798 - cost: 2.5872 - val_loss: 0.1059 - val_auc: 0.9906 - val_accuracy: 0.9703 - val_cost: 3.8062\n",
            "Epoch 130/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0688 - auc: 0.9952 - accuracy: 0.9799 - cost: 2.5810 - val_loss: 0.1078 - val_auc: 0.9904 - val_accuracy: 0.9692 - val_cost: 3.8591\n",
            "Epoch 131/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0686 - auc: 0.9953 - accuracy: 0.9800 - cost: 2.5660 - val_loss: 0.1073 - val_auc: 0.9906 - val_accuracy: 0.9711 - val_cost: 3.5946\n",
            "Epoch 132/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0691 - auc: 0.9951 - accuracy: 0.9799 - cost: 2.5606 - val_loss: 0.1100 - val_auc: 0.9902 - val_accuracy: 0.9688 - val_cost: 3.9583\n",
            "Epoch 133/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0685 - auc: 0.9952 - accuracy: 0.9797 - cost: 2.5961 - val_loss: 0.1050 - val_auc: 0.9908 - val_accuracy: 0.9703 - val_cost: 3.8128\n",
            "Epoch 134/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0692 - auc: 0.9951 - accuracy: 0.9800 - cost: 2.5637 - val_loss: 0.1068 - val_auc: 0.9908 - val_accuracy: 0.9703 - val_cost: 3.7500\n",
            "Epoch 135/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0683 - auc: 0.9952 - accuracy: 0.9802 - cost: 2.5428 - val_loss: 0.1098 - val_auc: 0.9908 - val_accuracy: 0.9691 - val_cost: 3.7169\n",
            "Epoch 136/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0685 - auc: 0.9952 - accuracy: 0.9800 - cost: 2.5610 - val_loss: 0.1068 - val_auc: 0.9908 - val_accuracy: 0.9697 - val_cost: 3.8327\n",
            "Epoch 137/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0686 - auc: 0.9952 - accuracy: 0.9796 - cost: 2.6080 - val_loss: 0.1065 - val_auc: 0.9908 - val_accuracy: 0.9702 - val_cost: 3.7302\n",
            "Epoch 138/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0689 - auc: 0.9951 - accuracy: 0.9801 - cost: 2.5397 - val_loss: 0.1066 - val_auc: 0.9906 - val_accuracy: 0.9695 - val_cost: 3.8988\n",
            "Epoch 139/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0685 - auc: 0.9952 - accuracy: 0.9796 - cost: 2.6100 - val_loss: 0.1061 - val_auc: 0.9908 - val_accuracy: 0.9699 - val_cost: 3.8294\n",
            "Epoch 140/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0681 - auc: 0.9953 - accuracy: 0.9800 - cost: 2.5575 - val_loss: 0.1088 - val_auc: 0.9906 - val_accuracy: 0.9701 - val_cost: 3.7070\n",
            "Epoch 141/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0681 - auc: 0.9954 - accuracy: 0.9798 - cost: 2.5667 - val_loss: 0.1094 - val_auc: 0.9903 - val_accuracy: 0.9699 - val_cost: 3.8393\n",
            "Epoch 142/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0679 - auc: 0.9953 - accuracy: 0.9801 - cost: 2.5482 - val_loss: 0.1080 - val_auc: 0.9905 - val_accuracy: 0.9704 - val_cost: 3.6541\n",
            "Epoch 143/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0662 - auc: 0.9954 - accuracy: 0.9807 - cost: 2.4618 - val_loss: 0.1063 - val_auc: 0.9907 - val_accuracy: 0.9708 - val_cost: 3.6376\n",
            "Epoch 144/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0671 - auc: 0.9953 - accuracy: 0.9806 - cost: 2.4842 - val_loss: 0.1077 - val_auc: 0.9908 - val_accuracy: 0.9697 - val_cost: 3.7401\n",
            "Epoch 145/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0676 - auc: 0.9953 - accuracy: 0.9802 - cost: 2.5278 - val_loss: 0.1091 - val_auc: 0.9906 - val_accuracy: 0.9708 - val_cost: 3.7235\n",
            "Epoch 146/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0664 - auc: 0.9954 - accuracy: 0.9805 - cost: 2.4954 - val_loss: 0.1080 - val_auc: 0.9909 - val_accuracy: 0.9706 - val_cost: 3.6442\n",
            "Epoch 147/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0670 - auc: 0.9954 - accuracy: 0.9804 - cost: 2.5000 - val_loss: 0.1084 - val_auc: 0.9905 - val_accuracy: 0.9708 - val_cost: 3.6409\n",
            "Epoch 148/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0672 - auc: 0.9953 - accuracy: 0.9806 - cost: 2.4788 - val_loss: 0.1067 - val_auc: 0.9908 - val_accuracy: 0.9699 - val_cost: 3.7963\n",
            "Epoch 149/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0662 - auc: 0.9955 - accuracy: 0.9804 - cost: 2.5093 - val_loss: 0.1077 - val_auc: 0.9907 - val_accuracy: 0.9699 - val_cost: 3.7599\n",
            "Epoch 150/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0668 - auc: 0.9954 - accuracy: 0.9805 - cost: 2.4823 - val_loss: 0.1084 - val_auc: 0.9906 - val_accuracy: 0.9706 - val_cost: 3.8062\n",
            "Epoch 151/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0674 - auc: 0.9954 - accuracy: 0.9805 - cost: 2.4942 - val_loss: 0.1080 - val_auc: 0.9905 - val_accuracy: 0.9706 - val_cost: 3.8029\n",
            "Epoch 152/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0658 - auc: 0.9953 - accuracy: 0.9812 - cost: 2.3978 - val_loss: 0.1080 - val_auc: 0.9907 - val_accuracy: 0.9706 - val_cost: 3.7269\n",
            "Epoch 153/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0663 - auc: 0.9955 - accuracy: 0.9808 - cost: 2.4549 - val_loss: 0.1068 - val_auc: 0.9906 - val_accuracy: 0.9710 - val_cost: 3.6706\n",
            "Epoch 154/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0660 - auc: 0.9955 - accuracy: 0.9810 - cost: 2.4286 - val_loss: 0.1098 - val_auc: 0.9902 - val_accuracy: 0.9705 - val_cost: 3.7467\n",
            "Epoch 155/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0670 - auc: 0.9953 - accuracy: 0.9804 - cost: 2.4946 - val_loss: 0.1095 - val_auc: 0.9901 - val_accuracy: 0.9696 - val_cost: 3.8459\n",
            "Epoch 156/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0662 - auc: 0.9955 - accuracy: 0.9807 - cost: 2.4672 - val_loss: 0.1070 - val_auc: 0.9909 - val_accuracy: 0.9701 - val_cost: 3.7864\n",
            "Epoch 157/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0663 - auc: 0.9954 - accuracy: 0.9805 - cost: 2.4826 - val_loss: 0.1083 - val_auc: 0.9903 - val_accuracy: 0.9706 - val_cost: 3.7434\n",
            "Epoch 158/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0662 - auc: 0.9954 - accuracy: 0.9804 - cost: 2.5039 - val_loss: 0.1069 - val_auc: 0.9909 - val_accuracy: 0.9710 - val_cost: 3.7401\n",
            "Epoch 159/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0665 - auc: 0.9954 - accuracy: 0.9805 - cost: 2.4950 - val_loss: 0.1093 - val_auc: 0.9905 - val_accuracy: 0.9705 - val_cost: 3.8492\n",
            "Epoch 160/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0659 - auc: 0.9955 - accuracy: 0.9808 - cost: 2.4603 - val_loss: 0.1085 - val_auc: 0.9904 - val_accuracy: 0.9712 - val_cost: 3.6442\n",
            "Epoch 161/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0654 - auc: 0.9956 - accuracy: 0.9806 - cost: 2.4668 - val_loss: 0.1077 - val_auc: 0.9905 - val_accuracy: 0.9701 - val_cost: 3.8128\n",
            "Epoch 162/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0654 - auc: 0.9955 - accuracy: 0.9809 - cost: 2.4421 - val_loss: 0.1074 - val_auc: 0.9910 - val_accuracy: 0.9700 - val_cost: 3.8426\n",
            "Epoch 163/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0658 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4703 - val_loss: 0.1091 - val_auc: 0.9904 - val_accuracy: 0.9710 - val_cost: 3.7004\n",
            "Epoch 164/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0652 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4421 - val_loss: 0.1067 - val_auc: 0.9907 - val_accuracy: 0.9704 - val_cost: 3.8194\n",
            "Epoch 165/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0660 - auc: 0.9955 - accuracy: 0.9804 - cost: 2.5015 - val_loss: 0.1084 - val_auc: 0.9907 - val_accuracy: 0.9703 - val_cost: 3.8161\n",
            "Epoch 166/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0655 - auc: 0.9955 - accuracy: 0.9811 - cost: 2.4178 - val_loss: 0.1083 - val_auc: 0.9906 - val_accuracy: 0.9712 - val_cost: 3.6177\n",
            "Epoch 167/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0647 - auc: 0.9956 - accuracy: 0.9811 - cost: 2.4093 - val_loss: 0.1071 - val_auc: 0.9907 - val_accuracy: 0.9714 - val_cost: 3.5813\n",
            "Epoch 168/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0657 - auc: 0.9955 - accuracy: 0.9809 - cost: 2.4414 - val_loss: 0.1112 - val_auc: 0.9904 - val_accuracy: 0.9703 - val_cost: 3.5549\n",
            "Epoch 169/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0656 - auc: 0.9955 - accuracy: 0.9810 - cost: 2.4309 - val_loss: 0.1096 - val_auc: 0.9905 - val_accuracy: 0.9705 - val_cost: 3.6276\n",
            "Epoch 170/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0648 - auc: 0.9955 - accuracy: 0.9812 - cost: 2.3846 - val_loss: 0.1102 - val_auc: 0.9902 - val_accuracy: 0.9699 - val_cost: 3.7831\n",
            "Epoch 171/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0657 - auc: 0.9955 - accuracy: 0.9808 - cost: 2.4522 - val_loss: 0.1094 - val_auc: 0.9903 - val_accuracy: 0.9707 - val_cost: 3.6806\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.1072 - auc: 0.9906 - accuracy: 0.9684 - cost: 3.9813\n",
            "500/500 [==============================] - 1s 949us/step\n",
            "fold train/predict time: 0:01:22.891088\n",
            "fold accuracy: 0.968375027179718 - fold cost: 3.981250047683716\n",
            "x_train shape: (144000, 67)\n",
            "Epoch 1/1000\n",
            "120/120 [==============================] - 2s 5ms/step - loss: 0.5310 - auc: 0.7969 - accuracy: 0.7281 - cost: 36.2218 - val_loss: 0.4002 - val_auc: 0.8974 - val_accuracy: 0.8238 - val_cost: 22.9134\n",
            "Epoch 2/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.3518 - auc: 0.9213 - accuracy: 0.8489 - cost: 19.2512 - val_loss: 0.3178 - val_auc: 0.9359 - val_accuracy: 0.8644 - val_cost: 17.2057\n",
            "Epoch 3/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.3022 - auc: 0.9423 - accuracy: 0.8751 - cost: 15.8071 - val_loss: 0.2880 - val_auc: 0.9475 - val_accuracy: 0.8808 - val_cost: 14.8413\n",
            "Epoch 4/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2739 - auc: 0.9526 - accuracy: 0.8885 - cost: 14.1015 - val_loss: 0.2644 - val_auc: 0.9560 - val_accuracy: 0.8935 - val_cost: 13.5813\n",
            "Epoch 5/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2507 - auc: 0.9604 - accuracy: 0.8995 - cost: 12.6998 - val_loss: 0.2456 - val_auc: 0.9620 - val_accuracy: 0.9031 - val_cost: 12.0701\n",
            "Epoch 6/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2324 - auc: 0.9659 - accuracy: 0.9082 - cost: 11.6169 - val_loss: 0.2300 - val_auc: 0.9666 - val_accuracy: 0.9104 - val_cost: 11.1938\n",
            "Epoch 7/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2164 - auc: 0.9704 - accuracy: 0.9157 - cost: 10.6289 - val_loss: 0.2159 - val_auc: 0.9705 - val_accuracy: 0.9176 - val_cost: 10.4530\n",
            "Epoch 8/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2030 - auc: 0.9738 - accuracy: 0.9220 - cost: 9.8615 - val_loss: 0.2049 - val_auc: 0.9733 - val_accuracy: 0.9235 - val_cost: 9.6164\n",
            "Epoch 9/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1921 - auc: 0.9764 - accuracy: 0.9270 - cost: 9.2106 - val_loss: 0.1958 - val_auc: 0.9756 - val_accuracy: 0.9287 - val_cost: 8.7930\n",
            "Epoch 10/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1827 - auc: 0.9785 - accuracy: 0.9315 - cost: 8.6516 - val_loss: 0.1880 - val_auc: 0.9772 - val_accuracy: 0.9334 - val_cost: 8.2606\n",
            "Epoch 11/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1762 - auc: 0.9799 - accuracy: 0.9342 - cost: 8.3198 - val_loss: 0.1814 - val_auc: 0.9786 - val_accuracy: 0.9355 - val_cost: 8.1746\n",
            "Epoch 12/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1694 - auc: 0.9813 - accuracy: 0.9374 - cost: 7.9201 - val_loss: 0.1768 - val_auc: 0.9795 - val_accuracy: 0.9381 - val_cost: 7.8869\n",
            "Epoch 13/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1636 - auc: 0.9825 - accuracy: 0.9402 - cost: 7.5679 - val_loss: 0.1734 - val_auc: 0.9803 - val_accuracy: 0.9395 - val_cost: 7.7315\n",
            "Epoch 14/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1591 - auc: 0.9833 - accuracy: 0.9428 - cost: 7.2110 - val_loss: 0.1680 - val_auc: 0.9813 - val_accuracy: 0.9428 - val_cost: 7.1230\n",
            "Epoch 15/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1537 - auc: 0.9843 - accuracy: 0.9454 - cost: 6.9271 - val_loss: 0.1651 - val_auc: 0.9819 - val_accuracy: 0.9438 - val_cost: 6.9246\n",
            "Epoch 16/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1506 - auc: 0.9849 - accuracy: 0.9463 - cost: 6.7959 - val_loss: 0.1623 - val_auc: 0.9824 - val_accuracy: 0.9449 - val_cost: 6.9015\n",
            "Epoch 17/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1469 - auc: 0.9856 - accuracy: 0.9483 - cost: 6.5417 - val_loss: 0.1588 - val_auc: 0.9833 - val_accuracy: 0.9459 - val_cost: 6.6700\n",
            "Epoch 18/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1439 - auc: 0.9860 - accuracy: 0.9488 - cost: 6.5004 - val_loss: 0.1560 - val_auc: 0.9836 - val_accuracy: 0.9458 - val_cost: 6.8188\n",
            "Epoch 19/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1407 - auc: 0.9865 - accuracy: 0.9506 - cost: 6.2604 - val_loss: 0.1540 - val_auc: 0.9839 - val_accuracy: 0.9482 - val_cost: 6.4517\n",
            "Epoch 20/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1386 - auc: 0.9869 - accuracy: 0.9522 - cost: 6.0440 - val_loss: 0.1522 - val_auc: 0.9842 - val_accuracy: 0.9488 - val_cost: 6.4385\n",
            "Epoch 21/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1355 - auc: 0.9875 - accuracy: 0.9529 - cost: 5.9726 - val_loss: 0.1516 - val_auc: 0.9843 - val_accuracy: 0.9497 - val_cost: 6.4451\n",
            "Epoch 22/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1335 - auc: 0.9877 - accuracy: 0.9534 - cost: 5.9016 - val_loss: 0.1490 - val_auc: 0.9848 - val_accuracy: 0.9497 - val_cost: 6.2401\n",
            "Epoch 23/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1314 - auc: 0.9880 - accuracy: 0.9544 - cost: 5.7531 - val_loss: 0.1483 - val_auc: 0.9848 - val_accuracy: 0.9508 - val_cost: 6.0813\n",
            "Epoch 24/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1299 - auc: 0.9883 - accuracy: 0.9548 - cost: 5.7315 - val_loss: 0.1470 - val_auc: 0.9852 - val_accuracy: 0.9511 - val_cost: 6.0185\n",
            "Epoch 25/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1279 - auc: 0.9885 - accuracy: 0.9560 - cost: 5.5617 - val_loss: 0.1459 - val_auc: 0.9853 - val_accuracy: 0.9515 - val_cost: 6.0714\n",
            "Epoch 26/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1256 - auc: 0.9889 - accuracy: 0.9574 - cost: 5.4012 - val_loss: 0.1441 - val_auc: 0.9855 - val_accuracy: 0.9534 - val_cost: 5.8730\n",
            "Epoch 27/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1233 - auc: 0.9893 - accuracy: 0.9584 - cost: 5.2766 - val_loss: 0.1436 - val_auc: 0.9856 - val_accuracy: 0.9534 - val_cost: 5.8003\n",
            "Epoch 28/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1229 - auc: 0.9892 - accuracy: 0.9582 - cost: 5.2959 - val_loss: 0.1412 - val_auc: 0.9861 - val_accuracy: 0.9547 - val_cost: 5.7242\n",
            "Epoch 29/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1213 - auc: 0.9895 - accuracy: 0.9592 - cost: 5.1655 - val_loss: 0.1412 - val_auc: 0.9860 - val_accuracy: 0.9551 - val_cost: 5.5589\n",
            "Epoch 30/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1187 - auc: 0.9899 - accuracy: 0.9600 - cost: 5.0725 - val_loss: 0.1390 - val_auc: 0.9863 - val_accuracy: 0.9553 - val_cost: 5.5952\n",
            "Epoch 31/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1188 - auc: 0.9899 - accuracy: 0.9602 - cost: 5.0424 - val_loss: 0.1384 - val_auc: 0.9863 - val_accuracy: 0.9569 - val_cost: 5.4167\n",
            "Epoch 32/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1161 - auc: 0.9902 - accuracy: 0.9613 - cost: 4.9097 - val_loss: 0.1372 - val_auc: 0.9866 - val_accuracy: 0.9562 - val_cost: 5.5622\n",
            "Epoch 33/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1150 - auc: 0.9903 - accuracy: 0.9619 - cost: 4.8268 - val_loss: 0.1362 - val_auc: 0.9868 - val_accuracy: 0.9564 - val_cost: 5.5126\n",
            "Epoch 34/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1138 - auc: 0.9905 - accuracy: 0.9623 - cost: 4.7805 - val_loss: 0.1362 - val_auc: 0.9866 - val_accuracy: 0.9559 - val_cost: 5.5952\n",
            "Epoch 35/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1123 - auc: 0.9906 - accuracy: 0.9634 - cost: 4.6134 - val_loss: 0.1344 - val_auc: 0.9870 - val_accuracy: 0.9573 - val_cost: 5.2844\n",
            "Epoch 36/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1116 - auc: 0.9907 - accuracy: 0.9634 - cost: 4.6493 - val_loss: 0.1338 - val_auc: 0.9871 - val_accuracy: 0.9575 - val_cost: 5.3406\n",
            "Epoch 37/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1105 - auc: 0.9908 - accuracy: 0.9638 - cost: 4.5814 - val_loss: 0.1316 - val_auc: 0.9872 - val_accuracy: 0.9589 - val_cost: 5.1058\n",
            "Epoch 38/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1085 - auc: 0.9911 - accuracy: 0.9646 - cost: 4.4923 - val_loss: 0.1309 - val_auc: 0.9875 - val_accuracy: 0.9585 - val_cost: 5.1885\n",
            "Epoch 39/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1078 - auc: 0.9912 - accuracy: 0.9650 - cost: 4.4383 - val_loss: 0.1308 - val_auc: 0.9874 - val_accuracy: 0.9585 - val_cost: 5.2050\n",
            "Epoch 40/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1066 - auc: 0.9914 - accuracy: 0.9651 - cost: 4.4379 - val_loss: 0.1291 - val_auc: 0.9877 - val_accuracy: 0.9599 - val_cost: 5.0595\n",
            "Epoch 41/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1047 - auc: 0.9916 - accuracy: 0.9657 - cost: 4.3380 - val_loss: 0.1315 - val_auc: 0.9875 - val_accuracy: 0.9582 - val_cost: 5.0265\n",
            "Epoch 42/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1046 - auc: 0.9915 - accuracy: 0.9663 - cost: 4.2593 - val_loss: 0.1292 - val_auc: 0.9877 - val_accuracy: 0.9597 - val_cost: 4.9868\n",
            "Epoch 43/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1030 - auc: 0.9919 - accuracy: 0.9666 - cost: 4.2434 - val_loss: 0.1288 - val_auc: 0.9876 - val_accuracy: 0.9601 - val_cost: 4.9471\n",
            "Epoch 44/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1029 - auc: 0.9918 - accuracy: 0.9670 - cost: 4.1898 - val_loss: 0.1279 - val_auc: 0.9879 - val_accuracy: 0.9601 - val_cost: 4.9173\n",
            "Epoch 45/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1015 - auc: 0.9918 - accuracy: 0.9675 - cost: 4.1381 - val_loss: 0.1269 - val_auc: 0.9878 - val_accuracy: 0.9599 - val_cost: 4.9405\n",
            "Epoch 46/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1006 - auc: 0.9920 - accuracy: 0.9680 - cost: 4.0613 - val_loss: 0.1253 - val_auc: 0.9882 - val_accuracy: 0.9614 - val_cost: 4.8512\n",
            "Epoch 47/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0995 - auc: 0.9922 - accuracy: 0.9680 - cost: 4.0721 - val_loss: 0.1251 - val_auc: 0.9882 - val_accuracy: 0.9617 - val_cost: 4.7156\n",
            "Epoch 48/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0988 - auc: 0.9922 - accuracy: 0.9686 - cost: 3.9857 - val_loss: 0.1254 - val_auc: 0.9880 - val_accuracy: 0.9604 - val_cost: 4.9504\n",
            "Epoch 49/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0969 - auc: 0.9924 - accuracy: 0.9694 - cost: 3.8870 - val_loss: 0.1240 - val_auc: 0.9883 - val_accuracy: 0.9611 - val_cost: 4.8843\n",
            "Epoch 50/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0972 - auc: 0.9924 - accuracy: 0.9691 - cost: 3.9398 - val_loss: 0.1240 - val_auc: 0.9882 - val_accuracy: 0.9618 - val_cost: 4.7751\n",
            "Epoch 51/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0973 - auc: 0.9925 - accuracy: 0.9689 - cost: 3.9448 - val_loss: 0.1230 - val_auc: 0.9884 - val_accuracy: 0.9619 - val_cost: 4.7057\n",
            "Epoch 52/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0960 - auc: 0.9926 - accuracy: 0.9694 - cost: 3.8823 - val_loss: 0.1215 - val_auc: 0.9885 - val_accuracy: 0.9626 - val_cost: 4.7288\n",
            "Epoch 53/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0953 - auc: 0.9927 - accuracy: 0.9694 - cost: 3.8935 - val_loss: 0.1228 - val_auc: 0.9885 - val_accuracy: 0.9624 - val_cost: 4.6759\n",
            "Epoch 54/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0947 - auc: 0.9928 - accuracy: 0.9706 - cost: 3.7400 - val_loss: 0.1211 - val_auc: 0.9888 - val_accuracy: 0.9626 - val_cost: 4.5767\n",
            "Epoch 55/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0944 - auc: 0.9927 - accuracy: 0.9704 - cost: 3.7600 - val_loss: 0.1206 - val_auc: 0.9887 - val_accuracy: 0.9633 - val_cost: 4.5899\n",
            "Epoch 56/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0924 - auc: 0.9930 - accuracy: 0.9707 - cost: 3.7238 - val_loss: 0.1202 - val_auc: 0.9888 - val_accuracy: 0.9644 - val_cost: 4.3552\n",
            "Epoch 57/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0919 - auc: 0.9931 - accuracy: 0.9712 - cost: 3.6609 - val_loss: 0.1213 - val_auc: 0.9886 - val_accuracy: 0.9633 - val_cost: 4.6296\n",
            "Epoch 58/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0920 - auc: 0.9929 - accuracy: 0.9714 - cost: 3.6404 - val_loss: 0.1202 - val_auc: 0.9890 - val_accuracy: 0.9637 - val_cost: 4.4312\n",
            "Epoch 59/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0913 - auc: 0.9930 - accuracy: 0.9714 - cost: 3.6532 - val_loss: 0.1189 - val_auc: 0.9890 - val_accuracy: 0.9631 - val_cost: 4.6627\n",
            "Epoch 60/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0911 - auc: 0.9931 - accuracy: 0.9714 - cost: 3.6478 - val_loss: 0.1184 - val_auc: 0.9888 - val_accuracy: 0.9644 - val_cost: 4.4577\n",
            "Epoch 61/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0891 - auc: 0.9933 - accuracy: 0.9719 - cost: 3.5818 - val_loss: 0.1194 - val_auc: 0.9885 - val_accuracy: 0.9644 - val_cost: 4.5238\n",
            "Epoch 62/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0893 - auc: 0.9933 - accuracy: 0.9722 - cost: 3.5409 - val_loss: 0.1175 - val_auc: 0.9891 - val_accuracy: 0.9655 - val_cost: 4.2493\n",
            "Epoch 63/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0884 - auc: 0.9934 - accuracy: 0.9726 - cost: 3.4865 - val_loss: 0.1169 - val_auc: 0.9889 - val_accuracy: 0.9654 - val_cost: 4.2758\n",
            "Epoch 64/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0880 - auc: 0.9934 - accuracy: 0.9728 - cost: 3.4711 - val_loss: 0.1165 - val_auc: 0.9890 - val_accuracy: 0.9653 - val_cost: 4.5172\n",
            "Epoch 65/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0876 - auc: 0.9935 - accuracy: 0.9724 - cost: 3.5243 - val_loss: 0.1162 - val_auc: 0.9894 - val_accuracy: 0.9643 - val_cost: 4.4775\n",
            "Epoch 66/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0872 - auc: 0.9936 - accuracy: 0.9730 - cost: 3.4518 - val_loss: 0.1163 - val_auc: 0.9890 - val_accuracy: 0.9660 - val_cost: 4.3585\n",
            "Epoch 67/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0865 - auc: 0.9936 - accuracy: 0.9726 - cost: 3.5062 - val_loss: 0.1159 - val_auc: 0.9890 - val_accuracy: 0.9654 - val_cost: 4.4312\n",
            "Epoch 68/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0850 - auc: 0.9938 - accuracy: 0.9733 - cost: 3.4039 - val_loss: 0.1166 - val_auc: 0.9890 - val_accuracy: 0.9659 - val_cost: 4.3056\n",
            "Epoch 69/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0853 - auc: 0.9935 - accuracy: 0.9739 - cost: 3.3356 - val_loss: 0.1172 - val_auc: 0.9890 - val_accuracy: 0.9658 - val_cost: 4.2427\n",
            "Epoch 70/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0845 - auc: 0.9937 - accuracy: 0.9737 - cost: 3.3553 - val_loss: 0.1150 - val_auc: 0.9893 - val_accuracy: 0.9652 - val_cost: 4.3948\n",
            "Epoch 71/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0843 - auc: 0.9938 - accuracy: 0.9741 - cost: 3.3036 - val_loss: 0.1154 - val_auc: 0.9893 - val_accuracy: 0.9658 - val_cost: 4.2526\n",
            "Epoch 72/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0846 - auc: 0.9938 - accuracy: 0.9737 - cost: 3.3646 - val_loss: 0.1133 - val_auc: 0.9896 - val_accuracy: 0.9666 - val_cost: 4.1766\n",
            "Epoch 73/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0836 - auc: 0.9938 - accuracy: 0.9738 - cost: 3.3395 - val_loss: 0.1158 - val_auc: 0.9893 - val_accuracy: 0.9658 - val_cost: 4.2097\n",
            "Epoch 74/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0827 - auc: 0.9940 - accuracy: 0.9746 - cost: 3.2481 - val_loss: 0.1149 - val_auc: 0.9893 - val_accuracy: 0.9660 - val_cost: 4.2196\n",
            "Epoch 75/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0820 - auc: 0.9940 - accuracy: 0.9750 - cost: 3.1871 - val_loss: 0.1146 - val_auc: 0.9895 - val_accuracy: 0.9663 - val_cost: 4.2262\n",
            "Epoch 76/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0821 - auc: 0.9940 - accuracy: 0.9747 - cost: 3.2218 - val_loss: 0.1165 - val_auc: 0.9893 - val_accuracy: 0.9655 - val_cost: 4.1997\n",
            "Epoch 77/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0814 - auc: 0.9940 - accuracy: 0.9752 - cost: 3.1609 - val_loss: 0.1134 - val_auc: 0.9894 - val_accuracy: 0.9672 - val_cost: 4.1303\n",
            "Epoch 78/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0810 - auc: 0.9941 - accuracy: 0.9755 - cost: 3.1285 - val_loss: 0.1138 - val_auc: 0.9895 - val_accuracy: 0.9667 - val_cost: 4.1435\n",
            "Epoch 79/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0817 - auc: 0.9940 - accuracy: 0.9749 - cost: 3.1944 - val_loss: 0.1143 - val_auc: 0.9895 - val_accuracy: 0.9671 - val_cost: 4.1667\n",
            "Epoch 80/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0806 - auc: 0.9941 - accuracy: 0.9752 - cost: 3.1574 - val_loss: 0.1165 - val_auc: 0.9892 - val_accuracy: 0.9666 - val_cost: 4.0708\n",
            "Epoch 81/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0802 - auc: 0.9941 - accuracy: 0.9756 - cost: 3.1146 - val_loss: 0.1144 - val_auc: 0.9893 - val_accuracy: 0.9669 - val_cost: 4.1501\n",
            "Epoch 82/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0793 - auc: 0.9942 - accuracy: 0.9759 - cost: 3.0656 - val_loss: 0.1132 - val_auc: 0.9895 - val_accuracy: 0.9679 - val_cost: 4.1038\n",
            "Epoch 83/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0798 - auc: 0.9941 - accuracy: 0.9757 - cost: 3.0953 - val_loss: 0.1146 - val_auc: 0.9890 - val_accuracy: 0.9676 - val_cost: 4.0509\n",
            "Epoch 84/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0792 - auc: 0.9942 - accuracy: 0.9756 - cost: 3.1211 - val_loss: 0.1141 - val_auc: 0.9895 - val_accuracy: 0.9683 - val_cost: 3.9749\n",
            "Epoch 85/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0789 - auc: 0.9942 - accuracy: 0.9762 - cost: 3.0386 - val_loss: 0.1155 - val_auc: 0.9891 - val_accuracy: 0.9657 - val_cost: 4.2427\n",
            "Epoch 86/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0783 - auc: 0.9943 - accuracy: 0.9763 - cost: 3.0212 - val_loss: 0.1147 - val_auc: 0.9894 - val_accuracy: 0.9661 - val_cost: 4.3915\n",
            "Epoch 87/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0779 - auc: 0.9944 - accuracy: 0.9761 - cost: 3.0401 - val_loss: 0.1139 - val_auc: 0.9894 - val_accuracy: 0.9684 - val_cost: 3.9815\n",
            "Epoch 88/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0769 - auc: 0.9945 - accuracy: 0.9769 - cost: 2.9479 - val_loss: 0.1126 - val_auc: 0.9896 - val_accuracy: 0.9679 - val_cost: 4.0112\n",
            "Epoch 89/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0770 - auc: 0.9946 - accuracy: 0.9767 - cost: 2.9676 - val_loss: 0.1144 - val_auc: 0.9895 - val_accuracy: 0.9678 - val_cost: 4.0245\n",
            "Epoch 90/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0765 - auc: 0.9945 - accuracy: 0.9773 - cost: 2.9001 - val_loss: 0.1141 - val_auc: 0.9893 - val_accuracy: 0.9674 - val_cost: 4.0675\n",
            "Epoch 91/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0767 - auc: 0.9946 - accuracy: 0.9768 - cost: 2.9695 - val_loss: 0.1127 - val_auc: 0.9898 - val_accuracy: 0.9688 - val_cost: 3.8988\n",
            "Epoch 92/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0760 - auc: 0.9945 - accuracy: 0.9772 - cost: 2.9267 - val_loss: 0.1134 - val_auc: 0.9895 - val_accuracy: 0.9672 - val_cost: 4.1005\n",
            "Epoch 93/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0759 - auc: 0.9945 - accuracy: 0.9769 - cost: 2.9429 - val_loss: 0.1128 - val_auc: 0.9897 - val_accuracy: 0.9680 - val_cost: 3.9980\n",
            "Epoch 94/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0753 - auc: 0.9947 - accuracy: 0.9772 - cost: 2.8981 - val_loss: 0.1126 - val_auc: 0.9898 - val_accuracy: 0.9683 - val_cost: 3.9749\n",
            "Epoch 95/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0753 - auc: 0.9946 - accuracy: 0.9775 - cost: 2.8750 - val_loss: 0.1128 - val_auc: 0.9898 - val_accuracy: 0.9688 - val_cost: 3.8657\n",
            "Epoch 96/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0753 - auc: 0.9947 - accuracy: 0.9773 - cost: 2.9008 - val_loss: 0.1130 - val_auc: 0.9898 - val_accuracy: 0.9669 - val_cost: 4.1237\n",
            "Epoch 97/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0743 - auc: 0.9947 - accuracy: 0.9776 - cost: 2.8681 - val_loss: 0.1115 - val_auc: 0.9898 - val_accuracy: 0.9673 - val_cost: 4.0840\n",
            "Epoch 98/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0739 - auc: 0.9947 - accuracy: 0.9780 - cost: 2.8110 - val_loss: 0.1132 - val_auc: 0.9897 - val_accuracy: 0.9683 - val_cost: 4.0344\n",
            "Epoch 99/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0736 - auc: 0.9948 - accuracy: 0.9779 - cost: 2.8202 - val_loss: 0.1132 - val_auc: 0.9895 - val_accuracy: 0.9676 - val_cost: 4.1435\n",
            "Epoch 100/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0742 - auc: 0.9946 - accuracy: 0.9776 - cost: 2.8630 - val_loss: 0.1133 - val_auc: 0.9895 - val_accuracy: 0.9672 - val_cost: 4.1005\n",
            "Epoch 101/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0735 - auc: 0.9948 - accuracy: 0.9778 - cost: 2.8403 - val_loss: 0.1147 - val_auc: 0.9893 - val_accuracy: 0.9673 - val_cost: 4.0708\n",
            "Epoch 102/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0738 - auc: 0.9947 - accuracy: 0.9779 - cost: 2.8368 - val_loss: 0.1158 - val_auc: 0.9894 - val_accuracy: 0.9681 - val_cost: 3.9550\n",
            "Epoch 103/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0738 - auc: 0.9947 - accuracy: 0.9779 - cost: 2.8252 - val_loss: 0.1146 - val_auc: 0.9896 - val_accuracy: 0.9682 - val_cost: 3.9484\n",
            "Epoch 104/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0730 - auc: 0.9950 - accuracy: 0.9779 - cost: 2.8160 - val_loss: 0.1149 - val_auc: 0.9896 - val_accuracy: 0.9690 - val_cost: 3.8029\n",
            "Epoch 105/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0732 - auc: 0.9949 - accuracy: 0.9779 - cost: 2.8345 - val_loss: 0.1152 - val_auc: 0.9895 - val_accuracy: 0.9683 - val_cost: 3.9120\n",
            "Epoch 106/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0721 - auc: 0.9950 - accuracy: 0.9781 - cost: 2.8002 - val_loss: 0.1133 - val_auc: 0.9895 - val_accuracy: 0.9688 - val_cost: 3.8690\n",
            "Epoch 107/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0723 - auc: 0.9948 - accuracy: 0.9787 - cost: 2.7257 - val_loss: 0.1129 - val_auc: 0.9896 - val_accuracy: 0.9682 - val_cost: 4.0278\n",
            "Epoch 108/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0719 - auc: 0.9950 - accuracy: 0.9783 - cost: 2.7770 - val_loss: 0.1156 - val_auc: 0.9895 - val_accuracy: 0.9673 - val_cost: 3.9815\n",
            "Epoch 109/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0733 - auc: 0.9948 - accuracy: 0.9783 - cost: 2.7735 - val_loss: 0.1147 - val_auc: 0.9896 - val_accuracy: 0.9686 - val_cost: 3.8988\n",
            "Epoch 110/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0715 - auc: 0.9950 - accuracy: 0.9789 - cost: 2.6860 - val_loss: 0.1140 - val_auc: 0.9896 - val_accuracy: 0.9697 - val_cost: 3.7831\n",
            "Epoch 111/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0714 - auc: 0.9950 - accuracy: 0.9786 - cost: 2.7334 - val_loss: 0.1159 - val_auc: 0.9894 - val_accuracy: 0.9675 - val_cost: 4.0642\n",
            "Epoch 112/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0714 - auc: 0.9950 - accuracy: 0.9792 - cost: 2.6682 - val_loss: 0.1146 - val_auc: 0.9896 - val_accuracy: 0.9678 - val_cost: 4.0741\n",
            "Epoch 113/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0712 - auc: 0.9950 - accuracy: 0.9787 - cost: 2.7292 - val_loss: 0.1133 - val_auc: 0.9897 - val_accuracy: 0.9674 - val_cost: 4.0642\n",
            "Epoch 114/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0712 - auc: 0.9950 - accuracy: 0.9790 - cost: 2.6875 - val_loss: 0.1142 - val_auc: 0.9896 - val_accuracy: 0.9681 - val_cost: 3.9848\n",
            "Epoch 115/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0704 - auc: 0.9951 - accuracy: 0.9788 - cost: 2.7079 - val_loss: 0.1159 - val_auc: 0.9894 - val_accuracy: 0.9685 - val_cost: 3.9021\n",
            "Epoch 116/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0698 - auc: 0.9951 - accuracy: 0.9790 - cost: 2.6817 - val_loss: 0.1136 - val_auc: 0.9896 - val_accuracy: 0.9690 - val_cost: 3.9352\n",
            "Epoch 117/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0697 - auc: 0.9951 - accuracy: 0.9795 - cost: 2.6219 - val_loss: 0.1148 - val_auc: 0.9894 - val_accuracy: 0.9683 - val_cost: 4.1237\n",
            "Epoch 118/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0694 - auc: 0.9952 - accuracy: 0.9795 - cost: 2.6204 - val_loss: 0.1143 - val_auc: 0.9897 - val_accuracy: 0.9681 - val_cost: 3.9253\n",
            "Epoch 119/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0704 - auc: 0.9951 - accuracy: 0.9785 - cost: 2.7442 - val_loss: 0.1146 - val_auc: 0.9897 - val_accuracy: 0.9672 - val_cost: 4.0079\n",
            "Epoch 120/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0697 - auc: 0.9951 - accuracy: 0.9794 - cost: 2.6389 - val_loss: 0.1132 - val_auc: 0.9896 - val_accuracy: 0.9686 - val_cost: 3.9583\n",
            "Epoch 121/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0694 - auc: 0.9952 - accuracy: 0.9794 - cost: 2.6350 - val_loss: 0.1125 - val_auc: 0.9898 - val_accuracy: 0.9684 - val_cost: 3.9451\n",
            "Epoch 122/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0691 - auc: 0.9953 - accuracy: 0.9796 - cost: 2.6103 - val_loss: 0.1143 - val_auc: 0.9895 - val_accuracy: 0.9692 - val_cost: 3.9286\n",
            "Epoch 123/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0693 - auc: 0.9953 - accuracy: 0.9797 - cost: 2.6030 - val_loss: 0.1159 - val_auc: 0.9892 - val_accuracy: 0.9686 - val_cost: 3.9683\n",
            "Epoch 124/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0684 - auc: 0.9954 - accuracy: 0.9794 - cost: 2.6427 - val_loss: 0.1135 - val_auc: 0.9897 - val_accuracy: 0.9681 - val_cost: 4.0377\n",
            "Epoch 125/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0692 - auc: 0.9953 - accuracy: 0.9792 - cost: 2.6532 - val_loss: 0.1115 - val_auc: 0.9900 - val_accuracy: 0.9689 - val_cost: 3.8790\n",
            "Epoch 126/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0682 - auc: 0.9953 - accuracy: 0.9798 - cost: 2.5791 - val_loss: 0.1151 - val_auc: 0.9896 - val_accuracy: 0.9685 - val_cost: 3.9153\n",
            "Epoch 127/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0681 - auc: 0.9953 - accuracy: 0.9801 - cost: 2.5336 - val_loss: 0.1137 - val_auc: 0.9897 - val_accuracy: 0.9683 - val_cost: 4.0807\n",
            "Epoch 128/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0683 - auc: 0.9952 - accuracy: 0.9800 - cost: 2.5490 - val_loss: 0.1132 - val_auc: 0.9898 - val_accuracy: 0.9696 - val_cost: 3.8062\n",
            "Epoch 129/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0688 - auc: 0.9952 - accuracy: 0.9794 - cost: 2.6289 - val_loss: 0.1143 - val_auc: 0.9897 - val_accuracy: 0.9686 - val_cost: 3.9914\n",
            "Epoch 130/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0683 - auc: 0.9952 - accuracy: 0.9798 - cost: 2.5849 - val_loss: 0.1159 - val_auc: 0.9896 - val_accuracy: 0.9692 - val_cost: 3.7169\n",
            "Epoch 131/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0674 - auc: 0.9954 - accuracy: 0.9801 - cost: 2.5463 - val_loss: 0.1158 - val_auc: 0.9895 - val_accuracy: 0.9687 - val_cost: 3.9517\n",
            "Epoch 132/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0687 - auc: 0.9953 - accuracy: 0.9797 - cost: 2.5961 - val_loss: 0.1166 - val_auc: 0.9893 - val_accuracy: 0.9674 - val_cost: 4.1766\n",
            "Epoch 133/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0670 - auc: 0.9955 - accuracy: 0.9800 - cost: 2.5517 - val_loss: 0.1157 - val_auc: 0.9895 - val_accuracy: 0.9690 - val_cost: 3.8426\n",
            "Epoch 134/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0676 - auc: 0.9953 - accuracy: 0.9801 - cost: 2.5544 - val_loss: 0.1132 - val_auc: 0.9896 - val_accuracy: 0.9688 - val_cost: 3.8790\n",
            "Epoch 135/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0672 - auc: 0.9954 - accuracy: 0.9802 - cost: 2.5432 - val_loss: 0.1157 - val_auc: 0.9899 - val_accuracy: 0.9678 - val_cost: 3.9980\n",
            "Epoch 136/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0674 - auc: 0.9954 - accuracy: 0.9800 - cost: 2.5625 - val_loss: 0.1154 - val_auc: 0.9898 - val_accuracy: 0.9689 - val_cost: 3.9286\n",
            "Epoch 137/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0668 - auc: 0.9954 - accuracy: 0.9801 - cost: 2.5367 - val_loss: 0.1149 - val_auc: 0.9894 - val_accuracy: 0.9696 - val_cost: 3.8492\n",
            "Epoch 138/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0666 - auc: 0.9956 - accuracy: 0.9806 - cost: 2.4776 - val_loss: 0.1143 - val_auc: 0.9897 - val_accuracy: 0.9685 - val_cost: 4.0046\n",
            "Epoch 139/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0670 - auc: 0.9955 - accuracy: 0.9803 - cost: 2.5328 - val_loss: 0.1136 - val_auc: 0.9897 - val_accuracy: 0.9694 - val_cost: 3.8360\n",
            "Epoch 140/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0664 - auc: 0.9955 - accuracy: 0.9801 - cost: 2.5413 - val_loss: 0.1171 - val_auc: 0.9896 - val_accuracy: 0.9697 - val_cost: 3.7599\n",
            "Epoch 141/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0666 - auc: 0.9955 - accuracy: 0.9801 - cost: 2.5448 - val_loss: 0.1148 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.7500\n",
            "Epoch 142/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0665 - auc: 0.9955 - accuracy: 0.9801 - cost: 2.5502 - val_loss: 0.1147 - val_auc: 0.9897 - val_accuracy: 0.9692 - val_cost: 3.9649\n",
            "Epoch 143/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0662 - auc: 0.9955 - accuracy: 0.9804 - cost: 2.5100 - val_loss: 0.1141 - val_auc: 0.9899 - val_accuracy: 0.9690 - val_cost: 3.8757\n",
            "Epoch 144/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0662 - auc: 0.9955 - accuracy: 0.9805 - cost: 2.4934 - val_loss: 0.1163 - val_auc: 0.9895 - val_accuracy: 0.9683 - val_cost: 4.0509\n",
            "Epoch 145/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0654 - auc: 0.9956 - accuracy: 0.9807 - cost: 2.4680 - val_loss: 0.1170 - val_auc: 0.9896 - val_accuracy: 0.9686 - val_cost: 4.1005\n",
            "Epoch 146/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0656 - auc: 0.9955 - accuracy: 0.9805 - cost: 2.4888 - val_loss: 0.1154 - val_auc: 0.9897 - val_accuracy: 0.9694 - val_cost: 3.8657\n",
            "Epoch 147/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0655 - auc: 0.9955 - accuracy: 0.9803 - cost: 2.5324 - val_loss: 0.1171 - val_auc: 0.9897 - val_accuracy: 0.9680 - val_cost: 3.9683\n",
            "Epoch 148/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0660 - auc: 0.9955 - accuracy: 0.9803 - cost: 2.5208 - val_loss: 0.1147 - val_auc: 0.9892 - val_accuracy: 0.9688 - val_cost: 3.9385\n",
            "Epoch 149/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0660 - auc: 0.9955 - accuracy: 0.9803 - cost: 2.5170 - val_loss: 0.1153 - val_auc: 0.9895 - val_accuracy: 0.9681 - val_cost: 3.9484\n",
            "Epoch 150/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0650 - auc: 0.9957 - accuracy: 0.9806 - cost: 2.4792 - val_loss: 0.1172 - val_auc: 0.9893 - val_accuracy: 0.9694 - val_cost: 3.8492\n",
            "Epoch 151/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0655 - auc: 0.9956 - accuracy: 0.9807 - cost: 2.4734 - val_loss: 0.1207 - val_auc: 0.9890 - val_accuracy: 0.9672 - val_cost: 4.2130\n",
            "Epoch 152/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0646 - auc: 0.9957 - accuracy: 0.9807 - cost: 2.4657 - val_loss: 0.1171 - val_auc: 0.9892 - val_accuracy: 0.9690 - val_cost: 3.9616\n",
            "Epoch 153/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0641 - auc: 0.9957 - accuracy: 0.9810 - cost: 2.4279 - val_loss: 0.1178 - val_auc: 0.9893 - val_accuracy: 0.9688 - val_cost: 4.0509\n",
            "Epoch 154/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0648 - auc: 0.9956 - accuracy: 0.9807 - cost: 2.4707 - val_loss: 0.1165 - val_auc: 0.9897 - val_accuracy: 0.9691 - val_cost: 3.8459\n",
            "Epoch 155/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0639 - auc: 0.9959 - accuracy: 0.9808 - cost: 2.4387 - val_loss: 0.1178 - val_auc: 0.9895 - val_accuracy: 0.9692 - val_cost: 3.8261\n",
            "Epoch 156/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0645 - auc: 0.9957 - accuracy: 0.9812 - cost: 2.4101 - val_loss: 0.1159 - val_auc: 0.9894 - val_accuracy: 0.9689 - val_cost: 3.8426\n",
            "Epoch 157/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0651 - auc: 0.9957 - accuracy: 0.9811 - cost: 2.4186 - val_loss: 0.1190 - val_auc: 0.9895 - val_accuracy: 0.9688 - val_cost: 3.8029\n",
            "Epoch 158/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0645 - auc: 0.9958 - accuracy: 0.9809 - cost: 2.4510 - val_loss: 0.1162 - val_auc: 0.9895 - val_accuracy: 0.9688 - val_cost: 3.9187\n",
            "Epoch 159/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0650 - auc: 0.9957 - accuracy: 0.9809 - cost: 2.4498 - val_loss: 0.1153 - val_auc: 0.9895 - val_accuracy: 0.9687 - val_cost: 3.9352\n",
            "Epoch 160/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0644 - auc: 0.9957 - accuracy: 0.9811 - cost: 2.4159 - val_loss: 0.1166 - val_auc: 0.9897 - val_accuracy: 0.9691 - val_cost: 3.9021\n",
            "Epoch 161/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0642 - auc: 0.9958 - accuracy: 0.9812 - cost: 2.4120 - val_loss: 0.1178 - val_auc: 0.9895 - val_accuracy: 0.9690 - val_cost: 3.8856\n",
            "Epoch 162/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0643 - auc: 0.9957 - accuracy: 0.9809 - cost: 2.4522 - val_loss: 0.1146 - val_auc: 0.9895 - val_accuracy: 0.9692 - val_cost: 3.8525\n",
            "Epoch 163/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0642 - auc: 0.9957 - accuracy: 0.9810 - cost: 2.4244 - val_loss: 0.1175 - val_auc: 0.9895 - val_accuracy: 0.9690 - val_cost: 3.9187\n",
            "Epoch 164/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0641 - auc: 0.9957 - accuracy: 0.9809 - cost: 2.4541 - val_loss: 0.1185 - val_auc: 0.9890 - val_accuracy: 0.9686 - val_cost: 4.0179\n",
            "Epoch 165/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0636 - auc: 0.9958 - accuracy: 0.9814 - cost: 2.3951 - val_loss: 0.1180 - val_auc: 0.9894 - val_accuracy: 0.9683 - val_cost: 3.9286\n",
            "Epoch 166/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0646 - auc: 0.9957 - accuracy: 0.9808 - cost: 2.4549 - val_loss: 0.1177 - val_auc: 0.9894 - val_accuracy: 0.9685 - val_cost: 4.0179\n",
            "Epoch 167/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0637 - auc: 0.9958 - accuracy: 0.9814 - cost: 2.3873 - val_loss: 0.1181 - val_auc: 0.9893 - val_accuracy: 0.9678 - val_cost: 4.0476\n",
            "Epoch 168/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0629 - auc: 0.9959 - accuracy: 0.9812 - cost: 2.4039 - val_loss: 0.1174 - val_auc: 0.9894 - val_accuracy: 0.9694 - val_cost: 3.8790\n",
            "Epoch 169/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0631 - auc: 0.9958 - accuracy: 0.9813 - cost: 2.3943 - val_loss: 0.1188 - val_auc: 0.9893 - val_accuracy: 0.9681 - val_cost: 3.9550\n",
            "Epoch 170/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0629 - auc: 0.9958 - accuracy: 0.9813 - cost: 2.3889 - val_loss: 0.1162 - val_auc: 0.9895 - val_accuracy: 0.9680 - val_cost: 3.9716\n",
            "Epoch 171/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0633 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3488 - val_loss: 0.1187 - val_auc: 0.9892 - val_accuracy: 0.9689 - val_cost: 3.8657\n",
            "Epoch 172/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0645 - auc: 0.9956 - accuracy: 0.9811 - cost: 2.4120 - val_loss: 0.1172 - val_auc: 0.9893 - val_accuracy: 0.9694 - val_cost: 3.8228\n",
            "Epoch 173/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0626 - auc: 0.9958 - accuracy: 0.9813 - cost: 2.3816 - val_loss: 0.1182 - val_auc: 0.9894 - val_accuracy: 0.9690 - val_cost: 3.8492\n",
            "Epoch 174/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0621 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3391 - val_loss: 0.1189 - val_auc: 0.9893 - val_accuracy: 0.9692 - val_cost: 3.8657\n",
            "Epoch 175/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0615 - auc: 0.9960 - accuracy: 0.9815 - cost: 2.3681 - val_loss: 0.1204 - val_auc: 0.9892 - val_accuracy: 0.9694 - val_cost: 3.8591\n",
            "Epoch 176/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0629 - auc: 0.9959 - accuracy: 0.9811 - cost: 2.4117 - val_loss: 0.1175 - val_auc: 0.9893 - val_accuracy: 0.9683 - val_cost: 3.9914\n",
            "Epoch 177/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0624 - auc: 0.9958 - accuracy: 0.9812 - cost: 2.4097 - val_loss: 0.1181 - val_auc: 0.9894 - val_accuracy: 0.9692 - val_cost: 3.8558\n",
            "Epoch 178/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0620 - auc: 0.9959 - accuracy: 0.9818 - cost: 2.3326 - val_loss: 0.1175 - val_auc: 0.9894 - val_accuracy: 0.9702 - val_cost: 3.7864\n",
            "Epoch 179/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0627 - auc: 0.9958 - accuracy: 0.9813 - cost: 2.4070 - val_loss: 0.1183 - val_auc: 0.9893 - val_accuracy: 0.9703 - val_cost: 3.7467\n",
            "Epoch 180/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0619 - auc: 0.9960 - accuracy: 0.9816 - cost: 2.3588 - val_loss: 0.1219 - val_auc: 0.9886 - val_accuracy: 0.9680 - val_cost: 4.0079\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.1050 - auc: 0.9909 - accuracy: 0.9696 - cost: 3.7531\n",
            "500/500 [==============================] - 1s 962us/step\n",
            "fold train/predict time: 0:01:23.817172\n",
            "fold accuracy: 0.9695624709129333 - fold cost: 3.753124952316284\n",
            "x_train shape: (144000, 67)\n",
            "Epoch 1/1000\n",
            "120/120 [==============================] - 2s 6ms/step - loss: 0.5305 - auc: 0.7972 - accuracy: 0.7281 - cost: 36.2566 - val_loss: 0.3996 - val_auc: 0.8989 - val_accuracy: 0.8243 - val_cost: 22.8274\n",
            "Epoch 2/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.3518 - auc: 0.9213 - accuracy: 0.8488 - cost: 19.2631 - val_loss: 0.3196 - val_auc: 0.9350 - val_accuracy: 0.8646 - val_cost: 17.2553\n",
            "Epoch 3/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.3013 - auc: 0.9425 - accuracy: 0.8748 - cost: 15.8692 - val_loss: 0.2898 - val_auc: 0.9468 - val_accuracy: 0.8793 - val_cost: 15.2910\n",
            "Epoch 4/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2730 - auc: 0.9529 - accuracy: 0.8891 - cost: 14.0297 - val_loss: 0.2627 - val_auc: 0.9565 - val_accuracy: 0.8928 - val_cost: 13.3862\n",
            "Epoch 5/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2497 - auc: 0.9606 - accuracy: 0.9004 - cost: 12.5953 - val_loss: 0.2428 - val_auc: 0.9627 - val_accuracy: 0.9047 - val_cost: 11.9345\n",
            "Epoch 6/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2308 - auc: 0.9663 - accuracy: 0.9099 - cost: 11.3958 - val_loss: 0.2277 - val_auc: 0.9671 - val_accuracy: 0.9128 - val_cost: 10.9656\n",
            "Epoch 7/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2147 - auc: 0.9708 - accuracy: 0.9165 - cost: 10.5521 - val_loss: 0.2136 - val_auc: 0.9713 - val_accuracy: 0.9207 - val_cost: 9.7586\n",
            "Epoch 8/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.2021 - auc: 0.9739 - accuracy: 0.9223 - cost: 9.7978 - val_loss: 0.2028 - val_auc: 0.9745 - val_accuracy: 0.9242 - val_cost: 9.2163\n",
            "Epoch 9/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1916 - auc: 0.9765 - accuracy: 0.9272 - cost: 9.2006 - val_loss: 0.1911 - val_auc: 0.9768 - val_accuracy: 0.9282 - val_cost: 9.0146\n",
            "Epoch 10/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1823 - auc: 0.9786 - accuracy: 0.9319 - cost: 8.6165 - val_loss: 0.1826 - val_auc: 0.9784 - val_accuracy: 0.9330 - val_cost: 8.5979\n",
            "Epoch 11/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1737 - auc: 0.9805 - accuracy: 0.9358 - cost: 8.1184 - val_loss: 0.1765 - val_auc: 0.9798 - val_accuracy: 0.9363 - val_cost: 7.8968\n",
            "Epoch 12/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1679 - auc: 0.9816 - accuracy: 0.9386 - cost: 7.7708 - val_loss: 0.1708 - val_auc: 0.9809 - val_accuracy: 0.9395 - val_cost: 7.5728\n",
            "Epoch 13/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1615 - auc: 0.9829 - accuracy: 0.9410 - cost: 7.4792 - val_loss: 0.1666 - val_auc: 0.9818 - val_accuracy: 0.9418 - val_cost: 7.1825\n",
            "Epoch 14/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1562 - auc: 0.9838 - accuracy: 0.9439 - cost: 7.0945 - val_loss: 0.1610 - val_auc: 0.9827 - val_accuracy: 0.9453 - val_cost: 6.9775\n",
            "Epoch 15/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1528 - auc: 0.9845 - accuracy: 0.9452 - cost: 6.9390 - val_loss: 0.1579 - val_auc: 0.9834 - val_accuracy: 0.9445 - val_cost: 6.9841\n",
            "Epoch 16/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1480 - auc: 0.9853 - accuracy: 0.9472 - cost: 6.6991 - val_loss: 0.1550 - val_auc: 0.9840 - val_accuracy: 0.9459 - val_cost: 6.7791\n",
            "Epoch 17/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1460 - auc: 0.9855 - accuracy: 0.9484 - cost: 6.5440 - val_loss: 0.1541 - val_auc: 0.9841 - val_accuracy: 0.9461 - val_cost: 6.7890\n",
            "Epoch 18/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1419 - auc: 0.9863 - accuracy: 0.9504 - cost: 6.2843 - val_loss: 0.1529 - val_auc: 0.9842 - val_accuracy: 0.9464 - val_cost: 6.7659\n",
            "Epoch 19/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1401 - auc: 0.9866 - accuracy: 0.9507 - cost: 6.2577 - val_loss: 0.1505 - val_auc: 0.9847 - val_accuracy: 0.9472 - val_cost: 6.6402\n",
            "Epoch 20/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1384 - auc: 0.9868 - accuracy: 0.9519 - cost: 6.0922 - val_loss: 0.1472 - val_auc: 0.9852 - val_accuracy: 0.9490 - val_cost: 6.5311\n",
            "Epoch 21/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1346 - auc: 0.9875 - accuracy: 0.9536 - cost: 5.8866 - val_loss: 0.1468 - val_auc: 0.9851 - val_accuracy: 0.9498 - val_cost: 6.3492\n",
            "Epoch 22/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1323 - auc: 0.9879 - accuracy: 0.9541 - cost: 5.8164 - val_loss: 0.1454 - val_auc: 0.9855 - val_accuracy: 0.9496 - val_cost: 6.4749\n",
            "Epoch 23/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1303 - auc: 0.9882 - accuracy: 0.9556 - cost: 5.6370 - val_loss: 0.1427 - val_auc: 0.9859 - val_accuracy: 0.9517 - val_cost: 6.0880\n",
            "Epoch 24/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1282 - auc: 0.9885 - accuracy: 0.9561 - cost: 5.5652 - val_loss: 0.1433 - val_auc: 0.9858 - val_accuracy: 0.9515 - val_cost: 6.0483\n",
            "Epoch 25/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1278 - auc: 0.9885 - accuracy: 0.9564 - cost: 5.5201 - val_loss: 0.1410 - val_auc: 0.9861 - val_accuracy: 0.9529 - val_cost: 6.0615\n",
            "Epoch 26/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1246 - auc: 0.9889 - accuracy: 0.9580 - cost: 5.3183 - val_loss: 0.1411 - val_auc: 0.9861 - val_accuracy: 0.9536 - val_cost: 5.8300\n",
            "Epoch 27/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1234 - auc: 0.9893 - accuracy: 0.9582 - cost: 5.2978 - val_loss: 0.1396 - val_auc: 0.9861 - val_accuracy: 0.9546 - val_cost: 5.8267\n",
            "Epoch 28/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1219 - auc: 0.9894 - accuracy: 0.9588 - cost: 5.2265 - val_loss: 0.1394 - val_auc: 0.9862 - val_accuracy: 0.9534 - val_cost: 5.9524\n",
            "Epoch 29/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1201 - auc: 0.9897 - accuracy: 0.9594 - cost: 5.1485 - val_loss: 0.1386 - val_auc: 0.9862 - val_accuracy: 0.9551 - val_cost: 5.6415\n",
            "Epoch 30/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1193 - auc: 0.9897 - accuracy: 0.9598 - cost: 5.1061 - val_loss: 0.1364 - val_auc: 0.9867 - val_accuracy: 0.9554 - val_cost: 5.5589\n",
            "Epoch 31/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1177 - auc: 0.9900 - accuracy: 0.9607 - cost: 4.9730 - val_loss: 0.1351 - val_auc: 0.9868 - val_accuracy: 0.9573 - val_cost: 5.3803\n",
            "Epoch 32/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1160 - auc: 0.9902 - accuracy: 0.9611 - cost: 4.9302 - val_loss: 0.1335 - val_auc: 0.9869 - val_accuracy: 0.9572 - val_cost: 5.3604\n",
            "Epoch 33/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1150 - auc: 0.9902 - accuracy: 0.9617 - cost: 4.8584 - val_loss: 0.1334 - val_auc: 0.9871 - val_accuracy: 0.9576 - val_cost: 5.2414\n",
            "Epoch 34/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1124 - auc: 0.9906 - accuracy: 0.9626 - cost: 4.7504 - val_loss: 0.1338 - val_auc: 0.9870 - val_accuracy: 0.9566 - val_cost: 5.5159\n",
            "Epoch 35/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1120 - auc: 0.9907 - accuracy: 0.9630 - cost: 4.6902 - val_loss: 0.1314 - val_auc: 0.9872 - val_accuracy: 0.9590 - val_cost: 5.1720\n",
            "Epoch 36/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1118 - auc: 0.9907 - accuracy: 0.9636 - cost: 4.6211 - val_loss: 0.1333 - val_auc: 0.9873 - val_accuracy: 0.9576 - val_cost: 5.1786\n",
            "Epoch 37/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1099 - auc: 0.9910 - accuracy: 0.9639 - cost: 4.5810 - val_loss: 0.1314 - val_auc: 0.9873 - val_accuracy: 0.9591 - val_cost: 5.1290\n",
            "Epoch 38/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1082 - auc: 0.9912 - accuracy: 0.9648 - cost: 4.4583 - val_loss: 0.1322 - val_auc: 0.9870 - val_accuracy: 0.9593 - val_cost: 5.0033\n",
            "Epoch 39/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1072 - auc: 0.9912 - accuracy: 0.9649 - cost: 4.4587 - val_loss: 0.1289 - val_auc: 0.9876 - val_accuracy: 0.9613 - val_cost: 4.8909\n",
            "Epoch 40/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1063 - auc: 0.9914 - accuracy: 0.9653 - cost: 4.4063 - val_loss: 0.1277 - val_auc: 0.9877 - val_accuracy: 0.9603 - val_cost: 5.0959\n",
            "Epoch 41/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1046 - auc: 0.9916 - accuracy: 0.9657 - cost: 4.3519 - val_loss: 0.1291 - val_auc: 0.9875 - val_accuracy: 0.9599 - val_cost: 4.9702\n",
            "Epoch 42/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1043 - auc: 0.9916 - accuracy: 0.9663 - cost: 4.2901 - val_loss: 0.1283 - val_auc: 0.9874 - val_accuracy: 0.9608 - val_cost: 4.8710\n",
            "Epoch 43/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1035 - auc: 0.9917 - accuracy: 0.9666 - cost: 4.2531 - val_loss: 0.1254 - val_auc: 0.9879 - val_accuracy: 0.9620 - val_cost: 4.7784\n",
            "Epoch 44/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1015 - auc: 0.9920 - accuracy: 0.9672 - cost: 4.1813 - val_loss: 0.1260 - val_auc: 0.9879 - val_accuracy: 0.9617 - val_cost: 4.7851\n",
            "Epoch 45/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1004 - auc: 0.9921 - accuracy: 0.9676 - cost: 4.1242 - val_loss: 0.1252 - val_auc: 0.9879 - val_accuracy: 0.9613 - val_cost: 4.9438\n",
            "Epoch 46/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0992 - auc: 0.9922 - accuracy: 0.9682 - cost: 4.0579 - val_loss: 0.1269 - val_auc: 0.9879 - val_accuracy: 0.9620 - val_cost: 4.5833\n",
            "Epoch 47/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0992 - auc: 0.9922 - accuracy: 0.9682 - cost: 4.0428 - val_loss: 0.1243 - val_auc: 0.9881 - val_accuracy: 0.9624 - val_cost: 4.7685\n",
            "Epoch 48/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0976 - auc: 0.9923 - accuracy: 0.9689 - cost: 3.9564 - val_loss: 0.1241 - val_auc: 0.9879 - val_accuracy: 0.9625 - val_cost: 4.5966\n",
            "Epoch 49/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0970 - auc: 0.9925 - accuracy: 0.9691 - cost: 3.9228 - val_loss: 0.1211 - val_auc: 0.9884 - val_accuracy: 0.9636 - val_cost: 4.7024\n",
            "Epoch 50/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0959 - auc: 0.9925 - accuracy: 0.9692 - cost: 3.9271 - val_loss: 0.1223 - val_auc: 0.9884 - val_accuracy: 0.9629 - val_cost: 4.5966\n",
            "Epoch 51/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0956 - auc: 0.9925 - accuracy: 0.9696 - cost: 3.8507 - val_loss: 0.1214 - val_auc: 0.9883 - val_accuracy: 0.9638 - val_cost: 4.4676\n",
            "Epoch 52/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0950 - auc: 0.9926 - accuracy: 0.9695 - cost: 3.8738 - val_loss: 0.1211 - val_auc: 0.9884 - val_accuracy: 0.9626 - val_cost: 4.8479\n",
            "Epoch 53/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0942 - auc: 0.9928 - accuracy: 0.9701 - cost: 3.8137 - val_loss: 0.1206 - val_auc: 0.9884 - val_accuracy: 0.9633 - val_cost: 4.6131\n",
            "Epoch 54/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0933 - auc: 0.9928 - accuracy: 0.9705 - cost: 3.7431 - val_loss: 0.1198 - val_auc: 0.9885 - val_accuracy: 0.9640 - val_cost: 4.5271\n",
            "Epoch 55/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0928 - auc: 0.9929 - accuracy: 0.9709 - cost: 3.7091 - val_loss: 0.1196 - val_auc: 0.9887 - val_accuracy: 0.9649 - val_cost: 4.5271\n",
            "Epoch 56/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0922 - auc: 0.9930 - accuracy: 0.9709 - cost: 3.7010 - val_loss: 0.1188 - val_auc: 0.9887 - val_accuracy: 0.9644 - val_cost: 4.3981\n",
            "Epoch 57/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0916 - auc: 0.9930 - accuracy: 0.9708 - cost: 3.7122 - val_loss: 0.1181 - val_auc: 0.9887 - val_accuracy: 0.9660 - val_cost: 4.2791\n",
            "Epoch 58/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0904 - auc: 0.9931 - accuracy: 0.9717 - cost: 3.5961 - val_loss: 0.1186 - val_auc: 0.9885 - val_accuracy: 0.9656 - val_cost: 4.2097\n",
            "Epoch 59/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0902 - auc: 0.9931 - accuracy: 0.9717 - cost: 3.6061 - val_loss: 0.1180 - val_auc: 0.9888 - val_accuracy: 0.9657 - val_cost: 4.2758\n",
            "Epoch 60/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0894 - auc: 0.9931 - accuracy: 0.9722 - cost: 3.5332 - val_loss: 0.1179 - val_auc: 0.9888 - val_accuracy: 0.9655 - val_cost: 4.3552\n",
            "Epoch 61/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0886 - auc: 0.9932 - accuracy: 0.9721 - cost: 3.5598 - val_loss: 0.1152 - val_auc: 0.9890 - val_accuracy: 0.9661 - val_cost: 4.2526\n",
            "Epoch 62/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0879 - auc: 0.9933 - accuracy: 0.9723 - cost: 3.5231 - val_loss: 0.1144 - val_auc: 0.9892 - val_accuracy: 0.9680 - val_cost: 3.9517\n",
            "Epoch 63/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0878 - auc: 0.9933 - accuracy: 0.9727 - cost: 3.4811 - val_loss: 0.1161 - val_auc: 0.9891 - val_accuracy: 0.9658 - val_cost: 4.3056\n",
            "Epoch 64/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0865 - auc: 0.9935 - accuracy: 0.9728 - cost: 3.4653 - val_loss: 0.1159 - val_auc: 0.9890 - val_accuracy: 0.9669 - val_cost: 4.1336\n",
            "Epoch 65/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0859 - auc: 0.9936 - accuracy: 0.9732 - cost: 3.4155 - val_loss: 0.1142 - val_auc: 0.9891 - val_accuracy: 0.9675 - val_cost: 4.0476\n",
            "Epoch 66/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0867 - auc: 0.9934 - accuracy: 0.9731 - cost: 3.4225 - val_loss: 0.1153 - val_auc: 0.9889 - val_accuracy: 0.9663 - val_cost: 4.2130\n",
            "Epoch 67/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0853 - auc: 0.9936 - accuracy: 0.9731 - cost: 3.4271 - val_loss: 0.1137 - val_auc: 0.9889 - val_accuracy: 0.9669 - val_cost: 4.1237\n",
            "Epoch 68/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0850 - auc: 0.9937 - accuracy: 0.9734 - cost: 3.4008 - val_loss: 0.1146 - val_auc: 0.9895 - val_accuracy: 0.9676 - val_cost: 4.0476\n",
            "Epoch 69/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0844 - auc: 0.9937 - accuracy: 0.9736 - cost: 3.3731 - val_loss: 0.1134 - val_auc: 0.9891 - val_accuracy: 0.9676 - val_cost: 4.0344\n",
            "Epoch 70/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0828 - auc: 0.9939 - accuracy: 0.9745 - cost: 3.2496 - val_loss: 0.1122 - val_auc: 0.9893 - val_accuracy: 0.9667 - val_cost: 4.1799\n",
            "Epoch 71/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0828 - auc: 0.9938 - accuracy: 0.9744 - cost: 3.2643 - val_loss: 0.1121 - val_auc: 0.9894 - val_accuracy: 0.9681 - val_cost: 3.9550\n",
            "Epoch 72/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0834 - auc: 0.9938 - accuracy: 0.9746 - cost: 3.2458 - val_loss: 0.1126 - val_auc: 0.9891 - val_accuracy: 0.9681 - val_cost: 4.0443\n",
            "Epoch 73/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0821 - auc: 0.9940 - accuracy: 0.9747 - cost: 3.2384 - val_loss: 0.1134 - val_auc: 0.9892 - val_accuracy: 0.9678 - val_cost: 3.9517\n",
            "Epoch 74/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0821 - auc: 0.9939 - accuracy: 0.9747 - cost: 3.2261 - val_loss: 0.1115 - val_auc: 0.9892 - val_accuracy: 0.9686 - val_cost: 3.9517\n",
            "Epoch 75/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0822 - auc: 0.9940 - accuracy: 0.9748 - cost: 3.1975 - val_loss: 0.1128 - val_auc: 0.9893 - val_accuracy: 0.9676 - val_cost: 4.1303\n",
            "Epoch 76/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0812 - auc: 0.9940 - accuracy: 0.9754 - cost: 3.1431 - val_loss: 0.1110 - val_auc: 0.9894 - val_accuracy: 0.9688 - val_cost: 3.8856\n",
            "Epoch 77/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0807 - auc: 0.9940 - accuracy: 0.9753 - cost: 3.1358 - val_loss: 0.1116 - val_auc: 0.9892 - val_accuracy: 0.9685 - val_cost: 3.9550\n",
            "Epoch 78/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0803 - auc: 0.9941 - accuracy: 0.9754 - cost: 3.1377 - val_loss: 0.1131 - val_auc: 0.9890 - val_accuracy: 0.9678 - val_cost: 3.9649\n",
            "Epoch 79/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0797 - auc: 0.9941 - accuracy: 0.9754 - cost: 3.1539 - val_loss: 0.1119 - val_auc: 0.9893 - val_accuracy: 0.9681 - val_cost: 4.0112\n",
            "Epoch 80/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0787 - auc: 0.9943 - accuracy: 0.9761 - cost: 3.0613 - val_loss: 0.1108 - val_auc: 0.9896 - val_accuracy: 0.9683 - val_cost: 3.9947\n",
            "Epoch 81/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0798 - auc: 0.9942 - accuracy: 0.9756 - cost: 3.1119 - val_loss: 0.1107 - val_auc: 0.9891 - val_accuracy: 0.9696 - val_cost: 3.7632\n",
            "Epoch 82/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0788 - auc: 0.9943 - accuracy: 0.9759 - cost: 3.0883 - val_loss: 0.1102 - val_auc: 0.9893 - val_accuracy: 0.9694 - val_cost: 3.8194\n",
            "Epoch 83/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0791 - auc: 0.9942 - accuracy: 0.9754 - cost: 3.1481 - val_loss: 0.1110 - val_auc: 0.9894 - val_accuracy: 0.9687 - val_cost: 4.0013\n",
            "Epoch 84/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0779 - auc: 0.9943 - accuracy: 0.9764 - cost: 3.0062 - val_loss: 0.1100 - val_auc: 0.9894 - val_accuracy: 0.9688 - val_cost: 3.9782\n",
            "Epoch 85/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0782 - auc: 0.9944 - accuracy: 0.9763 - cost: 3.0397 - val_loss: 0.1106 - val_auc: 0.9893 - val_accuracy: 0.9692 - val_cost: 3.8790\n",
            "Epoch 86/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0776 - auc: 0.9943 - accuracy: 0.9761 - cost: 3.0532 - val_loss: 0.1099 - val_auc: 0.9893 - val_accuracy: 0.9694 - val_cost: 3.9120\n",
            "Epoch 87/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0785 - auc: 0.9942 - accuracy: 0.9757 - cost: 3.0864 - val_loss: 0.1111 - val_auc: 0.9895 - val_accuracy: 0.9694 - val_cost: 3.9319\n",
            "Epoch 88/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0768 - auc: 0.9944 - accuracy: 0.9763 - cost: 3.0208 - val_loss: 0.1100 - val_auc: 0.9894 - val_accuracy: 0.9686 - val_cost: 4.0245\n",
            "Epoch 89/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0773 - auc: 0.9944 - accuracy: 0.9766 - cost: 2.9923 - val_loss: 0.1085 - val_auc: 0.9896 - val_accuracy: 0.9690 - val_cost: 3.9616\n",
            "Epoch 90/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0759 - auc: 0.9945 - accuracy: 0.9773 - cost: 2.8997 - val_loss: 0.1100 - val_auc: 0.9893 - val_accuracy: 0.9690 - val_cost: 3.8955\n",
            "Epoch 91/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0763 - auc: 0.9945 - accuracy: 0.9770 - cost: 2.9267 - val_loss: 0.1105 - val_auc: 0.9893 - val_accuracy: 0.9686 - val_cost: 3.9319\n",
            "Epoch 92/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0758 - auc: 0.9946 - accuracy: 0.9770 - cost: 2.9421 - val_loss: 0.1130 - val_auc: 0.9893 - val_accuracy: 0.9681 - val_cost: 3.9187\n",
            "Epoch 93/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0752 - auc: 0.9945 - accuracy: 0.9770 - cost: 2.9394 - val_loss: 0.1093 - val_auc: 0.9895 - val_accuracy: 0.9689 - val_cost: 3.9021\n",
            "Epoch 94/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0748 - auc: 0.9947 - accuracy: 0.9774 - cost: 2.8908 - val_loss: 0.1105 - val_auc: 0.9895 - val_accuracy: 0.9700 - val_cost: 3.6938\n",
            "Epoch 95/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0751 - auc: 0.9947 - accuracy: 0.9770 - cost: 2.9321 - val_loss: 0.1098 - val_auc: 0.9895 - val_accuracy: 0.9697 - val_cost: 3.8393\n",
            "Epoch 96/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0751 - auc: 0.9946 - accuracy: 0.9770 - cost: 2.9309 - val_loss: 0.1110 - val_auc: 0.9895 - val_accuracy: 0.9688 - val_cost: 4.0476\n",
            "Epoch 97/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0744 - auc: 0.9946 - accuracy: 0.9776 - cost: 2.8615 - val_loss: 0.1091 - val_auc: 0.9895 - val_accuracy: 0.9697 - val_cost: 3.8757\n",
            "Epoch 98/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0743 - auc: 0.9946 - accuracy: 0.9771 - cost: 2.9201 - val_loss: 0.1100 - val_auc: 0.9896 - val_accuracy: 0.9690 - val_cost: 3.8095\n",
            "Epoch 99/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0745 - auc: 0.9947 - accuracy: 0.9776 - cost: 2.8561 - val_loss: 0.1093 - val_auc: 0.9895 - val_accuracy: 0.9697 - val_cost: 3.7533\n",
            "Epoch 100/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0730 - auc: 0.9949 - accuracy: 0.9774 - cost: 2.8754 - val_loss: 0.1099 - val_auc: 0.9894 - val_accuracy: 0.9691 - val_cost: 3.9021\n",
            "Epoch 101/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0738 - auc: 0.9948 - accuracy: 0.9775 - cost: 2.8657 - val_loss: 0.1115 - val_auc: 0.9894 - val_accuracy: 0.9684 - val_cost: 4.0311\n",
            "Epoch 102/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0730 - auc: 0.9949 - accuracy: 0.9776 - cost: 2.8546 - val_loss: 0.1084 - val_auc: 0.9896 - val_accuracy: 0.9699 - val_cost: 3.8459\n",
            "Epoch 103/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0726 - auc: 0.9949 - accuracy: 0.9780 - cost: 2.8056 - val_loss: 0.1118 - val_auc: 0.9894 - val_accuracy: 0.9701 - val_cost: 3.7467\n",
            "Epoch 104/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0733 - auc: 0.9947 - accuracy: 0.9777 - cost: 2.8492 - val_loss: 0.1111 - val_auc: 0.9894 - val_accuracy: 0.9699 - val_cost: 3.7434\n",
            "Epoch 105/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0724 - auc: 0.9949 - accuracy: 0.9783 - cost: 2.7674 - val_loss: 0.1097 - val_auc: 0.9897 - val_accuracy: 0.9697 - val_cost: 3.8459\n",
            "Epoch 106/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0726 - auc: 0.9948 - accuracy: 0.9781 - cost: 2.8113 - val_loss: 0.1109 - val_auc: 0.9894 - val_accuracy: 0.9685 - val_cost: 3.9517\n",
            "Epoch 107/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0734 - auc: 0.9948 - accuracy: 0.9776 - cost: 2.8654 - val_loss: 0.1107 - val_auc: 0.9894 - val_accuracy: 0.9694 - val_cost: 3.9021\n",
            "Epoch 108/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0718 - auc: 0.9951 - accuracy: 0.9780 - cost: 2.8110 - val_loss: 0.1110 - val_auc: 0.9896 - val_accuracy: 0.9697 - val_cost: 3.8426\n",
            "Epoch 109/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0724 - auc: 0.9949 - accuracy: 0.9781 - cost: 2.7978 - val_loss: 0.1109 - val_auc: 0.9896 - val_accuracy: 0.9695 - val_cost: 3.7930\n",
            "Epoch 110/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0713 - auc: 0.9949 - accuracy: 0.9788 - cost: 2.7114 - val_loss: 0.1096 - val_auc: 0.9896 - val_accuracy: 0.9700 - val_cost: 3.7996\n",
            "Epoch 111/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0714 - auc: 0.9949 - accuracy: 0.9782 - cost: 2.7867 - val_loss: 0.1109 - val_auc: 0.9896 - val_accuracy: 0.9702 - val_cost: 3.8128\n",
            "Epoch 112/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0706 - auc: 0.9950 - accuracy: 0.9790 - cost: 2.6875 - val_loss: 0.1095 - val_auc: 0.9895 - val_accuracy: 0.9698 - val_cost: 3.8360\n",
            "Epoch 113/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0713 - auc: 0.9950 - accuracy: 0.9786 - cost: 2.7346 - val_loss: 0.1115 - val_auc: 0.9894 - val_accuracy: 0.9684 - val_cost: 3.8657\n",
            "Epoch 114/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0715 - auc: 0.9949 - accuracy: 0.9785 - cost: 2.7473 - val_loss: 0.1091 - val_auc: 0.9898 - val_accuracy: 0.9699 - val_cost: 3.9087\n",
            "Epoch 115/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0713 - auc: 0.9950 - accuracy: 0.9783 - cost: 2.7762 - val_loss: 0.1089 - val_auc: 0.9899 - val_accuracy: 0.9700 - val_cost: 3.8194\n",
            "Epoch 116/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0703 - auc: 0.9950 - accuracy: 0.9790 - cost: 2.6755 - val_loss: 0.1089 - val_auc: 0.9899 - val_accuracy: 0.9701 - val_cost: 3.8360\n",
            "Epoch 117/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0715 - auc: 0.9949 - accuracy: 0.9787 - cost: 2.7222 - val_loss: 0.1100 - val_auc: 0.9895 - val_accuracy: 0.9701 - val_cost: 3.7798\n",
            "Epoch 118/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0707 - auc: 0.9950 - accuracy: 0.9791 - cost: 2.6559 - val_loss: 0.1107 - val_auc: 0.9896 - val_accuracy: 0.9694 - val_cost: 3.8360\n",
            "Epoch 119/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0705 - auc: 0.9952 - accuracy: 0.9789 - cost: 2.6979 - val_loss: 0.1106 - val_auc: 0.9896 - val_accuracy: 0.9696 - val_cost: 3.8360\n",
            "Epoch 120/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0703 - auc: 0.9951 - accuracy: 0.9789 - cost: 2.6902 - val_loss: 0.1089 - val_auc: 0.9899 - val_accuracy: 0.9694 - val_cost: 3.9087\n",
            "Epoch 121/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0701 - auc: 0.9951 - accuracy: 0.9786 - cost: 2.7307 - val_loss: 0.1115 - val_auc: 0.9896 - val_accuracy: 0.9693 - val_cost: 3.9749\n",
            "Epoch 122/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0699 - auc: 0.9951 - accuracy: 0.9791 - cost: 2.6786 - val_loss: 0.1102 - val_auc: 0.9899 - val_accuracy: 0.9694 - val_cost: 3.8558\n",
            "Epoch 123/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0699 - auc: 0.9951 - accuracy: 0.9789 - cost: 2.6975 - val_loss: 0.1097 - val_auc: 0.9897 - val_accuracy: 0.9696 - val_cost: 3.9120\n",
            "Epoch 124/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0690 - auc: 0.9952 - accuracy: 0.9793 - cost: 2.6528 - val_loss: 0.1114 - val_auc: 0.9898 - val_accuracy: 0.9689 - val_cost: 3.9583\n",
            "Epoch 125/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0688 - auc: 0.9953 - accuracy: 0.9790 - cost: 2.6736 - val_loss: 0.1112 - val_auc: 0.9895 - val_accuracy: 0.9699 - val_cost: 3.8161\n",
            "Epoch 126/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0690 - auc: 0.9953 - accuracy: 0.9791 - cost: 2.6809 - val_loss: 0.1115 - val_auc: 0.9897 - val_accuracy: 0.9687 - val_cost: 4.0079\n",
            "Epoch 127/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0682 - auc: 0.9953 - accuracy: 0.9794 - cost: 2.6385 - val_loss: 0.1119 - val_auc: 0.9897 - val_accuracy: 0.9699 - val_cost: 3.8062\n",
            "Epoch 128/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0690 - auc: 0.9953 - accuracy: 0.9794 - cost: 2.6316 - val_loss: 0.1126 - val_auc: 0.9898 - val_accuracy: 0.9690 - val_cost: 3.8624\n",
            "Epoch 129/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0681 - auc: 0.9953 - accuracy: 0.9797 - cost: 2.5795 - val_loss: 0.1114 - val_auc: 0.9896 - val_accuracy: 0.9698 - val_cost: 3.9319\n",
            "Epoch 130/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0686 - auc: 0.9953 - accuracy: 0.9792 - cost: 2.6443 - val_loss: 0.1118 - val_auc: 0.9896 - val_accuracy: 0.9694 - val_cost: 3.9120\n",
            "Epoch 131/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0682 - auc: 0.9953 - accuracy: 0.9791 - cost: 2.6728 - val_loss: 0.1104 - val_auc: 0.9899 - val_accuracy: 0.9699 - val_cost: 3.8690\n",
            "Epoch 132/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0685 - auc: 0.9953 - accuracy: 0.9797 - cost: 2.5899 - val_loss: 0.1136 - val_auc: 0.9896 - val_accuracy: 0.9686 - val_cost: 3.9418\n",
            "Epoch 133/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0675 - auc: 0.9954 - accuracy: 0.9795 - cost: 2.6250 - val_loss: 0.1120 - val_auc: 0.9897 - val_accuracy: 0.9698 - val_cost: 3.8889\n",
            "Epoch 134/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0687 - auc: 0.9953 - accuracy: 0.9795 - cost: 2.6285 - val_loss: 0.1114 - val_auc: 0.9899 - val_accuracy: 0.9689 - val_cost: 3.9484\n",
            "Epoch 135/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0673 - auc: 0.9954 - accuracy: 0.9797 - cost: 2.5934 - val_loss: 0.1118 - val_auc: 0.9898 - val_accuracy: 0.9689 - val_cost: 3.9616\n",
            "Epoch 136/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0681 - auc: 0.9954 - accuracy: 0.9796 - cost: 2.6073 - val_loss: 0.1123 - val_auc: 0.9896 - val_accuracy: 0.9694 - val_cost: 3.9716\n",
            "Epoch 137/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0674 - auc: 0.9954 - accuracy: 0.9797 - cost: 2.5953 - val_loss: 0.1121 - val_auc: 0.9897 - val_accuracy: 0.9696 - val_cost: 3.9583\n",
            "Epoch 138/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0670 - auc: 0.9955 - accuracy: 0.9799 - cost: 2.5644 - val_loss: 0.1108 - val_auc: 0.9896 - val_accuracy: 0.9699 - val_cost: 3.8459\n",
            "Epoch 139/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0668 - auc: 0.9955 - accuracy: 0.9798 - cost: 2.5895 - val_loss: 0.1093 - val_auc: 0.9901 - val_accuracy: 0.9696 - val_cost: 3.9418\n",
            "Epoch 140/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0667 - auc: 0.9955 - accuracy: 0.9797 - cost: 2.5883 - val_loss: 0.1115 - val_auc: 0.9898 - val_accuracy: 0.9686 - val_cost: 3.9683\n",
            "Epoch 141/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0666 - auc: 0.9954 - accuracy: 0.9805 - cost: 2.4961 - val_loss: 0.1131 - val_auc: 0.9896 - val_accuracy: 0.9689 - val_cost: 3.9716\n",
            "Epoch 142/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0660 - auc: 0.9956 - accuracy: 0.9804 - cost: 2.5019 - val_loss: 0.1117 - val_auc: 0.9900 - val_accuracy: 0.9692 - val_cost: 3.9616\n",
            "Epoch 143/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0668 - auc: 0.9954 - accuracy: 0.9806 - cost: 2.4873 - val_loss: 0.1126 - val_auc: 0.9897 - val_accuracy: 0.9700 - val_cost: 3.8889\n",
            "Epoch 144/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0665 - auc: 0.9955 - accuracy: 0.9800 - cost: 2.5490 - val_loss: 0.1123 - val_auc: 0.9897 - val_accuracy: 0.9697 - val_cost: 3.8095\n",
            "Epoch 145/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0664 - auc: 0.9955 - accuracy: 0.9800 - cost: 2.5733 - val_loss: 0.1121 - val_auc: 0.9896 - val_accuracy: 0.9694 - val_cost: 4.0278\n",
            "Epoch 146/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0666 - auc: 0.9954 - accuracy: 0.9801 - cost: 2.5444 - val_loss: 0.1128 - val_auc: 0.9895 - val_accuracy: 0.9693 - val_cost: 3.9749\n",
            "Epoch 147/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0662 - auc: 0.9956 - accuracy: 0.9803 - cost: 2.5131 - val_loss: 0.1118 - val_auc: 0.9898 - val_accuracy: 0.9700 - val_cost: 3.8790\n",
            "Epoch 148/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0661 - auc: 0.9956 - accuracy: 0.9798 - cost: 2.5787 - val_loss: 0.1129 - val_auc: 0.9895 - val_accuracy: 0.9688 - val_cost: 3.9054\n",
            "Epoch 149/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0661 - auc: 0.9955 - accuracy: 0.9804 - cost: 2.5089 - val_loss: 0.1125 - val_auc: 0.9897 - val_accuracy: 0.9706 - val_cost: 3.7963\n",
            "Epoch 150/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0661 - auc: 0.9955 - accuracy: 0.9801 - cost: 2.5332 - val_loss: 0.1171 - val_auc: 0.9894 - val_accuracy: 0.9691 - val_cost: 3.8360\n",
            "Epoch 151/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0658 - auc: 0.9955 - accuracy: 0.9807 - cost: 2.4699 - val_loss: 0.1111 - val_auc: 0.9900 - val_accuracy: 0.9695 - val_cost: 3.9319\n",
            "Epoch 152/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0653 - auc: 0.9956 - accuracy: 0.9805 - cost: 2.5039 - val_loss: 0.1111 - val_auc: 0.9899 - val_accuracy: 0.9700 - val_cost: 3.7930\n",
            "Epoch 153/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0657 - auc: 0.9956 - accuracy: 0.9801 - cost: 2.5417 - val_loss: 0.1135 - val_auc: 0.9899 - val_accuracy: 0.9699 - val_cost: 3.9649\n",
            "Epoch 154/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0650 - auc: 0.9956 - accuracy: 0.9806 - cost: 2.4711 - val_loss: 0.1120 - val_auc: 0.9897 - val_accuracy: 0.9698 - val_cost: 3.8988\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.1055 - auc: 0.9905 - accuracy: 0.9703 - cost: 3.7469\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:01:15.901574\n",
            "fold accuracy: 0.9702500104904175 - fold cost: 3.746875047683716\n",
            "x_train shape: (144000, 67)\n",
            "Epoch 1/1000\n",
            "120/120 [==============================] - 2s 6ms/step - loss: 0.5329 - auc: 0.7947 - accuracy: 0.7258 - cost: 36.5664 - val_loss: 0.4023 - val_auc: 0.8973 - val_accuracy: 0.8249 - val_cost: 22.0403\n",
            "Epoch 2/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.3524 - auc: 0.9209 - accuracy: 0.8481 - cost: 19.3711 - val_loss: 0.3195 - val_auc: 0.9355 - val_accuracy: 0.8640 - val_cost: 16.6567\n",
            "Epoch 3/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.3027 - auc: 0.9420 - accuracy: 0.8746 - cost: 15.8654 - val_loss: 0.2882 - val_auc: 0.9476 - val_accuracy: 0.8817 - val_cost: 14.7751\n",
            "Epoch 4/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2740 - auc: 0.9526 - accuracy: 0.8887 - cost: 14.0911 - val_loss: 0.2632 - val_auc: 0.9565 - val_accuracy: 0.8944 - val_cost: 12.9464\n",
            "Epoch 5/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2511 - auc: 0.9603 - accuracy: 0.8995 - cost: 12.7141 - val_loss: 0.2438 - val_auc: 0.9626 - val_accuracy: 0.9023 - val_cost: 12.1925\n",
            "Epoch 6/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2322 - auc: 0.9659 - accuracy: 0.9084 - cost: 11.5783 - val_loss: 0.2264 - val_auc: 0.9675 - val_accuracy: 0.9135 - val_cost: 10.7341\n",
            "Epoch 7/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2152 - auc: 0.9707 - accuracy: 0.9165 - cost: 10.5498 - val_loss: 0.2126 - val_auc: 0.9716 - val_accuracy: 0.9210 - val_cost: 9.6495\n",
            "Epoch 8/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2027 - auc: 0.9739 - accuracy: 0.9221 - cost: 9.8318 - val_loss: 0.1988 - val_auc: 0.9748 - val_accuracy: 0.9271 - val_cost: 9.0873\n",
            "Epoch 9/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1901 - auc: 0.9769 - accuracy: 0.9279 - cost: 9.1127 - val_loss: 0.1908 - val_auc: 0.9766 - val_accuracy: 0.9306 - val_cost: 8.6210\n",
            "Epoch 10/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1815 - auc: 0.9789 - accuracy: 0.9322 - cost: 8.5610 - val_loss: 0.1829 - val_auc: 0.9782 - val_accuracy: 0.9342 - val_cost: 8.1911\n",
            "Epoch 11/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1730 - auc: 0.9806 - accuracy: 0.9366 - cost: 8.0185 - val_loss: 0.1757 - val_auc: 0.9797 - val_accuracy: 0.9384 - val_cost: 7.6058\n",
            "Epoch 12/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1670 - auc: 0.9817 - accuracy: 0.9386 - cost: 7.7828 - val_loss: 0.1698 - val_auc: 0.9809 - val_accuracy: 0.9398 - val_cost: 7.5595\n",
            "Epoch 13/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1615 - auc: 0.9828 - accuracy: 0.9410 - cost: 7.4753 - val_loss: 0.1671 - val_auc: 0.9815 - val_accuracy: 0.9419 - val_cost: 7.4537\n",
            "Epoch 14/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1571 - auc: 0.9837 - accuracy: 0.9434 - cost: 7.1686 - val_loss: 0.1628 - val_auc: 0.9824 - val_accuracy: 0.9435 - val_cost: 6.9048\n",
            "Epoch 15/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1531 - auc: 0.9843 - accuracy: 0.9451 - cost: 6.9452 - val_loss: 0.1581 - val_auc: 0.9831 - val_accuracy: 0.9445 - val_cost: 6.9808\n",
            "Epoch 16/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1492 - auc: 0.9851 - accuracy: 0.9470 - cost: 6.7064 - val_loss: 0.1574 - val_auc: 0.9833 - val_accuracy: 0.9460 - val_cost: 6.6435\n",
            "Epoch 17/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1457 - auc: 0.9857 - accuracy: 0.9488 - cost: 6.4807 - val_loss: 0.1529 - val_auc: 0.9842 - val_accuracy: 0.9470 - val_cost: 6.6303\n",
            "Epoch 18/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1424 - auc: 0.9863 - accuracy: 0.9500 - cost: 6.3287 - val_loss: 0.1520 - val_auc: 0.9842 - val_accuracy: 0.9479 - val_cost: 6.5509\n",
            "Epoch 19/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1396 - auc: 0.9867 - accuracy: 0.9516 - cost: 6.1454 - val_loss: 0.1492 - val_auc: 0.9847 - val_accuracy: 0.9508 - val_cost: 6.2533\n",
            "Epoch 20/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1371 - auc: 0.9871 - accuracy: 0.9524 - cost: 6.0417 - val_loss: 0.1486 - val_auc: 0.9847 - val_accuracy: 0.9508 - val_cost: 6.1739\n",
            "Epoch 21/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1354 - auc: 0.9873 - accuracy: 0.9534 - cost: 5.9035 - val_loss: 0.1468 - val_auc: 0.9851 - val_accuracy: 0.9521 - val_cost: 5.9722\n",
            "Epoch 22/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1335 - auc: 0.9877 - accuracy: 0.9542 - cost: 5.8179 - val_loss: 0.1468 - val_auc: 0.9854 - val_accuracy: 0.9519 - val_cost: 5.8730\n",
            "Epoch 23/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1299 - auc: 0.9883 - accuracy: 0.9552 - cost: 5.6863 - val_loss: 0.1454 - val_auc: 0.9856 - val_accuracy: 0.9524 - val_cost: 5.7474\n",
            "Epoch 24/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1286 - auc: 0.9885 - accuracy: 0.9559 - cost: 5.5961 - val_loss: 0.1438 - val_auc: 0.9856 - val_accuracy: 0.9523 - val_cost: 5.8598\n",
            "Epoch 25/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1275 - auc: 0.9885 - accuracy: 0.9565 - cost: 5.5239 - val_loss: 0.1446 - val_auc: 0.9855 - val_accuracy: 0.9533 - val_cost: 5.6448\n",
            "Epoch 26/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1255 - auc: 0.9888 - accuracy: 0.9572 - cost: 5.4441 - val_loss: 0.1413 - val_auc: 0.9857 - val_accuracy: 0.9548 - val_cost: 5.5820\n",
            "Epoch 27/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1240 - auc: 0.9890 - accuracy: 0.9580 - cost: 5.3476 - val_loss: 0.1389 - val_auc: 0.9861 - val_accuracy: 0.9558 - val_cost: 5.5390\n",
            "Epoch 28/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1220 - auc: 0.9894 - accuracy: 0.9587 - cost: 5.2539 - val_loss: 0.1391 - val_auc: 0.9860 - val_accuracy: 0.9560 - val_cost: 5.5126\n",
            "Epoch 29/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1208 - auc: 0.9895 - accuracy: 0.9596 - cost: 5.1617 - val_loss: 0.1390 - val_auc: 0.9863 - val_accuracy: 0.9551 - val_cost: 5.4200\n",
            "Epoch 30/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1196 - auc: 0.9896 - accuracy: 0.9596 - cost: 5.1416 - val_loss: 0.1382 - val_auc: 0.9861 - val_accuracy: 0.9572 - val_cost: 5.2480\n",
            "Epoch 31/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1181 - auc: 0.9898 - accuracy: 0.9599 - cost: 5.1053 - val_loss: 0.1368 - val_auc: 0.9863 - val_accuracy: 0.9572 - val_cost: 5.3472\n",
            "Epoch 32/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1164 - auc: 0.9901 - accuracy: 0.9614 - cost: 4.9171 - val_loss: 0.1374 - val_auc: 0.9864 - val_accuracy: 0.9565 - val_cost: 5.4134\n",
            "Epoch 33/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1160 - auc: 0.9902 - accuracy: 0.9613 - cost: 4.9201 - val_loss: 0.1354 - val_auc: 0.9866 - val_accuracy: 0.9581 - val_cost: 5.2183\n",
            "Epoch 34/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1139 - auc: 0.9904 - accuracy: 0.9626 - cost: 4.7519 - val_loss: 0.1358 - val_auc: 0.9865 - val_accuracy: 0.9569 - val_cost: 5.3042\n",
            "Epoch 35/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1136 - auc: 0.9905 - accuracy: 0.9623 - cost: 4.8002 - val_loss: 0.1332 - val_auc: 0.9867 - val_accuracy: 0.9586 - val_cost: 5.1389\n",
            "Epoch 36/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1127 - auc: 0.9905 - accuracy: 0.9630 - cost: 4.7180 - val_loss: 0.1332 - val_auc: 0.9869 - val_accuracy: 0.9589 - val_cost: 5.1521\n",
            "Epoch 37/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1115 - auc: 0.9908 - accuracy: 0.9634 - cost: 4.6647 - val_loss: 0.1329 - val_auc: 0.9869 - val_accuracy: 0.9601 - val_cost: 4.9372\n",
            "Epoch 38/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1103 - auc: 0.9909 - accuracy: 0.9637 - cost: 4.6123 - val_loss: 0.1318 - val_auc: 0.9870 - val_accuracy: 0.9590 - val_cost: 5.1587\n",
            "Epoch 39/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1088 - auc: 0.9910 - accuracy: 0.9642 - cost: 4.5652 - val_loss: 0.1318 - val_auc: 0.9869 - val_accuracy: 0.9598 - val_cost: 5.0331\n",
            "Epoch 40/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1077 - auc: 0.9912 - accuracy: 0.9646 - cost: 4.5154 - val_loss: 0.1319 - val_auc: 0.9869 - val_accuracy: 0.9594 - val_cost: 5.0265\n",
            "Epoch 41/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1067 - auc: 0.9913 - accuracy: 0.9648 - cost: 4.4834 - val_loss: 0.1306 - val_auc: 0.9872 - val_accuracy: 0.9606 - val_cost: 4.9074\n",
            "Epoch 42/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1056 - auc: 0.9915 - accuracy: 0.9653 - cost: 4.4205 - val_loss: 0.1303 - val_auc: 0.9871 - val_accuracy: 0.9594 - val_cost: 5.1058\n",
            "Epoch 43/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1056 - auc: 0.9914 - accuracy: 0.9654 - cost: 4.4063 - val_loss: 0.1291 - val_auc: 0.9873 - val_accuracy: 0.9619 - val_cost: 4.6362\n",
            "Epoch 44/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1047 - auc: 0.9916 - accuracy: 0.9659 - cost: 4.3515 - val_loss: 0.1283 - val_auc: 0.9875 - val_accuracy: 0.9610 - val_cost: 4.7619\n",
            "Epoch 45/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1034 - auc: 0.9917 - accuracy: 0.9666 - cost: 4.2554 - val_loss: 0.1272 - val_auc: 0.9877 - val_accuracy: 0.9615 - val_cost: 4.7288\n",
            "Epoch 46/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1036 - auc: 0.9917 - accuracy: 0.9665 - cost: 4.2593 - val_loss: 0.1282 - val_auc: 0.9874 - val_accuracy: 0.9617 - val_cost: 4.7685\n",
            "Epoch 47/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1027 - auc: 0.9918 - accuracy: 0.9667 - cost: 4.2434 - val_loss: 0.1285 - val_auc: 0.9874 - val_accuracy: 0.9615 - val_cost: 4.8214\n",
            "Epoch 48/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1025 - auc: 0.9919 - accuracy: 0.9664 - cost: 4.2913 - val_loss: 0.1269 - val_auc: 0.9876 - val_accuracy: 0.9617 - val_cost: 4.7685\n",
            "Epoch 49/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1006 - auc: 0.9921 - accuracy: 0.9674 - cost: 4.1617 - val_loss: 0.1266 - val_auc: 0.9877 - val_accuracy: 0.9622 - val_cost: 4.6462\n",
            "Epoch 50/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0989 - auc: 0.9922 - accuracy: 0.9684 - cost: 4.0247 - val_loss: 0.1270 - val_auc: 0.9875 - val_accuracy: 0.9619 - val_cost: 4.8611\n",
            "Epoch 51/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0994 - auc: 0.9922 - accuracy: 0.9684 - cost: 4.0390 - val_loss: 0.1252 - val_auc: 0.9878 - val_accuracy: 0.9617 - val_cost: 4.8016\n",
            "Epoch 52/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0991 - auc: 0.9922 - accuracy: 0.9680 - cost: 4.0764 - val_loss: 0.1252 - val_auc: 0.9879 - val_accuracy: 0.9633 - val_cost: 4.5205\n",
            "Epoch 53/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0973 - auc: 0.9925 - accuracy: 0.9690 - cost: 3.9552 - val_loss: 0.1235 - val_auc: 0.9879 - val_accuracy: 0.9639 - val_cost: 4.3915\n",
            "Epoch 54/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0978 - auc: 0.9924 - accuracy: 0.9687 - cost: 3.9934 - val_loss: 0.1229 - val_auc: 0.9881 - val_accuracy: 0.9640 - val_cost: 4.4511\n",
            "Epoch 55/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0962 - auc: 0.9924 - accuracy: 0.9690 - cost: 3.9603 - val_loss: 0.1228 - val_auc: 0.9881 - val_accuracy: 0.9638 - val_cost: 4.5007\n",
            "Epoch 56/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0956 - auc: 0.9926 - accuracy: 0.9692 - cost: 3.9329 - val_loss: 0.1213 - val_auc: 0.9884 - val_accuracy: 0.9643 - val_cost: 4.4511\n",
            "Epoch 57/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0949 - auc: 0.9927 - accuracy: 0.9696 - cost: 3.8777 - val_loss: 0.1230 - val_auc: 0.9882 - val_accuracy: 0.9629 - val_cost: 4.6495\n",
            "Epoch 58/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0944 - auc: 0.9927 - accuracy: 0.9701 - cost: 3.8241 - val_loss: 0.1217 - val_auc: 0.9884 - val_accuracy: 0.9652 - val_cost: 4.2493\n",
            "Epoch 59/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0939 - auc: 0.9928 - accuracy: 0.9695 - cost: 3.8885 - val_loss: 0.1224 - val_auc: 0.9882 - val_accuracy: 0.9642 - val_cost: 4.4345\n",
            "Epoch 60/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0939 - auc: 0.9927 - accuracy: 0.9697 - cost: 3.8700 - val_loss: 0.1212 - val_auc: 0.9885 - val_accuracy: 0.9638 - val_cost: 4.4874\n",
            "Epoch 61/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0922 - auc: 0.9930 - accuracy: 0.9708 - cost: 3.7326 - val_loss: 0.1210 - val_auc: 0.9883 - val_accuracy: 0.9651 - val_cost: 4.3089\n",
            "Epoch 62/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0917 - auc: 0.9930 - accuracy: 0.9710 - cost: 3.7018 - val_loss: 0.1207 - val_auc: 0.9886 - val_accuracy: 0.9651 - val_cost: 4.2196\n",
            "Epoch 63/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0927 - auc: 0.9929 - accuracy: 0.9702 - cost: 3.8098 - val_loss: 0.1205 - val_auc: 0.9885 - val_accuracy: 0.9651 - val_cost: 4.2493\n",
            "Epoch 64/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0907 - auc: 0.9930 - accuracy: 0.9719 - cost: 3.5968 - val_loss: 0.1214 - val_auc: 0.9887 - val_accuracy: 0.9654 - val_cost: 4.2328\n",
            "Epoch 65/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0907 - auc: 0.9931 - accuracy: 0.9714 - cost: 3.6644 - val_loss: 0.1202 - val_auc: 0.9886 - val_accuracy: 0.9662 - val_cost: 4.1104\n",
            "Epoch 66/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0898 - auc: 0.9932 - accuracy: 0.9717 - cost: 3.6208 - val_loss: 0.1217 - val_auc: 0.9887 - val_accuracy: 0.9656 - val_cost: 4.3089\n",
            "Epoch 67/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0897 - auc: 0.9932 - accuracy: 0.9719 - cost: 3.5860 - val_loss: 0.1211 - val_auc: 0.9886 - val_accuracy: 0.9638 - val_cost: 4.3585\n",
            "Epoch 68/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0893 - auc: 0.9933 - accuracy: 0.9717 - cost: 3.6235 - val_loss: 0.1202 - val_auc: 0.9887 - val_accuracy: 0.9651 - val_cost: 4.2163\n",
            "Epoch 69/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0890 - auc: 0.9932 - accuracy: 0.9722 - cost: 3.5687 - val_loss: 0.1188 - val_auc: 0.9887 - val_accuracy: 0.9659 - val_cost: 4.1435\n",
            "Epoch 70/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0881 - auc: 0.9934 - accuracy: 0.9730 - cost: 3.4518 - val_loss: 0.1194 - val_auc: 0.9886 - val_accuracy: 0.9655 - val_cost: 4.2593\n",
            "Epoch 71/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0874 - auc: 0.9934 - accuracy: 0.9725 - cost: 3.5104 - val_loss: 0.1192 - val_auc: 0.9888 - val_accuracy: 0.9669 - val_cost: 4.1204\n",
            "Epoch 72/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0872 - auc: 0.9935 - accuracy: 0.9730 - cost: 3.4579 - val_loss: 0.1186 - val_auc: 0.9887 - val_accuracy: 0.9656 - val_cost: 4.2593\n",
            "Epoch 73/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0873 - auc: 0.9934 - accuracy: 0.9723 - cost: 3.5490 - val_loss: 0.1182 - val_auc: 0.9888 - val_accuracy: 0.9668 - val_cost: 4.1204\n",
            "Epoch 74/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0864 - auc: 0.9936 - accuracy: 0.9729 - cost: 3.4784 - val_loss: 0.1188 - val_auc: 0.9889 - val_accuracy: 0.9666 - val_cost: 4.0642\n",
            "Epoch 75/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0856 - auc: 0.9936 - accuracy: 0.9735 - cost: 3.3885 - val_loss: 0.1184 - val_auc: 0.9889 - val_accuracy: 0.9658 - val_cost: 4.2097\n",
            "Epoch 76/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0852 - auc: 0.9937 - accuracy: 0.9733 - cost: 3.4055 - val_loss: 0.1189 - val_auc: 0.9887 - val_accuracy: 0.9653 - val_cost: 4.2857\n",
            "Epoch 77/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0842 - auc: 0.9938 - accuracy: 0.9737 - cost: 3.3669 - val_loss: 0.1188 - val_auc: 0.9887 - val_accuracy: 0.9658 - val_cost: 4.2097\n",
            "Epoch 78/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0845 - auc: 0.9938 - accuracy: 0.9738 - cost: 3.3557 - val_loss: 0.1177 - val_auc: 0.9889 - val_accuracy: 0.9657 - val_cost: 4.2163\n",
            "Epoch 79/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0843 - auc: 0.9937 - accuracy: 0.9740 - cost: 3.3291 - val_loss: 0.1182 - val_auc: 0.9887 - val_accuracy: 0.9658 - val_cost: 4.3022\n",
            "Epoch 80/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0834 - auc: 0.9939 - accuracy: 0.9744 - cost: 3.2731 - val_loss: 0.1180 - val_auc: 0.9890 - val_accuracy: 0.9669 - val_cost: 4.0708\n",
            "Epoch 81/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0831 - auc: 0.9938 - accuracy: 0.9744 - cost: 3.2793 - val_loss: 0.1155 - val_auc: 0.9892 - val_accuracy: 0.9663 - val_cost: 4.1766\n",
            "Epoch 82/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0828 - auc: 0.9938 - accuracy: 0.9745 - cost: 3.2608 - val_loss: 0.1174 - val_auc: 0.9888 - val_accuracy: 0.9654 - val_cost: 4.2758\n",
            "Epoch 83/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0827 - auc: 0.9938 - accuracy: 0.9744 - cost: 3.2739 - val_loss: 0.1176 - val_auc: 0.9890 - val_accuracy: 0.9660 - val_cost: 4.2361\n",
            "Epoch 84/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0831 - auc: 0.9937 - accuracy: 0.9748 - cost: 3.2242 - val_loss: 0.1179 - val_auc: 0.9890 - val_accuracy: 0.9667 - val_cost: 4.1336\n",
            "Epoch 85/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0817 - auc: 0.9940 - accuracy: 0.9749 - cost: 3.2126 - val_loss: 0.1171 - val_auc: 0.9889 - val_accuracy: 0.9676 - val_cost: 4.0311\n",
            "Epoch 86/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0818 - auc: 0.9940 - accuracy: 0.9746 - cost: 3.2658 - val_loss: 0.1179 - val_auc: 0.9888 - val_accuracy: 0.9666 - val_cost: 4.0774\n",
            "Epoch 87/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0805 - auc: 0.9940 - accuracy: 0.9754 - cost: 3.1497 - val_loss: 0.1190 - val_auc: 0.9886 - val_accuracy: 0.9656 - val_cost: 4.2361\n",
            "Epoch 88/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0803 - auc: 0.9942 - accuracy: 0.9751 - cost: 3.1933 - val_loss: 0.1186 - val_auc: 0.9887 - val_accuracy: 0.9669 - val_cost: 4.1138\n",
            "Epoch 89/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0802 - auc: 0.9941 - accuracy: 0.9750 - cost: 3.1906 - val_loss: 0.1172 - val_auc: 0.9890 - val_accuracy: 0.9663 - val_cost: 4.1501\n",
            "Epoch 90/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0805 - auc: 0.9941 - accuracy: 0.9750 - cost: 3.2025 - val_loss: 0.1191 - val_auc: 0.9887 - val_accuracy: 0.9662 - val_cost: 4.3287\n",
            "Epoch 91/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0804 - auc: 0.9941 - accuracy: 0.9750 - cost: 3.2079 - val_loss: 0.1185 - val_auc: 0.9884 - val_accuracy: 0.9665 - val_cost: 4.2493\n",
            "Epoch 92/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0801 - auc: 0.9940 - accuracy: 0.9755 - cost: 3.1381 - val_loss: 0.1173 - val_auc: 0.9887 - val_accuracy: 0.9667 - val_cost: 4.1634\n",
            "Epoch 93/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0801 - auc: 0.9941 - accuracy: 0.9755 - cost: 3.1285 - val_loss: 0.1186 - val_auc: 0.9885 - val_accuracy: 0.9664 - val_cost: 4.2063\n",
            "Epoch 94/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0796 - auc: 0.9942 - accuracy: 0.9756 - cost: 3.1304 - val_loss: 0.1169 - val_auc: 0.9891 - val_accuracy: 0.9664 - val_cost: 4.1071\n",
            "Epoch 95/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0798 - auc: 0.9942 - accuracy: 0.9755 - cost: 3.1300 - val_loss: 0.1166 - val_auc: 0.9891 - val_accuracy: 0.9675 - val_cost: 4.1270\n",
            "Epoch 96/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0785 - auc: 0.9943 - accuracy: 0.9760 - cost: 3.0814 - val_loss: 0.1175 - val_auc: 0.9891 - val_accuracy: 0.9668 - val_cost: 4.1733\n",
            "Epoch 97/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0783 - auc: 0.9941 - accuracy: 0.9766 - cost: 2.9992 - val_loss: 0.1175 - val_auc: 0.9889 - val_accuracy: 0.9661 - val_cost: 4.3056\n",
            "Epoch 98/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0777 - auc: 0.9943 - accuracy: 0.9762 - cost: 3.0613 - val_loss: 0.1191 - val_auc: 0.9888 - val_accuracy: 0.9660 - val_cost: 4.1964\n",
            "Epoch 99/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0771 - auc: 0.9945 - accuracy: 0.9762 - cost: 3.0475 - val_loss: 0.1178 - val_auc: 0.9888 - val_accuracy: 0.9686 - val_cost: 3.8459\n",
            "Epoch 100/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0775 - auc: 0.9944 - accuracy: 0.9763 - cost: 3.0251 - val_loss: 0.1192 - val_auc: 0.9887 - val_accuracy: 0.9663 - val_cost: 4.2097\n",
            "Epoch 101/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0771 - auc: 0.9944 - accuracy: 0.9766 - cost: 2.9942 - val_loss: 0.1181 - val_auc: 0.9890 - val_accuracy: 0.9668 - val_cost: 4.0410\n",
            "Epoch 102/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0777 - auc: 0.9943 - accuracy: 0.9764 - cost: 3.0274 - val_loss: 0.1197 - val_auc: 0.9884 - val_accuracy: 0.9666 - val_cost: 4.0410\n",
            "Epoch 103/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0766 - auc: 0.9945 - accuracy: 0.9767 - cost: 2.9738 - val_loss: 0.1174 - val_auc: 0.9890 - val_accuracy: 0.9676 - val_cost: 4.1567\n",
            "Epoch 104/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0760 - auc: 0.9945 - accuracy: 0.9768 - cost: 2.9796 - val_loss: 0.1166 - val_auc: 0.9888 - val_accuracy: 0.9664 - val_cost: 4.2560\n",
            "Epoch 105/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0768 - auc: 0.9944 - accuracy: 0.9764 - cost: 3.0258 - val_loss: 0.1171 - val_auc: 0.9890 - val_accuracy: 0.9675 - val_cost: 4.1104\n",
            "Epoch 106/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0761 - auc: 0.9945 - accuracy: 0.9766 - cost: 2.9969 - val_loss: 0.1204 - val_auc: 0.9890 - val_accuracy: 0.9660 - val_cost: 4.0939\n",
            "Epoch 107/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0759 - auc: 0.9946 - accuracy: 0.9767 - cost: 2.9826 - val_loss: 0.1200 - val_auc: 0.9887 - val_accuracy: 0.9663 - val_cost: 4.2593\n",
            "Epoch 108/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0770 - auc: 0.9943 - accuracy: 0.9767 - cost: 2.9846 - val_loss: 0.1168 - val_auc: 0.9889 - val_accuracy: 0.9674 - val_cost: 4.1038\n",
            "Epoch 109/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0760 - auc: 0.9946 - accuracy: 0.9766 - cost: 2.9838 - val_loss: 0.1196 - val_auc: 0.9889 - val_accuracy: 0.9675 - val_cost: 3.9782\n",
            "Epoch 110/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0746 - auc: 0.9948 - accuracy: 0.9772 - cost: 2.9271 - val_loss: 0.1196 - val_auc: 0.9887 - val_accuracy: 0.9670 - val_cost: 4.0542\n",
            "Epoch 111/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0755 - auc: 0.9946 - accuracy: 0.9776 - cost: 2.8738 - val_loss: 0.1190 - val_auc: 0.9890 - val_accuracy: 0.9673 - val_cost: 4.0410\n",
            "Epoch 112/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0752 - auc: 0.9946 - accuracy: 0.9771 - cost: 2.9236 - val_loss: 0.1168 - val_auc: 0.9891 - val_accuracy: 0.9671 - val_cost: 4.1931\n",
            "Epoch 113/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0741 - auc: 0.9947 - accuracy: 0.9776 - cost: 2.8812 - val_loss: 0.1186 - val_auc: 0.9889 - val_accuracy: 0.9678 - val_cost: 3.9649\n",
            "Epoch 114/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0749 - auc: 0.9947 - accuracy: 0.9776 - cost: 2.8696 - val_loss: 0.1194 - val_auc: 0.9888 - val_accuracy: 0.9664 - val_cost: 4.2824\n",
            "Epoch 115/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0756 - auc: 0.9945 - accuracy: 0.9767 - cost: 2.9772 - val_loss: 0.1197 - val_auc: 0.9888 - val_accuracy: 0.9674 - val_cost: 3.9550\n",
            "Epoch 116/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0746 - auc: 0.9946 - accuracy: 0.9777 - cost: 2.8603 - val_loss: 0.1214 - val_auc: 0.9886 - val_accuracy: 0.9672 - val_cost: 3.9517\n",
            "Epoch 117/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0744 - auc: 0.9946 - accuracy: 0.9777 - cost: 2.8576 - val_loss: 0.1182 - val_auc: 0.9891 - val_accuracy: 0.9679 - val_cost: 3.9815\n",
            "Epoch 118/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0741 - auc: 0.9947 - accuracy: 0.9777 - cost: 2.8627 - val_loss: 0.1188 - val_auc: 0.9889 - val_accuracy: 0.9678 - val_cost: 4.0079\n",
            "Epoch 119/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0735 - auc: 0.9948 - accuracy: 0.9778 - cost: 2.8596 - val_loss: 0.1192 - val_auc: 0.9890 - val_accuracy: 0.9676 - val_cost: 4.0079\n",
            "Epoch 120/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0736 - auc: 0.9948 - accuracy: 0.9778 - cost: 2.8507 - val_loss: 0.1204 - val_auc: 0.9887 - val_accuracy: 0.9674 - val_cost: 4.0079\n",
            "Epoch 121/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0735 - auc: 0.9947 - accuracy: 0.9777 - cost: 2.8592 - val_loss: 0.1186 - val_auc: 0.9888 - val_accuracy: 0.9679 - val_cost: 3.9815\n",
            "Epoch 122/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0727 - auc: 0.9949 - accuracy: 0.9781 - cost: 2.8063 - val_loss: 0.1192 - val_auc: 0.9889 - val_accuracy: 0.9679 - val_cost: 3.9716\n",
            "Epoch 123/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0731 - auc: 0.9949 - accuracy: 0.9779 - cost: 2.8461 - val_loss: 0.1185 - val_auc: 0.9889 - val_accuracy: 0.9670 - val_cost: 4.1038\n",
            "Epoch 124/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0725 - auc: 0.9949 - accuracy: 0.9785 - cost: 2.7546 - val_loss: 0.1183 - val_auc: 0.9889 - val_accuracy: 0.9680 - val_cost: 3.9815\n",
            "Epoch 125/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0721 - auc: 0.9950 - accuracy: 0.9785 - cost: 2.7600 - val_loss: 0.1195 - val_auc: 0.9890 - val_accuracy: 0.9676 - val_cost: 4.0377\n",
            "Epoch 126/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0719 - auc: 0.9950 - accuracy: 0.9781 - cost: 2.7990 - val_loss: 0.1184 - val_auc: 0.9891 - val_accuracy: 0.9669 - val_cost: 4.1733\n",
            "Epoch 127/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0724 - auc: 0.9948 - accuracy: 0.9782 - cost: 2.7990 - val_loss: 0.1202 - val_auc: 0.9890 - val_accuracy: 0.9674 - val_cost: 4.0146\n",
            "Epoch 128/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0717 - auc: 0.9950 - accuracy: 0.9782 - cost: 2.7878 - val_loss: 0.1200 - val_auc: 0.9885 - val_accuracy: 0.9668 - val_cost: 4.1997\n",
            "Epoch 129/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0721 - auc: 0.9949 - accuracy: 0.9784 - cost: 2.7747 - val_loss: 0.1179 - val_auc: 0.9890 - val_accuracy: 0.9678 - val_cost: 4.1071\n",
            "Epoch 130/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0719 - auc: 0.9949 - accuracy: 0.9783 - cost: 2.7851 - val_loss: 0.1218 - val_auc: 0.9886 - val_accuracy: 0.9673 - val_cost: 3.9947\n",
            "Epoch 131/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0717 - auc: 0.9950 - accuracy: 0.9785 - cost: 2.7612 - val_loss: 0.1183 - val_auc: 0.9891 - val_accuracy: 0.9665 - val_cost: 4.2262\n",
            "Epoch 132/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9950 - accuracy: 0.9786 - cost: 2.7369 - val_loss: 0.1200 - val_auc: 0.9890 - val_accuracy: 0.9668 - val_cost: 4.0972\n",
            "Epoch 133/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0713 - auc: 0.9949 - accuracy: 0.9789 - cost: 2.7168 - val_loss: 0.1193 - val_auc: 0.9888 - val_accuracy: 0.9674 - val_cost: 4.0774\n",
            "Epoch 134/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0708 - auc: 0.9950 - accuracy: 0.9789 - cost: 2.7103 - val_loss: 0.1189 - val_auc: 0.9891 - val_accuracy: 0.9676 - val_cost: 4.0939\n",
            "Epoch 135/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0713 - auc: 0.9949 - accuracy: 0.9786 - cost: 2.7473 - val_loss: 0.1196 - val_auc: 0.9889 - val_accuracy: 0.9676 - val_cost: 3.9749\n",
            "Epoch 136/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0710 - auc: 0.9950 - accuracy: 0.9786 - cost: 2.7427 - val_loss: 0.1183 - val_auc: 0.9888 - val_accuracy: 0.9683 - val_cost: 3.9484\n",
            "Epoch 137/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0698 - auc: 0.9951 - accuracy: 0.9790 - cost: 2.6852 - val_loss: 0.1167 - val_auc: 0.9892 - val_accuracy: 0.9678 - val_cost: 4.1898\n",
            "Epoch 138/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0700 - auc: 0.9952 - accuracy: 0.9793 - cost: 2.6590 - val_loss: 0.1210 - val_auc: 0.9887 - val_accuracy: 0.9681 - val_cost: 3.9683\n",
            "Epoch 139/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0699 - auc: 0.9951 - accuracy: 0.9789 - cost: 2.7052 - val_loss: 0.1198 - val_auc: 0.9891 - val_accuracy: 0.9679 - val_cost: 4.0443\n",
            "Epoch 140/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0709 - auc: 0.9951 - accuracy: 0.9788 - cost: 2.7172 - val_loss: 0.1185 - val_auc: 0.9892 - val_accuracy: 0.9679 - val_cost: 4.0708\n",
            "Epoch 141/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0701 - auc: 0.9950 - accuracy: 0.9791 - cost: 2.6875 - val_loss: 0.1180 - val_auc: 0.9890 - val_accuracy: 0.9681 - val_cost: 3.9616\n",
            "Epoch 142/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0691 - auc: 0.9951 - accuracy: 0.9789 - cost: 2.7106 - val_loss: 0.1216 - val_auc: 0.9888 - val_accuracy: 0.9674 - val_cost: 3.9583\n",
            "Epoch 143/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0699 - auc: 0.9952 - accuracy: 0.9789 - cost: 2.7160 - val_loss: 0.1217 - val_auc: 0.9883 - val_accuracy: 0.9673 - val_cost: 4.0344\n",
            "Epoch 144/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0702 - auc: 0.9951 - accuracy: 0.9786 - cost: 2.7488 - val_loss: 0.1191 - val_auc: 0.9889 - val_accuracy: 0.9681 - val_cost: 3.9815\n",
            "Epoch 145/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0690 - auc: 0.9953 - accuracy: 0.9792 - cost: 2.6717 - val_loss: 0.1195 - val_auc: 0.9889 - val_accuracy: 0.9680 - val_cost: 4.0708\n",
            "Epoch 146/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0694 - auc: 0.9952 - accuracy: 0.9790 - cost: 2.7006 - val_loss: 0.1199 - val_auc: 0.9888 - val_accuracy: 0.9682 - val_cost: 4.0046\n",
            "Epoch 147/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0694 - auc: 0.9952 - accuracy: 0.9795 - cost: 2.6265 - val_loss: 0.1175 - val_auc: 0.9888 - val_accuracy: 0.9685 - val_cost: 4.0112\n",
            "Epoch 148/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0694 - auc: 0.9952 - accuracy: 0.9793 - cost: 2.6551 - val_loss: 0.1197 - val_auc: 0.9890 - val_accuracy: 0.9676 - val_cost: 4.0708\n",
            "Epoch 149/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0690 - auc: 0.9952 - accuracy: 0.9794 - cost: 2.6516 - val_loss: 0.1200 - val_auc: 0.9889 - val_accuracy: 0.9665 - val_cost: 4.0807\n",
            "Epoch 150/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0695 - auc: 0.9952 - accuracy: 0.9793 - cost: 2.6501 - val_loss: 0.1194 - val_auc: 0.9889 - val_accuracy: 0.9677 - val_cost: 4.1171\n",
            "Epoch 151/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0689 - auc: 0.9952 - accuracy: 0.9791 - cost: 2.6833 - val_loss: 0.1220 - val_auc: 0.9884 - val_accuracy: 0.9674 - val_cost: 3.9980\n",
            "Epoch 152/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0682 - auc: 0.9954 - accuracy: 0.9798 - cost: 2.5860 - val_loss: 0.1188 - val_auc: 0.9892 - val_accuracy: 0.9677 - val_cost: 4.1138\n",
            "Epoch 153/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0679 - auc: 0.9953 - accuracy: 0.9793 - cost: 2.6539 - val_loss: 0.1206 - val_auc: 0.9891 - val_accuracy: 0.9679 - val_cost: 3.9087\n",
            "Epoch 154/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0693 - auc: 0.9952 - accuracy: 0.9796 - cost: 2.6235 - val_loss: 0.1200 - val_auc: 0.9888 - val_accuracy: 0.9681 - val_cost: 4.0278\n",
            "Epoch 155/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0688 - auc: 0.9954 - accuracy: 0.9793 - cost: 2.6566 - val_loss: 0.1196 - val_auc: 0.9890 - val_accuracy: 0.9680 - val_cost: 4.0046\n",
            "Epoch 156/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0685 - auc: 0.9953 - accuracy: 0.9798 - cost: 2.5918 - val_loss: 0.1208 - val_auc: 0.9890 - val_accuracy: 0.9674 - val_cost: 4.0476\n",
            "Epoch 157/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0672 - auc: 0.9954 - accuracy: 0.9802 - cost: 2.5367 - val_loss: 0.1209 - val_auc: 0.9886 - val_accuracy: 0.9682 - val_cost: 3.9980\n",
            "Epoch 158/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0684 - auc: 0.9955 - accuracy: 0.9795 - cost: 2.6277 - val_loss: 0.1189 - val_auc: 0.9888 - val_accuracy: 0.9681 - val_cost: 3.9716\n",
            "Epoch 159/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0675 - auc: 0.9954 - accuracy: 0.9796 - cost: 2.6119 - val_loss: 0.1198 - val_auc: 0.9890 - val_accuracy: 0.9678 - val_cost: 3.9319\n",
            "Epoch 160/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0680 - auc: 0.9954 - accuracy: 0.9795 - cost: 2.6300 - val_loss: 0.1198 - val_auc: 0.9888 - val_accuracy: 0.9682 - val_cost: 4.0344\n",
            "Epoch 161/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0678 - auc: 0.9953 - accuracy: 0.9797 - cost: 2.6096 - val_loss: 0.1187 - val_auc: 0.9890 - val_accuracy: 0.9678 - val_cost: 4.0278\n",
            "Epoch 162/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0682 - auc: 0.9954 - accuracy: 0.9794 - cost: 2.6478 - val_loss: 0.1200 - val_auc: 0.9892 - val_accuracy: 0.9667 - val_cost: 4.1601\n",
            "Epoch 163/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0670 - auc: 0.9955 - accuracy: 0.9797 - cost: 2.6127 - val_loss: 0.1204 - val_auc: 0.9890 - val_accuracy: 0.9685 - val_cost: 3.9087\n",
            "Epoch 164/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0676 - auc: 0.9954 - accuracy: 0.9797 - cost: 2.5984 - val_loss: 0.1186 - val_auc: 0.9892 - val_accuracy: 0.9688 - val_cost: 3.9187\n",
            "Epoch 165/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0671 - auc: 0.9955 - accuracy: 0.9797 - cost: 2.6022 - val_loss: 0.1189 - val_auc: 0.9887 - val_accuracy: 0.9681 - val_cost: 4.0708\n",
            "Epoch 166/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0662 - auc: 0.9955 - accuracy: 0.9803 - cost: 2.5197 - val_loss: 0.1201 - val_auc: 0.9885 - val_accuracy: 0.9682 - val_cost: 3.9815\n",
            "Epoch 167/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0671 - auc: 0.9954 - accuracy: 0.9798 - cost: 2.5856 - val_loss: 0.1202 - val_auc: 0.9887 - val_accuracy: 0.9682 - val_cost: 3.9021\n",
            "Epoch 168/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0668 - auc: 0.9955 - accuracy: 0.9800 - cost: 2.5702 - val_loss: 0.1195 - val_auc: 0.9888 - val_accuracy: 0.9686 - val_cost: 3.8757\n",
            "Epoch 169/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0675 - auc: 0.9954 - accuracy: 0.9797 - cost: 2.6096 - val_loss: 0.1202 - val_auc: 0.9890 - val_accuracy: 0.9677 - val_cost: 3.9716\n",
            "Epoch 170/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0672 - auc: 0.9954 - accuracy: 0.9797 - cost: 2.5903 - val_loss: 0.1212 - val_auc: 0.9886 - val_accuracy: 0.9686 - val_cost: 3.9054\n",
            "Epoch 171/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0677 - auc: 0.9953 - accuracy: 0.9800 - cost: 2.5772 - val_loss: 0.1200 - val_auc: 0.9887 - val_accuracy: 0.9682 - val_cost: 3.9451\n",
            "Epoch 172/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0671 - auc: 0.9955 - accuracy: 0.9799 - cost: 2.5745 - val_loss: 0.1211 - val_auc: 0.9890 - val_accuracy: 0.9682 - val_cost: 4.0377\n",
            "Epoch 173/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0669 - auc: 0.9954 - accuracy: 0.9802 - cost: 2.5343 - val_loss: 0.1205 - val_auc: 0.9887 - val_accuracy: 0.9681 - val_cost: 4.0013\n",
            "Epoch 174/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0666 - auc: 0.9955 - accuracy: 0.9801 - cost: 2.5451 - val_loss: 0.1216 - val_auc: 0.9889 - val_accuracy: 0.9669 - val_cost: 4.1270\n",
            "Epoch 175/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0663 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4923 - val_loss: 0.1208 - val_auc: 0.9889 - val_accuracy: 0.9675 - val_cost: 4.0079\n",
            "Epoch 176/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0656 - auc: 0.9957 - accuracy: 0.9807 - cost: 2.4877 - val_loss: 0.1208 - val_auc: 0.9891 - val_accuracy: 0.9676 - val_cost: 4.0013\n",
            "Epoch 177/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0656 - auc: 0.9957 - accuracy: 0.9802 - cost: 2.5421 - val_loss: 0.1219 - val_auc: 0.9887 - val_accuracy: 0.9678 - val_cost: 4.0245\n",
            "Epoch 178/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0671 - auc: 0.9955 - accuracy: 0.9797 - cost: 2.6007 - val_loss: 0.1251 - val_auc: 0.9885 - val_accuracy: 0.9672 - val_cost: 4.0112\n",
            "Epoch 179/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0670 - auc: 0.9954 - accuracy: 0.9802 - cost: 2.5382 - val_loss: 0.1215 - val_auc: 0.9891 - val_accuracy: 0.9679 - val_cost: 3.9980\n",
            "Epoch 180/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0656 - auc: 0.9956 - accuracy: 0.9806 - cost: 2.4950 - val_loss: 0.1198 - val_auc: 0.9888 - val_accuracy: 0.9682 - val_cost: 4.0046\n",
            "Epoch 181/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0653 - auc: 0.9956 - accuracy: 0.9804 - cost: 2.5143 - val_loss: 0.1202 - val_auc: 0.9889 - val_accuracy: 0.9683 - val_cost: 3.9352\n",
            "Epoch 182/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0651 - auc: 0.9957 - accuracy: 0.9804 - cost: 2.5112 - val_loss: 0.1224 - val_auc: 0.9887 - val_accuracy: 0.9682 - val_cost: 4.0179\n",
            "Epoch 183/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0662 - auc: 0.9956 - accuracy: 0.9801 - cost: 2.5536 - val_loss: 0.1223 - val_auc: 0.9891 - val_accuracy: 0.9678 - val_cost: 3.9616\n",
            "Epoch 184/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0661 - auc: 0.9956 - accuracy: 0.9803 - cost: 2.5390 - val_loss: 0.1219 - val_auc: 0.9886 - val_accuracy: 0.9679 - val_cost: 4.0112\n",
            "Epoch 185/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0658 - auc: 0.9957 - accuracy: 0.9801 - cost: 2.5536 - val_loss: 0.1225 - val_auc: 0.9889 - val_accuracy: 0.9669 - val_cost: 4.2063\n",
            "Epoch 186/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0656 - auc: 0.9956 - accuracy: 0.9805 - cost: 2.5096 - val_loss: 0.1258 - val_auc: 0.9886 - val_accuracy: 0.9680 - val_cost: 3.9848\n",
            "Epoch 187/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0655 - auc: 0.9956 - accuracy: 0.9806 - cost: 2.4946 - val_loss: 0.1218 - val_auc: 0.9890 - val_accuracy: 0.9669 - val_cost: 4.1700\n",
            "Epoch 188/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0651 - auc: 0.9957 - accuracy: 0.9803 - cost: 2.5247 - val_loss: 0.1216 - val_auc: 0.9890 - val_accuracy: 0.9681 - val_cost: 3.9683\n",
            "Epoch 189/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0654 - auc: 0.9957 - accuracy: 0.9804 - cost: 2.5158 - val_loss: 0.1220 - val_auc: 0.9888 - val_accuracy: 0.9681 - val_cost: 3.9352\n",
            "Epoch 190/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0649 - auc: 0.9958 - accuracy: 0.9806 - cost: 2.4873 - val_loss: 0.1225 - val_auc: 0.9886 - val_accuracy: 0.9679 - val_cost: 4.0377\n",
            "Epoch 191/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0644 - auc: 0.9956 - accuracy: 0.9811 - cost: 2.4290 - val_loss: 0.1237 - val_auc: 0.9886 - val_accuracy: 0.9679 - val_cost: 3.9914\n",
            "Epoch 192/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0647 - auc: 0.9957 - accuracy: 0.9802 - cost: 2.5436 - val_loss: 0.1222 - val_auc: 0.9888 - val_accuracy: 0.9678 - val_cost: 4.1303\n",
            "Epoch 193/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0655 - auc: 0.9957 - accuracy: 0.9803 - cost: 2.5228 - val_loss: 0.1223 - val_auc: 0.9888 - val_accuracy: 0.9678 - val_cost: 4.0443\n",
            "Epoch 194/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0657 - auc: 0.9956 - accuracy: 0.9802 - cost: 2.5285 - val_loss: 0.1219 - val_auc: 0.9888 - val_accuracy: 0.9690 - val_cost: 3.8690\n",
            "Epoch 195/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0645 - auc: 0.9957 - accuracy: 0.9811 - cost: 2.4240 - val_loss: 0.1216 - val_auc: 0.9886 - val_accuracy: 0.9675 - val_cost: 4.0906\n",
            "Epoch 196/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0646 - auc: 0.9958 - accuracy: 0.9805 - cost: 2.5027 - val_loss: 0.1251 - val_auc: 0.9885 - val_accuracy: 0.9681 - val_cost: 4.0179\n",
            "Epoch 197/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0654 - auc: 0.9957 - accuracy: 0.9802 - cost: 2.5432 - val_loss: 0.1226 - val_auc: 0.9890 - val_accuracy: 0.9678 - val_cost: 3.9782\n",
            "Epoch 198/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0649 - auc: 0.9957 - accuracy: 0.9808 - cost: 2.4653 - val_loss: 0.1227 - val_auc: 0.9885 - val_accuracy: 0.9683 - val_cost: 4.0311\n",
            "Epoch 199/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0640 - auc: 0.9958 - accuracy: 0.9808 - cost: 2.4630 - val_loss: 0.1220 - val_auc: 0.9886 - val_accuracy: 0.9683 - val_cost: 3.9749\n",
            "Epoch 200/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0643 - auc: 0.9958 - accuracy: 0.9804 - cost: 2.5135 - val_loss: 0.1219 - val_auc: 0.9887 - val_accuracy: 0.9688 - val_cost: 3.9881\n",
            "Epoch 201/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0639 - auc: 0.9958 - accuracy: 0.9805 - cost: 2.4988 - val_loss: 0.1229 - val_auc: 0.9887 - val_accuracy: 0.9683 - val_cost: 3.9848\n",
            "Epoch 202/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0651 - auc: 0.9957 - accuracy: 0.9804 - cost: 2.5185 - val_loss: 0.1244 - val_auc: 0.9888 - val_accuracy: 0.9679 - val_cost: 3.8922\n",
            "Epoch 203/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0638 - auc: 0.9958 - accuracy: 0.9808 - cost: 2.4560 - val_loss: 0.1234 - val_auc: 0.9886 - val_accuracy: 0.9684 - val_cost: 3.9319\n",
            "Epoch 204/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0639 - auc: 0.9959 - accuracy: 0.9806 - cost: 2.4927 - val_loss: 0.1237 - val_auc: 0.9884 - val_accuracy: 0.9678 - val_cost: 4.0575\n",
            "Epoch 205/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0644 - auc: 0.9958 - accuracy: 0.9811 - cost: 2.4271 - val_loss: 0.1233 - val_auc: 0.9888 - val_accuracy: 0.9686 - val_cost: 3.9716\n",
            "Epoch 206/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0642 - auc: 0.9958 - accuracy: 0.9810 - cost: 2.4402 - val_loss: 0.1240 - val_auc: 0.9886 - val_accuracy: 0.9678 - val_cost: 4.0873\n",
            "Epoch 207/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0638 - auc: 0.9958 - accuracy: 0.9808 - cost: 2.4595 - val_loss: 0.1228 - val_auc: 0.9887 - val_accuracy: 0.9687 - val_cost: 4.0112\n",
            "Epoch 208/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0638 - auc: 0.9958 - accuracy: 0.9810 - cost: 2.4375 - val_loss: 0.1243 - val_auc: 0.9886 - val_accuracy: 0.9686 - val_cost: 3.9187\n",
            "Epoch 209/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0640 - auc: 0.9958 - accuracy: 0.9808 - cost: 2.4599 - val_loss: 0.1221 - val_auc: 0.9886 - val_accuracy: 0.9685 - val_cost: 3.9087\n",
            "Epoch 210/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0635 - auc: 0.9958 - accuracy: 0.9813 - cost: 2.3997 - val_loss: 0.1251 - val_auc: 0.9883 - val_accuracy: 0.9680 - val_cost: 3.9716\n",
            "Epoch 211/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0640 - auc: 0.9958 - accuracy: 0.9808 - cost: 2.4711 - val_loss: 0.1231 - val_auc: 0.9884 - val_accuracy: 0.9680 - val_cost: 4.0972\n",
            "Epoch 212/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0643 - auc: 0.9957 - accuracy: 0.9805 - cost: 2.5073 - val_loss: 0.1238 - val_auc: 0.9889 - val_accuracy: 0.9690 - val_cost: 3.9153\n",
            "Epoch 213/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0639 - auc: 0.9958 - accuracy: 0.9805 - cost: 2.5096 - val_loss: 0.1245 - val_auc: 0.9889 - val_accuracy: 0.9681 - val_cost: 3.9153\n",
            "Epoch 214/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0638 - auc: 0.9959 - accuracy: 0.9806 - cost: 2.4911 - val_loss: 0.1235 - val_auc: 0.9885 - val_accuracy: 0.9675 - val_cost: 4.1766\n",
            "Epoch 215/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0620 - auc: 0.9960 - accuracy: 0.9814 - cost: 2.3831 - val_loss: 0.1233 - val_auc: 0.9887 - val_accuracy: 0.9681 - val_cost: 4.0642\n",
            "Epoch 216/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0641 - auc: 0.9958 - accuracy: 0.9807 - cost: 2.4707 - val_loss: 0.1235 - val_auc: 0.9886 - val_accuracy: 0.9681 - val_cost: 4.0112\n",
            "Epoch 217/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0640 - auc: 0.9958 - accuracy: 0.9808 - cost: 2.4715 - val_loss: 0.1234 - val_auc: 0.9888 - val_accuracy: 0.9675 - val_cost: 4.1038\n",
            "Epoch 218/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0631 - auc: 0.9958 - accuracy: 0.9810 - cost: 2.4456 - val_loss: 0.1249 - val_auc: 0.9884 - val_accuracy: 0.9674 - val_cost: 4.1071\n",
            "Epoch 219/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0626 - auc: 0.9960 - accuracy: 0.9812 - cost: 2.4120 - val_loss: 0.1248 - val_auc: 0.9889 - val_accuracy: 0.9676 - val_cost: 4.0939\n",
            "Epoch 220/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0626 - auc: 0.9959 - accuracy: 0.9810 - cost: 2.4444 - val_loss: 0.1245 - val_auc: 0.9883 - val_accuracy: 0.9677 - val_cost: 4.0906\n",
            "Epoch 221/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0633 - auc: 0.9960 - accuracy: 0.9812 - cost: 2.4147 - val_loss: 0.1248 - val_auc: 0.9885 - val_accuracy: 0.9678 - val_cost: 4.0245\n",
            "Epoch 222/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0629 - auc: 0.9960 - accuracy: 0.9808 - cost: 2.4645 - val_loss: 0.1233 - val_auc: 0.9887 - val_accuracy: 0.9679 - val_cost: 4.0509\n",
            "Epoch 223/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0630 - auc: 0.9959 - accuracy: 0.9807 - cost: 2.4672 - val_loss: 0.1259 - val_auc: 0.9882 - val_accuracy: 0.9686 - val_cost: 3.9220\n",
            "Epoch 224/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0621 - auc: 0.9962 - accuracy: 0.9814 - cost: 2.3850 - val_loss: 0.1245 - val_auc: 0.9881 - val_accuracy: 0.9680 - val_cost: 4.0509\n",
            "Epoch 225/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0619 - auc: 0.9961 - accuracy: 0.9811 - cost: 2.4271 - val_loss: 0.1250 - val_auc: 0.9887 - val_accuracy: 0.9681 - val_cost: 3.9947\n",
            "Epoch 226/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0628 - auc: 0.9959 - accuracy: 0.9810 - cost: 2.4437 - val_loss: 0.1268 - val_auc: 0.9888 - val_accuracy: 0.9683 - val_cost: 3.9484\n",
            "Epoch 227/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0624 - auc: 0.9959 - accuracy: 0.9813 - cost: 2.3989 - val_loss: 0.1230 - val_auc: 0.9889 - val_accuracy: 0.9681 - val_cost: 3.9616\n",
            "Epoch 228/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0626 - auc: 0.9960 - accuracy: 0.9809 - cost: 2.4537 - val_loss: 0.1263 - val_auc: 0.9883 - val_accuracy: 0.9672 - val_cost: 4.0608\n",
            "Epoch 229/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0629 - auc: 0.9958 - accuracy: 0.9814 - cost: 2.4032 - val_loss: 0.1248 - val_auc: 0.9884 - val_accuracy: 0.9684 - val_cost: 3.9848\n",
            "Epoch 230/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0624 - auc: 0.9959 - accuracy: 0.9809 - cost: 2.4545 - val_loss: 0.1246 - val_auc: 0.9884 - val_accuracy: 0.9685 - val_cost: 3.9153\n",
            "Epoch 231/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0621 - auc: 0.9961 - accuracy: 0.9809 - cost: 2.4460 - val_loss: 0.1253 - val_auc: 0.9885 - val_accuracy: 0.9681 - val_cost: 3.8856\n",
            "Epoch 232/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0624 - auc: 0.9960 - accuracy: 0.9811 - cost: 2.4282 - val_loss: 0.1253 - val_auc: 0.9882 - val_accuracy: 0.9678 - val_cost: 3.9616\n",
            "Epoch 233/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0621 - auc: 0.9960 - accuracy: 0.9812 - cost: 2.4209 - val_loss: 0.1266 - val_auc: 0.9885 - val_accuracy: 0.9676 - val_cost: 3.9914\n",
            "Epoch 234/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0626 - auc: 0.9960 - accuracy: 0.9814 - cost: 2.3862 - val_loss: 0.1268 - val_auc: 0.9884 - val_accuracy: 0.9678 - val_cost: 3.9749\n",
            "Epoch 235/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0614 - auc: 0.9962 - accuracy: 0.9814 - cost: 2.3850 - val_loss: 0.1264 - val_auc: 0.9886 - val_accuracy: 0.9685 - val_cost: 3.9220\n",
            "Epoch 236/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0619 - auc: 0.9961 - accuracy: 0.9813 - cost: 2.4128 - val_loss: 0.1272 - val_auc: 0.9884 - val_accuracy: 0.9675 - val_cost: 4.0212\n",
            "Epoch 237/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0609 - auc: 0.9962 - accuracy: 0.9818 - cost: 2.3252 - val_loss: 0.1254 - val_auc: 0.9886 - val_accuracy: 0.9683 - val_cost: 3.9385\n",
            "Epoch 238/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0623 - auc: 0.9960 - accuracy: 0.9809 - cost: 2.4448 - val_loss: 0.1270 - val_auc: 0.9883 - val_accuracy: 0.9676 - val_cost: 4.0476\n",
            "Epoch 239/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0613 - auc: 0.9961 - accuracy: 0.9812 - cost: 2.4086 - val_loss: 0.1260 - val_auc: 0.9883 - val_accuracy: 0.9674 - val_cost: 4.1799\n",
            "Epoch 240/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0614 - auc: 0.9961 - accuracy: 0.9814 - cost: 2.3808 - val_loss: 0.1273 - val_auc: 0.9882 - val_accuracy: 0.9683 - val_cost: 3.9153\n",
            "Epoch 241/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0620 - auc: 0.9961 - accuracy: 0.9806 - cost: 2.4865 - val_loss: 0.1280 - val_auc: 0.9881 - val_accuracy: 0.9677 - val_cost: 3.9914\n",
            "Epoch 242/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0618 - auc: 0.9962 - accuracy: 0.9811 - cost: 2.4340 - val_loss: 0.1267 - val_auc: 0.9883 - val_accuracy: 0.9669 - val_cost: 4.1369\n",
            "Epoch 243/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0611 - auc: 0.9962 - accuracy: 0.9814 - cost: 2.3947 - val_loss: 0.1274 - val_auc: 0.9881 - val_accuracy: 0.9681 - val_cost: 3.9087\n",
            "Epoch 244/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0612 - auc: 0.9961 - accuracy: 0.9817 - cost: 2.3534 - val_loss: 0.1259 - val_auc: 0.9882 - val_accuracy: 0.9676 - val_cost: 4.0476\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.1096 - auc: 0.9904 - accuracy: 0.9697 - cost: 3.7594\n",
            "500/500 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:01:57.323113\n",
            "fold accuracy: 0.9697499871253967 - fold cost: 3.7593750953674316\n",
            "x_train shape: (144000, 67)\n",
            "Epoch 1/1000\n",
            "120/120 [==============================] - 2s 6ms/step - loss: 0.5296 - auc: 0.7983 - accuracy: 0.7292 - cost: 36.1088 - val_loss: 0.3988 - val_auc: 0.9005 - val_accuracy: 0.8259 - val_cost: 21.8585\n",
            "Epoch 2/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.3523 - auc: 0.9210 - accuracy: 0.8490 - cost: 19.2496 - val_loss: 0.3143 - val_auc: 0.9375 - val_accuracy: 0.8660 - val_cost: 16.6766\n",
            "Epoch 3/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.3026 - auc: 0.9419 - accuracy: 0.8742 - cost: 15.9595 - val_loss: 0.2848 - val_auc: 0.9486 - val_accuracy: 0.8803 - val_cost: 15.0397\n",
            "Epoch 4/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2744 - auc: 0.9524 - accuracy: 0.8889 - cost: 14.0583 - val_loss: 0.2587 - val_auc: 0.9579 - val_accuracy: 0.8960 - val_cost: 13.1052\n",
            "Epoch 5/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2510 - auc: 0.9602 - accuracy: 0.8992 - cost: 12.7623 - val_loss: 0.2394 - val_auc: 0.9636 - val_accuracy: 0.9040 - val_cost: 12.0106\n",
            "Epoch 6/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2326 - auc: 0.9658 - accuracy: 0.9085 - cost: 11.5737 - val_loss: 0.2228 - val_auc: 0.9686 - val_accuracy: 0.9124 - val_cost: 10.8234\n",
            "Epoch 7/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2169 - auc: 0.9702 - accuracy: 0.9159 - cost: 10.6038 - val_loss: 0.2095 - val_auc: 0.9723 - val_accuracy: 0.9203 - val_cost: 9.8347\n",
            "Epoch 8/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.2035 - auc: 0.9737 - accuracy: 0.9222 - cost: 9.8426 - val_loss: 0.1977 - val_auc: 0.9754 - val_accuracy: 0.9250 - val_cost: 9.1700\n",
            "Epoch 9/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1928 - auc: 0.9762 - accuracy: 0.9277 - cost: 9.1339 - val_loss: 0.1869 - val_auc: 0.9775 - val_accuracy: 0.9317 - val_cost: 8.5516\n",
            "Epoch 10/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1824 - auc: 0.9787 - accuracy: 0.9317 - cost: 8.6400 - val_loss: 0.1804 - val_auc: 0.9790 - val_accuracy: 0.9331 - val_cost: 8.5251\n",
            "Epoch 11/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1754 - auc: 0.9801 - accuracy: 0.9349 - cost: 8.2473 - val_loss: 0.1724 - val_auc: 0.9805 - val_accuracy: 0.9387 - val_cost: 7.7480\n",
            "Epoch 12/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1689 - auc: 0.9815 - accuracy: 0.9379 - cost: 7.8642 - val_loss: 0.1668 - val_auc: 0.9817 - val_accuracy: 0.9398 - val_cost: 7.3909\n",
            "Epoch 13/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1625 - auc: 0.9828 - accuracy: 0.9410 - cost: 7.4811 - val_loss: 0.1618 - val_auc: 0.9827 - val_accuracy: 0.9413 - val_cost: 7.3810\n",
            "Epoch 14/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1576 - auc: 0.9835 - accuracy: 0.9435 - cost: 7.1871 - val_loss: 0.1619 - val_auc: 0.9832 - val_accuracy: 0.9428 - val_cost: 6.8155\n",
            "Epoch 15/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1529 - auc: 0.9844 - accuracy: 0.9453 - cost: 6.9340 - val_loss: 0.1558 - val_auc: 0.9836 - val_accuracy: 0.9447 - val_cost: 6.9345\n",
            "Epoch 16/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1489 - auc: 0.9852 - accuracy: 0.9474 - cost: 6.6748 - val_loss: 0.1519 - val_auc: 0.9846 - val_accuracy: 0.9473 - val_cost: 6.4319\n",
            "Epoch 17/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1449 - auc: 0.9858 - accuracy: 0.9483 - cost: 6.5718 - val_loss: 0.1497 - val_auc: 0.9848 - val_accuracy: 0.9483 - val_cost: 6.3558\n",
            "Epoch 18/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1427 - auc: 0.9862 - accuracy: 0.9496 - cost: 6.3858 - val_loss: 0.1456 - val_auc: 0.9854 - val_accuracy: 0.9483 - val_cost: 6.4484\n",
            "Epoch 19/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1382 - auc: 0.9869 - accuracy: 0.9514 - cost: 6.1617 - val_loss: 0.1439 - val_auc: 0.9859 - val_accuracy: 0.9496 - val_cost: 6.2070\n",
            "Epoch 20/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1363 - auc: 0.9872 - accuracy: 0.9533 - cost: 5.9367 - val_loss: 0.1424 - val_auc: 0.9860 - val_accuracy: 0.9507 - val_cost: 6.1475\n",
            "Epoch 21/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1331 - auc: 0.9878 - accuracy: 0.9539 - cost: 5.8476 - val_loss: 0.1412 - val_auc: 0.9861 - val_accuracy: 0.9508 - val_cost: 6.1574\n",
            "Epoch 22/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1311 - auc: 0.9880 - accuracy: 0.9549 - cost: 5.7303 - val_loss: 0.1386 - val_auc: 0.9865 - val_accuracy: 0.9524 - val_cost: 5.9722\n",
            "Epoch 23/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1287 - auc: 0.9884 - accuracy: 0.9561 - cost: 5.5656 - val_loss: 0.1352 - val_auc: 0.9869 - val_accuracy: 0.9553 - val_cost: 5.6250\n",
            "Epoch 24/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1255 - auc: 0.9888 - accuracy: 0.9567 - cost: 5.5008 - val_loss: 0.1351 - val_auc: 0.9870 - val_accuracy: 0.9538 - val_cost: 5.8565\n",
            "Epoch 25/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1237 - auc: 0.9892 - accuracy: 0.9579 - cost: 5.3468 - val_loss: 0.1326 - val_auc: 0.9873 - val_accuracy: 0.9561 - val_cost: 5.5522\n",
            "Epoch 26/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1227 - auc: 0.9892 - accuracy: 0.9584 - cost: 5.2836 - val_loss: 0.1335 - val_auc: 0.9874 - val_accuracy: 0.9553 - val_cost: 5.4101\n",
            "Epoch 27/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1200 - auc: 0.9896 - accuracy: 0.9601 - cost: 5.0814 - val_loss: 0.1318 - val_auc: 0.9874 - val_accuracy: 0.9576 - val_cost: 5.3935\n",
            "Epoch 28/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1176 - auc: 0.9899 - accuracy: 0.9605 - cost: 5.0274 - val_loss: 0.1299 - val_auc: 0.9876 - val_accuracy: 0.9581 - val_cost: 5.2910\n",
            "Epoch 29/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1167 - auc: 0.9900 - accuracy: 0.9609 - cost: 4.9734 - val_loss: 0.1286 - val_auc: 0.9876 - val_accuracy: 0.9586 - val_cost: 5.1025\n",
            "Epoch 30/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1141 - auc: 0.9904 - accuracy: 0.9622 - cost: 4.8094 - val_loss: 0.1282 - val_auc: 0.9877 - val_accuracy: 0.9599 - val_cost: 4.8909\n",
            "Epoch 31/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1131 - auc: 0.9905 - accuracy: 0.9625 - cost: 4.7581 - val_loss: 0.1262 - val_auc: 0.9880 - val_accuracy: 0.9592 - val_cost: 5.1290\n",
            "Epoch 32/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1115 - auc: 0.9908 - accuracy: 0.9630 - cost: 4.7006 - val_loss: 0.1271 - val_auc: 0.9878 - val_accuracy: 0.9585 - val_cost: 5.1025\n",
            "Epoch 33/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1096 - auc: 0.9910 - accuracy: 0.9640 - cost: 4.5860 - val_loss: 0.1262 - val_auc: 0.9880 - val_accuracy: 0.9599 - val_cost: 5.0827\n",
            "Epoch 34/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1091 - auc: 0.9910 - accuracy: 0.9644 - cost: 4.5332 - val_loss: 0.1247 - val_auc: 0.9883 - val_accuracy: 0.9603 - val_cost: 4.9372\n",
            "Epoch 35/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.1073 - auc: 0.9913 - accuracy: 0.9651 - cost: 4.4367 - val_loss: 0.1255 - val_auc: 0.9884 - val_accuracy: 0.9593 - val_cost: 4.8743\n",
            "Epoch 36/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1061 - auc: 0.9914 - accuracy: 0.9658 - cost: 4.3472 - val_loss: 0.1229 - val_auc: 0.9884 - val_accuracy: 0.9602 - val_cost: 4.9636\n",
            "Epoch 37/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1045 - auc: 0.9915 - accuracy: 0.9655 - cost: 4.3931 - val_loss: 0.1219 - val_auc: 0.9885 - val_accuracy: 0.9611 - val_cost: 4.7189\n",
            "Epoch 38/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1033 - auc: 0.9916 - accuracy: 0.9670 - cost: 4.1983 - val_loss: 0.1229 - val_auc: 0.9884 - val_accuracy: 0.9607 - val_cost: 4.8810\n",
            "Epoch 39/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1030 - auc: 0.9917 - accuracy: 0.9667 - cost: 4.2365 - val_loss: 0.1225 - val_auc: 0.9886 - val_accuracy: 0.9616 - val_cost: 4.6098\n",
            "Epoch 40/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.1023 - auc: 0.9917 - accuracy: 0.9674 - cost: 4.1474 - val_loss: 0.1202 - val_auc: 0.9887 - val_accuracy: 0.9629 - val_cost: 4.6925\n",
            "Epoch 41/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.1013 - auc: 0.9919 - accuracy: 0.9671 - cost: 4.2029 - val_loss: 0.1208 - val_auc: 0.9887 - val_accuracy: 0.9612 - val_cost: 4.7553\n",
            "Epoch 42/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1002 - auc: 0.9919 - accuracy: 0.9677 - cost: 4.1076 - val_loss: 0.1186 - val_auc: 0.9889 - val_accuracy: 0.9640 - val_cost: 4.5569\n",
            "Epoch 43/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0988 - auc: 0.9922 - accuracy: 0.9685 - cost: 4.0150 - val_loss: 0.1189 - val_auc: 0.9891 - val_accuracy: 0.9627 - val_cost: 4.6759\n",
            "Epoch 44/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0976 - auc: 0.9922 - accuracy: 0.9690 - cost: 3.9545 - val_loss: 0.1183 - val_auc: 0.9890 - val_accuracy: 0.9626 - val_cost: 4.5899\n",
            "Epoch 45/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0969 - auc: 0.9924 - accuracy: 0.9691 - cost: 3.9406 - val_loss: 0.1174 - val_auc: 0.9892 - val_accuracy: 0.9644 - val_cost: 4.3188\n",
            "Epoch 46/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0958 - auc: 0.9925 - accuracy: 0.9695 - cost: 3.8866 - val_loss: 0.1171 - val_auc: 0.9891 - val_accuracy: 0.9637 - val_cost: 4.5635\n",
            "Epoch 47/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0955 - auc: 0.9926 - accuracy: 0.9697 - cost: 3.8630 - val_loss: 0.1175 - val_auc: 0.9892 - val_accuracy: 0.9634 - val_cost: 4.4180\n",
            "Epoch 48/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0948 - auc: 0.9926 - accuracy: 0.9697 - cost: 3.8515 - val_loss: 0.1161 - val_auc: 0.9895 - val_accuracy: 0.9644 - val_cost: 4.5073\n",
            "Epoch 49/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0939 - auc: 0.9927 - accuracy: 0.9705 - cost: 3.7666 - val_loss: 0.1156 - val_auc: 0.9894 - val_accuracy: 0.9651 - val_cost: 4.3485\n",
            "Epoch 50/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0926 - auc: 0.9928 - accuracy: 0.9710 - cost: 3.6968 - val_loss: 0.1163 - val_auc: 0.9891 - val_accuracy: 0.9655 - val_cost: 4.3981\n",
            "Epoch 51/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0920 - auc: 0.9929 - accuracy: 0.9710 - cost: 3.6964 - val_loss: 0.1143 - val_auc: 0.9894 - val_accuracy: 0.9658 - val_cost: 4.2328\n",
            "Epoch 52/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0907 - auc: 0.9929 - accuracy: 0.9716 - cost: 3.6285 - val_loss: 0.1141 - val_auc: 0.9895 - val_accuracy: 0.9653 - val_cost: 4.2593\n",
            "Epoch 53/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0907 - auc: 0.9929 - accuracy: 0.9714 - cost: 3.6512 - val_loss: 0.1140 - val_auc: 0.9897 - val_accuracy: 0.9648 - val_cost: 4.3287\n",
            "Epoch 54/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0898 - auc: 0.9932 - accuracy: 0.9724 - cost: 3.5174 - val_loss: 0.1143 - val_auc: 0.9894 - val_accuracy: 0.9661 - val_cost: 4.2163\n",
            "Epoch 55/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0893 - auc: 0.9932 - accuracy: 0.9724 - cost: 3.5251 - val_loss: 0.1142 - val_auc: 0.9895 - val_accuracy: 0.9664 - val_cost: 4.2626\n",
            "Epoch 56/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0879 - auc: 0.9933 - accuracy: 0.9723 - cost: 3.5475 - val_loss: 0.1131 - val_auc: 0.9896 - val_accuracy: 0.9674 - val_cost: 3.9980\n",
            "Epoch 57/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0883 - auc: 0.9933 - accuracy: 0.9724 - cost: 3.5154 - val_loss: 0.1121 - val_auc: 0.9899 - val_accuracy: 0.9664 - val_cost: 4.2295\n",
            "Epoch 58/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0873 - auc: 0.9934 - accuracy: 0.9729 - cost: 3.4591 - val_loss: 0.1114 - val_auc: 0.9898 - val_accuracy: 0.9674 - val_cost: 4.0575\n",
            "Epoch 59/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0873 - auc: 0.9933 - accuracy: 0.9731 - cost: 3.4398 - val_loss: 0.1127 - val_auc: 0.9895 - val_accuracy: 0.9672 - val_cost: 4.0675\n",
            "Epoch 60/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0864 - auc: 0.9934 - accuracy: 0.9737 - cost: 3.3584 - val_loss: 0.1134 - val_auc: 0.9895 - val_accuracy: 0.9667 - val_cost: 4.2824\n",
            "Epoch 61/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0858 - auc: 0.9935 - accuracy: 0.9731 - cost: 3.4275 - val_loss: 0.1119 - val_auc: 0.9898 - val_accuracy: 0.9669 - val_cost: 4.0840\n",
            "Epoch 62/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0847 - auc: 0.9937 - accuracy: 0.9736 - cost: 3.3785 - val_loss: 0.1110 - val_auc: 0.9898 - val_accuracy: 0.9680 - val_cost: 3.9782\n",
            "Epoch 63/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0841 - auc: 0.9938 - accuracy: 0.9739 - cost: 3.3295 - val_loss: 0.1117 - val_auc: 0.9900 - val_accuracy: 0.9675 - val_cost: 4.1799\n",
            "Epoch 64/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0838 - auc: 0.9938 - accuracy: 0.9742 - cost: 3.3071 - val_loss: 0.1099 - val_auc: 0.9899 - val_accuracy: 0.9672 - val_cost: 4.0476\n",
            "Epoch 65/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0833 - auc: 0.9938 - accuracy: 0.9748 - cost: 3.2176 - val_loss: 0.1094 - val_auc: 0.9901 - val_accuracy: 0.9690 - val_cost: 3.9120\n",
            "Epoch 66/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0839 - auc: 0.9937 - accuracy: 0.9739 - cost: 3.3426 - val_loss: 0.1097 - val_auc: 0.9898 - val_accuracy: 0.9683 - val_cost: 3.9352\n",
            "Epoch 67/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0827 - auc: 0.9939 - accuracy: 0.9743 - cost: 3.2716 - val_loss: 0.1092 - val_auc: 0.9900 - val_accuracy: 0.9690 - val_cost: 3.8459\n",
            "Epoch 68/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0826 - auc: 0.9939 - accuracy: 0.9746 - cost: 3.2473 - val_loss: 0.1105 - val_auc: 0.9896 - val_accuracy: 0.9688 - val_cost: 3.9054\n",
            "Epoch 69/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0812 - auc: 0.9941 - accuracy: 0.9748 - cost: 3.2234 - val_loss: 0.1104 - val_auc: 0.9899 - val_accuracy: 0.9680 - val_cost: 4.0146\n",
            "Epoch 70/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0817 - auc: 0.9940 - accuracy: 0.9747 - cost: 3.2234 - val_loss: 0.1114 - val_auc: 0.9898 - val_accuracy: 0.9681 - val_cost: 4.0642\n",
            "Epoch 71/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0820 - auc: 0.9939 - accuracy: 0.9750 - cost: 3.2006 - val_loss: 0.1101 - val_auc: 0.9900 - val_accuracy: 0.9683 - val_cost: 3.9815\n",
            "Epoch 72/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0800 - auc: 0.9942 - accuracy: 0.9751 - cost: 3.1902 - val_loss: 0.1099 - val_auc: 0.9899 - val_accuracy: 0.9690 - val_cost: 3.7897\n",
            "Epoch 73/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0799 - auc: 0.9942 - accuracy: 0.9752 - cost: 3.1613 - val_loss: 0.1122 - val_auc: 0.9897 - val_accuracy: 0.9673 - val_cost: 3.9187\n",
            "Epoch 74/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0799 - auc: 0.9941 - accuracy: 0.9755 - cost: 3.1223 - val_loss: 0.1091 - val_auc: 0.9900 - val_accuracy: 0.9693 - val_cost: 3.8128\n",
            "Epoch 75/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0786 - auc: 0.9942 - accuracy: 0.9761 - cost: 3.0478 - val_loss: 0.1112 - val_auc: 0.9900 - val_accuracy: 0.9684 - val_cost: 3.9649\n",
            "Epoch 76/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0792 - auc: 0.9942 - accuracy: 0.9759 - cost: 3.0810 - val_loss: 0.1084 - val_auc: 0.9902 - val_accuracy: 0.9699 - val_cost: 3.7500\n",
            "Epoch 77/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0789 - auc: 0.9942 - accuracy: 0.9760 - cost: 3.0617 - val_loss: 0.1108 - val_auc: 0.9902 - val_accuracy: 0.9679 - val_cost: 3.9484\n",
            "Epoch 78/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0779 - auc: 0.9943 - accuracy: 0.9762 - cost: 3.0409 - val_loss: 0.1098 - val_auc: 0.9904 - val_accuracy: 0.9686 - val_cost: 3.9451\n",
            "Epoch 79/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0785 - auc: 0.9943 - accuracy: 0.9761 - cost: 3.0606 - val_loss: 0.1105 - val_auc: 0.9903 - val_accuracy: 0.9687 - val_cost: 3.9815\n",
            "Epoch 80/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0772 - auc: 0.9944 - accuracy: 0.9767 - cost: 2.9738 - val_loss: 0.1133 - val_auc: 0.9899 - val_accuracy: 0.9673 - val_cost: 4.0509\n",
            "Epoch 81/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0776 - auc: 0.9943 - accuracy: 0.9761 - cost: 3.0525 - val_loss: 0.1114 - val_auc: 0.9900 - val_accuracy: 0.9683 - val_cost: 4.0311\n",
            "Epoch 82/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0781 - auc: 0.9943 - accuracy: 0.9765 - cost: 2.9965 - val_loss: 0.1099 - val_auc: 0.9901 - val_accuracy: 0.9694 - val_cost: 3.7765\n",
            "Epoch 83/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0770 - auc: 0.9944 - accuracy: 0.9768 - cost: 2.9672 - val_loss: 0.1098 - val_auc: 0.9902 - val_accuracy: 0.9701 - val_cost: 3.8228\n",
            "Epoch 84/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0765 - auc: 0.9945 - accuracy: 0.9769 - cost: 2.9576 - val_loss: 0.1113 - val_auc: 0.9899 - val_accuracy: 0.9694 - val_cost: 3.7798\n",
            "Epoch 85/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0764 - auc: 0.9945 - accuracy: 0.9772 - cost: 2.9290 - val_loss: 0.1104 - val_auc: 0.9900 - val_accuracy: 0.9695 - val_cost: 3.7831\n",
            "Epoch 86/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0756 - auc: 0.9946 - accuracy: 0.9768 - cost: 2.9684 - val_loss: 0.1123 - val_auc: 0.9899 - val_accuracy: 0.9693 - val_cost: 3.6673\n",
            "Epoch 87/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0763 - auc: 0.9944 - accuracy: 0.9770 - cost: 2.9468 - val_loss: 0.1104 - val_auc: 0.9902 - val_accuracy: 0.9690 - val_cost: 3.8790\n",
            "Epoch 88/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0753 - auc: 0.9946 - accuracy: 0.9770 - cost: 2.9367 - val_loss: 0.1087 - val_auc: 0.9901 - val_accuracy: 0.9697 - val_cost: 3.7897\n",
            "Epoch 89/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0757 - auc: 0.9945 - accuracy: 0.9774 - cost: 2.8939 - val_loss: 0.1083 - val_auc: 0.9901 - val_accuracy: 0.9699 - val_cost: 3.8095\n",
            "Epoch 90/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0741 - auc: 0.9947 - accuracy: 0.9779 - cost: 2.8279 - val_loss: 0.1107 - val_auc: 0.9900 - val_accuracy: 0.9691 - val_cost: 3.8591\n",
            "Epoch 91/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0741 - auc: 0.9947 - accuracy: 0.9777 - cost: 2.8569 - val_loss: 0.1101 - val_auc: 0.9901 - val_accuracy: 0.9702 - val_cost: 3.6442\n",
            "Epoch 92/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0744 - auc: 0.9947 - accuracy: 0.9781 - cost: 2.7901 - val_loss: 0.1111 - val_auc: 0.9900 - val_accuracy: 0.9701 - val_cost: 3.7632\n",
            "Epoch 93/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0745 - auc: 0.9946 - accuracy: 0.9774 - cost: 2.8989 - val_loss: 0.1099 - val_auc: 0.9900 - val_accuracy: 0.9694 - val_cost: 3.8757\n",
            "Epoch 94/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0742 - auc: 0.9946 - accuracy: 0.9777 - cost: 2.8576 - val_loss: 0.1104 - val_auc: 0.9901 - val_accuracy: 0.9697 - val_cost: 3.8062\n",
            "Epoch 95/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0728 - auc: 0.9948 - accuracy: 0.9780 - cost: 2.8198 - val_loss: 0.1105 - val_auc: 0.9899 - val_accuracy: 0.9688 - val_cost: 3.9187\n",
            "Epoch 96/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0742 - auc: 0.9946 - accuracy: 0.9777 - cost: 2.8534 - val_loss: 0.1096 - val_auc: 0.9900 - val_accuracy: 0.9699 - val_cost: 3.7037\n",
            "Epoch 97/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0737 - auc: 0.9947 - accuracy: 0.9774 - cost: 2.8985 - val_loss: 0.1123 - val_auc: 0.9901 - val_accuracy: 0.9690 - val_cost: 4.0013\n",
            "Epoch 98/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0726 - auc: 0.9947 - accuracy: 0.9781 - cost: 2.8102 - val_loss: 0.1109 - val_auc: 0.9899 - val_accuracy: 0.9701 - val_cost: 3.6343\n",
            "Epoch 99/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0726 - auc: 0.9950 - accuracy: 0.9784 - cost: 2.7654 - val_loss: 0.1103 - val_auc: 0.9899 - val_accuracy: 0.9697 - val_cost: 3.8624\n",
            "Epoch 100/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0724 - auc: 0.9949 - accuracy: 0.9785 - cost: 2.7539 - val_loss: 0.1132 - val_auc: 0.9898 - val_accuracy: 0.9703 - val_cost: 3.5747\n",
            "Epoch 101/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0732 - auc: 0.9949 - accuracy: 0.9781 - cost: 2.8086 - val_loss: 0.1128 - val_auc: 0.9898 - val_accuracy: 0.9692 - val_cost: 3.9385\n",
            "Epoch 102/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0729 - auc: 0.9948 - accuracy: 0.9782 - cost: 2.7948 - val_loss: 0.1107 - val_auc: 0.9900 - val_accuracy: 0.9700 - val_cost: 3.7500\n",
            "Epoch 103/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0721 - auc: 0.9949 - accuracy: 0.9783 - cost: 2.7809 - val_loss: 0.1107 - val_auc: 0.9903 - val_accuracy: 0.9709 - val_cost: 3.6177\n",
            "Epoch 104/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0720 - auc: 0.9949 - accuracy: 0.9783 - cost: 2.7647 - val_loss: 0.1112 - val_auc: 0.9898 - val_accuracy: 0.9694 - val_cost: 3.8690\n",
            "Epoch 105/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0712 - auc: 0.9950 - accuracy: 0.9784 - cost: 2.7616 - val_loss: 0.1108 - val_auc: 0.9903 - val_accuracy: 0.9702 - val_cost: 3.7566\n",
            "Epoch 106/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0719 - auc: 0.9949 - accuracy: 0.9782 - cost: 2.7855 - val_loss: 0.1114 - val_auc: 0.9898 - val_accuracy: 0.9697 - val_cost: 3.7963\n",
            "Epoch 107/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0711 - auc: 0.9950 - accuracy: 0.9790 - cost: 2.6995 - val_loss: 0.1129 - val_auc: 0.9897 - val_accuracy: 0.9695 - val_cost: 3.8790\n",
            "Epoch 108/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0714 - auc: 0.9950 - accuracy: 0.9785 - cost: 2.7589 - val_loss: 0.1109 - val_auc: 0.9899 - val_accuracy: 0.9698 - val_cost: 3.7599\n",
            "Epoch 109/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0718 - auc: 0.9948 - accuracy: 0.9784 - cost: 2.7461 - val_loss: 0.1104 - val_auc: 0.9901 - val_accuracy: 0.9700 - val_cost: 3.7798\n",
            "Epoch 110/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0712 - auc: 0.9949 - accuracy: 0.9787 - cost: 2.7203 - val_loss: 0.1107 - val_auc: 0.9900 - val_accuracy: 0.9703 - val_cost: 3.7368\n",
            "Epoch 111/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0719 - auc: 0.9949 - accuracy: 0.9782 - cost: 2.7894 - val_loss: 0.1112 - val_auc: 0.9899 - val_accuracy: 0.9701 - val_cost: 3.7269\n",
            "Epoch 112/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0700 - auc: 0.9951 - accuracy: 0.9789 - cost: 2.6987 - val_loss: 0.1127 - val_auc: 0.9899 - val_accuracy: 0.9695 - val_cost: 3.7235\n",
            "Epoch 113/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0707 - auc: 0.9949 - accuracy: 0.9789 - cost: 2.7037 - val_loss: 0.1106 - val_auc: 0.9897 - val_accuracy: 0.9704 - val_cost: 3.6475\n",
            "Epoch 114/1000\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.0698 - auc: 0.9950 - accuracy: 0.9791 - cost: 2.6744 - val_loss: 0.1096 - val_auc: 0.9903 - val_accuracy: 0.9701 - val_cost: 3.7037\n",
            "Epoch 115/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0706 - auc: 0.9951 - accuracy: 0.9790 - cost: 2.6964 - val_loss: 0.1112 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.6574\n",
            "Epoch 116/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0698 - auc: 0.9951 - accuracy: 0.9792 - cost: 2.6644 - val_loss: 0.1122 - val_auc: 0.9897 - val_accuracy: 0.9698 - val_cost: 3.6938\n",
            "Epoch 117/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0697 - auc: 0.9951 - accuracy: 0.9796 - cost: 2.6204 - val_loss: 0.1113 - val_auc: 0.9901 - val_accuracy: 0.9703 - val_cost: 3.6574\n",
            "Epoch 118/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0700 - auc: 0.9949 - accuracy: 0.9792 - cost: 2.6705 - val_loss: 0.1095 - val_auc: 0.9902 - val_accuracy: 0.9703 - val_cost: 3.6839\n",
            "Epoch 119/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0693 - auc: 0.9952 - accuracy: 0.9795 - cost: 2.6292 - val_loss: 0.1126 - val_auc: 0.9898 - val_accuracy: 0.9701 - val_cost: 3.6905\n",
            "Epoch 120/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0697 - auc: 0.9951 - accuracy: 0.9794 - cost: 2.6319 - val_loss: 0.1107 - val_auc: 0.9900 - val_accuracy: 0.9706 - val_cost: 3.7202\n",
            "Epoch 121/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0689 - auc: 0.9952 - accuracy: 0.9796 - cost: 2.6177 - val_loss: 0.1124 - val_auc: 0.9899 - val_accuracy: 0.9718 - val_cost: 3.4226\n",
            "Epoch 122/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0686 - auc: 0.9952 - accuracy: 0.9795 - cost: 2.6308 - val_loss: 0.1120 - val_auc: 0.9901 - val_accuracy: 0.9708 - val_cost: 3.5714\n",
            "Epoch 123/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0683 - auc: 0.9953 - accuracy: 0.9795 - cost: 2.6235 - val_loss: 0.1139 - val_auc: 0.9897 - val_accuracy: 0.9699 - val_cost: 3.6806\n",
            "Epoch 124/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0692 - auc: 0.9952 - accuracy: 0.9791 - cost: 2.6836 - val_loss: 0.1125 - val_auc: 0.9898 - val_accuracy: 0.9708 - val_cost: 3.6739\n",
            "Epoch 125/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0686 - auc: 0.9952 - accuracy: 0.9798 - cost: 2.5907 - val_loss: 0.1114 - val_auc: 0.9900 - val_accuracy: 0.9705 - val_cost: 3.7202\n",
            "Epoch 126/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0679 - auc: 0.9953 - accuracy: 0.9803 - cost: 2.5313 - val_loss: 0.1143 - val_auc: 0.9896 - val_accuracy: 0.9697 - val_cost: 3.7335\n",
            "Epoch 127/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0682 - auc: 0.9953 - accuracy: 0.9798 - cost: 2.5876 - val_loss: 0.1129 - val_auc: 0.9902 - val_accuracy: 0.9701 - val_cost: 3.8790\n",
            "Epoch 128/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0687 - auc: 0.9953 - accuracy: 0.9793 - cost: 2.6485 - val_loss: 0.1132 - val_auc: 0.9899 - val_accuracy: 0.9705 - val_cost: 3.6739\n",
            "Epoch 129/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0681 - auc: 0.9951 - accuracy: 0.9798 - cost: 2.5937 - val_loss: 0.1122 - val_auc: 0.9897 - val_accuracy: 0.9700 - val_cost: 3.7037\n",
            "Epoch 130/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0687 - auc: 0.9952 - accuracy: 0.9797 - cost: 2.6007 - val_loss: 0.1121 - val_auc: 0.9898 - val_accuracy: 0.9712 - val_cost: 3.5946\n",
            "Epoch 131/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0688 - auc: 0.9951 - accuracy: 0.9797 - cost: 2.6019 - val_loss: 0.1130 - val_auc: 0.9898 - val_accuracy: 0.9698 - val_cost: 3.8095\n",
            "Epoch 132/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0686 - auc: 0.9952 - accuracy: 0.9797 - cost: 2.6080 - val_loss: 0.1103 - val_auc: 0.9901 - val_accuracy: 0.9705 - val_cost: 3.6574\n",
            "Epoch 133/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0677 - auc: 0.9952 - accuracy: 0.9798 - cost: 2.5791 - val_loss: 0.1142 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.5880\n",
            "Epoch 134/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0675 - auc: 0.9952 - accuracy: 0.9800 - cost: 2.5656 - val_loss: 0.1129 - val_auc: 0.9896 - val_accuracy: 0.9697 - val_cost: 3.7632\n",
            "Epoch 135/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0671 - auc: 0.9953 - accuracy: 0.9801 - cost: 2.5498 - val_loss: 0.1158 - val_auc: 0.9893 - val_accuracy: 0.9708 - val_cost: 3.5946\n",
            "Epoch 136/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0679 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.5752 - val_loss: 0.1100 - val_auc: 0.9902 - val_accuracy: 0.9710 - val_cost: 3.6144\n",
            "Epoch 137/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0672 - auc: 0.9953 - accuracy: 0.9803 - cost: 2.5282 - val_loss: 0.1126 - val_auc: 0.9897 - val_accuracy: 0.9704 - val_cost: 3.6442\n",
            "Epoch 138/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0687 - auc: 0.9953 - accuracy: 0.9792 - cost: 2.6752 - val_loss: 0.1102 - val_auc: 0.9901 - val_accuracy: 0.9704 - val_cost: 3.7566\n",
            "Epoch 139/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0675 - auc: 0.9954 - accuracy: 0.9799 - cost: 2.5826 - val_loss: 0.1118 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.6574\n",
            "Epoch 140/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0677 - auc: 0.9953 - accuracy: 0.9799 - cost: 2.5787 - val_loss: 0.1124 - val_auc: 0.9900 - val_accuracy: 0.9699 - val_cost: 3.7632\n",
            "Epoch 141/1000\n",
            "120/120 [==============================] - 1s 4ms/step - loss: 0.0670 - auc: 0.9955 - accuracy: 0.9797 - cost: 2.5995 - val_loss: 0.1129 - val_auc: 0.9897 - val_accuracy: 0.9699 - val_cost: 3.7235\n",
            "Epoch 142/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0663 - auc: 0.9955 - accuracy: 0.9804 - cost: 2.5174 - val_loss: 0.1128 - val_auc: 0.9899 - val_accuracy: 0.9703 - val_cost: 3.5714\n",
            "Epoch 143/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0664 - auc: 0.9954 - accuracy: 0.9802 - cost: 2.5397 - val_loss: 0.1134 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.6673\n",
            "Epoch 144/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0667 - auc: 0.9953 - accuracy: 0.9802 - cost: 2.5405 - val_loss: 0.1119 - val_auc: 0.9901 - val_accuracy: 0.9707 - val_cost: 3.6376\n",
            "Epoch 145/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0667 - auc: 0.9954 - accuracy: 0.9804 - cost: 2.5143 - val_loss: 0.1106 - val_auc: 0.9901 - val_accuracy: 0.9708 - val_cost: 3.6607\n",
            "Epoch 146/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0664 - auc: 0.9955 - accuracy: 0.9807 - cost: 2.4753 - val_loss: 0.1143 - val_auc: 0.9898 - val_accuracy: 0.9710 - val_cost: 3.5086\n",
            "Epoch 147/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0669 - auc: 0.9953 - accuracy: 0.9804 - cost: 2.5197 - val_loss: 0.1128 - val_auc: 0.9900 - val_accuracy: 0.9711 - val_cost: 3.5946\n",
            "Epoch 148/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0664 - auc: 0.9954 - accuracy: 0.9804 - cost: 2.5131 - val_loss: 0.1136 - val_auc: 0.9896 - val_accuracy: 0.9706 - val_cost: 3.6276\n",
            "Epoch 149/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0667 - auc: 0.9953 - accuracy: 0.9805 - cost: 2.4977 - val_loss: 0.1121 - val_auc: 0.9900 - val_accuracy: 0.9712 - val_cost: 3.5813\n",
            "Epoch 150/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0662 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4834 - val_loss: 0.1137 - val_auc: 0.9899 - val_accuracy: 0.9714 - val_cost: 3.5119\n",
            "Epoch 151/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0659 - auc: 0.9955 - accuracy: 0.9805 - cost: 2.4992 - val_loss: 0.1111 - val_auc: 0.9902 - val_accuracy: 0.9717 - val_cost: 3.4921\n",
            "Epoch 152/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0661 - auc: 0.9954 - accuracy: 0.9804 - cost: 2.5147 - val_loss: 0.1129 - val_auc: 0.9898 - val_accuracy: 0.9710 - val_cost: 3.5384\n",
            "Epoch 153/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0652 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4823 - val_loss: 0.1112 - val_auc: 0.9902 - val_accuracy: 0.9716 - val_cost: 3.4854\n",
            "Epoch 154/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0662 - auc: 0.9955 - accuracy: 0.9806 - cost: 2.4915 - val_loss: 0.1125 - val_auc: 0.9902 - val_accuracy: 0.9717 - val_cost: 3.5218\n",
            "Epoch 155/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0659 - auc: 0.9954 - accuracy: 0.9804 - cost: 2.5197 - val_loss: 0.1115 - val_auc: 0.9899 - val_accuracy: 0.9713 - val_cost: 3.6210\n",
            "Epoch 156/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0656 - auc: 0.9955 - accuracy: 0.9808 - cost: 2.4606 - val_loss: 0.1122 - val_auc: 0.9901 - val_accuracy: 0.9712 - val_cost: 3.5714\n",
            "Epoch 157/1000\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.0654 - auc: 0.9954 - accuracy: 0.9803 - cost: 2.5285 - val_loss: 0.1134 - val_auc: 0.9899 - val_accuracy: 0.9709 - val_cost: 3.5913\n",
            "Epoch 158/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0660 - auc: 0.9955 - accuracy: 0.9803 - cost: 2.5258 - val_loss: 0.1120 - val_auc: 0.9900 - val_accuracy: 0.9715 - val_cost: 3.5317\n",
            "Epoch 159/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0657 - auc: 0.9955 - accuracy: 0.9803 - cost: 2.5347 - val_loss: 0.1128 - val_auc: 0.9900 - val_accuracy: 0.9717 - val_cost: 3.4854\n",
            "Epoch 160/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0648 - auc: 0.9956 - accuracy: 0.9811 - cost: 2.4221 - val_loss: 0.1119 - val_auc: 0.9901 - val_accuracy: 0.9711 - val_cost: 3.5780\n",
            "Epoch 161/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0651 - auc: 0.9956 - accuracy: 0.9805 - cost: 2.4946 - val_loss: 0.1125 - val_auc: 0.9899 - val_accuracy: 0.9717 - val_cost: 3.4987\n",
            "Epoch 162/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0646 - auc: 0.9956 - accuracy: 0.9811 - cost: 2.4232 - val_loss: 0.1127 - val_auc: 0.9899 - val_accuracy: 0.9712 - val_cost: 3.4689\n",
            "Epoch 163/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0653 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4487 - val_loss: 0.1128 - val_auc: 0.9900 - val_accuracy: 0.9720 - val_cost: 3.4325\n",
            "Epoch 164/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0656 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4529 - val_loss: 0.1126 - val_auc: 0.9900 - val_accuracy: 0.9710 - val_cost: 3.6177\n",
            "Epoch 165/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0650 - auc: 0.9956 - accuracy: 0.9808 - cost: 2.4641 - val_loss: 0.1152 - val_auc: 0.9897 - val_accuracy: 0.9715 - val_cost: 3.5913\n",
            "Epoch 166/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0650 - auc: 0.9956 - accuracy: 0.9805 - cost: 2.5031 - val_loss: 0.1110 - val_auc: 0.9901 - val_accuracy: 0.9716 - val_cost: 3.5284\n",
            "Epoch 167/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0645 - auc: 0.9956 - accuracy: 0.9810 - cost: 2.4356 - val_loss: 0.1138 - val_auc: 0.9896 - val_accuracy: 0.9712 - val_cost: 3.4954\n",
            "Epoch 168/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0643 - auc: 0.9957 - accuracy: 0.9808 - cost: 2.4549 - val_loss: 0.1134 - val_auc: 0.9898 - val_accuracy: 0.9712 - val_cost: 3.4855\n",
            "Epoch 169/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0635 - auc: 0.9958 - accuracy: 0.9813 - cost: 2.4008 - val_loss: 0.1153 - val_auc: 0.9894 - val_accuracy: 0.9719 - val_cost: 3.4127\n",
            "Epoch 170/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0642 - auc: 0.9956 - accuracy: 0.9810 - cost: 2.4282 - val_loss: 0.1123 - val_auc: 0.9897 - val_accuracy: 0.9713 - val_cost: 3.6276\n",
            "Epoch 171/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0641 - auc: 0.9957 - accuracy: 0.9812 - cost: 2.4082 - val_loss: 0.1122 - val_auc: 0.9898 - val_accuracy: 0.9713 - val_cost: 3.6012\n",
            "Epoch 172/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0644 - auc: 0.9958 - accuracy: 0.9810 - cost: 2.4360 - val_loss: 0.1125 - val_auc: 0.9899 - val_accuracy: 0.9713 - val_cost: 3.4888\n",
            "Epoch 173/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0643 - auc: 0.9957 - accuracy: 0.9811 - cost: 2.4167 - val_loss: 0.1129 - val_auc: 0.9899 - val_accuracy: 0.9706 - val_cost: 3.6806\n",
            "Epoch 174/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0646 - auc: 0.9956 - accuracy: 0.9811 - cost: 2.4259 - val_loss: 0.1129 - val_auc: 0.9902 - val_accuracy: 0.9712 - val_cost: 3.5582\n",
            "Epoch 175/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0646 - auc: 0.9957 - accuracy: 0.9810 - cost: 2.4325 - val_loss: 0.1139 - val_auc: 0.9897 - val_accuracy: 0.9712 - val_cost: 3.5086\n",
            "Epoch 176/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0644 - auc: 0.9956 - accuracy: 0.9807 - cost: 2.4846 - val_loss: 0.1135 - val_auc: 0.9902 - val_accuracy: 0.9712 - val_cost: 3.5979\n",
            "Epoch 177/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0638 - auc: 0.9956 - accuracy: 0.9812 - cost: 2.4109 - val_loss: 0.1147 - val_auc: 0.9900 - val_accuracy: 0.9719 - val_cost: 3.4425\n",
            "Epoch 178/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0634 - auc: 0.9958 - accuracy: 0.9810 - cost: 2.4363 - val_loss: 0.1131 - val_auc: 0.9900 - val_accuracy: 0.9708 - val_cost: 3.6045\n",
            "Epoch 179/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0644 - auc: 0.9957 - accuracy: 0.9813 - cost: 2.3989 - val_loss: 0.1117 - val_auc: 0.9900 - val_accuracy: 0.9717 - val_cost: 3.5152\n",
            "Epoch 180/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0639 - auc: 0.9957 - accuracy: 0.9810 - cost: 2.4406 - val_loss: 0.1139 - val_auc: 0.9899 - val_accuracy: 0.9717 - val_cost: 3.5020\n",
            "Epoch 181/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0636 - auc: 0.9957 - accuracy: 0.9813 - cost: 2.3881 - val_loss: 0.1140 - val_auc: 0.9898 - val_accuracy: 0.9711 - val_cost: 3.5880\n",
            "Epoch 182/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0630 - auc: 0.9957 - accuracy: 0.9819 - cost: 2.3306 - val_loss: 0.1133 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.7434\n",
            "Epoch 183/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0635 - auc: 0.9958 - accuracy: 0.9812 - cost: 2.4066 - val_loss: 0.1147 - val_auc: 0.9900 - val_accuracy: 0.9722 - val_cost: 3.4325\n",
            "Epoch 184/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0631 - auc: 0.9958 - accuracy: 0.9818 - cost: 2.3395 - val_loss: 0.1135 - val_auc: 0.9899 - val_accuracy: 0.9717 - val_cost: 3.5417\n",
            "Epoch 185/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0632 - auc: 0.9958 - accuracy: 0.9814 - cost: 2.3920 - val_loss: 0.1147 - val_auc: 0.9898 - val_accuracy: 0.9712 - val_cost: 3.5251\n",
            "Epoch 186/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0634 - auc: 0.9958 - accuracy: 0.9813 - cost: 2.4032 - val_loss: 0.1148 - val_auc: 0.9898 - val_accuracy: 0.9699 - val_cost: 3.7864\n",
            "Epoch 187/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0624 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3519 - val_loss: 0.1159 - val_auc: 0.9897 - val_accuracy: 0.9712 - val_cost: 3.5582\n",
            "Epoch 188/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0630 - auc: 0.9958 - accuracy: 0.9813 - cost: 2.4051 - val_loss: 0.1164 - val_auc: 0.9896 - val_accuracy: 0.9717 - val_cost: 3.4656\n",
            "Epoch 189/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0631 - auc: 0.9958 - accuracy: 0.9812 - cost: 2.4090 - val_loss: 0.1139 - val_auc: 0.9899 - val_accuracy: 0.9712 - val_cost: 3.5351\n",
            "Epoch 190/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0630 - auc: 0.9959 - accuracy: 0.9815 - cost: 2.3846 - val_loss: 0.1158 - val_auc: 0.9897 - val_accuracy: 0.9714 - val_cost: 3.5813\n",
            "Epoch 191/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0631 - auc: 0.9958 - accuracy: 0.9813 - cost: 2.3993 - val_loss: 0.1150 - val_auc: 0.9898 - val_accuracy: 0.9714 - val_cost: 3.4557\n",
            "Epoch 192/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0625 - auc: 0.9958 - accuracy: 0.9818 - cost: 2.3341 - val_loss: 0.1155 - val_auc: 0.9901 - val_accuracy: 0.9704 - val_cost: 3.6508\n",
            "Epoch 193/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0630 - auc: 0.9958 - accuracy: 0.9814 - cost: 2.3935 - val_loss: 0.1154 - val_auc: 0.9899 - val_accuracy: 0.9716 - val_cost: 3.4788\n",
            "Epoch 194/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0631 - auc: 0.9958 - accuracy: 0.9814 - cost: 2.3846 - val_loss: 0.1146 - val_auc: 0.9902 - val_accuracy: 0.9708 - val_cost: 3.7269\n",
            "Epoch 195/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0633 - auc: 0.9957 - accuracy: 0.9815 - cost: 2.3723 - val_loss: 0.1156 - val_auc: 0.9897 - val_accuracy: 0.9711 - val_cost: 3.5218\n",
            "Epoch 196/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0629 - auc: 0.9959 - accuracy: 0.9813 - cost: 2.3951 - val_loss: 0.1149 - val_auc: 0.9900 - val_accuracy: 0.9710 - val_cost: 3.5251\n",
            "Epoch 197/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0623 - auc: 0.9959 - accuracy: 0.9812 - cost: 2.4105 - val_loss: 0.1153 - val_auc: 0.9900 - val_accuracy: 0.9705 - val_cost: 3.6243\n",
            "Epoch 198/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0621 - auc: 0.9960 - accuracy: 0.9818 - cost: 2.3418 - val_loss: 0.1138 - val_auc: 0.9900 - val_accuracy: 0.9727 - val_cost: 3.3466\n",
            "Epoch 199/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0613 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3268 - val_loss: 0.1165 - val_auc: 0.9900 - val_accuracy: 0.9701 - val_cost: 3.7004\n",
            "Epoch 200/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0629 - auc: 0.9957 - accuracy: 0.9815 - cost: 2.3773 - val_loss: 0.1147 - val_auc: 0.9901 - val_accuracy: 0.9706 - val_cost: 3.6210\n",
            "Epoch 201/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0621 - auc: 0.9959 - accuracy: 0.9818 - cost: 2.3422 - val_loss: 0.1145 - val_auc: 0.9899 - val_accuracy: 0.9726 - val_cost: 3.3796\n",
            "Epoch 202/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0627 - auc: 0.9958 - accuracy: 0.9817 - cost: 2.3453 - val_loss: 0.1150 - val_auc: 0.9897 - val_accuracy: 0.9713 - val_cost: 3.4722\n",
            "Epoch 203/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0620 - auc: 0.9959 - accuracy: 0.9817 - cost: 2.3661 - val_loss: 0.1141 - val_auc: 0.9898 - val_accuracy: 0.9717 - val_cost: 3.5218\n",
            "Epoch 204/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0614 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3206 - val_loss: 0.1154 - val_auc: 0.9898 - val_accuracy: 0.9708 - val_cost: 3.5714\n",
            "Epoch 205/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0611 - auc: 0.9959 - accuracy: 0.9820 - cost: 2.3225 - val_loss: 0.1176 - val_auc: 0.9898 - val_accuracy: 0.9704 - val_cost: 3.6673\n",
            "Epoch 206/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0616 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3264 - val_loss: 0.1145 - val_auc: 0.9900 - val_accuracy: 0.9703 - val_cost: 3.7996\n",
            "Epoch 207/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0617 - auc: 0.9960 - accuracy: 0.9819 - cost: 2.3326 - val_loss: 0.1162 - val_auc: 0.9897 - val_accuracy: 0.9728 - val_cost: 3.2540\n",
            "Epoch 208/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0616 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3167 - val_loss: 0.1149 - val_auc: 0.9897 - val_accuracy: 0.9713 - val_cost: 3.6409\n",
            "Epoch 209/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0622 - auc: 0.9959 - accuracy: 0.9814 - cost: 2.3873 - val_loss: 0.1154 - val_auc: 0.9900 - val_accuracy: 0.9710 - val_cost: 3.5020\n",
            "Epoch 210/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0615 - auc: 0.9960 - accuracy: 0.9817 - cost: 2.3457 - val_loss: 0.1163 - val_auc: 0.9893 - val_accuracy: 0.9706 - val_cost: 3.5946\n",
            "Epoch 211/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0608 - auc: 0.9960 - accuracy: 0.9823 - cost: 2.2874 - val_loss: 0.1164 - val_auc: 0.9900 - val_accuracy: 0.9711 - val_cost: 3.5351\n",
            "Epoch 212/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0617 - auc: 0.9959 - accuracy: 0.9816 - cost: 2.3735 - val_loss: 0.1160 - val_auc: 0.9895 - val_accuracy: 0.9712 - val_cost: 3.5615\n",
            "Epoch 213/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0612 - auc: 0.9959 - accuracy: 0.9822 - cost: 2.2886 - val_loss: 0.1149 - val_auc: 0.9898 - val_accuracy: 0.9707 - val_cost: 3.6276\n",
            "Epoch 214/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0605 - auc: 0.9962 - accuracy: 0.9822 - cost: 2.2890 - val_loss: 0.1160 - val_auc: 0.9897 - val_accuracy: 0.9705 - val_cost: 3.6045\n",
            "Epoch 215/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0613 - auc: 0.9960 - accuracy: 0.9820 - cost: 2.3090 - val_loss: 0.1167 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.5847\n",
            "Epoch 216/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0612 - auc: 0.9960 - accuracy: 0.9822 - cost: 2.2863 - val_loss: 0.1162 - val_auc: 0.9898 - val_accuracy: 0.9711 - val_cost: 3.5946\n",
            "Epoch 217/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0610 - auc: 0.9961 - accuracy: 0.9820 - cost: 2.3094 - val_loss: 0.1170 - val_auc: 0.9899 - val_accuracy: 0.9705 - val_cost: 3.6078\n",
            "Epoch 218/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0611 - auc: 0.9960 - accuracy: 0.9822 - cost: 2.2874 - val_loss: 0.1166 - val_auc: 0.9893 - val_accuracy: 0.9707 - val_cost: 3.6442\n",
            "Epoch 219/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0608 - auc: 0.9961 - accuracy: 0.9820 - cost: 2.3113 - val_loss: 0.1181 - val_auc: 0.9897 - val_accuracy: 0.9717 - val_cost: 3.4623\n",
            "Epoch 220/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0617 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3179 - val_loss: 0.1167 - val_auc: 0.9895 - val_accuracy: 0.9714 - val_cost: 3.4954\n",
            "Epoch 221/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0618 - auc: 0.9958 - accuracy: 0.9819 - cost: 2.3279 - val_loss: 0.1172 - val_auc: 0.9896 - val_accuracy: 0.9705 - val_cost: 3.7004\n",
            "Epoch 222/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0601 - auc: 0.9960 - accuracy: 0.9825 - cost: 2.2481 - val_loss: 0.1172 - val_auc: 0.9897 - val_accuracy: 0.9717 - val_cost: 3.4061\n",
            "Epoch 223/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0605 - auc: 0.9961 - accuracy: 0.9822 - cost: 2.2878 - val_loss: 0.1165 - val_auc: 0.9896 - val_accuracy: 0.9714 - val_cost: 3.5351\n",
            "Epoch 224/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0611 - auc: 0.9960 - accuracy: 0.9816 - cost: 2.3603 - val_loss: 0.1169 - val_auc: 0.9898 - val_accuracy: 0.9717 - val_cost: 3.4656\n",
            "Epoch 225/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0601 - auc: 0.9961 - accuracy: 0.9821 - cost: 2.3021 - val_loss: 0.1158 - val_auc: 0.9900 - val_accuracy: 0.9710 - val_cost: 3.5979\n",
            "Epoch 226/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0605 - auc: 0.9960 - accuracy: 0.9824 - cost: 2.2697 - val_loss: 0.1180 - val_auc: 0.9898 - val_accuracy: 0.9704 - val_cost: 3.6276\n",
            "Epoch 227/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0609 - auc: 0.9960 - accuracy: 0.9819 - cost: 2.3272 - val_loss: 0.1160 - val_auc: 0.9900 - val_accuracy: 0.9721 - val_cost: 3.3763\n",
            "Epoch 228/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0613 - auc: 0.9960 - accuracy: 0.9821 - cost: 2.2940 - val_loss: 0.1172 - val_auc: 0.9897 - val_accuracy: 0.9710 - val_cost: 3.6144\n",
            "Epoch 229/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0605 - auc: 0.9960 - accuracy: 0.9821 - cost: 2.3098 - val_loss: 0.1167 - val_auc: 0.9900 - val_accuracy: 0.9710 - val_cost: 3.4987\n",
            "Epoch 230/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0604 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2739 - val_loss: 0.1159 - val_auc: 0.9898 - val_accuracy: 0.9714 - val_cost: 3.5847\n",
            "Epoch 231/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0603 - auc: 0.9960 - accuracy: 0.9824 - cost: 2.2674 - val_loss: 0.1166 - val_auc: 0.9901 - val_accuracy: 0.9718 - val_cost: 3.4921\n",
            "Epoch 232/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0599 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2643 - val_loss: 0.1163 - val_auc: 0.9899 - val_accuracy: 0.9714 - val_cost: 3.5648\n",
            "Epoch 233/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0597 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2542 - val_loss: 0.1158 - val_auc: 0.9900 - val_accuracy: 0.9708 - val_cost: 3.6905\n",
            "Epoch 234/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0603 - auc: 0.9959 - accuracy: 0.9824 - cost: 2.2577 - val_loss: 0.1191 - val_auc: 0.9898 - val_accuracy: 0.9708 - val_cost: 3.5251\n",
            "Epoch 235/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0609 - auc: 0.9960 - accuracy: 0.9818 - cost: 2.3430 - val_loss: 0.1177 - val_auc: 0.9894 - val_accuracy: 0.9719 - val_cost: 3.4623\n",
            "Epoch 236/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0596 - auc: 0.9960 - accuracy: 0.9824 - cost: 2.2635 - val_loss: 0.1185 - val_auc: 0.9896 - val_accuracy: 0.9707 - val_cost: 3.5880\n",
            "Epoch 237/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0604 - auc: 0.9960 - accuracy: 0.9823 - cost: 2.2728 - val_loss: 0.1194 - val_auc: 0.9894 - val_accuracy: 0.9712 - val_cost: 3.5516\n",
            "Epoch 238/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0602 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2654 - val_loss: 0.1174 - val_auc: 0.9893 - val_accuracy: 0.9712 - val_cost: 3.6111\n",
            "Epoch 239/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0596 - auc: 0.9962 - accuracy: 0.9823 - cost: 2.2758 - val_loss: 0.1165 - val_auc: 0.9900 - val_accuracy: 0.9711 - val_cost: 3.5384\n",
            "Epoch 240/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0598 - auc: 0.9961 - accuracy: 0.9825 - cost: 2.2400 - val_loss: 0.1178 - val_auc: 0.9897 - val_accuracy: 0.9708 - val_cost: 3.7235\n",
            "Epoch 241/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0589 - auc: 0.9963 - accuracy: 0.9829 - cost: 2.1941 - val_loss: 0.1190 - val_auc: 0.9899 - val_accuracy: 0.9719 - val_cost: 3.4226\n",
            "Epoch 242/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0593 - auc: 0.9963 - accuracy: 0.9825 - cost: 2.2434 - val_loss: 0.1163 - val_auc: 0.9897 - val_accuracy: 0.9711 - val_cost: 3.6177\n",
            "Epoch 243/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0595 - auc: 0.9962 - accuracy: 0.9827 - cost: 2.2245 - val_loss: 0.1187 - val_auc: 0.9896 - val_accuracy: 0.9701 - val_cost: 3.6541\n",
            "Epoch 244/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0600 - auc: 0.9962 - accuracy: 0.9821 - cost: 2.3021 - val_loss: 0.1186 - val_auc: 0.9896 - val_accuracy: 0.9710 - val_cost: 3.4954\n",
            "Epoch 245/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0589 - auc: 0.9962 - accuracy: 0.9826 - cost: 2.2265 - val_loss: 0.1171 - val_auc: 0.9895 - val_accuracy: 0.9709 - val_cost: 3.6177\n",
            "Epoch 246/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0593 - auc: 0.9962 - accuracy: 0.9825 - cost: 2.2585 - val_loss: 0.1190 - val_auc: 0.9894 - val_accuracy: 0.9708 - val_cost: 3.6508\n",
            "Epoch 247/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0593 - auc: 0.9962 - accuracy: 0.9823 - cost: 2.2809 - val_loss: 0.1170 - val_auc: 0.9896 - val_accuracy: 0.9713 - val_cost: 3.4855\n",
            "Epoch 248/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0587 - auc: 0.9963 - accuracy: 0.9827 - cost: 2.2215 - val_loss: 0.1193 - val_auc: 0.9894 - val_accuracy: 0.9710 - val_cost: 3.6541\n",
            "Epoch 249/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0599 - auc: 0.9962 - accuracy: 0.9823 - cost: 2.2785 - val_loss: 0.1183 - val_auc: 0.9896 - val_accuracy: 0.9717 - val_cost: 3.4788\n",
            "Epoch 250/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0610 - auc: 0.9960 - accuracy: 0.9823 - cost: 2.2708 - val_loss: 0.1182 - val_auc: 0.9894 - val_accuracy: 0.9699 - val_cost: 3.7434\n",
            "Epoch 251/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0581 - auc: 0.9963 - accuracy: 0.9829 - cost: 2.1979 - val_loss: 0.1176 - val_auc: 0.9898 - val_accuracy: 0.9722 - val_cost: 3.4656\n",
            "Epoch 252/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0603 - auc: 0.9962 - accuracy: 0.9823 - cost: 2.2782 - val_loss: 0.1177 - val_auc: 0.9897 - val_accuracy: 0.9710 - val_cost: 3.5780\n",
            "Epoch 253/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0595 - auc: 0.9962 - accuracy: 0.9823 - cost: 2.2735 - val_loss: 0.1186 - val_auc: 0.9897 - val_accuracy: 0.9712 - val_cost: 3.5384\n",
            "Epoch 254/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0591 - auc: 0.9963 - accuracy: 0.9825 - cost: 2.2535 - val_loss: 0.1185 - val_auc: 0.9897 - val_accuracy: 0.9719 - val_cost: 3.4392\n",
            "Epoch 255/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0589 - auc: 0.9961 - accuracy: 0.9829 - cost: 2.2025 - val_loss: 0.1191 - val_auc: 0.9894 - val_accuracy: 0.9713 - val_cost: 3.5516\n",
            "Epoch 256/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0591 - auc: 0.9962 - accuracy: 0.9828 - cost: 2.2106 - val_loss: 0.1183 - val_auc: 0.9894 - val_accuracy: 0.9710 - val_cost: 3.5417\n",
            "Epoch 257/1000\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0593 - auc: 0.9962 - accuracy: 0.9826 - cost: 2.2400 - val_loss: 0.1192 - val_auc: 0.9895 - val_accuracy: 0.9712 - val_cost: 3.5516\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.1144 - auc: 0.9905 - accuracy: 0.9695 - cost: 3.7875\n",
            "500/500 [==============================] - 0s 835us/step\n",
            "fold train/predict time: 0:01:50.467014\n",
            "fold accuracy: 0.9695000052452087 - fold cost: 3.7874999046325684\n",
            "total train/predict time: 0:16:59.496230\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m4_results = fold_results"
      ],
      "metadata": {
        "id": "fszFGfDwmD7r"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_m4 = np.zeros(len(y))\n",
        "for i in fold_results.keys():\n",
        "  for j in range(len(fold_results.get(i).get('predictions'))):\n",
        "    idx = fold_results.get(i).get('index')[j]\n",
        "    preds_m4[idx] = np.round(fold_results.get(i).get('predictions')[j],0)\n",
        "m4_cost = cost_func(y,preds_m4)\n",
        "m4_cost"
      ],
      "metadata": {
        "id": "WMZkaNGNeKT0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70649305-7d18-413b-a1cf-032959c2117f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "587650"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_new = np.zeros(len(y))\n",
        "for i in m4_results.keys():\n",
        "  for j in range(len(m4_results.get(i).get('predictions'))):\n",
        "    idx = m4_results.get(i).get('index')[j]\n",
        "    if m4_results.get(i).get('predictions')[j] > 0.6:\n",
        "      preds_new[idx] = 1\n",
        "    else:\n",
        "      preds_new[idx] = 0\n",
        "m4_cost_t = cost_func(y,preds_new)\n",
        "m4_cost_t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3X7K7DWxmHit",
        "outputId": "ca4b2860-1649-45c8-a8bf-622b6546f251"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "579700"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(model4, show_shapes=True, rankdir=\"LR\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "btrT6ETQQIe4",
        "outputId": "b2457088-db65-4cd2-c527-03a91378faef"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model4.summary()\n"
      ],
      "metadata": {
        "id": "7jg2oQFvH2QS",
        "outputId": "7423f56b-2270-41e2-b367-c1427c91d6c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Relu1 (Dense)               (None, 64)                4352      \n",
            "                                                                 \n",
            " Relu2 (Dense)               (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " Activation (Dense)          (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,577\n",
            "Trainable params: 8,577\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model4.save('model4.keras')"
      ],
      "metadata": {
        "id": "IwcfGqFmC4nv"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor='val_cost', mode='min',patience=50,restore_best_weights=True,start_from_epoch=100)\n",
        "fold_results = {}\n",
        "t_tot = now()\n",
        "for i, (train_index, test_index) in enumerate(skf.split(X,y)):\n",
        "  # building model within loop to reset weights each time\n",
        "  tf.keras.backend.clear_session()\n",
        "  tf.keras.utils.set_random_seed(807)\n",
        "  model5 = tf.keras.Sequential()\n",
        "  model5.add(tf.keras.Input(shape=(X.shape[1],)))\n",
        "  model5.add(tf.keras.layers.Dense(64, activation='relu',name=\"Relu1\"))\n",
        "  model5.add(tf.keras.layers.Dense(64, activation='relu', name=\"Relu2\"))\n",
        "  model5.add(tf.keras.layers.Dropout(0.2))\n",
        "  model5.add(tf.keras.layers.Dense(1, activation='sigmoid', name=\"Activation\"))\n",
        "  model5.compile(optimizer='adam',\n",
        "                loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "                metrics = [tf.keras.metrics.AUC(from_logits=False), 'accuracy',cost])\n",
        "  t_fold = now()\n",
        "  print('x_train shape:', X[train_index].shape)\n",
        "  model5.fit(X[train_index],y[train_index],epochs=1000,batch_size=1024,validation_split=0.1,callbacks=[es])\n",
        "  score = model5.evaluate(X[test_index],y[test_index])\n",
        "  fold_results.update({i:{'predictions':model5.predict(X[test_index]).flatten(),'index':test_index,'y_true':y[test_index]}})\n",
        "  print('fold train/predict time: %s' % (now()-t_fold))\n",
        "  print('fold accuracy: {} - fold cost: {}'.format(score[2],score[3]))\n",
        "print('total train/predict time: %s' % (now()-t_tot))"
      ],
      "metadata": {
        "id": "DVNOkJr3oYGb",
        "outputId": "26e7d888-3916-49d1-899c-2f2c1e7edb45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (128000, 67)\n",
            "Epoch 1/1000\n",
            "113/113 [==============================] - 2s 5ms/step - loss: 0.5423 - auc: 0.7852 - accuracy: 0.7189 - cost: 37.4732 - val_loss: 0.4179 - val_auc: 0.8882 - val_accuracy: 0.8152 - val_cost: 23.7380\n",
            "Epoch 2/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.3621 - auc: 0.9165 - accuracy: 0.8436 - cost: 19.9780 - val_loss: 0.3249 - val_auc: 0.9330 - val_accuracy: 0.8636 - val_cost: 17.0936\n",
            "Epoch 3/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.3094 - auc: 0.9394 - accuracy: 0.8712 - cost: 16.3393 - val_loss: 0.2957 - val_auc: 0.9448 - val_accuracy: 0.8760 - val_cost: 15.4785\n",
            "Epoch 4/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.2825 - auc: 0.9495 - accuracy: 0.8843 - cost: 14.6523 - val_loss: 0.2733 - val_auc: 0.9528 - val_accuracy: 0.8891 - val_cost: 13.8522\n",
            "Epoch 5/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.2599 - auc: 0.9574 - accuracy: 0.8956 - cost: 13.2290 - val_loss: 0.2532 - val_auc: 0.9595 - val_accuracy: 0.8986 - val_cost: 12.6239\n",
            "Epoch 6/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.2411 - auc: 0.9633 - accuracy: 0.9042 - cost: 12.1336 - val_loss: 0.2365 - val_auc: 0.9646 - val_accuracy: 0.9067 - val_cost: 11.6511\n",
            "Epoch 7/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.2256 - auc: 0.9678 - accuracy: 0.9119 - cost: 11.1155 - val_loss: 0.2232 - val_auc: 0.9684 - val_accuracy: 0.9156 - val_cost: 10.6558\n",
            "Epoch 8/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.2136 - auc: 0.9711 - accuracy: 0.9171 - cost: 10.4834 - val_loss: 0.2101 - val_auc: 0.9721 - val_accuracy: 0.9212 - val_cost: 9.8295\n",
            "Epoch 9/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.2007 - auc: 0.9744 - accuracy: 0.9234 - cost: 9.6714 - val_loss: 0.1994 - val_auc: 0.9746 - val_accuracy: 0.9264 - val_cost: 9.4464\n",
            "Epoch 10/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1916 - auc: 0.9765 - accuracy: 0.9274 - cost: 9.2082 - val_loss: 0.1928 - val_auc: 0.9765 - val_accuracy: 0.9305 - val_cost: 9.1158\n",
            "Epoch 11/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1829 - auc: 0.9785 - accuracy: 0.9316 - cost: 8.6642 - val_loss: 0.1843 - val_auc: 0.9779 - val_accuracy: 0.9331 - val_cost: 8.5036\n",
            "Epoch 12/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1755 - auc: 0.9800 - accuracy: 0.9353 - cost: 8.1867 - val_loss: 0.1783 - val_auc: 0.9794 - val_accuracy: 0.9373 - val_cost: 7.9102\n",
            "Epoch 13/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1690 - auc: 0.9814 - accuracy: 0.9384 - cost: 7.7969 - val_loss: 0.1725 - val_auc: 0.9805 - val_accuracy: 0.9392 - val_cost: 7.6510\n",
            "Epoch 14/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1641 - auc: 0.9823 - accuracy: 0.9402 - cost: 7.5744 - val_loss: 0.1699 - val_auc: 0.9808 - val_accuracy: 0.9403 - val_cost: 7.5984\n",
            "Epoch 15/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1599 - auc: 0.9831 - accuracy: 0.9421 - cost: 7.3307 - val_loss: 0.1653 - val_auc: 0.9820 - val_accuracy: 0.9420 - val_cost: 7.2979\n",
            "Epoch 16/1000\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.1557 - auc: 0.9839 - accuracy: 0.9445 - cost: 7.0412 - val_loss: 0.1629 - val_auc: 0.9824 - val_accuracy: 0.9421 - val_cost: 7.3054\n",
            "Epoch 17/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1520 - auc: 0.9845 - accuracy: 0.9460 - cost: 6.8398 - val_loss: 0.1592 - val_auc: 0.9832 - val_accuracy: 0.9443 - val_cost: 7.1477\n",
            "Epoch 18/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1480 - auc: 0.9853 - accuracy: 0.9472 - cost: 6.7003 - val_loss: 0.1571 - val_auc: 0.9834 - val_accuracy: 0.9450 - val_cost: 6.9336\n",
            "Epoch 19/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1452 - auc: 0.9858 - accuracy: 0.9490 - cost: 6.4751 - val_loss: 0.1568 - val_auc: 0.9835 - val_accuracy: 0.9450 - val_cost: 6.9862\n",
            "Epoch 20/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1423 - auc: 0.9863 - accuracy: 0.9502 - cost: 6.3200 - val_loss: 0.1534 - val_auc: 0.9840 - val_accuracy: 0.9473 - val_cost: 6.5918\n",
            "Epoch 21/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1401 - auc: 0.9866 - accuracy: 0.9515 - cost: 6.1670 - val_loss: 0.1526 - val_auc: 0.9842 - val_accuracy: 0.9480 - val_cost: 6.5580\n",
            "Epoch 22/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1387 - auc: 0.9868 - accuracy: 0.9526 - cost: 6.0322 - val_loss: 0.1494 - val_auc: 0.9847 - val_accuracy: 0.9502 - val_cost: 6.3401\n",
            "Epoch 23/1000\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.1358 - auc: 0.9872 - accuracy: 0.9529 - cost: 5.9821 - val_loss: 0.1481 - val_auc: 0.9848 - val_accuracy: 0.9503 - val_cost: 6.2876\n",
            "Epoch 24/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1344 - auc: 0.9875 - accuracy: 0.9534 - cost: 5.9056 - val_loss: 0.1474 - val_auc: 0.9851 - val_accuracy: 0.9507 - val_cost: 6.2425\n",
            "Epoch 25/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1320 - auc: 0.9879 - accuracy: 0.9547 - cost: 5.7501 - val_loss: 0.1463 - val_auc: 0.9852 - val_accuracy: 0.9516 - val_cost: 6.0810\n",
            "Epoch 26/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1296 - auc: 0.9882 - accuracy: 0.9563 - cost: 5.5720 - val_loss: 0.1446 - val_auc: 0.9854 - val_accuracy: 0.9533 - val_cost: 5.8406\n",
            "Epoch 27/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1285 - auc: 0.9884 - accuracy: 0.9564 - cost: 5.5297 - val_loss: 0.1435 - val_auc: 0.9855 - val_accuracy: 0.9534 - val_cost: 5.9420\n",
            "Epoch 28/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1267 - auc: 0.9886 - accuracy: 0.9567 - cost: 5.4968 - val_loss: 0.1438 - val_auc: 0.9855 - val_accuracy: 0.9528 - val_cost: 5.9721\n",
            "Epoch 29/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1256 - auc: 0.9888 - accuracy: 0.9574 - cost: 5.4225 - val_loss: 0.1432 - val_auc: 0.9859 - val_accuracy: 0.9529 - val_cost: 5.6791\n",
            "Epoch 30/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1230 - auc: 0.9892 - accuracy: 0.9579 - cost: 5.3370 - val_loss: 0.1401 - val_auc: 0.9860 - val_accuracy: 0.9550 - val_cost: 5.5965\n",
            "Epoch 31/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1215 - auc: 0.9894 - accuracy: 0.9592 - cost: 5.1611 - val_loss: 0.1396 - val_auc: 0.9860 - val_accuracy: 0.9555 - val_cost: 5.5664\n",
            "Epoch 32/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1204 - auc: 0.9895 - accuracy: 0.9590 - cost: 5.1913 - val_loss: 0.1393 - val_auc: 0.9861 - val_accuracy: 0.9559 - val_cost: 5.6265\n",
            "Epoch 33/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1190 - auc: 0.9898 - accuracy: 0.9595 - cost: 5.1615 - val_loss: 0.1377 - val_auc: 0.9863 - val_accuracy: 0.9548 - val_cost: 5.7542\n",
            "Epoch 34/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1183 - auc: 0.9899 - accuracy: 0.9601 - cost: 5.0777 - val_loss: 0.1375 - val_auc: 0.9863 - val_accuracy: 0.9555 - val_cost: 5.6866\n",
            "Epoch 35/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1170 - auc: 0.9900 - accuracy: 0.9604 - cost: 5.0159 - val_loss: 0.1361 - val_auc: 0.9865 - val_accuracy: 0.9555 - val_cost: 5.6566\n",
            "Epoch 36/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1150 - auc: 0.9903 - accuracy: 0.9615 - cost: 4.9092 - val_loss: 0.1358 - val_auc: 0.9866 - val_accuracy: 0.9564 - val_cost: 5.3974\n",
            "Epoch 37/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1144 - auc: 0.9903 - accuracy: 0.9618 - cost: 4.8513 - val_loss: 0.1374 - val_auc: 0.9862 - val_accuracy: 0.9552 - val_cost: 5.8444\n",
            "Epoch 38/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1124 - auc: 0.9907 - accuracy: 0.9627 - cost: 4.7584 - val_loss: 0.1348 - val_auc: 0.9869 - val_accuracy: 0.9581 - val_cost: 5.2021\n",
            "Epoch 39/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1117 - auc: 0.9908 - accuracy: 0.9633 - cost: 4.6698 - val_loss: 0.1346 - val_auc: 0.9869 - val_accuracy: 0.9581 - val_cost: 5.3673\n",
            "Epoch 40/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1108 - auc: 0.9908 - accuracy: 0.9634 - cost: 4.6495 - val_loss: 0.1350 - val_auc: 0.9869 - val_accuracy: 0.9570 - val_cost: 5.4162\n",
            "Epoch 41/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1093 - auc: 0.9910 - accuracy: 0.9636 - cost: 4.6292 - val_loss: 0.1327 - val_auc: 0.9869 - val_accuracy: 0.9586 - val_cost: 5.3486\n",
            "Epoch 42/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1084 - auc: 0.9912 - accuracy: 0.9643 - cost: 4.5574 - val_loss: 0.1329 - val_auc: 0.9871 - val_accuracy: 0.9586 - val_cost: 5.2471\n",
            "Epoch 43/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1086 - auc: 0.9911 - accuracy: 0.9638 - cost: 4.5911 - val_loss: 0.1321 - val_auc: 0.9872 - val_accuracy: 0.9591 - val_cost: 5.1795\n",
            "Epoch 44/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1076 - auc: 0.9913 - accuracy: 0.9645 - cost: 4.5099 - val_loss: 0.1323 - val_auc: 0.9872 - val_accuracy: 0.9591 - val_cost: 5.1345\n",
            "Epoch 45/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1063 - auc: 0.9914 - accuracy: 0.9652 - cost: 4.4308 - val_loss: 0.1319 - val_auc: 0.9870 - val_accuracy: 0.9594 - val_cost: 5.1119\n",
            "Epoch 46/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1051 - auc: 0.9915 - accuracy: 0.9655 - cost: 4.4006 - val_loss: 0.1309 - val_auc: 0.9871 - val_accuracy: 0.9591 - val_cost: 5.2772\n",
            "Epoch 47/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1050 - auc: 0.9916 - accuracy: 0.9658 - cost: 4.3595 - val_loss: 0.1302 - val_auc: 0.9872 - val_accuracy: 0.9600 - val_cost: 5.0706\n",
            "Epoch 48/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1035 - auc: 0.9917 - accuracy: 0.9664 - cost: 4.2666 - val_loss: 0.1308 - val_auc: 0.9873 - val_accuracy: 0.9595 - val_cost: 5.1382\n",
            "Epoch 49/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1023 - auc: 0.9919 - accuracy: 0.9664 - cost: 4.2748 - val_loss: 0.1298 - val_auc: 0.9874 - val_accuracy: 0.9600 - val_cost: 5.1044\n",
            "Epoch 50/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1024 - auc: 0.9918 - accuracy: 0.9667 - cost: 4.2316 - val_loss: 0.1285 - val_auc: 0.9875 - val_accuracy: 0.9596 - val_cost: 5.1307\n",
            "Epoch 51/1000\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.1005 - auc: 0.9922 - accuracy: 0.9670 - cost: 4.2096 - val_loss: 0.1293 - val_auc: 0.9876 - val_accuracy: 0.9595 - val_cost: 5.1795\n",
            "Epoch 52/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1003 - auc: 0.9921 - accuracy: 0.9674 - cost: 4.1508 - val_loss: 0.1290 - val_auc: 0.9875 - val_accuracy: 0.9604 - val_cost: 4.9392\n",
            "Epoch 53/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0993 - auc: 0.9923 - accuracy: 0.9676 - cost: 4.1305 - val_loss: 0.1310 - val_auc: 0.9873 - val_accuracy: 0.9590 - val_cost: 5.0218\n",
            "Epoch 54/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0976 - auc: 0.9925 - accuracy: 0.9685 - cost: 4.0104 - val_loss: 0.1272 - val_auc: 0.9875 - val_accuracy: 0.9613 - val_cost: 4.9654\n",
            "Epoch 55/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0976 - auc: 0.9924 - accuracy: 0.9685 - cost: 4.0294 - val_loss: 0.1289 - val_auc: 0.9877 - val_accuracy: 0.9609 - val_cost: 4.8302\n",
            "Epoch 56/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0980 - auc: 0.9923 - accuracy: 0.9688 - cost: 3.9732 - val_loss: 0.1273 - val_auc: 0.9877 - val_accuracy: 0.9624 - val_cost: 4.6687\n",
            "Epoch 57/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0966 - auc: 0.9925 - accuracy: 0.9691 - cost: 3.9404 - val_loss: 0.1258 - val_auc: 0.9879 - val_accuracy: 0.9620 - val_cost: 4.8152\n",
            "Epoch 58/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0956 - auc: 0.9927 - accuracy: 0.9689 - cost: 3.9689 - val_loss: 0.1258 - val_auc: 0.9878 - val_accuracy: 0.9621 - val_cost: 4.7927\n",
            "Epoch 59/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0949 - auc: 0.9928 - accuracy: 0.9693 - cost: 3.9196 - val_loss: 0.1266 - val_auc: 0.9881 - val_accuracy: 0.9623 - val_cost: 4.6725\n",
            "Epoch 60/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0943 - auc: 0.9928 - accuracy: 0.9696 - cost: 3.8708 - val_loss: 0.1248 - val_auc: 0.9881 - val_accuracy: 0.9638 - val_cost: 4.4884\n",
            "Epoch 61/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0934 - auc: 0.9928 - accuracy: 0.9705 - cost: 3.7637 - val_loss: 0.1251 - val_auc: 0.9879 - val_accuracy: 0.9634 - val_cost: 4.5485\n",
            "Epoch 62/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0926 - auc: 0.9930 - accuracy: 0.9705 - cost: 3.7714 - val_loss: 0.1240 - val_auc: 0.9882 - val_accuracy: 0.9638 - val_cost: 4.5035\n",
            "Epoch 63/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0921 - auc: 0.9930 - accuracy: 0.9704 - cost: 3.7602 - val_loss: 0.1240 - val_auc: 0.9882 - val_accuracy: 0.9627 - val_cost: 4.7739\n",
            "Epoch 64/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0917 - auc: 0.9930 - accuracy: 0.9707 - cost: 3.7412 - val_loss: 0.1239 - val_auc: 0.9883 - val_accuracy: 0.9631 - val_cost: 4.6499\n",
            "Epoch 65/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0906 - auc: 0.9932 - accuracy: 0.9711 - cost: 3.6876 - val_loss: 0.1239 - val_auc: 0.9882 - val_accuracy: 0.9638 - val_cost: 4.4884\n",
            "Epoch 66/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0911 - auc: 0.9931 - accuracy: 0.9712 - cost: 3.6777 - val_loss: 0.1219 - val_auc: 0.9885 - val_accuracy: 0.9644 - val_cost: 4.4734\n",
            "Epoch 67/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0898 - auc: 0.9932 - accuracy: 0.9715 - cost: 3.6388 - val_loss: 0.1218 - val_auc: 0.9884 - val_accuracy: 0.9630 - val_cost: 4.6462\n",
            "Epoch 68/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0891 - auc: 0.9934 - accuracy: 0.9713 - cost: 3.6582 - val_loss: 0.1205 - val_auc: 0.9885 - val_accuracy: 0.9652 - val_cost: 4.3006\n",
            "Epoch 69/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0887 - auc: 0.9934 - accuracy: 0.9725 - cost: 3.5264 - val_loss: 0.1201 - val_auc: 0.9883 - val_accuracy: 0.9645 - val_cost: 4.4847\n",
            "Epoch 70/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0874 - auc: 0.9936 - accuracy: 0.9728 - cost: 3.4849 - val_loss: 0.1226 - val_auc: 0.9884 - val_accuracy: 0.9638 - val_cost: 4.5974\n",
            "Epoch 71/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0872 - auc: 0.9935 - accuracy: 0.9724 - cost: 3.5182 - val_loss: 0.1216 - val_auc: 0.9884 - val_accuracy: 0.9651 - val_cost: 4.3833\n",
            "Epoch 72/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0870 - auc: 0.9935 - accuracy: 0.9728 - cost: 3.4875 - val_loss: 0.1221 - val_auc: 0.9885 - val_accuracy: 0.9654 - val_cost: 4.2668\n",
            "Epoch 73/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0863 - auc: 0.9936 - accuracy: 0.9725 - cost: 3.5169 - val_loss: 0.1188 - val_auc: 0.9887 - val_accuracy: 0.9656 - val_cost: 4.3607\n",
            "Epoch 74/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0849 - auc: 0.9938 - accuracy: 0.9734 - cost: 3.3808 - val_loss: 0.1197 - val_auc: 0.9888 - val_accuracy: 0.9652 - val_cost: 4.3645\n",
            "Epoch 75/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0843 - auc: 0.9939 - accuracy: 0.9736 - cost: 3.3761 - val_loss: 0.1187 - val_auc: 0.9887 - val_accuracy: 0.9655 - val_cost: 4.3081\n",
            "Epoch 76/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0841 - auc: 0.9938 - accuracy: 0.9735 - cost: 3.3856 - val_loss: 0.1188 - val_auc: 0.9887 - val_accuracy: 0.9656 - val_cost: 4.3570\n",
            "Epoch 77/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0839 - auc: 0.9939 - accuracy: 0.9737 - cost: 3.3795 - val_loss: 0.1171 - val_auc: 0.9892 - val_accuracy: 0.9661 - val_cost: 4.3119\n",
            "Epoch 78/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0831 - auc: 0.9940 - accuracy: 0.9742 - cost: 3.2983 - val_loss: 0.1178 - val_auc: 0.9889 - val_accuracy: 0.9659 - val_cost: 4.3232\n",
            "Epoch 79/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0826 - auc: 0.9941 - accuracy: 0.9744 - cost: 3.2719 - val_loss: 0.1180 - val_auc: 0.9888 - val_accuracy: 0.9677 - val_cost: 4.0340\n",
            "Epoch 80/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0823 - auc: 0.9941 - accuracy: 0.9742 - cost: 3.3030 - val_loss: 0.1167 - val_auc: 0.9892 - val_accuracy: 0.9666 - val_cost: 4.2668\n",
            "Epoch 81/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0807 - auc: 0.9942 - accuracy: 0.9749 - cost: 3.2028 - val_loss: 0.1197 - val_auc: 0.9890 - val_accuracy: 0.9660 - val_cost: 4.2218\n",
            "Epoch 82/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0817 - auc: 0.9941 - accuracy: 0.9747 - cost: 3.2240 - val_loss: 0.1149 - val_auc: 0.9892 - val_accuracy: 0.9673 - val_cost: 4.1504\n",
            "Epoch 83/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0801 - auc: 0.9942 - accuracy: 0.9752 - cost: 3.1807 - val_loss: 0.1178 - val_auc: 0.9892 - val_accuracy: 0.9673 - val_cost: 4.0077\n",
            "Epoch 84/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0814 - auc: 0.9940 - accuracy: 0.9751 - cost: 3.1855 - val_loss: 0.1161 - val_auc: 0.9895 - val_accuracy: 0.9670 - val_cost: 4.1166\n",
            "Epoch 85/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0807 - auc: 0.9941 - accuracy: 0.9755 - cost: 3.1293 - val_loss: 0.1164 - val_auc: 0.9893 - val_accuracy: 0.9671 - val_cost: 4.1429\n",
            "Epoch 86/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0796 - auc: 0.9943 - accuracy: 0.9754 - cost: 3.1540 - val_loss: 0.1167 - val_auc: 0.9893 - val_accuracy: 0.9676 - val_cost: 4.1541\n",
            "Epoch 87/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0795 - auc: 0.9942 - accuracy: 0.9755 - cost: 3.1250 - val_loss: 0.1145 - val_auc: 0.9893 - val_accuracy: 0.9679 - val_cost: 4.0002\n",
            "Epoch 88/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0782 - auc: 0.9943 - accuracy: 0.9760 - cost: 3.0680 - val_loss: 0.1166 - val_auc: 0.9893 - val_accuracy: 0.9670 - val_cost: 4.1354\n",
            "Epoch 89/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0784 - auc: 0.9945 - accuracy: 0.9760 - cost: 3.0723 - val_loss: 0.1135 - val_auc: 0.9898 - val_accuracy: 0.9680 - val_cost: 4.0415\n",
            "Epoch 90/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0778 - auc: 0.9945 - accuracy: 0.9762 - cost: 3.0347 - val_loss: 0.1134 - val_auc: 0.9897 - val_accuracy: 0.9677 - val_cost: 4.0753\n",
            "Epoch 91/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0774 - auc: 0.9945 - accuracy: 0.9768 - cost: 2.9725 - val_loss: 0.1133 - val_auc: 0.9896 - val_accuracy: 0.9687 - val_cost: 3.9739\n",
            "Epoch 92/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0768 - auc: 0.9946 - accuracy: 0.9767 - cost: 2.9811 - val_loss: 0.1140 - val_auc: 0.9895 - val_accuracy: 0.9679 - val_cost: 3.9401\n",
            "Epoch 93/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0764 - auc: 0.9946 - accuracy: 0.9771 - cost: 2.9318 - val_loss: 0.1134 - val_auc: 0.9897 - val_accuracy: 0.9679 - val_cost: 4.0002\n",
            "Epoch 94/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0767 - auc: 0.9946 - accuracy: 0.9768 - cost: 2.9699 - val_loss: 0.1122 - val_auc: 0.9898 - val_accuracy: 0.9682 - val_cost: 4.0565\n",
            "Epoch 95/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0756 - auc: 0.9946 - accuracy: 0.9771 - cost: 2.9314 - val_loss: 0.1137 - val_auc: 0.9896 - val_accuracy: 0.9680 - val_cost: 4.0602\n",
            "Epoch 96/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0760 - auc: 0.9946 - accuracy: 0.9767 - cost: 3.0014 - val_loss: 0.1141 - val_auc: 0.9894 - val_accuracy: 0.9689 - val_cost: 3.9363\n",
            "Epoch 97/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0753 - auc: 0.9948 - accuracy: 0.9767 - cost: 2.9846 - val_loss: 0.1128 - val_auc: 0.9899 - val_accuracy: 0.9680 - val_cost: 4.1466\n",
            "Epoch 98/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0743 - auc: 0.9948 - accuracy: 0.9775 - cost: 2.8791 - val_loss: 0.1132 - val_auc: 0.9898 - val_accuracy: 0.9685 - val_cost: 4.0114\n",
            "Epoch 99/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0753 - auc: 0.9946 - accuracy: 0.9770 - cost: 2.9392 - val_loss: 0.1148 - val_auc: 0.9897 - val_accuracy: 0.9691 - val_cost: 3.8574\n",
            "Epoch 100/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0746 - auc: 0.9948 - accuracy: 0.9771 - cost: 2.9526 - val_loss: 0.1133 - val_auc: 0.9896 - val_accuracy: 0.9691 - val_cost: 3.9100\n",
            "Epoch 101/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0737 - auc: 0.9949 - accuracy: 0.9779 - cost: 2.8351 - val_loss: 0.1121 - val_auc: 0.9899 - val_accuracy: 0.9681 - val_cost: 3.9551\n",
            "Epoch 102/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0738 - auc: 0.9949 - accuracy: 0.9773 - cost: 2.8973 - val_loss: 0.1149 - val_auc: 0.9895 - val_accuracy: 0.9697 - val_cost: 3.6997\n",
            "Epoch 103/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0740 - auc: 0.9949 - accuracy: 0.9775 - cost: 2.8917 - val_loss: 0.1107 - val_auc: 0.9902 - val_accuracy: 0.9689 - val_cost: 3.9663\n",
            "Epoch 104/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0730 - auc: 0.9950 - accuracy: 0.9780 - cost: 2.8243 - val_loss: 0.1138 - val_auc: 0.9899 - val_accuracy: 0.9680 - val_cost: 4.1579\n",
            "Epoch 105/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0737 - auc: 0.9950 - accuracy: 0.9774 - cost: 2.9059 - val_loss: 0.1107 - val_auc: 0.9901 - val_accuracy: 0.9697 - val_cost: 3.8161\n",
            "Epoch 106/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0727 - auc: 0.9950 - accuracy: 0.9774 - cost: 2.8860 - val_loss: 0.1125 - val_auc: 0.9901 - val_accuracy: 0.9694 - val_cost: 3.7372\n",
            "Epoch 107/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0733 - auc: 0.9949 - accuracy: 0.9777 - cost: 2.8653 - val_loss: 0.1106 - val_auc: 0.9903 - val_accuracy: 0.9695 - val_cost: 3.8987\n",
            "Epoch 108/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0719 - auc: 0.9951 - accuracy: 0.9782 - cost: 2.7884 - val_loss: 0.1115 - val_auc: 0.9902 - val_accuracy: 0.9695 - val_cost: 3.8086\n",
            "Epoch 109/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0718 - auc: 0.9951 - accuracy: 0.9781 - cost: 2.7979 - val_loss: 0.1108 - val_auc: 0.9900 - val_accuracy: 0.9694 - val_cost: 3.7861\n",
            "Epoch 110/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0715 - auc: 0.9951 - accuracy: 0.9781 - cost: 2.8109 - val_loss: 0.1104 - val_auc: 0.9905 - val_accuracy: 0.9695 - val_cost: 3.8424\n",
            "Epoch 111/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0716 - auc: 0.9951 - accuracy: 0.9782 - cost: 2.8057 - val_loss: 0.1118 - val_auc: 0.9901 - val_accuracy: 0.9701 - val_cost: 3.7109\n",
            "Epoch 112/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0712 - auc: 0.9951 - accuracy: 0.9784 - cost: 2.7698 - val_loss: 0.1120 - val_auc: 0.9902 - val_accuracy: 0.9698 - val_cost: 3.7861\n",
            "Epoch 113/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0708 - auc: 0.9951 - accuracy: 0.9784 - cost: 2.7763 - val_loss: 0.1110 - val_auc: 0.9901 - val_accuracy: 0.9703 - val_cost: 3.6358\n",
            "Epoch 114/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0704 - auc: 0.9951 - accuracy: 0.9787 - cost: 2.7344 - val_loss: 0.1092 - val_auc: 0.9903 - val_accuracy: 0.9699 - val_cost: 3.7898\n",
            "Epoch 115/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0693 - auc: 0.9953 - accuracy: 0.9786 - cost: 2.7434 - val_loss: 0.1097 - val_auc: 0.9901 - val_accuracy: 0.9699 - val_cost: 3.7936\n",
            "Epoch 116/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0705 - auc: 0.9952 - accuracy: 0.9786 - cost: 2.7352 - val_loss: 0.1108 - val_auc: 0.9901 - val_accuracy: 0.9701 - val_cost: 3.8123\n",
            "Epoch 117/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0696 - auc: 0.9952 - accuracy: 0.9789 - cost: 2.6912 - val_loss: 0.1114 - val_auc: 0.9901 - val_accuracy: 0.9687 - val_cost: 4.0903\n",
            "Epoch 118/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0695 - auc: 0.9953 - accuracy: 0.9789 - cost: 2.7037 - val_loss: 0.1120 - val_auc: 0.9901 - val_accuracy: 0.9705 - val_cost: 3.7485\n",
            "Epoch 119/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0696 - auc: 0.9953 - accuracy: 0.9791 - cost: 2.6894 - val_loss: 0.1102 - val_auc: 0.9900 - val_accuracy: 0.9698 - val_cost: 3.7936\n",
            "Epoch 120/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0688 - auc: 0.9954 - accuracy: 0.9794 - cost: 2.6441 - val_loss: 0.1095 - val_auc: 0.9904 - val_accuracy: 0.9697 - val_cost: 3.8349\n",
            "Epoch 121/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0695 - auc: 0.9952 - accuracy: 0.9790 - cost: 2.6890 - val_loss: 0.1101 - val_auc: 0.9902 - val_accuracy: 0.9701 - val_cost: 3.7936\n",
            "Epoch 122/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0685 - auc: 0.9954 - accuracy: 0.9796 - cost: 2.6069 - val_loss: 0.1106 - val_auc: 0.9905 - val_accuracy: 0.9699 - val_cost: 3.7635\n",
            "Epoch 123/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0688 - auc: 0.9953 - accuracy: 0.9793 - cost: 2.6497 - val_loss: 0.1114 - val_auc: 0.9903 - val_accuracy: 0.9696 - val_cost: 3.7034\n",
            "Epoch 124/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0690 - auc: 0.9952 - accuracy: 0.9789 - cost: 2.7093 - val_loss: 0.1098 - val_auc: 0.9902 - val_accuracy: 0.9702 - val_cost: 3.7260\n",
            "Epoch 125/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0683 - auc: 0.9954 - accuracy: 0.9793 - cost: 2.6523 - val_loss: 0.1110 - val_auc: 0.9903 - val_accuracy: 0.9705 - val_cost: 3.7297\n",
            "Epoch 126/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0675 - auc: 0.9955 - accuracy: 0.9800 - cost: 2.5615 - val_loss: 0.1109 - val_auc: 0.9900 - val_accuracy: 0.9705 - val_cost: 3.7523\n",
            "Epoch 127/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0675 - auc: 0.9955 - accuracy: 0.9793 - cost: 2.6458 - val_loss: 0.1106 - val_auc: 0.9903 - val_accuracy: 0.9694 - val_cost: 3.8349\n",
            "Epoch 128/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0675 - auc: 0.9954 - accuracy: 0.9797 - cost: 2.6060 - val_loss: 0.1112 - val_auc: 0.9901 - val_accuracy: 0.9693 - val_cost: 3.8424\n",
            "Epoch 129/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0670 - auc: 0.9956 - accuracy: 0.9793 - cost: 2.6579 - val_loss: 0.1124 - val_auc: 0.9901 - val_accuracy: 0.9705 - val_cost: 3.6471\n",
            "Epoch 130/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0678 - auc: 0.9954 - accuracy: 0.9794 - cost: 2.6367 - val_loss: 0.1110 - val_auc: 0.9903 - val_accuracy: 0.9695 - val_cost: 3.8386\n",
            "Epoch 131/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0670 - auc: 0.9956 - accuracy: 0.9796 - cost: 2.6194 - val_loss: 0.1113 - val_auc: 0.9900 - val_accuracy: 0.9702 - val_cost: 3.7109\n",
            "Epoch 132/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0659 - auc: 0.9957 - accuracy: 0.9799 - cost: 2.5792 - val_loss: 0.1118 - val_auc: 0.9901 - val_accuracy: 0.9693 - val_cost: 3.8724\n",
            "Epoch 133/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0670 - auc: 0.9956 - accuracy: 0.9797 - cost: 2.6125 - val_loss: 0.1127 - val_auc: 0.9898 - val_accuracy: 0.9693 - val_cost: 3.8011\n",
            "Epoch 134/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0661 - auc: 0.9956 - accuracy: 0.9800 - cost: 2.5602 - val_loss: 0.1129 - val_auc: 0.9902 - val_accuracy: 0.9702 - val_cost: 3.7109\n",
            "Epoch 135/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0663 - auc: 0.9956 - accuracy: 0.9797 - cost: 2.6026 - val_loss: 0.1122 - val_auc: 0.9897 - val_accuracy: 0.9699 - val_cost: 3.8161\n",
            "Epoch 136/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0670 - auc: 0.9955 - accuracy: 0.9801 - cost: 2.5442 - val_loss: 0.1109 - val_auc: 0.9904 - val_accuracy: 0.9709 - val_cost: 3.6433\n",
            "Epoch 137/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0653 - auc: 0.9957 - accuracy: 0.9805 - cost: 2.5023 - val_loss: 0.1116 - val_auc: 0.9905 - val_accuracy: 0.9709 - val_cost: 3.6396\n",
            "Epoch 138/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0664 - auc: 0.9955 - accuracy: 0.9800 - cost: 2.5581 - val_loss: 0.1120 - val_auc: 0.9903 - val_accuracy: 0.9695 - val_cost: 3.9626\n",
            "Epoch 139/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0652 - auc: 0.9958 - accuracy: 0.9804 - cost: 2.5218 - val_loss: 0.1114 - val_auc: 0.9903 - val_accuracy: 0.9702 - val_cost: 3.7560\n",
            "Epoch 140/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0649 - auc: 0.9958 - accuracy: 0.9802 - cost: 2.5365 - val_loss: 0.1130 - val_auc: 0.9899 - val_accuracy: 0.9698 - val_cost: 3.7297\n",
            "Epoch 141/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0654 - auc: 0.9957 - accuracy: 0.9800 - cost: 2.5719 - val_loss: 0.1130 - val_auc: 0.9899 - val_accuracy: 0.9703 - val_cost: 3.6546\n",
            "Epoch 142/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0656 - auc: 0.9957 - accuracy: 0.9801 - cost: 2.5373 - val_loss: 0.1137 - val_auc: 0.9900 - val_accuracy: 0.9695 - val_cost: 3.7635\n",
            "Epoch 143/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0653 - auc: 0.9958 - accuracy: 0.9799 - cost: 2.5823 - val_loss: 0.1133 - val_auc: 0.9901 - val_accuracy: 0.9694 - val_cost: 3.8462\n",
            "Epoch 144/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0651 - auc: 0.9957 - accuracy: 0.9804 - cost: 2.5283 - val_loss: 0.1128 - val_auc: 0.9899 - val_accuracy: 0.9691 - val_cost: 3.8574\n",
            "Epoch 145/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0653 - auc: 0.9957 - accuracy: 0.9797 - cost: 2.5957 - val_loss: 0.1109 - val_auc: 0.9901 - val_accuracy: 0.9714 - val_cost: 3.6208\n",
            "Epoch 146/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0632 - auc: 0.9960 - accuracy: 0.9809 - cost: 2.4405 - val_loss: 0.1142 - val_auc: 0.9902 - val_accuracy: 0.9701 - val_cost: 3.7184\n",
            "Epoch 147/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0646 - auc: 0.9959 - accuracy: 0.9804 - cost: 2.5097 - val_loss: 0.1138 - val_auc: 0.9903 - val_accuracy: 0.9712 - val_cost: 3.6546\n",
            "Epoch 148/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0646 - auc: 0.9957 - accuracy: 0.9807 - cost: 2.4669 - val_loss: 0.1123 - val_auc: 0.9901 - val_accuracy: 0.9701 - val_cost: 3.7861\n",
            "Epoch 149/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0644 - auc: 0.9958 - accuracy: 0.9805 - cost: 2.5010 - val_loss: 0.1128 - val_auc: 0.9903 - val_accuracy: 0.9691 - val_cost: 3.9250\n",
            "Epoch 150/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0646 - auc: 0.9957 - accuracy: 0.9804 - cost: 2.5036 - val_loss: 0.1142 - val_auc: 0.9899 - val_accuracy: 0.9709 - val_cost: 3.7147\n",
            "Epoch 151/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0643 - auc: 0.9958 - accuracy: 0.9806 - cost: 2.4911 - val_loss: 0.1136 - val_auc: 0.9900 - val_accuracy: 0.9696 - val_cost: 3.8724\n",
            "Epoch 152/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0639 - auc: 0.9958 - accuracy: 0.9808 - cost: 2.4742 - val_loss: 0.1140 - val_auc: 0.9900 - val_accuracy: 0.9709 - val_cost: 3.6659\n",
            "Epoch 153/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0631 - auc: 0.9959 - accuracy: 0.9810 - cost: 2.4453 - val_loss: 0.1124 - val_auc: 0.9903 - val_accuracy: 0.9705 - val_cost: 3.7410\n",
            "Epoch 154/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0630 - auc: 0.9960 - accuracy: 0.9810 - cost: 2.4453 - val_loss: 0.1149 - val_auc: 0.9898 - val_accuracy: 0.9706 - val_cost: 3.6396\n",
            "Epoch 155/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0631 - auc: 0.9960 - accuracy: 0.9811 - cost: 2.4405 - val_loss: 0.1149 - val_auc: 0.9898 - val_accuracy: 0.9702 - val_cost: 3.7222\n",
            "Epoch 156/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0627 - auc: 0.9959 - accuracy: 0.9809 - cost: 2.4375 - val_loss: 0.1133 - val_auc: 0.9899 - val_accuracy: 0.9712 - val_cost: 3.6208\n",
            "Epoch 157/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0624 - auc: 0.9961 - accuracy: 0.9812 - cost: 2.4107 - val_loss: 0.1124 - val_auc: 0.9900 - val_accuracy: 0.9706 - val_cost: 3.7222\n",
            "Epoch 158/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0631 - auc: 0.9959 - accuracy: 0.9813 - cost: 2.4081 - val_loss: 0.1159 - val_auc: 0.9899 - val_accuracy: 0.9699 - val_cost: 3.7410\n",
            "Epoch 159/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0625 - auc: 0.9961 - accuracy: 0.9809 - cost: 2.4371 - val_loss: 0.1150 - val_auc: 0.9897 - val_accuracy: 0.9703 - val_cost: 3.7184\n",
            "Epoch 160/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0633 - auc: 0.9959 - accuracy: 0.9810 - cost: 2.4349 - val_loss: 0.1133 - val_auc: 0.9897 - val_accuracy: 0.9705 - val_cost: 3.7072\n",
            "Epoch 161/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0618 - auc: 0.9961 - accuracy: 0.9814 - cost: 2.3917 - val_loss: 0.1163 - val_auc: 0.9898 - val_accuracy: 0.9696 - val_cost: 3.7973\n",
            "Epoch 162/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0619 - auc: 0.9961 - accuracy: 0.9812 - cost: 2.4107 - val_loss: 0.1156 - val_auc: 0.9900 - val_accuracy: 0.9708 - val_cost: 3.5269\n",
            "Epoch 163/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0623 - auc: 0.9960 - accuracy: 0.9811 - cost: 2.4310 - val_loss: 0.1151 - val_auc: 0.9896 - val_accuracy: 0.9705 - val_cost: 3.6396\n",
            "Epoch 164/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0621 - auc: 0.9961 - accuracy: 0.9811 - cost: 2.4233 - val_loss: 0.1150 - val_auc: 0.9901 - val_accuracy: 0.9714 - val_cost: 3.5419\n",
            "Epoch 165/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0624 - auc: 0.9960 - accuracy: 0.9812 - cost: 2.4181 - val_loss: 0.1156 - val_auc: 0.9900 - val_accuracy: 0.9706 - val_cost: 3.6283\n",
            "Epoch 166/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0628 - auc: 0.9960 - accuracy: 0.9808 - cost: 2.4570 - val_loss: 0.1162 - val_auc: 0.9896 - val_accuracy: 0.9701 - val_cost: 3.7410\n",
            "Epoch 167/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0622 - auc: 0.9960 - accuracy: 0.9812 - cost: 2.4120 - val_loss: 0.1159 - val_auc: 0.9898 - val_accuracy: 0.9702 - val_cost: 3.7635\n",
            "Epoch 168/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0614 - auc: 0.9961 - accuracy: 0.9814 - cost: 2.3826 - val_loss: 0.1162 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.7523\n",
            "Epoch 169/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0618 - auc: 0.9961 - accuracy: 0.9812 - cost: 2.4310 - val_loss: 0.1171 - val_auc: 0.9894 - val_accuracy: 0.9702 - val_cost: 3.7260\n",
            "Epoch 170/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0624 - auc: 0.9962 - accuracy: 0.9811 - cost: 2.4250 - val_loss: 0.1175 - val_auc: 0.9898 - val_accuracy: 0.9692 - val_cost: 3.7523\n",
            "Epoch 171/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0624 - auc: 0.9960 - accuracy: 0.9810 - cost: 2.4371 - val_loss: 0.1170 - val_auc: 0.9895 - val_accuracy: 0.9692 - val_cost: 3.8612\n",
            "Epoch 172/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0614 - auc: 0.9961 - accuracy: 0.9813 - cost: 2.3921 - val_loss: 0.1152 - val_auc: 0.9900 - val_accuracy: 0.9699 - val_cost: 3.7523\n",
            "Epoch 173/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0613 - auc: 0.9961 - accuracy: 0.9814 - cost: 2.3904 - val_loss: 0.1194 - val_auc: 0.9896 - val_accuracy: 0.9688 - val_cost: 3.8800\n",
            "Epoch 174/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0612 - auc: 0.9963 - accuracy: 0.9813 - cost: 2.3822 - val_loss: 0.1157 - val_auc: 0.9900 - val_accuracy: 0.9700 - val_cost: 3.8086\n",
            "Epoch 175/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0602 - auc: 0.9963 - accuracy: 0.9818 - cost: 2.3252 - val_loss: 0.1154 - val_auc: 0.9896 - val_accuracy: 0.9704 - val_cost: 3.7447\n",
            "Epoch 176/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0606 - auc: 0.9962 - accuracy: 0.9814 - cost: 2.3757 - val_loss: 0.1177 - val_auc: 0.9895 - val_accuracy: 0.9691 - val_cost: 3.9325\n",
            "Epoch 177/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0610 - auc: 0.9963 - accuracy: 0.9814 - cost: 2.3865 - val_loss: 0.1179 - val_auc: 0.9897 - val_accuracy: 0.9698 - val_cost: 3.8236\n",
            "Epoch 178/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0614 - auc: 0.9961 - accuracy: 0.9818 - cost: 2.3334 - val_loss: 0.1174 - val_auc: 0.9896 - val_accuracy: 0.9695 - val_cost: 3.8349\n",
            "Epoch 179/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0605 - auc: 0.9963 - accuracy: 0.9817 - cost: 2.3541 - val_loss: 0.1162 - val_auc: 0.9898 - val_accuracy: 0.9695 - val_cost: 3.8386\n",
            "Epoch 180/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0604 - auc: 0.9963 - accuracy: 0.9819 - cost: 2.3049 - val_loss: 0.1162 - val_auc: 0.9898 - val_accuracy: 0.9697 - val_cost: 3.8687\n",
            "Epoch 181/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0602 - auc: 0.9962 - accuracy: 0.9817 - cost: 2.3602 - val_loss: 0.1189 - val_auc: 0.9895 - val_accuracy: 0.9701 - val_cost: 3.7823\n",
            "Epoch 182/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0611 - auc: 0.9961 - accuracy: 0.9816 - cost: 2.3541 - val_loss: 0.1162 - val_auc: 0.9896 - val_accuracy: 0.9714 - val_cost: 3.5607\n",
            "Epoch 183/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0605 - auc: 0.9962 - accuracy: 0.9816 - cost: 2.3667 - val_loss: 0.1178 - val_auc: 0.9895 - val_accuracy: 0.9708 - val_cost: 3.6621\n",
            "Epoch 184/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0598 - auc: 0.9964 - accuracy: 0.9816 - cost: 2.3623 - val_loss: 0.1202 - val_auc: 0.9893 - val_accuracy: 0.9700 - val_cost: 3.7372\n",
            "Epoch 185/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0602 - auc: 0.9963 - accuracy: 0.9818 - cost: 2.3208 - val_loss: 0.1200 - val_auc: 0.9893 - val_accuracy: 0.9690 - val_cost: 3.9288\n",
            "Epoch 186/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0593 - auc: 0.9964 - accuracy: 0.9816 - cost: 2.3727 - val_loss: 0.1184 - val_auc: 0.9897 - val_accuracy: 0.9701 - val_cost: 3.7823\n",
            "Epoch 187/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0604 - auc: 0.9963 - accuracy: 0.9817 - cost: 2.3407 - val_loss: 0.1181 - val_auc: 0.9900 - val_accuracy: 0.9702 - val_cost: 3.6884\n",
            "Epoch 188/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0596 - auc: 0.9963 - accuracy: 0.9822 - cost: 2.2768 - val_loss: 0.1206 - val_auc: 0.9893 - val_accuracy: 0.9700 - val_cost: 3.8274\n",
            "Epoch 189/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0603 - auc: 0.9961 - accuracy: 0.9813 - cost: 2.4025 - val_loss: 0.1206 - val_auc: 0.9897 - val_accuracy: 0.9691 - val_cost: 3.8987\n",
            "Epoch 190/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0587 - auc: 0.9965 - accuracy: 0.9819 - cost: 2.3252 - val_loss: 0.1212 - val_auc: 0.9893 - val_accuracy: 0.9688 - val_cost: 3.9288\n",
            "Epoch 191/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0592 - auc: 0.9964 - accuracy: 0.9820 - cost: 2.2958 - val_loss: 0.1199 - val_auc: 0.9891 - val_accuracy: 0.9691 - val_cost: 3.8574\n",
            "Epoch 192/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0602 - auc: 0.9963 - accuracy: 0.9816 - cost: 2.3654 - val_loss: 0.1202 - val_auc: 0.9895 - val_accuracy: 0.9693 - val_cost: 3.8649\n",
            "Epoch 193/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0589 - auc: 0.9963 - accuracy: 0.9823 - cost: 2.2776 - val_loss: 0.1228 - val_auc: 0.9888 - val_accuracy: 0.9698 - val_cost: 3.7635\n",
            "Epoch 194/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0593 - auc: 0.9963 - accuracy: 0.9822 - cost: 2.2919 - val_loss: 0.1222 - val_auc: 0.9892 - val_accuracy: 0.9688 - val_cost: 3.8311\n",
            "Epoch 195/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0590 - auc: 0.9965 - accuracy: 0.9817 - cost: 2.3524 - val_loss: 0.1208 - val_auc: 0.9896 - val_accuracy: 0.9698 - val_cost: 3.7523\n",
            "Epoch 196/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0582 - auc: 0.9965 - accuracy: 0.9822 - cost: 2.2846 - val_loss: 0.1205 - val_auc: 0.9894 - val_accuracy: 0.9687 - val_cost: 4.0189\n",
            "Epoch 197/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0586 - auc: 0.9964 - accuracy: 0.9824 - cost: 2.2396 - val_loss: 0.1235 - val_auc: 0.9888 - val_accuracy: 0.9687 - val_cost: 3.9926\n",
            "Epoch 198/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0597 - auc: 0.9963 - accuracy: 0.9821 - cost: 2.2941 - val_loss: 0.1221 - val_auc: 0.9889 - val_accuracy: 0.9682 - val_cost: 4.0002\n",
            "Epoch 199/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0591 - auc: 0.9964 - accuracy: 0.9821 - cost: 2.3040 - val_loss: 0.1227 - val_auc: 0.9892 - val_accuracy: 0.9700 - val_cost: 3.8086\n",
            "Epoch 200/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0582 - auc: 0.9964 - accuracy: 0.9828 - cost: 2.2020 - val_loss: 0.1203 - val_auc: 0.9892 - val_accuracy: 0.9698 - val_cost: 3.8386\n",
            "Epoch 201/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0586 - auc: 0.9963 - accuracy: 0.9827 - cost: 2.2314 - val_loss: 0.1206 - val_auc: 0.9894 - val_accuracy: 0.9702 - val_cost: 3.7936\n",
            "Epoch 202/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0582 - auc: 0.9963 - accuracy: 0.9825 - cost: 2.2439 - val_loss: 0.1213 - val_auc: 0.9893 - val_accuracy: 0.9702 - val_cost: 3.7447\n",
            "Epoch 203/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0584 - auc: 0.9965 - accuracy: 0.9823 - cost: 2.2725 - val_loss: 0.1226 - val_auc: 0.9892 - val_accuracy: 0.9700 - val_cost: 3.7485\n",
            "Epoch 204/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0585 - auc: 0.9964 - accuracy: 0.9819 - cost: 2.3196 - val_loss: 0.1231 - val_auc: 0.9890 - val_accuracy: 0.9699 - val_cost: 3.7598\n",
            "Epoch 205/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0592 - auc: 0.9964 - accuracy: 0.9819 - cost: 2.3260 - val_loss: 0.1203 - val_auc: 0.9894 - val_accuracy: 0.9707 - val_cost: 3.6997\n",
            "Epoch 206/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0584 - auc: 0.9964 - accuracy: 0.9823 - cost: 2.2591 - val_loss: 0.1201 - val_auc: 0.9889 - val_accuracy: 0.9702 - val_cost: 3.8386\n",
            "Epoch 207/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0583 - auc: 0.9964 - accuracy: 0.9825 - cost: 2.2496 - val_loss: 0.1198 - val_auc: 0.9893 - val_accuracy: 0.9694 - val_cost: 3.8537\n",
            "Epoch 208/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0577 - auc: 0.9966 - accuracy: 0.9822 - cost: 2.2837 - val_loss: 0.1225 - val_auc: 0.9894 - val_accuracy: 0.9697 - val_cost: 3.8311\n",
            "Epoch 209/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0576 - auc: 0.9966 - accuracy: 0.9822 - cost: 2.2846 - val_loss: 0.1239 - val_auc: 0.9888 - val_accuracy: 0.9684 - val_cost: 3.9964\n",
            "Epoch 210/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0580 - auc: 0.9965 - accuracy: 0.9827 - cost: 2.2245 - val_loss: 0.1234 - val_auc: 0.9889 - val_accuracy: 0.9691 - val_cost: 3.8386\n",
            "Epoch 211/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0572 - auc: 0.9967 - accuracy: 0.9825 - cost: 2.2400 - val_loss: 0.1224 - val_auc: 0.9892 - val_accuracy: 0.9683 - val_cost: 3.9926\n",
            "Epoch 212/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0577 - auc: 0.9965 - accuracy: 0.9825 - cost: 2.2470 - val_loss: 0.1223 - val_auc: 0.9887 - val_accuracy: 0.9705 - val_cost: 3.7598\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1165 - auc: 0.9900 - accuracy: 0.9699 - cost: 3.6469\n",
            "1000/1000 [==============================] - 1s 954us/step\n",
            "fold train/predict time: 0:01:33.018849\n",
            "fold accuracy: 0.9699062705039978 - fold cost: 3.6468749046325684\n",
            "x_train shape: (128000, 67)\n",
            "Epoch 1/1000\n",
            "113/113 [==============================] - 2s 5ms/step - loss: 0.5425 - auc: 0.7849 - accuracy: 0.7192 - cost: 37.4991 - val_loss: 0.4134 - val_auc: 0.8917 - val_accuracy: 0.8183 - val_cost: 23.0206\n",
            "Epoch 2/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.3611 - auc: 0.9171 - accuracy: 0.8451 - cost: 19.7693 - val_loss: 0.3209 - val_auc: 0.9342 - val_accuracy: 0.8631 - val_cost: 17.0974\n",
            "Epoch 3/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.3074 - auc: 0.9401 - accuracy: 0.8720 - cost: 16.2109 - val_loss: 0.2924 - val_auc: 0.9455 - val_accuracy: 0.8815 - val_cost: 14.9452\n",
            "Epoch 4/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.2800 - auc: 0.9505 - accuracy: 0.8855 - cost: 14.4907 - val_loss: 0.2671 - val_auc: 0.9547 - val_accuracy: 0.8917 - val_cost: 13.6343\n",
            "Epoch 5/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.2568 - auc: 0.9583 - accuracy: 0.8969 - cost: 13.0639 - val_loss: 0.2482 - val_auc: 0.9609 - val_accuracy: 0.9021 - val_cost: 12.1732\n",
            "Epoch 6/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.2390 - auc: 0.9639 - accuracy: 0.9050 - cost: 11.9910 - val_loss: 0.2326 - val_auc: 0.9659 - val_accuracy: 0.9095 - val_cost: 11.5760\n",
            "Epoch 7/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.2230 - auc: 0.9686 - accuracy: 0.9134 - cost: 10.9677 - val_loss: 0.2177 - val_auc: 0.9699 - val_accuracy: 0.9184 - val_cost: 10.2614\n",
            "Epoch 8/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.2096 - auc: 0.9720 - accuracy: 0.9197 - cost: 10.1653 - val_loss: 0.2078 - val_auc: 0.9731 - val_accuracy: 0.9209 - val_cost: 9.5252\n",
            "Epoch 9/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1989 - auc: 0.9748 - accuracy: 0.9246 - cost: 9.5236 - val_loss: 0.1969 - val_auc: 0.9753 - val_accuracy: 0.9267 - val_cost: 9.0820\n",
            "Epoch 10/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1888 - auc: 0.9771 - accuracy: 0.9286 - cost: 9.0138 - val_loss: 0.1896 - val_auc: 0.9769 - val_accuracy: 0.9305 - val_cost: 8.6200\n",
            "Epoch 11/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1815 - auc: 0.9787 - accuracy: 0.9318 - cost: 8.6102 - val_loss: 0.1833 - val_auc: 0.9786 - val_accuracy: 0.9344 - val_cost: 8.0980\n",
            "Epoch 12/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1739 - auc: 0.9804 - accuracy: 0.9352 - cost: 8.2031 - val_loss: 0.1774 - val_auc: 0.9796 - val_accuracy: 0.9373 - val_cost: 8.0341\n",
            "Epoch 13/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1682 - auc: 0.9815 - accuracy: 0.9388 - cost: 7.7390 - val_loss: 0.1732 - val_auc: 0.9804 - val_accuracy: 0.9388 - val_cost: 7.6435\n",
            "Epoch 14/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1633 - auc: 0.9825 - accuracy: 0.9409 - cost: 7.4841 - val_loss: 0.1683 - val_auc: 0.9815 - val_accuracy: 0.9412 - val_cost: 7.2942\n",
            "Epoch 15/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1587 - auc: 0.9834 - accuracy: 0.9428 - cost: 7.2356 - val_loss: 0.1642 - val_auc: 0.9823 - val_accuracy: 0.9417 - val_cost: 7.3392\n",
            "Epoch 16/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1537 - auc: 0.9842 - accuracy: 0.9451 - cost: 6.9513 - val_loss: 0.1622 - val_auc: 0.9825 - val_accuracy: 0.9441 - val_cost: 6.9561\n",
            "Epoch 17/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1512 - auc: 0.9847 - accuracy: 0.9455 - cost: 6.8964 - val_loss: 0.1595 - val_auc: 0.9833 - val_accuracy: 0.9436 - val_cost: 7.0913\n",
            "Epoch 18/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1474 - auc: 0.9854 - accuracy: 0.9473 - cost: 6.6860 - val_loss: 0.1571 - val_auc: 0.9836 - val_accuracy: 0.9455 - val_cost: 6.9148\n",
            "Epoch 19/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1434 - auc: 0.9860 - accuracy: 0.9497 - cost: 6.3688 - val_loss: 0.1532 - val_auc: 0.9844 - val_accuracy: 0.9460 - val_cost: 6.8096\n",
            "Epoch 20/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1417 - auc: 0.9864 - accuracy: 0.9501 - cost: 6.3386 - val_loss: 0.1533 - val_auc: 0.9844 - val_accuracy: 0.9470 - val_cost: 6.5204\n",
            "Epoch 21/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1387 - auc: 0.9869 - accuracy: 0.9513 - cost: 6.1618 - val_loss: 0.1513 - val_auc: 0.9847 - val_accuracy: 0.9473 - val_cost: 6.5580\n",
            "Epoch 22/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1365 - auc: 0.9872 - accuracy: 0.9521 - cost: 6.0655 - val_loss: 0.1487 - val_auc: 0.9852 - val_accuracy: 0.9471 - val_cost: 6.5430\n",
            "Epoch 23/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1338 - auc: 0.9876 - accuracy: 0.9538 - cost: 5.8455 - val_loss: 0.1464 - val_auc: 0.9853 - val_accuracy: 0.9503 - val_cost: 6.2312\n",
            "Epoch 24/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1311 - auc: 0.9880 - accuracy: 0.9549 - cost: 5.7107 - val_loss: 0.1473 - val_auc: 0.9854 - val_accuracy: 0.9506 - val_cost: 6.0998\n",
            "Epoch 25/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1296 - auc: 0.9882 - accuracy: 0.9552 - cost: 5.6900 - val_loss: 0.1452 - val_auc: 0.9856 - val_accuracy: 0.9499 - val_cost: 6.2200\n",
            "Epoch 26/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1280 - auc: 0.9885 - accuracy: 0.9563 - cost: 5.5478 - val_loss: 0.1440 - val_auc: 0.9857 - val_accuracy: 0.9505 - val_cost: 6.1448\n",
            "Epoch 27/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1262 - auc: 0.9888 - accuracy: 0.9567 - cost: 5.4847 - val_loss: 0.1418 - val_auc: 0.9861 - val_accuracy: 0.9519 - val_cost: 5.9871\n",
            "Epoch 28/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1246 - auc: 0.9889 - accuracy: 0.9575 - cost: 5.3940 - val_loss: 0.1404 - val_auc: 0.9864 - val_accuracy: 0.9533 - val_cost: 5.7993\n",
            "Epoch 29/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1224 - auc: 0.9893 - accuracy: 0.9583 - cost: 5.2864 - val_loss: 0.1415 - val_auc: 0.9860 - val_accuracy: 0.9538 - val_cost: 5.9570\n",
            "Epoch 30/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1217 - auc: 0.9894 - accuracy: 0.9590 - cost: 5.2091 - val_loss: 0.1405 - val_auc: 0.9861 - val_accuracy: 0.9552 - val_cost: 5.5627\n",
            "Epoch 31/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1195 - auc: 0.9897 - accuracy: 0.9601 - cost: 5.0492 - val_loss: 0.1377 - val_auc: 0.9866 - val_accuracy: 0.9552 - val_cost: 5.6002\n",
            "Epoch 32/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1186 - auc: 0.9898 - accuracy: 0.9606 - cost: 4.9844 - val_loss: 0.1377 - val_auc: 0.9865 - val_accuracy: 0.9558 - val_cost: 5.5364\n",
            "Epoch 33/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1165 - auc: 0.9902 - accuracy: 0.9611 - cost: 4.9386 - val_loss: 0.1372 - val_auc: 0.9866 - val_accuracy: 0.9554 - val_cost: 5.5439\n",
            "Epoch 34/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1149 - auc: 0.9903 - accuracy: 0.9617 - cost: 4.8482 - val_loss: 0.1392 - val_auc: 0.9861 - val_accuracy: 0.9576 - val_cost: 5.2471\n",
            "Epoch 35/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1142 - auc: 0.9903 - accuracy: 0.9623 - cost: 4.7808 - val_loss: 0.1368 - val_auc: 0.9867 - val_accuracy: 0.9568 - val_cost: 5.3223\n",
            "Epoch 36/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1125 - auc: 0.9906 - accuracy: 0.9632 - cost: 4.6789 - val_loss: 0.1353 - val_auc: 0.9866 - val_accuracy: 0.9570 - val_cost: 5.4049\n",
            "Epoch 37/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1114 - auc: 0.9906 - accuracy: 0.9631 - cost: 4.6987 - val_loss: 0.1357 - val_auc: 0.9866 - val_accuracy: 0.9588 - val_cost: 5.1307\n",
            "Epoch 38/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1098 - auc: 0.9909 - accuracy: 0.9645 - cost: 4.5190 - val_loss: 0.1351 - val_auc: 0.9869 - val_accuracy: 0.9560 - val_cost: 5.5138\n",
            "Epoch 39/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1090 - auc: 0.9911 - accuracy: 0.9642 - cost: 4.5436 - val_loss: 0.1347 - val_auc: 0.9868 - val_accuracy: 0.9578 - val_cost: 5.2471\n",
            "Epoch 40/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1075 - auc: 0.9912 - accuracy: 0.9649 - cost: 4.4637 - val_loss: 0.1341 - val_auc: 0.9869 - val_accuracy: 0.9582 - val_cost: 5.1495\n",
            "Epoch 41/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1070 - auc: 0.9913 - accuracy: 0.9647 - cost: 4.4866 - val_loss: 0.1331 - val_auc: 0.9871 - val_accuracy: 0.9596 - val_cost: 5.0443\n",
            "Epoch 42/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1056 - auc: 0.9915 - accuracy: 0.9657 - cost: 4.3708 - val_loss: 0.1324 - val_auc: 0.9873 - val_accuracy: 0.9589 - val_cost: 5.0255\n",
            "Epoch 43/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1044 - auc: 0.9916 - accuracy: 0.9661 - cost: 4.2943 - val_loss: 0.1316 - val_auc: 0.9872 - val_accuracy: 0.9592 - val_cost: 5.0143\n",
            "Epoch 44/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1033 - auc: 0.9917 - accuracy: 0.9671 - cost: 4.1629 - val_loss: 0.1305 - val_auc: 0.9873 - val_accuracy: 0.9602 - val_cost: 4.9467\n",
            "Epoch 45/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1023 - auc: 0.9918 - accuracy: 0.9670 - cost: 4.1932 - val_loss: 0.1324 - val_auc: 0.9869 - val_accuracy: 0.9588 - val_cost: 5.0406\n",
            "Epoch 46/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1022 - auc: 0.9918 - accuracy: 0.9673 - cost: 4.1422 - val_loss: 0.1304 - val_auc: 0.9872 - val_accuracy: 0.9596 - val_cost: 4.9955\n",
            "Epoch 47/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1005 - auc: 0.9920 - accuracy: 0.9677 - cost: 4.0860 - val_loss: 0.1287 - val_auc: 0.9875 - val_accuracy: 0.9605 - val_cost: 5.0255\n",
            "Epoch 48/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1008 - auc: 0.9920 - accuracy: 0.9675 - cost: 4.1288 - val_loss: 0.1298 - val_auc: 0.9871 - val_accuracy: 0.9610 - val_cost: 4.8903\n",
            "Epoch 49/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0979 - auc: 0.9924 - accuracy: 0.9688 - cost: 3.9594 - val_loss: 0.1288 - val_auc: 0.9874 - val_accuracy: 0.9608 - val_cost: 4.9955\n",
            "Epoch 50/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0985 - auc: 0.9922 - accuracy: 0.9688 - cost: 3.9732 - val_loss: 0.1277 - val_auc: 0.9875 - val_accuracy: 0.9619 - val_cost: 4.7776\n",
            "Epoch 51/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0973 - auc: 0.9923 - accuracy: 0.9691 - cost: 3.9041 - val_loss: 0.1292 - val_auc: 0.9875 - val_accuracy: 0.9610 - val_cost: 4.8227\n",
            "Epoch 52/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0961 - auc: 0.9926 - accuracy: 0.9690 - cost: 3.9218 - val_loss: 0.1268 - val_auc: 0.9876 - val_accuracy: 0.9619 - val_cost: 4.7964\n",
            "Epoch 53/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0956 - auc: 0.9925 - accuracy: 0.9698 - cost: 3.8233 - val_loss: 0.1253 - val_auc: 0.9879 - val_accuracy: 0.9630 - val_cost: 4.7213\n",
            "Epoch 54/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0953 - auc: 0.9926 - accuracy: 0.9697 - cost: 3.8518 - val_loss: 0.1254 - val_auc: 0.9878 - val_accuracy: 0.9620 - val_cost: 4.7401\n",
            "Epoch 55/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0943 - auc: 0.9928 - accuracy: 0.9703 - cost: 3.7714 - val_loss: 0.1265 - val_auc: 0.9878 - val_accuracy: 0.9618 - val_cost: 4.7213\n",
            "Epoch 56/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0936 - auc: 0.9929 - accuracy: 0.9704 - cost: 3.7550 - val_loss: 0.1245 - val_auc: 0.9877 - val_accuracy: 0.9627 - val_cost: 4.6875\n",
            "Epoch 57/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0933 - auc: 0.9927 - accuracy: 0.9710 - cost: 3.6781 - val_loss: 0.1242 - val_auc: 0.9879 - val_accuracy: 0.9632 - val_cost: 4.5823\n",
            "Epoch 58/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0922 - auc: 0.9930 - accuracy: 0.9712 - cost: 3.6582 - val_loss: 0.1227 - val_auc: 0.9881 - val_accuracy: 0.9629 - val_cost: 4.6875\n",
            "Epoch 59/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0913 - auc: 0.9931 - accuracy: 0.9715 - cost: 3.6163 - val_loss: 0.1237 - val_auc: 0.9882 - val_accuracy: 0.9635 - val_cost: 4.5110\n",
            "Epoch 60/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0907 - auc: 0.9931 - accuracy: 0.9718 - cost: 3.5696 - val_loss: 0.1232 - val_auc: 0.9879 - val_accuracy: 0.9641 - val_cost: 4.4734\n",
            "Epoch 61/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0903 - auc: 0.9931 - accuracy: 0.9716 - cost: 3.6042 - val_loss: 0.1222 - val_auc: 0.9882 - val_accuracy: 0.9645 - val_cost: 4.4434\n",
            "Epoch 62/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0902 - auc: 0.9931 - accuracy: 0.9715 - cost: 3.6306 - val_loss: 0.1218 - val_auc: 0.9883 - val_accuracy: 0.9637 - val_cost: 4.5335\n",
            "Epoch 63/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0894 - auc: 0.9933 - accuracy: 0.9723 - cost: 3.5195 - val_loss: 0.1226 - val_auc: 0.9882 - val_accuracy: 0.9643 - val_cost: 4.4847\n",
            "Epoch 64/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0888 - auc: 0.9932 - accuracy: 0.9728 - cost: 3.4659 - val_loss: 0.1217 - val_auc: 0.9881 - val_accuracy: 0.9649 - val_cost: 4.4133\n",
            "Epoch 65/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0879 - auc: 0.9933 - accuracy: 0.9726 - cost: 3.4789 - val_loss: 0.1213 - val_auc: 0.9884 - val_accuracy: 0.9648 - val_cost: 4.4659\n",
            "Epoch 66/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0869 - auc: 0.9935 - accuracy: 0.9730 - cost: 3.4361 - val_loss: 0.1197 - val_auc: 0.9884 - val_accuracy: 0.9654 - val_cost: 4.3645\n",
            "Epoch 67/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0865 - auc: 0.9935 - accuracy: 0.9733 - cost: 3.3968 - val_loss: 0.1193 - val_auc: 0.9884 - val_accuracy: 0.9662 - val_cost: 4.2067\n",
            "Epoch 68/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0861 - auc: 0.9936 - accuracy: 0.9732 - cost: 3.4093 - val_loss: 0.1217 - val_auc: 0.9881 - val_accuracy: 0.9656 - val_cost: 4.3194\n",
            "Epoch 69/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0863 - auc: 0.9936 - accuracy: 0.9734 - cost: 3.3920 - val_loss: 0.1210 - val_auc: 0.9882 - val_accuracy: 0.9655 - val_cost: 4.3570\n",
            "Epoch 70/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0860 - auc: 0.9935 - accuracy: 0.9739 - cost: 3.3233 - val_loss: 0.1212 - val_auc: 0.9884 - val_accuracy: 0.9649 - val_cost: 4.3419\n",
            "Epoch 71/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0841 - auc: 0.9938 - accuracy: 0.9742 - cost: 3.2702 - val_loss: 0.1222 - val_auc: 0.9883 - val_accuracy: 0.9645 - val_cost: 4.4133\n",
            "Epoch 72/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0845 - auc: 0.9938 - accuracy: 0.9739 - cost: 3.3238 - val_loss: 0.1197 - val_auc: 0.9887 - val_accuracy: 0.9650 - val_cost: 4.3457\n",
            "Epoch 73/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0837 - auc: 0.9938 - accuracy: 0.9742 - cost: 3.2823 - val_loss: 0.1199 - val_auc: 0.9886 - val_accuracy: 0.9663 - val_cost: 4.2105\n",
            "Epoch 74/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0829 - auc: 0.9939 - accuracy: 0.9745 - cost: 3.2456 - val_loss: 0.1207 - val_auc: 0.9885 - val_accuracy: 0.9649 - val_cost: 4.3419\n",
            "Epoch 75/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0831 - auc: 0.9938 - accuracy: 0.9748 - cost: 3.1989 - val_loss: 0.1193 - val_auc: 0.9886 - val_accuracy: 0.9651 - val_cost: 4.3457\n",
            "Epoch 76/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0820 - auc: 0.9941 - accuracy: 0.9745 - cost: 3.2261 - val_loss: 0.1213 - val_auc: 0.9885 - val_accuracy: 0.9652 - val_cost: 4.4509\n",
            "Epoch 77/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0819 - auc: 0.9941 - accuracy: 0.9747 - cost: 3.2110 - val_loss: 0.1204 - val_auc: 0.9887 - val_accuracy: 0.9656 - val_cost: 4.2969\n",
            "Epoch 78/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0818 - auc: 0.9940 - accuracy: 0.9751 - cost: 3.1587 - val_loss: 0.1210 - val_auc: 0.9886 - val_accuracy: 0.9666 - val_cost: 4.2480\n",
            "Epoch 79/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0811 - auc: 0.9940 - accuracy: 0.9751 - cost: 3.1673 - val_loss: 0.1202 - val_auc: 0.9887 - val_accuracy: 0.9657 - val_cost: 4.2405\n",
            "Epoch 80/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0810 - auc: 0.9940 - accuracy: 0.9755 - cost: 3.1207 - val_loss: 0.1205 - val_auc: 0.9886 - val_accuracy: 0.9655 - val_cost: 4.3044\n",
            "Epoch 81/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0813 - auc: 0.9940 - accuracy: 0.9754 - cost: 3.1367 - val_loss: 0.1207 - val_auc: 0.9884 - val_accuracy: 0.9664 - val_cost: 4.2556\n",
            "Epoch 82/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0796 - auc: 0.9942 - accuracy: 0.9759 - cost: 3.0727 - val_loss: 0.1189 - val_auc: 0.9888 - val_accuracy: 0.9679 - val_cost: 4.0640\n",
            "Epoch 83/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0802 - auc: 0.9941 - accuracy: 0.9753 - cost: 3.1280 - val_loss: 0.1189 - val_auc: 0.9886 - val_accuracy: 0.9669 - val_cost: 4.1091\n",
            "Epoch 84/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0800 - auc: 0.9942 - accuracy: 0.9759 - cost: 3.0641 - val_loss: 0.1173 - val_auc: 0.9888 - val_accuracy: 0.9671 - val_cost: 4.1016\n",
            "Epoch 85/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0783 - auc: 0.9945 - accuracy: 0.9761 - cost: 3.0502 - val_loss: 0.1202 - val_auc: 0.9885 - val_accuracy: 0.9672 - val_cost: 4.0715\n",
            "Epoch 86/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0778 - auc: 0.9945 - accuracy: 0.9766 - cost: 2.9777 - val_loss: 0.1193 - val_auc: 0.9885 - val_accuracy: 0.9666 - val_cost: 4.1654\n",
            "Epoch 87/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0778 - auc: 0.9944 - accuracy: 0.9766 - cost: 2.9729 - val_loss: 0.1197 - val_auc: 0.9885 - val_accuracy: 0.9682 - val_cost: 4.0490\n",
            "Epoch 88/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0777 - auc: 0.9944 - accuracy: 0.9766 - cost: 2.9837 - val_loss: 0.1198 - val_auc: 0.9886 - val_accuracy: 0.9660 - val_cost: 4.3006\n",
            "Epoch 89/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0782 - auc: 0.9943 - accuracy: 0.9758 - cost: 3.0926 - val_loss: 0.1194 - val_auc: 0.9885 - val_accuracy: 0.9662 - val_cost: 4.3044\n",
            "Epoch 90/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0778 - auc: 0.9945 - accuracy: 0.9767 - cost: 2.9759 - val_loss: 0.1196 - val_auc: 0.9885 - val_accuracy: 0.9674 - val_cost: 4.1316\n",
            "Epoch 91/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0763 - auc: 0.9945 - accuracy: 0.9772 - cost: 2.9107 - val_loss: 0.1188 - val_auc: 0.9891 - val_accuracy: 0.9665 - val_cost: 4.2969\n",
            "Epoch 92/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0764 - auc: 0.9945 - accuracy: 0.9770 - cost: 2.9405 - val_loss: 0.1180 - val_auc: 0.9886 - val_accuracy: 0.9669 - val_cost: 4.2480\n",
            "Epoch 93/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0767 - auc: 0.9944 - accuracy: 0.9771 - cost: 2.9249 - val_loss: 0.1185 - val_auc: 0.9884 - val_accuracy: 0.9671 - val_cost: 4.1391\n",
            "Epoch 94/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0756 - auc: 0.9946 - accuracy: 0.9774 - cost: 2.8774 - val_loss: 0.1181 - val_auc: 0.9886 - val_accuracy: 0.9678 - val_cost: 4.0640\n",
            "Epoch 95/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0753 - auc: 0.9947 - accuracy: 0.9771 - cost: 2.9167 - val_loss: 0.1196 - val_auc: 0.9887 - val_accuracy: 0.9682 - val_cost: 3.9851\n",
            "Epoch 96/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0758 - auc: 0.9945 - accuracy: 0.9768 - cost: 2.9552 - val_loss: 0.1184 - val_auc: 0.9888 - val_accuracy: 0.9670 - val_cost: 4.1842\n",
            "Epoch 97/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0742 - auc: 0.9947 - accuracy: 0.9777 - cost: 2.8364 - val_loss: 0.1183 - val_auc: 0.9888 - val_accuracy: 0.9670 - val_cost: 4.1692\n",
            "Epoch 98/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0752 - auc: 0.9947 - accuracy: 0.9772 - cost: 2.9150 - val_loss: 0.1201 - val_auc: 0.9886 - val_accuracy: 0.9677 - val_cost: 4.0264\n",
            "Epoch 99/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0746 - auc: 0.9947 - accuracy: 0.9776 - cost: 2.8364 - val_loss: 0.1186 - val_auc: 0.9890 - val_accuracy: 0.9679 - val_cost: 3.9964\n",
            "Epoch 100/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0739 - auc: 0.9948 - accuracy: 0.9776 - cost: 2.8368 - val_loss: 0.1183 - val_auc: 0.9888 - val_accuracy: 0.9677 - val_cost: 4.1316\n",
            "Epoch 101/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0740 - auc: 0.9948 - accuracy: 0.9776 - cost: 2.8618 - val_loss: 0.1173 - val_auc: 0.9888 - val_accuracy: 0.9680 - val_cost: 4.0415\n",
            "Epoch 102/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0733 - auc: 0.9948 - accuracy: 0.9783 - cost: 2.7737 - val_loss: 0.1182 - val_auc: 0.9889 - val_accuracy: 0.9675 - val_cost: 4.1429\n",
            "Epoch 103/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0736 - auc: 0.9947 - accuracy: 0.9782 - cost: 2.7737 - val_loss: 0.1187 - val_auc: 0.9890 - val_accuracy: 0.9678 - val_cost: 4.1128\n",
            "Epoch 104/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0732 - auc: 0.9949 - accuracy: 0.9782 - cost: 2.7970 - val_loss: 0.1202 - val_auc: 0.9886 - val_accuracy: 0.9674 - val_cost: 4.2556\n",
            "Epoch 105/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0730 - auc: 0.9948 - accuracy: 0.9778 - cost: 2.8333 - val_loss: 0.1187 - val_auc: 0.9888 - val_accuracy: 0.9672 - val_cost: 4.2180\n",
            "Epoch 106/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0720 - auc: 0.9950 - accuracy: 0.9785 - cost: 2.7409 - val_loss: 0.1198 - val_auc: 0.9886 - val_accuracy: 0.9676 - val_cost: 4.1504\n",
            "Epoch 107/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0727 - auc: 0.9949 - accuracy: 0.9784 - cost: 2.7616 - val_loss: 0.1206 - val_auc: 0.9889 - val_accuracy: 0.9677 - val_cost: 4.1279\n",
            "Epoch 108/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0721 - auc: 0.9948 - accuracy: 0.9787 - cost: 2.7110 - val_loss: 0.1183 - val_auc: 0.9891 - val_accuracy: 0.9673 - val_cost: 4.1241\n",
            "Epoch 109/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0716 - auc: 0.9950 - accuracy: 0.9790 - cost: 2.6868 - val_loss: 0.1192 - val_auc: 0.9886 - val_accuracy: 0.9680 - val_cost: 3.9175\n",
            "Epoch 110/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0716 - auc: 0.9950 - accuracy: 0.9786 - cost: 2.7240 - val_loss: 0.1182 - val_auc: 0.9891 - val_accuracy: 0.9680 - val_cost: 3.9776\n",
            "Epoch 111/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0717 - auc: 0.9949 - accuracy: 0.9784 - cost: 2.7417 - val_loss: 0.1164 - val_auc: 0.9888 - val_accuracy: 0.9678 - val_cost: 4.1279\n",
            "Epoch 112/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0719 - auc: 0.9950 - accuracy: 0.9782 - cost: 2.7888 - val_loss: 0.1196 - val_auc: 0.9887 - val_accuracy: 0.9670 - val_cost: 4.1466\n",
            "Epoch 113/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0714 - auc: 0.9950 - accuracy: 0.9785 - cost: 2.7309 - val_loss: 0.1210 - val_auc: 0.9884 - val_accuracy: 0.9678 - val_cost: 4.0264\n",
            "Epoch 114/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0704 - auc: 0.9951 - accuracy: 0.9790 - cost: 2.6881 - val_loss: 0.1175 - val_auc: 0.9889 - val_accuracy: 0.9681 - val_cost: 4.0189\n",
            "Epoch 115/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0699 - auc: 0.9952 - accuracy: 0.9790 - cost: 2.6613 - val_loss: 0.1201 - val_auc: 0.9884 - val_accuracy: 0.9674 - val_cost: 4.1166\n",
            "Epoch 116/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0702 - auc: 0.9952 - accuracy: 0.9789 - cost: 2.6976 - val_loss: 0.1203 - val_auc: 0.9890 - val_accuracy: 0.9684 - val_cost: 4.0152\n",
            "Epoch 117/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0696 - auc: 0.9952 - accuracy: 0.9789 - cost: 2.6938 - val_loss: 0.1198 - val_auc: 0.9889 - val_accuracy: 0.9680 - val_cost: 4.0152\n",
            "Epoch 118/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0702 - auc: 0.9951 - accuracy: 0.9789 - cost: 2.6825 - val_loss: 0.1200 - val_auc: 0.9890 - val_accuracy: 0.9673 - val_cost: 4.1617\n",
            "Epoch 119/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0698 - auc: 0.9951 - accuracy: 0.9789 - cost: 2.6989 - val_loss: 0.1209 - val_auc: 0.9888 - val_accuracy: 0.9670 - val_cost: 4.1692\n",
            "Epoch 120/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0698 - auc: 0.9951 - accuracy: 0.9792 - cost: 2.6471 - val_loss: 0.1192 - val_auc: 0.9888 - val_accuracy: 0.9679 - val_cost: 4.1617\n",
            "Epoch 121/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0694 - auc: 0.9952 - accuracy: 0.9796 - cost: 2.6112 - val_loss: 0.1206 - val_auc: 0.9887 - val_accuracy: 0.9678 - val_cost: 3.9814\n",
            "Epoch 122/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0690 - auc: 0.9952 - accuracy: 0.9791 - cost: 2.6631 - val_loss: 0.1203 - val_auc: 0.9889 - val_accuracy: 0.9691 - val_cost: 3.8837\n",
            "Epoch 123/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0688 - auc: 0.9953 - accuracy: 0.9794 - cost: 2.6263 - val_loss: 0.1219 - val_auc: 0.9888 - val_accuracy: 0.9676 - val_cost: 4.0114\n",
            "Epoch 124/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0691 - auc: 0.9952 - accuracy: 0.9796 - cost: 2.5931 - val_loss: 0.1190 - val_auc: 0.9892 - val_accuracy: 0.9684 - val_cost: 3.9851\n",
            "Epoch 125/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0685 - auc: 0.9953 - accuracy: 0.9795 - cost: 2.6155 - val_loss: 0.1209 - val_auc: 0.9889 - val_accuracy: 0.9677 - val_cost: 4.0114\n",
            "Epoch 126/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0689 - auc: 0.9952 - accuracy: 0.9794 - cost: 2.6229 - val_loss: 0.1218 - val_auc: 0.9886 - val_accuracy: 0.9675 - val_cost: 4.0565\n",
            "Epoch 127/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0683 - auc: 0.9952 - accuracy: 0.9796 - cost: 2.6047 - val_loss: 0.1231 - val_auc: 0.9890 - val_accuracy: 0.9681 - val_cost: 4.1091\n",
            "Epoch 128/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0681 - auc: 0.9953 - accuracy: 0.9797 - cost: 2.6009 - val_loss: 0.1214 - val_auc: 0.9888 - val_accuracy: 0.9681 - val_cost: 3.9851\n",
            "Epoch 129/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0688 - auc: 0.9953 - accuracy: 0.9797 - cost: 2.5875 - val_loss: 0.1194 - val_auc: 0.9888 - val_accuracy: 0.9688 - val_cost: 3.8875\n",
            "Epoch 130/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0675 - auc: 0.9954 - accuracy: 0.9800 - cost: 2.5594 - val_loss: 0.1212 - val_auc: 0.9887 - val_accuracy: 0.9687 - val_cost: 3.9851\n",
            "Epoch 131/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0681 - auc: 0.9953 - accuracy: 0.9796 - cost: 2.6026 - val_loss: 0.1227 - val_auc: 0.9888 - val_accuracy: 0.9691 - val_cost: 3.9025\n",
            "Epoch 132/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0671 - auc: 0.9955 - accuracy: 0.9803 - cost: 2.5049 - val_loss: 0.1228 - val_auc: 0.9887 - val_accuracy: 0.9666 - val_cost: 4.1692\n",
            "Epoch 133/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0673 - auc: 0.9954 - accuracy: 0.9797 - cost: 2.5745 - val_loss: 0.1190 - val_auc: 0.9891 - val_accuracy: 0.9685 - val_cost: 4.0264\n",
            "Epoch 134/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0668 - auc: 0.9955 - accuracy: 0.9800 - cost: 2.5689 - val_loss: 0.1220 - val_auc: 0.9889 - val_accuracy: 0.9677 - val_cost: 4.0565\n",
            "Epoch 135/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0672 - auc: 0.9954 - accuracy: 0.9797 - cost: 2.5888 - val_loss: 0.1213 - val_auc: 0.9888 - val_accuracy: 0.9694 - val_cost: 3.8687\n",
            "Epoch 136/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0669 - auc: 0.9955 - accuracy: 0.9799 - cost: 2.5723 - val_loss: 0.1223 - val_auc: 0.9888 - val_accuracy: 0.9697 - val_cost: 3.8912\n",
            "Epoch 137/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0671 - auc: 0.9955 - accuracy: 0.9799 - cost: 2.5663 - val_loss: 0.1220 - val_auc: 0.9889 - val_accuracy: 0.9684 - val_cost: 3.9100\n",
            "Epoch 138/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0672 - auc: 0.9954 - accuracy: 0.9799 - cost: 2.5615 - val_loss: 0.1230 - val_auc: 0.9891 - val_accuracy: 0.9682 - val_cost: 3.9814\n",
            "Epoch 139/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0659 - auc: 0.9956 - accuracy: 0.9802 - cost: 2.5300 - val_loss: 0.1216 - val_auc: 0.9888 - val_accuracy: 0.9680 - val_cost: 3.9964\n",
            "Epoch 140/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0665 - auc: 0.9955 - accuracy: 0.9803 - cost: 2.5062 - val_loss: 0.1222 - val_auc: 0.9886 - val_accuracy: 0.9693 - val_cost: 3.8424\n",
            "Epoch 141/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0658 - auc: 0.9955 - accuracy: 0.9807 - cost: 2.4799 - val_loss: 0.1210 - val_auc: 0.9890 - val_accuracy: 0.9688 - val_cost: 3.8800\n",
            "Epoch 142/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0662 - auc: 0.9955 - accuracy: 0.9802 - cost: 2.5391 - val_loss: 0.1245 - val_auc: 0.9886 - val_accuracy: 0.9682 - val_cost: 3.9851\n",
            "Epoch 143/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0657 - auc: 0.9956 - accuracy: 0.9805 - cost: 2.4777 - val_loss: 0.1229 - val_auc: 0.9888 - val_accuracy: 0.9691 - val_cost: 3.8462\n",
            "Epoch 144/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0659 - auc: 0.9956 - accuracy: 0.9805 - cost: 2.4881 - val_loss: 0.1223 - val_auc: 0.9888 - val_accuracy: 0.9677 - val_cost: 4.1053\n",
            "Epoch 145/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0657 - auc: 0.9956 - accuracy: 0.9802 - cost: 2.5395 - val_loss: 0.1244 - val_auc: 0.9888 - val_accuracy: 0.9676 - val_cost: 3.9814\n",
            "Epoch 146/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0659 - auc: 0.9957 - accuracy: 0.9801 - cost: 2.5438 - val_loss: 0.1237 - val_auc: 0.9889 - val_accuracy: 0.9682 - val_cost: 4.0602\n",
            "Epoch 147/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0659 - auc: 0.9957 - accuracy: 0.9803 - cost: 2.5088 - val_loss: 0.1245 - val_auc: 0.9886 - val_accuracy: 0.9685 - val_cost: 3.9814\n",
            "Epoch 148/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0651 - auc: 0.9956 - accuracy: 0.9806 - cost: 2.4704 - val_loss: 0.1221 - val_auc: 0.9886 - val_accuracy: 0.9689 - val_cost: 3.9739\n",
            "Epoch 149/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0653 - auc: 0.9956 - accuracy: 0.9807 - cost: 2.4630 - val_loss: 0.1241 - val_auc: 0.9891 - val_accuracy: 0.9684 - val_cost: 3.9551\n",
            "Epoch 150/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0647 - auc: 0.9956 - accuracy: 0.9811 - cost: 2.4090 - val_loss: 0.1246 - val_auc: 0.9885 - val_accuracy: 0.9695 - val_cost: 3.8199\n",
            "Epoch 151/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0647 - auc: 0.9957 - accuracy: 0.9805 - cost: 2.5028 - val_loss: 0.1236 - val_auc: 0.9883 - val_accuracy: 0.9690 - val_cost: 3.9100\n",
            "Epoch 152/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0651 - auc: 0.9957 - accuracy: 0.9805 - cost: 2.4894 - val_loss: 0.1270 - val_auc: 0.9885 - val_accuracy: 0.9688 - val_cost: 3.9213\n",
            "Epoch 153/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0653 - auc: 0.9956 - accuracy: 0.9808 - cost: 2.4449 - val_loss: 0.1258 - val_auc: 0.9881 - val_accuracy: 0.9691 - val_cost: 3.8912\n",
            "Epoch 154/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0641 - auc: 0.9959 - accuracy: 0.9808 - cost: 2.4574 - val_loss: 0.1275 - val_auc: 0.9883 - val_accuracy: 0.9680 - val_cost: 4.1767\n",
            "Epoch 155/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0647 - auc: 0.9956 - accuracy: 0.9809 - cost: 2.4414 - val_loss: 0.1242 - val_auc: 0.9887 - val_accuracy: 0.9690 - val_cost: 3.8912\n",
            "Epoch 156/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0635 - auc: 0.9958 - accuracy: 0.9810 - cost: 2.4315 - val_loss: 0.1259 - val_auc: 0.9884 - val_accuracy: 0.9680 - val_cost: 4.0189\n",
            "Epoch 157/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0648 - auc: 0.9957 - accuracy: 0.9807 - cost: 2.4626 - val_loss: 0.1234 - val_auc: 0.9889 - val_accuracy: 0.9693 - val_cost: 3.8161\n",
            "Epoch 158/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0646 - auc: 0.9957 - accuracy: 0.9809 - cost: 2.4466 - val_loss: 0.1254 - val_auc: 0.9886 - val_accuracy: 0.9681 - val_cost: 4.0302\n",
            "Epoch 159/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0640 - auc: 0.9958 - accuracy: 0.9813 - cost: 2.3891 - val_loss: 0.1289 - val_auc: 0.9884 - val_accuracy: 0.9680 - val_cost: 4.0340\n",
            "Epoch 160/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0638 - auc: 0.9958 - accuracy: 0.9812 - cost: 2.4099 - val_loss: 0.1253 - val_auc: 0.9885 - val_accuracy: 0.9685 - val_cost: 3.9513\n",
            "Epoch 161/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0636 - auc: 0.9958 - accuracy: 0.9811 - cost: 2.4077 - val_loss: 0.1241 - val_auc: 0.9886 - val_accuracy: 0.9690 - val_cost: 3.9438\n",
            "Epoch 162/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0631 - auc: 0.9959 - accuracy: 0.9814 - cost: 2.3749 - val_loss: 0.1242 - val_auc: 0.9883 - val_accuracy: 0.9690 - val_cost: 3.8950\n",
            "Epoch 163/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0635 - auc: 0.9958 - accuracy: 0.9812 - cost: 2.4042 - val_loss: 0.1255 - val_auc: 0.9886 - val_accuracy: 0.9688 - val_cost: 3.9476\n",
            "Epoch 164/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0640 - auc: 0.9958 - accuracy: 0.9812 - cost: 2.4142 - val_loss: 0.1287 - val_auc: 0.9880 - val_accuracy: 0.9693 - val_cost: 3.8499\n",
            "Epoch 165/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0630 - auc: 0.9958 - accuracy: 0.9814 - cost: 2.3870 - val_loss: 0.1275 - val_auc: 0.9886 - val_accuracy: 0.9690 - val_cost: 3.8537\n",
            "Epoch 166/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0636 - auc: 0.9958 - accuracy: 0.9814 - cost: 2.3718 - val_loss: 0.1260 - val_auc: 0.9881 - val_accuracy: 0.9692 - val_cost: 3.8762\n",
            "Epoch 167/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0634 - auc: 0.9959 - accuracy: 0.9814 - cost: 2.3805 - val_loss: 0.1254 - val_auc: 0.9882 - val_accuracy: 0.9680 - val_cost: 4.0527\n",
            "Epoch 168/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0624 - auc: 0.9959 - accuracy: 0.9819 - cost: 2.3152 - val_loss: 0.1243 - val_auc: 0.9887 - val_accuracy: 0.9689 - val_cost: 3.9250\n",
            "Epoch 169/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0624 - auc: 0.9960 - accuracy: 0.9819 - cost: 2.3183 - val_loss: 0.1280 - val_auc: 0.9883 - val_accuracy: 0.9681 - val_cost: 3.9739\n",
            "Epoch 170/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0624 - auc: 0.9959 - accuracy: 0.9815 - cost: 2.3571 - val_loss: 0.1274 - val_auc: 0.9883 - val_accuracy: 0.9689 - val_cost: 3.8649\n",
            "Epoch 171/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0624 - auc: 0.9960 - accuracy: 0.9815 - cost: 2.3671 - val_loss: 0.1258 - val_auc: 0.9883 - val_accuracy: 0.9696 - val_cost: 3.8011\n",
            "Epoch 172/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0624 - auc: 0.9959 - accuracy: 0.9815 - cost: 2.3632 - val_loss: 0.1286 - val_auc: 0.9885 - val_accuracy: 0.9684 - val_cost: 3.9814\n",
            "Epoch 173/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0616 - auc: 0.9960 - accuracy: 0.9817 - cost: 2.3386 - val_loss: 0.1268 - val_auc: 0.9884 - val_accuracy: 0.9694 - val_cost: 3.8612\n",
            "Epoch 174/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0623 - auc: 0.9959 - accuracy: 0.9818 - cost: 2.3208 - val_loss: 0.1270 - val_auc: 0.9882 - val_accuracy: 0.9696 - val_cost: 3.7598\n",
            "Epoch 175/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0629 - auc: 0.9959 - accuracy: 0.9810 - cost: 2.4475 - val_loss: 0.1276 - val_auc: 0.9885 - val_accuracy: 0.9694 - val_cost: 3.8687\n",
            "Epoch 176/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0619 - auc: 0.9961 - accuracy: 0.9815 - cost: 2.3762 - val_loss: 0.1279 - val_auc: 0.9884 - val_accuracy: 0.9695 - val_cost: 3.7936\n",
            "Epoch 177/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0618 - auc: 0.9961 - accuracy: 0.9816 - cost: 2.3546 - val_loss: 0.1280 - val_auc: 0.9882 - val_accuracy: 0.9688 - val_cost: 3.9288\n",
            "Epoch 178/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0618 - auc: 0.9960 - accuracy: 0.9817 - cost: 2.3420 - val_loss: 0.1297 - val_auc: 0.9879 - val_accuracy: 0.9680 - val_cost: 4.0227\n",
            "Epoch 179/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0618 - auc: 0.9960 - accuracy: 0.9816 - cost: 2.3502 - val_loss: 0.1268 - val_auc: 0.9882 - val_accuracy: 0.9686 - val_cost: 3.9062\n",
            "Epoch 180/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0614 - auc: 0.9960 - accuracy: 0.9814 - cost: 2.3775 - val_loss: 0.1290 - val_auc: 0.9882 - val_accuracy: 0.9691 - val_cost: 3.9062\n",
            "Epoch 181/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0617 - auc: 0.9961 - accuracy: 0.9818 - cost: 2.3325 - val_loss: 0.1283 - val_auc: 0.9884 - val_accuracy: 0.9693 - val_cost: 3.8274\n",
            "Epoch 182/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0613 - auc: 0.9960 - accuracy: 0.9817 - cost: 2.3282 - val_loss: 0.1298 - val_auc: 0.9881 - val_accuracy: 0.9695 - val_cost: 3.9476\n",
            "Epoch 183/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0615 - auc: 0.9960 - accuracy: 0.9812 - cost: 2.4125 - val_loss: 0.1288 - val_auc: 0.9885 - val_accuracy: 0.9685 - val_cost: 3.9213\n",
            "Epoch 184/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0608 - auc: 0.9961 - accuracy: 0.9820 - cost: 2.2958 - val_loss: 0.1287 - val_auc: 0.9884 - val_accuracy: 0.9698 - val_cost: 3.7184\n",
            "Epoch 185/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0615 - auc: 0.9962 - accuracy: 0.9814 - cost: 2.3749 - val_loss: 0.1294 - val_auc: 0.9881 - val_accuracy: 0.9691 - val_cost: 3.8912\n",
            "Epoch 186/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0612 - auc: 0.9960 - accuracy: 0.9819 - cost: 2.3187 - val_loss: 0.1267 - val_auc: 0.9885 - val_accuracy: 0.9695 - val_cost: 3.8424\n",
            "Epoch 187/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0614 - auc: 0.9961 - accuracy: 0.9816 - cost: 2.3567 - val_loss: 0.1312 - val_auc: 0.9884 - val_accuracy: 0.9686 - val_cost: 3.8687\n",
            "Epoch 188/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0613 - auc: 0.9959 - accuracy: 0.9823 - cost: 2.2621 - val_loss: 0.1262 - val_auc: 0.9885 - val_accuracy: 0.9696 - val_cost: 3.8048\n",
            "Epoch 189/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0610 - auc: 0.9961 - accuracy: 0.9819 - cost: 2.3170 - val_loss: 0.1292 - val_auc: 0.9884 - val_accuracy: 0.9688 - val_cost: 3.9626\n",
            "Epoch 190/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0603 - auc: 0.9962 - accuracy: 0.9824 - cost: 2.2500 - val_loss: 0.1266 - val_auc: 0.9887 - val_accuracy: 0.9685 - val_cost: 3.9926\n",
            "Epoch 191/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0609 - auc: 0.9961 - accuracy: 0.9820 - cost: 2.2997 - val_loss: 0.1281 - val_auc: 0.9885 - val_accuracy: 0.9693 - val_cost: 3.8950\n",
            "Epoch 192/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0612 - auc: 0.9960 - accuracy: 0.9816 - cost: 2.3623 - val_loss: 0.1312 - val_auc: 0.9880 - val_accuracy: 0.9692 - val_cost: 3.7710\n",
            "Epoch 193/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0601 - auc: 0.9962 - accuracy: 0.9819 - cost: 2.3062 - val_loss: 0.1320 - val_auc: 0.9884 - val_accuracy: 0.9693 - val_cost: 3.7147\n",
            "Epoch 194/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0607 - auc: 0.9961 - accuracy: 0.9819 - cost: 2.3036 - val_loss: 0.1278 - val_auc: 0.9888 - val_accuracy: 0.9701 - val_cost: 3.7973\n",
            "Epoch 195/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0606 - auc: 0.9961 - accuracy: 0.9821 - cost: 2.2889 - val_loss: 0.1320 - val_auc: 0.9884 - val_accuracy: 0.9687 - val_cost: 3.9100\n",
            "Epoch 196/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0607 - auc: 0.9961 - accuracy: 0.9817 - cost: 2.3386 - val_loss: 0.1280 - val_auc: 0.9884 - val_accuracy: 0.9691 - val_cost: 3.9889\n",
            "Epoch 197/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0597 - auc: 0.9962 - accuracy: 0.9821 - cost: 2.2992 - val_loss: 0.1302 - val_auc: 0.9884 - val_accuracy: 0.9686 - val_cost: 3.9250\n",
            "Epoch 198/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0606 - auc: 0.9962 - accuracy: 0.9821 - cost: 2.2815 - val_loss: 0.1294 - val_auc: 0.9883 - val_accuracy: 0.9695 - val_cost: 3.9138\n",
            "Epoch 199/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0604 - auc: 0.9962 - accuracy: 0.9822 - cost: 2.2915 - val_loss: 0.1295 - val_auc: 0.9882 - val_accuracy: 0.9695 - val_cost: 3.9062\n",
            "Epoch 200/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0600 - auc: 0.9962 - accuracy: 0.9822 - cost: 2.2742 - val_loss: 0.1300 - val_auc: 0.9883 - val_accuracy: 0.9698 - val_cost: 3.8161\n",
            "Epoch 201/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0592 - auc: 0.9962 - accuracy: 0.9827 - cost: 2.2141 - val_loss: 0.1288 - val_auc: 0.9885 - val_accuracy: 0.9702 - val_cost: 3.7335\n",
            "Epoch 202/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0609 - auc: 0.9962 - accuracy: 0.9821 - cost: 2.2910 - val_loss: 0.1304 - val_auc: 0.9883 - val_accuracy: 0.9699 - val_cost: 3.7861\n",
            "Epoch 203/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0600 - auc: 0.9962 - accuracy: 0.9817 - cost: 2.3351 - val_loss: 0.1310 - val_auc: 0.9881 - val_accuracy: 0.9698 - val_cost: 3.8123\n",
            "Epoch 204/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0590 - auc: 0.9962 - accuracy: 0.9822 - cost: 2.2694 - val_loss: 0.1298 - val_auc: 0.9882 - val_accuracy: 0.9691 - val_cost: 3.9363\n",
            "Epoch 205/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0601 - auc: 0.9962 - accuracy: 0.9821 - cost: 2.2833 - val_loss: 0.1299 - val_auc: 0.9881 - val_accuracy: 0.9702 - val_cost: 3.7973\n",
            "Epoch 206/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0601 - auc: 0.9961 - accuracy: 0.9823 - cost: 2.2608 - val_loss: 0.1315 - val_auc: 0.9883 - val_accuracy: 0.9693 - val_cost: 3.9175\n",
            "Epoch 207/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0599 - auc: 0.9961 - accuracy: 0.9822 - cost: 2.2824 - val_loss: 0.1288 - val_auc: 0.9881 - val_accuracy: 0.9695 - val_cost: 3.8274\n",
            "Epoch 208/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0595 - auc: 0.9963 - accuracy: 0.9821 - cost: 2.2880 - val_loss: 0.1308 - val_auc: 0.9879 - val_accuracy: 0.9692 - val_cost: 3.8537\n",
            "Epoch 209/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0593 - auc: 0.9963 - accuracy: 0.9826 - cost: 2.2180 - val_loss: 0.1316 - val_auc: 0.9879 - val_accuracy: 0.9688 - val_cost: 3.9814\n",
            "Epoch 210/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0594 - auc: 0.9964 - accuracy: 0.9823 - cost: 2.2642 - val_loss: 0.1316 - val_auc: 0.9879 - val_accuracy: 0.9688 - val_cost: 4.0152\n",
            "Epoch 211/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0595 - auc: 0.9962 - accuracy: 0.9824 - cost: 2.2543 - val_loss: 0.1346 - val_auc: 0.9879 - val_accuracy: 0.9688 - val_cost: 3.9062\n",
            "Epoch 212/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0595 - auc: 0.9964 - accuracy: 0.9822 - cost: 2.2742 - val_loss: 0.1335 - val_auc: 0.9881 - val_accuracy: 0.9678 - val_cost: 4.0790\n",
            "Epoch 213/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0598 - auc: 0.9962 - accuracy: 0.9822 - cost: 2.2841 - val_loss: 0.1338 - val_auc: 0.9877 - val_accuracy: 0.9686 - val_cost: 3.9814\n",
            "Epoch 214/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0591 - auc: 0.9963 - accuracy: 0.9822 - cost: 2.2979 - val_loss: 0.1294 - val_auc: 0.9882 - val_accuracy: 0.9690 - val_cost: 3.9363\n",
            "Epoch 215/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0585 - auc: 0.9963 - accuracy: 0.9827 - cost: 2.2063 - val_loss: 0.1334 - val_auc: 0.9879 - val_accuracy: 0.9698 - val_cost: 3.7635\n",
            "Epoch 216/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0590 - auc: 0.9964 - accuracy: 0.9825 - cost: 2.2331 - val_loss: 0.1324 - val_auc: 0.9880 - val_accuracy: 0.9685 - val_cost: 3.9250\n",
            "Epoch 217/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0590 - auc: 0.9962 - accuracy: 0.9823 - cost: 2.2604 - val_loss: 0.1347 - val_auc: 0.9879 - val_accuracy: 0.9679 - val_cost: 4.1053\n",
            "Epoch 218/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0583 - auc: 0.9964 - accuracy: 0.9828 - cost: 2.2102 - val_loss: 0.1313 - val_auc: 0.9883 - val_accuracy: 0.9702 - val_cost: 3.7222\n",
            "Epoch 219/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0600 - auc: 0.9961 - accuracy: 0.9824 - cost: 2.2435 - val_loss: 0.1340 - val_auc: 0.9881 - val_accuracy: 0.9702 - val_cost: 3.7297\n",
            "Epoch 220/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0588 - auc: 0.9963 - accuracy: 0.9824 - cost: 2.2673 - val_loss: 0.1303 - val_auc: 0.9883 - val_accuracy: 0.9698 - val_cost: 3.8912\n",
            "Epoch 221/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0595 - auc: 0.9962 - accuracy: 0.9823 - cost: 2.2668 - val_loss: 0.1297 - val_auc: 0.9883 - val_accuracy: 0.9685 - val_cost: 4.0340\n",
            "Epoch 222/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0587 - auc: 0.9963 - accuracy: 0.9826 - cost: 2.2344 - val_loss: 0.1328 - val_auc: 0.9881 - val_accuracy: 0.9696 - val_cost: 3.7147\n",
            "Epoch 223/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0587 - auc: 0.9963 - accuracy: 0.9829 - cost: 2.2007 - val_loss: 0.1304 - val_auc: 0.9883 - val_accuracy: 0.9701 - val_cost: 3.7861\n",
            "Epoch 224/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0593 - auc: 0.9962 - accuracy: 0.9827 - cost: 2.2232 - val_loss: 0.1339 - val_auc: 0.9877 - val_accuracy: 0.9686 - val_cost: 3.9476\n",
            "Epoch 225/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0583 - auc: 0.9964 - accuracy: 0.9827 - cost: 2.2085 - val_loss: 0.1323 - val_auc: 0.9883 - val_accuracy: 0.9703 - val_cost: 3.7297\n",
            "Epoch 226/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0579 - auc: 0.9964 - accuracy: 0.9828 - cost: 2.2076 - val_loss: 0.1311 - val_auc: 0.9883 - val_accuracy: 0.9694 - val_cost: 3.9213\n",
            "Epoch 227/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0582 - auc: 0.9963 - accuracy: 0.9827 - cost: 2.2288 - val_loss: 0.1346 - val_auc: 0.9883 - val_accuracy: 0.9684 - val_cost: 3.9551\n",
            "Epoch 228/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0579 - auc: 0.9964 - accuracy: 0.9826 - cost: 2.2357 - val_loss: 0.1311 - val_auc: 0.9885 - val_accuracy: 0.9694 - val_cost: 3.8762\n",
            "Epoch 229/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0577 - auc: 0.9966 - accuracy: 0.9825 - cost: 2.2431 - val_loss: 0.1341 - val_auc: 0.9884 - val_accuracy: 0.9696 - val_cost: 3.7598\n",
            "Epoch 230/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0571 - auc: 0.9965 - accuracy: 0.9830 - cost: 2.1830 - val_loss: 0.1329 - val_auc: 0.9880 - val_accuracy: 0.9697 - val_cost: 3.8161\n",
            "Epoch 231/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0593 - auc: 0.9963 - accuracy: 0.9822 - cost: 2.2660 - val_loss: 0.1338 - val_auc: 0.9878 - val_accuracy: 0.9695 - val_cost: 3.8424\n",
            "Epoch 232/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0576 - auc: 0.9965 - accuracy: 0.9828 - cost: 2.1942 - val_loss: 0.1352 - val_auc: 0.9881 - val_accuracy: 0.9688 - val_cost: 3.9325\n",
            "Epoch 233/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0575 - auc: 0.9963 - accuracy: 0.9826 - cost: 2.2353 - val_loss: 0.1358 - val_auc: 0.9878 - val_accuracy: 0.9683 - val_cost: 3.9626\n",
            "Epoch 234/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0576 - auc: 0.9964 - accuracy: 0.9828 - cost: 2.1951 - val_loss: 0.1340 - val_auc: 0.9881 - val_accuracy: 0.9691 - val_cost: 3.8274\n",
            "Epoch 235/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0579 - auc: 0.9964 - accuracy: 0.9831 - cost: 2.1653 - val_loss: 0.1348 - val_auc: 0.9881 - val_accuracy: 0.9696 - val_cost: 3.8537\n",
            "Epoch 236/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0577 - auc: 0.9963 - accuracy: 0.9829 - cost: 2.1899 - val_loss: 0.1350 - val_auc: 0.9877 - val_accuracy: 0.9697 - val_cost: 3.7898\n",
            "Epoch 237/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0585 - auc: 0.9963 - accuracy: 0.9825 - cost: 2.2413 - val_loss: 0.1368 - val_auc: 0.9877 - val_accuracy: 0.9688 - val_cost: 3.9626\n",
            "Epoch 238/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0568 - auc: 0.9966 - accuracy: 0.9830 - cost: 2.1700 - val_loss: 0.1343 - val_auc: 0.9877 - val_accuracy: 0.9693 - val_cost: 3.8950\n",
            "Epoch 239/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0573 - auc: 0.9965 - accuracy: 0.9834 - cost: 2.1350 - val_loss: 0.1349 - val_auc: 0.9884 - val_accuracy: 0.9698 - val_cost: 3.7785\n",
            "Epoch 240/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0570 - auc: 0.9965 - accuracy: 0.9831 - cost: 2.1562 - val_loss: 0.1349 - val_auc: 0.9880 - val_accuracy: 0.9687 - val_cost: 3.8724\n",
            "Epoch 241/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0578 - auc: 0.9964 - accuracy: 0.9828 - cost: 2.1904 - val_loss: 0.1349 - val_auc: 0.9876 - val_accuracy: 0.9691 - val_cost: 3.8987\n",
            "Epoch 242/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0578 - auc: 0.9964 - accuracy: 0.9828 - cost: 2.2025 - val_loss: 0.1364 - val_auc: 0.9878 - val_accuracy: 0.9694 - val_cost: 3.8537\n",
            "Epoch 243/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0575 - auc: 0.9964 - accuracy: 0.9831 - cost: 2.1484 - val_loss: 0.1337 - val_auc: 0.9879 - val_accuracy: 0.9688 - val_cost: 3.9776\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1098 - auc: 0.9903 - accuracy: 0.9702 - cost: 3.6719\n",
            "1000/1000 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:02:02.362399\n",
            "fold accuracy: 0.9701562523841858 - fold cost: 3.671875\n",
            "x_train shape: (128000, 67)\n",
            "Epoch 1/1000\n",
            "113/113 [==============================] - 2s 7ms/step - loss: 0.5396 - auc: 0.7878 - accuracy: 0.7205 - cost: 37.2658 - val_loss: 0.4118 - val_auc: 0.8920 - val_accuracy: 0.8199 - val_cost: 23.3586\n",
            "Epoch 2/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.3597 - auc: 0.9176 - accuracy: 0.8448 - cost: 19.7931 - val_loss: 0.3256 - val_auc: 0.9329 - val_accuracy: 0.8630 - val_cost: 16.9809\n",
            "Epoch 3/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.3077 - auc: 0.9401 - accuracy: 0.8713 - cost: 16.2844 - val_loss: 0.2952 - val_auc: 0.9448 - val_accuracy: 0.8761 - val_cost: 15.6250\n",
            "Epoch 4/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2794 - auc: 0.9506 - accuracy: 0.8858 - cost: 14.4553 - val_loss: 0.2715 - val_auc: 0.9534 - val_accuracy: 0.8887 - val_cost: 14.0550\n",
            "Epoch 5/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2559 - auc: 0.9586 - accuracy: 0.8966 - cost: 13.0976 - val_loss: 0.2517 - val_auc: 0.9602 - val_accuracy: 0.8984 - val_cost: 13.0634\n",
            "Epoch 6/1000\n",
            "113/113 [==============================] - 1s 4ms/step - loss: 0.2377 - auc: 0.9643 - accuracy: 0.9058 - cost: 11.9141 - val_loss: 0.2342 - val_auc: 0.9654 - val_accuracy: 0.9084 - val_cost: 11.5723\n",
            "Epoch 7/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.2221 - auc: 0.9687 - accuracy: 0.9136 - cost: 10.9241 - val_loss: 0.2205 - val_auc: 0.9694 - val_accuracy: 0.9145 - val_cost: 10.5657\n",
            "Epoch 8/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.2079 - auc: 0.9726 - accuracy: 0.9199 - cost: 10.1359 - val_loss: 0.2095 - val_auc: 0.9724 - val_accuracy: 0.9202 - val_cost: 9.8558\n",
            "Epoch 9/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1972 - auc: 0.9752 - accuracy: 0.9253 - cost: 9.4437 - val_loss: 0.1989 - val_auc: 0.9752 - val_accuracy: 0.9268 - val_cost: 8.9844\n",
            "Epoch 10/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1884 - auc: 0.9772 - accuracy: 0.9289 - cost: 8.9913 - val_loss: 0.1898 - val_auc: 0.9771 - val_accuracy: 0.9309 - val_cost: 8.8454\n",
            "Epoch 11/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1798 - auc: 0.9791 - accuracy: 0.9337 - cost: 8.3911 - val_loss: 0.1860 - val_auc: 0.9782 - val_accuracy: 0.9312 - val_cost: 8.9994\n",
            "Epoch 12/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1736 - auc: 0.9804 - accuracy: 0.9359 - cost: 8.1042 - val_loss: 0.1775 - val_auc: 0.9800 - val_accuracy: 0.9354 - val_cost: 7.9665\n",
            "Epoch 13/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1671 - auc: 0.9818 - accuracy: 0.9388 - cost: 7.7594 - val_loss: 0.1721 - val_auc: 0.9807 - val_accuracy: 0.9373 - val_cost: 7.9139\n",
            "Epoch 14/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1628 - auc: 0.9826 - accuracy: 0.9408 - cost: 7.4953 - val_loss: 0.1684 - val_auc: 0.9816 - val_accuracy: 0.9383 - val_cost: 7.9890\n",
            "Epoch 15/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1579 - auc: 0.9835 - accuracy: 0.9433 - cost: 7.2387 - val_loss: 0.1633 - val_auc: 0.9826 - val_accuracy: 0.9418 - val_cost: 7.2942\n",
            "Epoch 16/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1539 - auc: 0.9842 - accuracy: 0.9451 - cost: 6.9552 - val_loss: 0.1604 - val_auc: 0.9830 - val_accuracy: 0.9434 - val_cost: 7.2228\n",
            "Epoch 17/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1498 - auc: 0.9850 - accuracy: 0.9468 - cost: 6.7417 - val_loss: 0.1574 - val_auc: 0.9835 - val_accuracy: 0.9441 - val_cost: 7.1026\n",
            "Epoch 18/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1456 - auc: 0.9857 - accuracy: 0.9478 - cost: 6.6436 - val_loss: 0.1562 - val_auc: 0.9840 - val_accuracy: 0.9431 - val_cost: 7.0125\n",
            "Epoch 19/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1437 - auc: 0.9860 - accuracy: 0.9492 - cost: 6.4259 - val_loss: 0.1520 - val_auc: 0.9845 - val_accuracy: 0.9469 - val_cost: 6.7308\n",
            "Epoch 20/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1403 - auc: 0.9866 - accuracy: 0.9514 - cost: 6.1852 - val_loss: 0.1502 - val_auc: 0.9849 - val_accuracy: 0.9454 - val_cost: 6.8134\n",
            "Epoch 21/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1382 - auc: 0.9870 - accuracy: 0.9521 - cost: 6.0750 - val_loss: 0.1475 - val_auc: 0.9853 - val_accuracy: 0.9484 - val_cost: 6.4528\n",
            "Epoch 22/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1352 - auc: 0.9874 - accuracy: 0.9533 - cost: 5.9220 - val_loss: 0.1464 - val_auc: 0.9855 - val_accuracy: 0.9496 - val_cost: 6.5242\n",
            "Epoch 23/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1333 - auc: 0.9877 - accuracy: 0.9533 - cost: 5.9225 - val_loss: 0.1442 - val_auc: 0.9857 - val_accuracy: 0.9502 - val_cost: 6.3063\n",
            "Epoch 24/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1315 - auc: 0.9880 - accuracy: 0.9551 - cost: 5.7146 - val_loss: 0.1436 - val_auc: 0.9856 - val_accuracy: 0.9513 - val_cost: 6.1899\n",
            "Epoch 25/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1296 - auc: 0.9882 - accuracy: 0.9557 - cost: 5.6178 - val_loss: 0.1427 - val_auc: 0.9859 - val_accuracy: 0.9506 - val_cost: 6.2500\n",
            "Epoch 26/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1277 - auc: 0.9885 - accuracy: 0.9559 - cost: 5.6144 - val_loss: 0.1424 - val_auc: 0.9861 - val_accuracy: 0.9530 - val_cost: 5.8105\n",
            "Epoch 27/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1263 - auc: 0.9887 - accuracy: 0.9571 - cost: 5.4549 - val_loss: 0.1412 - val_auc: 0.9860 - val_accuracy: 0.9522 - val_cost: 6.1711\n",
            "Epoch 28/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1238 - auc: 0.9890 - accuracy: 0.9580 - cost: 5.3283 - val_loss: 0.1378 - val_auc: 0.9869 - val_accuracy: 0.9548 - val_cost: 5.5889\n",
            "Epoch 29/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1230 - auc: 0.9892 - accuracy: 0.9583 - cost: 5.3020 - val_loss: 0.1365 - val_auc: 0.9870 - val_accuracy: 0.9545 - val_cost: 5.8030\n",
            "Epoch 30/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1199 - auc: 0.9897 - accuracy: 0.9598 - cost: 5.1136 - val_loss: 0.1362 - val_auc: 0.9870 - val_accuracy: 0.9553 - val_cost: 5.5364\n",
            "Epoch 31/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1188 - auc: 0.9897 - accuracy: 0.9601 - cost: 5.0699 - val_loss: 0.1339 - val_auc: 0.9872 - val_accuracy: 0.9560 - val_cost: 5.6603\n",
            "Epoch 32/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1177 - auc: 0.9900 - accuracy: 0.9611 - cost: 4.9394 - val_loss: 0.1329 - val_auc: 0.9873 - val_accuracy: 0.9570 - val_cost: 5.3861\n",
            "Epoch 33/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1161 - auc: 0.9902 - accuracy: 0.9618 - cost: 4.8642 - val_loss: 0.1312 - val_auc: 0.9876 - val_accuracy: 0.9580 - val_cost: 5.3110\n",
            "Epoch 34/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1143 - auc: 0.9904 - accuracy: 0.9618 - cost: 4.8582 - val_loss: 0.1310 - val_auc: 0.9875 - val_accuracy: 0.9579 - val_cost: 5.5101\n",
            "Epoch 35/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1134 - auc: 0.9905 - accuracy: 0.9627 - cost: 4.7458 - val_loss: 0.1325 - val_auc: 0.9874 - val_accuracy: 0.9578 - val_cost: 5.1946\n",
            "Epoch 36/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1123 - auc: 0.9906 - accuracy: 0.9629 - cost: 4.7234 - val_loss: 0.1294 - val_auc: 0.9878 - val_accuracy: 0.9601 - val_cost: 4.9955\n",
            "Epoch 37/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1105 - auc: 0.9908 - accuracy: 0.9638 - cost: 4.5976 - val_loss: 0.1285 - val_auc: 0.9880 - val_accuracy: 0.9588 - val_cost: 5.1082\n",
            "Epoch 38/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1095 - auc: 0.9910 - accuracy: 0.9643 - cost: 4.5484 - val_loss: 0.1299 - val_auc: 0.9879 - val_accuracy: 0.9588 - val_cost: 5.0406\n",
            "Epoch 39/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1087 - auc: 0.9910 - accuracy: 0.9642 - cost: 4.5484 - val_loss: 0.1277 - val_auc: 0.9878 - val_accuracy: 0.9602 - val_cost: 4.8828\n",
            "Epoch 40/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1066 - auc: 0.9914 - accuracy: 0.9656 - cost: 4.4019 - val_loss: 0.1266 - val_auc: 0.9879 - val_accuracy: 0.9605 - val_cost: 4.8415\n",
            "Epoch 41/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1047 - auc: 0.9916 - accuracy: 0.9661 - cost: 4.3012 - val_loss: 0.1240 - val_auc: 0.9881 - val_accuracy: 0.9618 - val_cost: 4.9166\n",
            "Epoch 42/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1056 - auc: 0.9914 - accuracy: 0.9661 - cost: 4.3340 - val_loss: 0.1231 - val_auc: 0.9885 - val_accuracy: 0.9608 - val_cost: 4.8715\n",
            "Epoch 43/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1035 - auc: 0.9918 - accuracy: 0.9670 - cost: 4.2057 - val_loss: 0.1229 - val_auc: 0.9887 - val_accuracy: 0.9620 - val_cost: 4.7852\n",
            "Epoch 44/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1030 - auc: 0.9917 - accuracy: 0.9667 - cost: 4.2316 - val_loss: 0.1222 - val_auc: 0.9887 - val_accuracy: 0.9634 - val_cost: 4.6161\n",
            "Epoch 45/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1025 - auc: 0.9918 - accuracy: 0.9672 - cost: 4.1629 - val_loss: 0.1210 - val_auc: 0.9886 - val_accuracy: 0.9629 - val_cost: 4.7288\n",
            "Epoch 46/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1000 - auc: 0.9921 - accuracy: 0.9680 - cost: 4.0765 - val_loss: 0.1208 - val_auc: 0.9884 - val_accuracy: 0.9634 - val_cost: 4.6349\n",
            "Epoch 47/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0997 - auc: 0.9921 - accuracy: 0.9682 - cost: 4.0510 - val_loss: 0.1193 - val_auc: 0.9889 - val_accuracy: 0.9645 - val_cost: 4.5297\n",
            "Epoch 48/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0989 - auc: 0.9921 - accuracy: 0.9684 - cost: 4.0363 - val_loss: 0.1192 - val_auc: 0.9889 - val_accuracy: 0.9645 - val_cost: 4.5072\n",
            "Epoch 49/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0979 - auc: 0.9922 - accuracy: 0.9689 - cost: 3.9611 - val_loss: 0.1193 - val_auc: 0.9887 - val_accuracy: 0.9641 - val_cost: 4.5898\n",
            "Epoch 50/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0975 - auc: 0.9923 - accuracy: 0.9694 - cost: 3.8881 - val_loss: 0.1200 - val_auc: 0.9886 - val_accuracy: 0.9645 - val_cost: 4.5222\n",
            "Epoch 51/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0963 - auc: 0.9924 - accuracy: 0.9697 - cost: 3.8527 - val_loss: 0.1178 - val_auc: 0.9885 - val_accuracy: 0.9659 - val_cost: 4.4058\n",
            "Epoch 52/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0964 - auc: 0.9924 - accuracy: 0.9694 - cost: 3.8894 - val_loss: 0.1178 - val_auc: 0.9890 - val_accuracy: 0.9648 - val_cost: 4.5147\n",
            "Epoch 53/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0947 - auc: 0.9926 - accuracy: 0.9704 - cost: 3.7693 - val_loss: 0.1193 - val_auc: 0.9884 - val_accuracy: 0.9647 - val_cost: 4.5410\n",
            "Epoch 54/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0938 - auc: 0.9928 - accuracy: 0.9706 - cost: 3.7373 - val_loss: 0.1183 - val_auc: 0.9890 - val_accuracy: 0.9641 - val_cost: 4.5560\n",
            "Epoch 55/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0929 - auc: 0.9929 - accuracy: 0.9709 - cost: 3.7118 - val_loss: 0.1158 - val_auc: 0.9892 - val_accuracy: 0.9659 - val_cost: 4.4020\n",
            "Epoch 56/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0931 - auc: 0.9928 - accuracy: 0.9709 - cost: 3.6932 - val_loss: 0.1164 - val_auc: 0.9891 - val_accuracy: 0.9662 - val_cost: 4.2368\n",
            "Epoch 57/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0922 - auc: 0.9929 - accuracy: 0.9714 - cost: 3.6457 - val_loss: 0.1145 - val_auc: 0.9893 - val_accuracy: 0.9664 - val_cost: 4.2931\n",
            "Epoch 58/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0917 - auc: 0.9929 - accuracy: 0.9714 - cost: 3.6345 - val_loss: 0.1143 - val_auc: 0.9893 - val_accuracy: 0.9673 - val_cost: 4.1316\n",
            "Epoch 59/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0907 - auc: 0.9931 - accuracy: 0.9718 - cost: 3.6081 - val_loss: 0.1159 - val_auc: 0.9892 - val_accuracy: 0.9669 - val_cost: 4.1692\n",
            "Epoch 60/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0904 - auc: 0.9931 - accuracy: 0.9719 - cost: 3.5731 - val_loss: 0.1145 - val_auc: 0.9894 - val_accuracy: 0.9660 - val_cost: 4.2668\n",
            "Epoch 61/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0901 - auc: 0.9932 - accuracy: 0.9721 - cost: 3.5632 - val_loss: 0.1138 - val_auc: 0.9893 - val_accuracy: 0.9666 - val_cost: 4.2894\n",
            "Epoch 62/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0884 - auc: 0.9932 - accuracy: 0.9724 - cost: 3.5199 - val_loss: 0.1165 - val_auc: 0.9891 - val_accuracy: 0.9666 - val_cost: 4.1579\n",
            "Epoch 63/1000\n",
            "113/113 [==============================] - 1s 4ms/step - loss: 0.0888 - auc: 0.9933 - accuracy: 0.9721 - cost: 3.5541 - val_loss: 0.1147 - val_auc: 0.9894 - val_accuracy: 0.9659 - val_cost: 4.3307\n",
            "Epoch 64/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0886 - auc: 0.9932 - accuracy: 0.9725 - cost: 3.5044 - val_loss: 0.1147 - val_auc: 0.9893 - val_accuracy: 0.9670 - val_cost: 4.0903\n",
            "Epoch 65/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0876 - auc: 0.9933 - accuracy: 0.9736 - cost: 3.3761 - val_loss: 0.1142 - val_auc: 0.9892 - val_accuracy: 0.9672 - val_cost: 4.1955\n",
            "Epoch 66/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0868 - auc: 0.9935 - accuracy: 0.9732 - cost: 3.4098 - val_loss: 0.1128 - val_auc: 0.9894 - val_accuracy: 0.9669 - val_cost: 4.1955\n",
            "Epoch 67/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0868 - auc: 0.9934 - accuracy: 0.9734 - cost: 3.3972 - val_loss: 0.1133 - val_auc: 0.9897 - val_accuracy: 0.9670 - val_cost: 4.2368\n",
            "Epoch 68/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0859 - auc: 0.9936 - accuracy: 0.9734 - cost: 3.3877 - val_loss: 0.1138 - val_auc: 0.9895 - val_accuracy: 0.9666 - val_cost: 4.1955\n",
            "Epoch 69/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0855 - auc: 0.9935 - accuracy: 0.9737 - cost: 3.3557 - val_loss: 0.1133 - val_auc: 0.9898 - val_accuracy: 0.9671 - val_cost: 4.1504\n",
            "Epoch 70/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0852 - auc: 0.9936 - accuracy: 0.9735 - cost: 3.3722 - val_loss: 0.1125 - val_auc: 0.9898 - val_accuracy: 0.9677 - val_cost: 4.0565\n",
            "Epoch 71/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0843 - auc: 0.9936 - accuracy: 0.9739 - cost: 3.3411 - val_loss: 0.1148 - val_auc: 0.9893 - val_accuracy: 0.9673 - val_cost: 4.1466\n",
            "Epoch 72/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0844 - auc: 0.9937 - accuracy: 0.9743 - cost: 3.2702 - val_loss: 0.1137 - val_auc: 0.9894 - val_accuracy: 0.9673 - val_cost: 4.2631\n",
            "Epoch 73/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0835 - auc: 0.9937 - accuracy: 0.9740 - cost: 3.3104 - val_loss: 0.1142 - val_auc: 0.9897 - val_accuracy: 0.9673 - val_cost: 4.0753\n",
            "Epoch 74/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0836 - auc: 0.9937 - accuracy: 0.9745 - cost: 3.2637 - val_loss: 0.1156 - val_auc: 0.9896 - val_accuracy: 0.9659 - val_cost: 4.2067\n",
            "Epoch 75/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0831 - auc: 0.9937 - accuracy: 0.9748 - cost: 3.2097 - val_loss: 0.1123 - val_auc: 0.9896 - val_accuracy: 0.9683 - val_cost: 4.0227\n",
            "Epoch 76/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0831 - auc: 0.9938 - accuracy: 0.9744 - cost: 3.2749 - val_loss: 0.1117 - val_auc: 0.9897 - val_accuracy: 0.9684 - val_cost: 4.0377\n",
            "Epoch 77/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0818 - auc: 0.9940 - accuracy: 0.9748 - cost: 3.2222 - val_loss: 0.1125 - val_auc: 0.9896 - val_accuracy: 0.9670 - val_cost: 4.1880\n",
            "Epoch 78/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0820 - auc: 0.9939 - accuracy: 0.9746 - cost: 3.2369 - val_loss: 0.1139 - val_auc: 0.9896 - val_accuracy: 0.9675 - val_cost: 4.0340\n",
            "Epoch 79/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0813 - auc: 0.9941 - accuracy: 0.9746 - cost: 3.2378 - val_loss: 0.1105 - val_auc: 0.9900 - val_accuracy: 0.9691 - val_cost: 3.9663\n",
            "Epoch 80/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0811 - auc: 0.9941 - accuracy: 0.9754 - cost: 3.1514 - val_loss: 0.1121 - val_auc: 0.9897 - val_accuracy: 0.9684 - val_cost: 4.0002\n",
            "Epoch 81/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0814 - auc: 0.9940 - accuracy: 0.9752 - cost: 3.1652 - val_loss: 0.1133 - val_auc: 0.9896 - val_accuracy: 0.9677 - val_cost: 4.0340\n",
            "Epoch 82/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0808 - auc: 0.9940 - accuracy: 0.9751 - cost: 3.1846 - val_loss: 0.1108 - val_auc: 0.9899 - val_accuracy: 0.9687 - val_cost: 3.9476\n",
            "Epoch 83/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0808 - auc: 0.9940 - accuracy: 0.9752 - cost: 3.1578 - val_loss: 0.1134 - val_auc: 0.9896 - val_accuracy: 0.9683 - val_cost: 3.9926\n",
            "Epoch 84/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0797 - auc: 0.9942 - accuracy: 0.9754 - cost: 3.1406 - val_loss: 0.1117 - val_auc: 0.9898 - val_accuracy: 0.9691 - val_cost: 3.9062\n",
            "Epoch 85/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0795 - auc: 0.9942 - accuracy: 0.9756 - cost: 3.1233 - val_loss: 0.1114 - val_auc: 0.9899 - val_accuracy: 0.9683 - val_cost: 3.9964\n",
            "Epoch 86/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0789 - auc: 0.9942 - accuracy: 0.9756 - cost: 3.1081 - val_loss: 0.1122 - val_auc: 0.9898 - val_accuracy: 0.9677 - val_cost: 4.0527\n",
            "Epoch 87/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0793 - auc: 0.9943 - accuracy: 0.9756 - cost: 3.1146 - val_loss: 0.1125 - val_auc: 0.9901 - val_accuracy: 0.9680 - val_cost: 3.9626\n",
            "Epoch 88/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0782 - auc: 0.9944 - accuracy: 0.9761 - cost: 3.0399 - val_loss: 0.1137 - val_auc: 0.9896 - val_accuracy: 0.9684 - val_cost: 4.0828\n",
            "Epoch 89/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0784 - auc: 0.9943 - accuracy: 0.9763 - cost: 3.0191 - val_loss: 0.1113 - val_auc: 0.9900 - val_accuracy: 0.9683 - val_cost: 4.1203\n",
            "Epoch 90/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0784 - auc: 0.9944 - accuracy: 0.9763 - cost: 3.0265 - val_loss: 0.1101 - val_auc: 0.9901 - val_accuracy: 0.9695 - val_cost: 3.8612\n",
            "Epoch 91/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0779 - auc: 0.9944 - accuracy: 0.9762 - cost: 3.0334 - val_loss: 0.1115 - val_auc: 0.9896 - val_accuracy: 0.9693 - val_cost: 3.9062\n",
            "Epoch 92/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0773 - auc: 0.9945 - accuracy: 0.9765 - cost: 2.9997 - val_loss: 0.1122 - val_auc: 0.9899 - val_accuracy: 0.9680 - val_cost: 3.9325\n",
            "Epoch 93/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0762 - auc: 0.9945 - accuracy: 0.9770 - cost: 2.9375 - val_loss: 0.1108 - val_auc: 0.9899 - val_accuracy: 0.9696 - val_cost: 3.8687\n",
            "Epoch 94/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0774 - auc: 0.9945 - accuracy: 0.9762 - cost: 3.0217 - val_loss: 0.1108 - val_auc: 0.9898 - val_accuracy: 0.9695 - val_cost: 3.8574\n",
            "Epoch 95/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0764 - auc: 0.9945 - accuracy: 0.9765 - cost: 3.0187 - val_loss: 0.1121 - val_auc: 0.9899 - val_accuracy: 0.9683 - val_cost: 3.9476\n",
            "Epoch 96/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0764 - auc: 0.9945 - accuracy: 0.9765 - cost: 2.9846 - val_loss: 0.1111 - val_auc: 0.9898 - val_accuracy: 0.9688 - val_cost: 3.9701\n",
            "Epoch 97/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0757 - auc: 0.9947 - accuracy: 0.9773 - cost: 2.9081 - val_loss: 0.1126 - val_auc: 0.9900 - val_accuracy: 0.9682 - val_cost: 3.9438\n",
            "Epoch 98/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0760 - auc: 0.9945 - accuracy: 0.9770 - cost: 2.9517 - val_loss: 0.1112 - val_auc: 0.9899 - val_accuracy: 0.9691 - val_cost: 3.8687\n",
            "Epoch 99/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0757 - auc: 0.9946 - accuracy: 0.9774 - cost: 2.8791 - val_loss: 0.1116 - val_auc: 0.9898 - val_accuracy: 0.9680 - val_cost: 3.9926\n",
            "Epoch 100/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0752 - auc: 0.9946 - accuracy: 0.9770 - cost: 2.9504 - val_loss: 0.1112 - val_auc: 0.9903 - val_accuracy: 0.9681 - val_cost: 3.9476\n",
            "Epoch 101/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0750 - auc: 0.9947 - accuracy: 0.9775 - cost: 2.8796 - val_loss: 0.1113 - val_auc: 0.9898 - val_accuracy: 0.9688 - val_cost: 3.9476\n",
            "Epoch 102/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0744 - auc: 0.9948 - accuracy: 0.9774 - cost: 2.8921 - val_loss: 0.1111 - val_auc: 0.9899 - val_accuracy: 0.9684 - val_cost: 3.9663\n",
            "Epoch 103/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0747 - auc: 0.9947 - accuracy: 0.9770 - cost: 2.9236 - val_loss: 0.1120 - val_auc: 0.9898 - val_accuracy: 0.9688 - val_cost: 3.8800\n",
            "Epoch 104/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0751 - auc: 0.9947 - accuracy: 0.9771 - cost: 2.9496 - val_loss: 0.1130 - val_auc: 0.9898 - val_accuracy: 0.9684 - val_cost: 3.9814\n",
            "Epoch 105/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0738 - auc: 0.9948 - accuracy: 0.9778 - cost: 2.8325 - val_loss: 0.1114 - val_auc: 0.9900 - val_accuracy: 0.9688 - val_cost: 4.0077\n",
            "Epoch 106/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0755 - auc: 0.9946 - accuracy: 0.9776 - cost: 2.8653 - val_loss: 0.1090 - val_auc: 0.9902 - val_accuracy: 0.9692 - val_cost: 3.9025\n",
            "Epoch 107/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0743 - auc: 0.9947 - accuracy: 0.9774 - cost: 2.8791 - val_loss: 0.1128 - val_auc: 0.9900 - val_accuracy: 0.9680 - val_cost: 3.9851\n",
            "Epoch 108/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0733 - auc: 0.9948 - accuracy: 0.9780 - cost: 2.8182 - val_loss: 0.1114 - val_auc: 0.9902 - val_accuracy: 0.9688 - val_cost: 3.9476\n",
            "Epoch 109/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0735 - auc: 0.9949 - accuracy: 0.9778 - cost: 2.8549 - val_loss: 0.1146 - val_auc: 0.9898 - val_accuracy: 0.9677 - val_cost: 3.9889\n",
            "Epoch 110/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0733 - auc: 0.9949 - accuracy: 0.9782 - cost: 2.7832 - val_loss: 0.1098 - val_auc: 0.9902 - val_accuracy: 0.9693 - val_cost: 3.9062\n",
            "Epoch 111/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0728 - auc: 0.9950 - accuracy: 0.9781 - cost: 2.7832 - val_loss: 0.1096 - val_auc: 0.9904 - val_accuracy: 0.9698 - val_cost: 3.8123\n",
            "Epoch 112/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0727 - auc: 0.9949 - accuracy: 0.9779 - cost: 2.8351 - val_loss: 0.1119 - val_auc: 0.9897 - val_accuracy: 0.9688 - val_cost: 3.9588\n",
            "Epoch 113/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0727 - auc: 0.9950 - accuracy: 0.9780 - cost: 2.8044 - val_loss: 0.1126 - val_auc: 0.9899 - val_accuracy: 0.9691 - val_cost: 3.8499\n",
            "Epoch 114/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0724 - auc: 0.9950 - accuracy: 0.9778 - cost: 2.8459 - val_loss: 0.1133 - val_auc: 0.9897 - val_accuracy: 0.9691 - val_cost: 3.8462\n",
            "Epoch 115/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0723 - auc: 0.9949 - accuracy: 0.9784 - cost: 2.7573 - val_loss: 0.1104 - val_auc: 0.9902 - val_accuracy: 0.9695 - val_cost: 3.8274\n",
            "Epoch 116/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0718 - auc: 0.9950 - accuracy: 0.9784 - cost: 2.7607 - val_loss: 0.1100 - val_auc: 0.9901 - val_accuracy: 0.9698 - val_cost: 3.8462\n",
            "Epoch 117/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0727 - auc: 0.9949 - accuracy: 0.9778 - cost: 2.8588 - val_loss: 0.1099 - val_auc: 0.9899 - val_accuracy: 0.9686 - val_cost: 3.9588\n",
            "Epoch 118/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0719 - auc: 0.9951 - accuracy: 0.9781 - cost: 2.7918 - val_loss: 0.1104 - val_auc: 0.9900 - val_accuracy: 0.9697 - val_cost: 3.8048\n",
            "Epoch 119/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0710 - auc: 0.9951 - accuracy: 0.9785 - cost: 2.7651 - val_loss: 0.1116 - val_auc: 0.9899 - val_accuracy: 0.9695 - val_cost: 3.7785\n",
            "Epoch 120/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0707 - auc: 0.9952 - accuracy: 0.9788 - cost: 2.7197 - val_loss: 0.1115 - val_auc: 0.9900 - val_accuracy: 0.9681 - val_cost: 3.9325\n",
            "Epoch 121/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0714 - auc: 0.9951 - accuracy: 0.9783 - cost: 2.7854 - val_loss: 0.1109 - val_auc: 0.9900 - val_accuracy: 0.9693 - val_cost: 3.8574\n",
            "Epoch 122/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0698 - auc: 0.9952 - accuracy: 0.9790 - cost: 2.6899 - val_loss: 0.1111 - val_auc: 0.9901 - val_accuracy: 0.9693 - val_cost: 3.9551\n",
            "Epoch 123/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0708 - auc: 0.9951 - accuracy: 0.9787 - cost: 2.7236 - val_loss: 0.1118 - val_auc: 0.9899 - val_accuracy: 0.9680 - val_cost: 4.0002\n",
            "Epoch 124/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0707 - auc: 0.9951 - accuracy: 0.9788 - cost: 2.7184 - val_loss: 0.1134 - val_auc: 0.9898 - val_accuracy: 0.9687 - val_cost: 3.8386\n",
            "Epoch 125/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0707 - auc: 0.9952 - accuracy: 0.9787 - cost: 2.7244 - val_loss: 0.1099 - val_auc: 0.9901 - val_accuracy: 0.9705 - val_cost: 3.6546\n",
            "Epoch 126/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0702 - auc: 0.9952 - accuracy: 0.9788 - cost: 2.7305 - val_loss: 0.1117 - val_auc: 0.9902 - val_accuracy: 0.9690 - val_cost: 3.8462\n",
            "Epoch 127/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0698 - auc: 0.9953 - accuracy: 0.9790 - cost: 2.7037 - val_loss: 0.1108 - val_auc: 0.9900 - val_accuracy: 0.9693 - val_cost: 3.9401\n",
            "Epoch 128/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0700 - auc: 0.9953 - accuracy: 0.9790 - cost: 2.6860 - val_loss: 0.1133 - val_auc: 0.9901 - val_accuracy: 0.9695 - val_cost: 3.7748\n",
            "Epoch 129/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0695 - auc: 0.9952 - accuracy: 0.9789 - cost: 2.6881 - val_loss: 0.1096 - val_auc: 0.9901 - val_accuracy: 0.9694 - val_cost: 3.8499\n",
            "Epoch 130/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0698 - auc: 0.9952 - accuracy: 0.9789 - cost: 2.7072 - val_loss: 0.1136 - val_auc: 0.9898 - val_accuracy: 0.9700 - val_cost: 3.7184\n",
            "Epoch 131/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0695 - auc: 0.9953 - accuracy: 0.9791 - cost: 2.6795 - val_loss: 0.1112 - val_auc: 0.9898 - val_accuracy: 0.9677 - val_cost: 4.0302\n",
            "Epoch 132/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0691 - auc: 0.9955 - accuracy: 0.9792 - cost: 2.6678 - val_loss: 0.1124 - val_auc: 0.9899 - val_accuracy: 0.9683 - val_cost: 4.0077\n",
            "Epoch 133/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0684 - auc: 0.9955 - accuracy: 0.9793 - cost: 2.6384 - val_loss: 0.1124 - val_auc: 0.9900 - val_accuracy: 0.9695 - val_cost: 3.8649\n",
            "Epoch 134/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0696 - auc: 0.9951 - accuracy: 0.9792 - cost: 2.6691 - val_loss: 0.1116 - val_auc: 0.9902 - val_accuracy: 0.9687 - val_cost: 4.0565\n",
            "Epoch 135/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0687 - auc: 0.9954 - accuracy: 0.9793 - cost: 2.6687 - val_loss: 0.1104 - val_auc: 0.9900 - val_accuracy: 0.9687 - val_cost: 3.9776\n",
            "Epoch 136/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0687 - auc: 0.9953 - accuracy: 0.9797 - cost: 2.6078 - val_loss: 0.1110 - val_auc: 0.9902 - val_accuracy: 0.9690 - val_cost: 3.8875\n",
            "Epoch 137/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0677 - auc: 0.9956 - accuracy: 0.9794 - cost: 2.6333 - val_loss: 0.1100 - val_auc: 0.9900 - val_accuracy: 0.9695 - val_cost: 3.8236\n",
            "Epoch 138/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0680 - auc: 0.9954 - accuracy: 0.9794 - cost: 2.6445 - val_loss: 0.1106 - val_auc: 0.9902 - val_accuracy: 0.9691 - val_cost: 4.0039\n",
            "Epoch 139/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0681 - auc: 0.9954 - accuracy: 0.9796 - cost: 2.6298 - val_loss: 0.1126 - val_auc: 0.9901 - val_accuracy: 0.9687 - val_cost: 3.9513\n",
            "Epoch 140/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0689 - auc: 0.9954 - accuracy: 0.9795 - cost: 2.6229 - val_loss: 0.1128 - val_auc: 0.9902 - val_accuracy: 0.9691 - val_cost: 3.8386\n",
            "Epoch 141/1000\n",
            "113/113 [==============================] - 1s 4ms/step - loss: 0.0676 - auc: 0.9955 - accuracy: 0.9794 - cost: 2.6302 - val_loss: 0.1133 - val_auc: 0.9899 - val_accuracy: 0.9692 - val_cost: 3.9025\n",
            "Epoch 142/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0676 - auc: 0.9954 - accuracy: 0.9800 - cost: 2.5598 - val_loss: 0.1115 - val_auc: 0.9902 - val_accuracy: 0.9687 - val_cost: 3.9701\n",
            "Epoch 143/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0681 - auc: 0.9955 - accuracy: 0.9795 - cost: 2.6203 - val_loss: 0.1114 - val_auc: 0.9902 - val_accuracy: 0.9695 - val_cost: 3.8537\n",
            "Epoch 144/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0671 - auc: 0.9956 - accuracy: 0.9799 - cost: 2.5659 - val_loss: 0.1127 - val_auc: 0.9901 - val_accuracy: 0.9690 - val_cost: 3.8875\n",
            "Epoch 145/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0672 - auc: 0.9956 - accuracy: 0.9801 - cost: 2.5559 - val_loss: 0.1131 - val_auc: 0.9901 - val_accuracy: 0.9689 - val_cost: 3.8311\n",
            "Epoch 146/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0673 - auc: 0.9955 - accuracy: 0.9798 - cost: 2.5875 - val_loss: 0.1117 - val_auc: 0.9902 - val_accuracy: 0.9694 - val_cost: 3.9062\n",
            "Epoch 147/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0667 - auc: 0.9956 - accuracy: 0.9799 - cost: 2.5689 - val_loss: 0.1141 - val_auc: 0.9904 - val_accuracy: 0.9683 - val_cost: 3.9363\n",
            "Epoch 148/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0670 - auc: 0.9955 - accuracy: 0.9800 - cost: 2.5607 - val_loss: 0.1119 - val_auc: 0.9902 - val_accuracy: 0.9696 - val_cost: 3.8837\n",
            "Epoch 149/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0667 - auc: 0.9957 - accuracy: 0.9794 - cost: 2.6393 - val_loss: 0.1142 - val_auc: 0.9897 - val_accuracy: 0.9698 - val_cost: 3.8311\n",
            "Epoch 150/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0667 - auc: 0.9956 - accuracy: 0.9801 - cost: 2.5563 - val_loss: 0.1130 - val_auc: 0.9902 - val_accuracy: 0.9706 - val_cost: 3.6621\n",
            "Epoch 151/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0656 - auc: 0.9957 - accuracy: 0.9801 - cost: 2.5494 - val_loss: 0.1117 - val_auc: 0.9902 - val_accuracy: 0.9690 - val_cost: 3.8950\n",
            "Epoch 152/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0655 - auc: 0.9957 - accuracy: 0.9801 - cost: 2.5563 - val_loss: 0.1141 - val_auc: 0.9901 - val_accuracy: 0.9687 - val_cost: 3.9814\n",
            "Epoch 153/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0655 - auc: 0.9957 - accuracy: 0.9804 - cost: 2.5296 - val_loss: 0.1118 - val_auc: 0.9902 - val_accuracy: 0.9700 - val_cost: 3.7785\n",
            "Epoch 154/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0665 - auc: 0.9955 - accuracy: 0.9801 - cost: 2.5430 - val_loss: 0.1121 - val_auc: 0.9903 - val_accuracy: 0.9695 - val_cost: 3.7823\n",
            "Epoch 155/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0652 - auc: 0.9958 - accuracy: 0.9805 - cost: 2.5162 - val_loss: 0.1138 - val_auc: 0.9902 - val_accuracy: 0.9691 - val_cost: 3.7861\n",
            "Epoch 156/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0654 - auc: 0.9957 - accuracy: 0.9805 - cost: 2.4950 - val_loss: 0.1148 - val_auc: 0.9898 - val_accuracy: 0.9691 - val_cost: 3.8349\n",
            "Epoch 157/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0645 - auc: 0.9958 - accuracy: 0.9809 - cost: 2.4535 - val_loss: 0.1137 - val_auc: 0.9901 - val_accuracy: 0.9694 - val_cost: 3.8987\n",
            "Epoch 158/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0660 - auc: 0.9956 - accuracy: 0.9801 - cost: 2.5442 - val_loss: 0.1119 - val_auc: 0.9903 - val_accuracy: 0.9698 - val_cost: 3.7447\n",
            "Epoch 159/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0649 - auc: 0.9958 - accuracy: 0.9802 - cost: 2.5430 - val_loss: 0.1132 - val_auc: 0.9902 - val_accuracy: 0.9705 - val_cost: 3.6584\n",
            "Epoch 160/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0651 - auc: 0.9957 - accuracy: 0.9806 - cost: 2.4807 - val_loss: 0.1135 - val_auc: 0.9900 - val_accuracy: 0.9698 - val_cost: 3.8386\n",
            "Epoch 161/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0655 - auc: 0.9957 - accuracy: 0.9804 - cost: 2.5062 - val_loss: 0.1152 - val_auc: 0.9899 - val_accuracy: 0.9702 - val_cost: 3.7410\n",
            "Epoch 162/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0647 - auc: 0.9958 - accuracy: 0.9805 - cost: 2.4959 - val_loss: 0.1149 - val_auc: 0.9897 - val_accuracy: 0.9695 - val_cost: 3.7523\n",
            "Epoch 163/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0645 - auc: 0.9958 - accuracy: 0.9809 - cost: 2.4488 - val_loss: 0.1139 - val_auc: 0.9901 - val_accuracy: 0.9701 - val_cost: 3.7372\n",
            "Epoch 164/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0646 - auc: 0.9958 - accuracy: 0.9805 - cost: 2.4876 - val_loss: 0.1131 - val_auc: 0.9902 - val_accuracy: 0.9695 - val_cost: 3.8762\n",
            "Epoch 165/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0636 - auc: 0.9959 - accuracy: 0.9802 - cost: 2.5330 - val_loss: 0.1126 - val_auc: 0.9901 - val_accuracy: 0.9705 - val_cost: 3.7034\n",
            "Epoch 166/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0637 - auc: 0.9959 - accuracy: 0.9812 - cost: 2.4060 - val_loss: 0.1177 - val_auc: 0.9894 - val_accuracy: 0.9702 - val_cost: 3.6208\n",
            "Epoch 167/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0638 - auc: 0.9959 - accuracy: 0.9807 - cost: 2.4652 - val_loss: 0.1125 - val_auc: 0.9902 - val_accuracy: 0.9699 - val_cost: 3.7598\n",
            "Epoch 168/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0638 - auc: 0.9959 - accuracy: 0.9807 - cost: 2.4803 - val_loss: 0.1160 - val_auc: 0.9898 - val_accuracy: 0.9688 - val_cost: 3.9062\n",
            "Epoch 169/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0644 - auc: 0.9958 - accuracy: 0.9803 - cost: 2.5097 - val_loss: 0.1124 - val_auc: 0.9902 - val_accuracy: 0.9705 - val_cost: 3.7523\n",
            "Epoch 170/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0639 - auc: 0.9959 - accuracy: 0.9805 - cost: 2.5010 - val_loss: 0.1151 - val_auc: 0.9900 - val_accuracy: 0.9699 - val_cost: 3.6959\n",
            "Epoch 171/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0636 - auc: 0.9959 - accuracy: 0.9808 - cost: 2.4621 - val_loss: 0.1144 - val_auc: 0.9898 - val_accuracy: 0.9691 - val_cost: 3.9401\n",
            "Epoch 172/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0630 - auc: 0.9960 - accuracy: 0.9810 - cost: 2.4289 - val_loss: 0.1151 - val_auc: 0.9898 - val_accuracy: 0.9696 - val_cost: 3.9250\n",
            "Epoch 173/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0642 - auc: 0.9959 - accuracy: 0.9807 - cost: 2.4751 - val_loss: 0.1174 - val_auc: 0.9895 - val_accuracy: 0.9689 - val_cost: 3.7335\n",
            "Epoch 174/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0631 - auc: 0.9960 - accuracy: 0.9813 - cost: 2.3887 - val_loss: 0.1169 - val_auc: 0.9896 - val_accuracy: 0.9689 - val_cost: 3.8161\n",
            "Epoch 175/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0637 - auc: 0.9960 - accuracy: 0.9809 - cost: 2.4475 - val_loss: 0.1141 - val_auc: 0.9898 - val_accuracy: 0.9697 - val_cost: 3.7673\n",
            "Epoch 176/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0631 - auc: 0.9959 - accuracy: 0.9810 - cost: 2.4323 - val_loss: 0.1172 - val_auc: 0.9898 - val_accuracy: 0.9693 - val_cost: 3.7410\n",
            "Epoch 177/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0632 - auc: 0.9959 - accuracy: 0.9811 - cost: 2.4181 - val_loss: 0.1148 - val_auc: 0.9897 - val_accuracy: 0.9688 - val_cost: 3.9438\n",
            "Epoch 178/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0634 - auc: 0.9960 - accuracy: 0.9807 - cost: 2.4881 - val_loss: 0.1164 - val_auc: 0.9896 - val_accuracy: 0.9700 - val_cost: 3.7297\n",
            "Epoch 179/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0632 - auc: 0.9959 - accuracy: 0.9809 - cost: 2.4539 - val_loss: 0.1163 - val_auc: 0.9894 - val_accuracy: 0.9685 - val_cost: 3.9513\n",
            "Epoch 180/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0626 - auc: 0.9961 - accuracy: 0.9812 - cost: 2.4146 - val_loss: 0.1174 - val_auc: 0.9895 - val_accuracy: 0.9684 - val_cost: 3.9138\n",
            "Epoch 181/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0628 - auc: 0.9960 - accuracy: 0.9815 - cost: 2.3740 - val_loss: 0.1149 - val_auc: 0.9898 - val_accuracy: 0.9699 - val_cost: 3.7184\n",
            "Epoch 182/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0627 - auc: 0.9960 - accuracy: 0.9811 - cost: 2.4185 - val_loss: 0.1155 - val_auc: 0.9898 - val_accuracy: 0.9699 - val_cost: 3.6959\n",
            "Epoch 183/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0624 - auc: 0.9960 - accuracy: 0.9814 - cost: 2.3960 - val_loss: 0.1183 - val_auc: 0.9900 - val_accuracy: 0.9695 - val_cost: 3.7898\n",
            "Epoch 184/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0621 - auc: 0.9959 - accuracy: 0.9808 - cost: 2.4522 - val_loss: 0.1157 - val_auc: 0.9899 - val_accuracy: 0.9695 - val_cost: 3.7447\n",
            "Epoch 185/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0629 - auc: 0.9961 - accuracy: 0.9807 - cost: 2.4738 - val_loss: 0.1137 - val_auc: 0.9898 - val_accuracy: 0.9690 - val_cost: 3.9739\n",
            "Epoch 186/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0619 - auc: 0.9962 - accuracy: 0.9811 - cost: 2.4107 - val_loss: 0.1168 - val_auc: 0.9897 - val_accuracy: 0.9695 - val_cost: 3.7936\n",
            "Epoch 187/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0623 - auc: 0.9960 - accuracy: 0.9811 - cost: 2.4220 - val_loss: 0.1161 - val_auc: 0.9901 - val_accuracy: 0.9689 - val_cost: 3.8950\n",
            "Epoch 188/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0618 - auc: 0.9961 - accuracy: 0.9812 - cost: 2.4081 - val_loss: 0.1196 - val_auc: 0.9893 - val_accuracy: 0.9691 - val_cost: 3.8462\n",
            "Epoch 189/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0619 - auc: 0.9961 - accuracy: 0.9814 - cost: 2.3775 - val_loss: 0.1184 - val_auc: 0.9896 - val_accuracy: 0.9691 - val_cost: 3.8349\n",
            "Epoch 190/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0624 - auc: 0.9960 - accuracy: 0.9812 - cost: 2.4073 - val_loss: 0.1167 - val_auc: 0.9899 - val_accuracy: 0.9686 - val_cost: 3.9250\n",
            "Epoch 191/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0618 - auc: 0.9961 - accuracy: 0.9814 - cost: 2.3818 - val_loss: 0.1168 - val_auc: 0.9895 - val_accuracy: 0.9703 - val_cost: 3.7523\n",
            "Epoch 192/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0620 - auc: 0.9960 - accuracy: 0.9813 - cost: 2.3943 - val_loss: 0.1158 - val_auc: 0.9899 - val_accuracy: 0.9699 - val_cost: 3.7748\n",
            "Epoch 193/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0611 - auc: 0.9962 - accuracy: 0.9817 - cost: 2.3420 - val_loss: 0.1169 - val_auc: 0.9900 - val_accuracy: 0.9689 - val_cost: 3.7260\n",
            "Epoch 194/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0620 - auc: 0.9961 - accuracy: 0.9812 - cost: 2.4181 - val_loss: 0.1158 - val_auc: 0.9897 - val_accuracy: 0.9691 - val_cost: 3.8462\n",
            "Epoch 195/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0612 - auc: 0.9962 - accuracy: 0.9814 - cost: 2.3865 - val_loss: 0.1185 - val_auc: 0.9898 - val_accuracy: 0.9696 - val_cost: 3.6884\n",
            "Epoch 196/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0611 - auc: 0.9962 - accuracy: 0.9814 - cost: 2.3753 - val_loss: 0.1164 - val_auc: 0.9900 - val_accuracy: 0.9695 - val_cost: 3.7222\n",
            "Epoch 197/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0601 - auc: 0.9963 - accuracy: 0.9816 - cost: 2.3628 - val_loss: 0.1162 - val_auc: 0.9898 - val_accuracy: 0.9700 - val_cost: 3.7297\n",
            "Epoch 198/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0606 - auc: 0.9961 - accuracy: 0.9817 - cost: 2.3299 - val_loss: 0.1141 - val_auc: 0.9901 - val_accuracy: 0.9701 - val_cost: 3.6584\n",
            "Epoch 199/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0606 - auc: 0.9963 - accuracy: 0.9817 - cost: 2.3377 - val_loss: 0.1167 - val_auc: 0.9899 - val_accuracy: 0.9691 - val_cost: 3.9250\n",
            "Epoch 200/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0602 - auc: 0.9962 - accuracy: 0.9819 - cost: 2.3200 - val_loss: 0.1181 - val_auc: 0.9901 - val_accuracy: 0.9690 - val_cost: 3.8311\n",
            "Epoch 201/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0612 - auc: 0.9962 - accuracy: 0.9815 - cost: 2.3762 - val_loss: 0.1192 - val_auc: 0.9898 - val_accuracy: 0.9694 - val_cost: 3.7748\n",
            "Epoch 202/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0604 - auc: 0.9963 - accuracy: 0.9816 - cost: 2.3502 - val_loss: 0.1188 - val_auc: 0.9898 - val_accuracy: 0.9689 - val_cost: 3.8724\n",
            "Epoch 203/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0607 - auc: 0.9963 - accuracy: 0.9815 - cost: 2.3727 - val_loss: 0.1205 - val_auc: 0.9896 - val_accuracy: 0.9694 - val_cost: 3.7785\n",
            "Epoch 204/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0610 - auc: 0.9961 - accuracy: 0.9817 - cost: 2.3403 - val_loss: 0.1170 - val_auc: 0.9898 - val_accuracy: 0.9690 - val_cost: 3.8274\n",
            "Epoch 205/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0600 - auc: 0.9963 - accuracy: 0.9818 - cost: 2.3247 - val_loss: 0.1170 - val_auc: 0.9898 - val_accuracy: 0.9701 - val_cost: 3.7785\n",
            "Epoch 206/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0606 - auc: 0.9963 - accuracy: 0.9815 - cost: 2.3749 - val_loss: 0.1183 - val_auc: 0.9898 - val_accuracy: 0.9687 - val_cost: 3.8574\n",
            "Epoch 207/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0602 - auc: 0.9963 - accuracy: 0.9816 - cost: 2.3554 - val_loss: 0.1175 - val_auc: 0.9897 - val_accuracy: 0.9692 - val_cost: 3.8048\n",
            "Epoch 208/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0599 - auc: 0.9964 - accuracy: 0.9818 - cost: 2.3317 - val_loss: 0.1185 - val_auc: 0.9902 - val_accuracy: 0.9705 - val_cost: 3.6433\n",
            "Epoch 209/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0598 - auc: 0.9963 - accuracy: 0.9819 - cost: 2.3165 - val_loss: 0.1199 - val_auc: 0.9895 - val_accuracy: 0.9688 - val_cost: 3.8349\n",
            "Epoch 210/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0611 - auc: 0.9962 - accuracy: 0.9818 - cost: 2.3304 - val_loss: 0.1177 - val_auc: 0.9899 - val_accuracy: 0.9701 - val_cost: 3.7372\n",
            "Epoch 211/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0602 - auc: 0.9963 - accuracy: 0.9821 - cost: 2.2936 - val_loss: 0.1183 - val_auc: 0.9897 - val_accuracy: 0.9681 - val_cost: 3.9175\n",
            "Epoch 212/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0597 - auc: 0.9963 - accuracy: 0.9822 - cost: 2.2707 - val_loss: 0.1165 - val_auc: 0.9898 - val_accuracy: 0.9693 - val_cost: 3.8612\n",
            "Epoch 213/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0607 - auc: 0.9962 - accuracy: 0.9816 - cost: 2.3438 - val_loss: 0.1160 - val_auc: 0.9900 - val_accuracy: 0.9697 - val_cost: 3.7447\n",
            "Epoch 214/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0596 - auc: 0.9963 - accuracy: 0.9824 - cost: 2.2608 - val_loss: 0.1200 - val_auc: 0.9896 - val_accuracy: 0.9690 - val_cost: 3.8199\n",
            "Epoch 215/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0603 - auc: 0.9963 - accuracy: 0.9817 - cost: 2.3234 - val_loss: 0.1164 - val_auc: 0.9902 - val_accuracy: 0.9695 - val_cost: 3.8349\n",
            "Epoch 216/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0597 - auc: 0.9964 - accuracy: 0.9817 - cost: 2.3563 - val_loss: 0.1172 - val_auc: 0.9899 - val_accuracy: 0.9691 - val_cost: 3.7823\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1130 - auc: 0.9905 - accuracy: 0.9696 - cost: 3.7969\n",
            "1000/1000 [==============================] - 1s 968us/step\n",
            "fold train/predict time: 0:01:54.005321\n",
            "fold accuracy: 0.9695624709129333 - fold cost: 3.796875\n",
            "x_train shape: (128000, 67)\n",
            "Epoch 1/1000\n",
            "113/113 [==============================] - 2s 5ms/step - loss: 0.5381 - auc: 0.7898 - accuracy: 0.7219 - cost: 37.0286 - val_loss: 0.4109 - val_auc: 0.8923 - val_accuracy: 0.8207 - val_cost: 22.6412\n",
            "Epoch 2/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.3604 - auc: 0.9174 - accuracy: 0.8442 - cost: 19.8480 - val_loss: 0.3265 - val_auc: 0.9321 - val_accuracy: 0.8620 - val_cost: 17.5556\n",
            "Epoch 3/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.3093 - auc: 0.9394 - accuracy: 0.8707 - cost: 16.3782 - val_loss: 0.2984 - val_auc: 0.9434 - val_accuracy: 0.8738 - val_cost: 16.0457\n",
            "Epoch 4/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.2825 - auc: 0.9495 - accuracy: 0.8846 - cost: 14.5936 - val_loss: 0.2756 - val_auc: 0.9520 - val_accuracy: 0.8872 - val_cost: 14.2015\n",
            "Epoch 5/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.2599 - auc: 0.9573 - accuracy: 0.8952 - cost: 13.2035 - val_loss: 0.2574 - val_auc: 0.9585 - val_accuracy: 0.8958 - val_cost: 12.8305\n",
            "Epoch 6/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.2414 - auc: 0.9632 - accuracy: 0.9038 - cost: 12.1513 - val_loss: 0.2415 - val_auc: 0.9632 - val_accuracy: 0.9068 - val_cost: 11.4671\n",
            "Epoch 7/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.2261 - auc: 0.9677 - accuracy: 0.9108 - cost: 11.2637 - val_loss: 0.2278 - val_auc: 0.9675 - val_accuracy: 0.9134 - val_cost: 10.4417\n",
            "Epoch 8/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.2109 - auc: 0.9717 - accuracy: 0.9187 - cost: 10.2643 - val_loss: 0.2148 - val_auc: 0.9705 - val_accuracy: 0.9184 - val_cost: 10.1750\n",
            "Epoch 9/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1996 - auc: 0.9747 - accuracy: 0.9231 - cost: 9.7146 - val_loss: 0.2048 - val_auc: 0.9733 - val_accuracy: 0.9248 - val_cost: 9.3525\n",
            "Epoch 10/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1896 - auc: 0.9770 - accuracy: 0.9283 - cost: 9.0457 - val_loss: 0.1968 - val_auc: 0.9751 - val_accuracy: 0.9277 - val_cost: 9.1384\n",
            "Epoch 11/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1818 - auc: 0.9787 - accuracy: 0.9318 - cost: 8.6071 - val_loss: 0.1902 - val_auc: 0.9765 - val_accuracy: 0.9298 - val_cost: 8.7027\n",
            "Epoch 12/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1742 - auc: 0.9803 - accuracy: 0.9359 - cost: 8.0903 - val_loss: 0.1834 - val_auc: 0.9783 - val_accuracy: 0.9352 - val_cost: 8.0078\n",
            "Epoch 13/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1670 - auc: 0.9818 - accuracy: 0.9387 - cost: 7.7343 - val_loss: 0.1785 - val_auc: 0.9791 - val_accuracy: 0.9362 - val_cost: 8.0379\n",
            "Epoch 14/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1626 - auc: 0.9826 - accuracy: 0.9409 - cost: 7.4711 - val_loss: 0.1748 - val_auc: 0.9801 - val_accuracy: 0.9384 - val_cost: 7.7073\n",
            "Epoch 15/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1578 - auc: 0.9835 - accuracy: 0.9430 - cost: 7.1898 - val_loss: 0.1696 - val_auc: 0.9810 - val_accuracy: 0.9407 - val_cost: 7.3806\n",
            "Epoch 16/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1535 - auc: 0.9844 - accuracy: 0.9451 - cost: 6.9448 - val_loss: 0.1669 - val_auc: 0.9816 - val_accuracy: 0.9413 - val_cost: 7.2942\n",
            "Epoch 17/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1506 - auc: 0.9848 - accuracy: 0.9458 - cost: 6.8645 - val_loss: 0.1647 - val_auc: 0.9822 - val_accuracy: 0.9435 - val_cost: 7.0388\n",
            "Epoch 18/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1477 - auc: 0.9854 - accuracy: 0.9476 - cost: 6.6411 - val_loss: 0.1620 - val_auc: 0.9826 - val_accuracy: 0.9446 - val_cost: 6.8472\n",
            "Epoch 19/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1440 - auc: 0.9859 - accuracy: 0.9495 - cost: 6.4004 - val_loss: 0.1584 - val_auc: 0.9832 - val_accuracy: 0.9443 - val_cost: 6.9336\n",
            "Epoch 20/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1408 - auc: 0.9865 - accuracy: 0.9505 - cost: 6.2828 - val_loss: 0.1576 - val_auc: 0.9835 - val_accuracy: 0.9465 - val_cost: 6.7909\n",
            "Epoch 21/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1392 - auc: 0.9868 - accuracy: 0.9515 - cost: 6.1407 - val_loss: 0.1556 - val_auc: 0.9838 - val_accuracy: 0.9464 - val_cost: 6.6068\n",
            "Epoch 22/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1372 - auc: 0.9872 - accuracy: 0.9515 - cost: 6.1359 - val_loss: 0.1549 - val_auc: 0.9841 - val_accuracy: 0.9474 - val_cost: 6.3927\n",
            "Epoch 23/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1346 - auc: 0.9875 - accuracy: 0.9527 - cost: 5.9834 - val_loss: 0.1534 - val_auc: 0.9843 - val_accuracy: 0.9480 - val_cost: 6.3401\n",
            "Epoch 24/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1323 - auc: 0.9879 - accuracy: 0.9545 - cost: 5.7600 - val_loss: 0.1505 - val_auc: 0.9848 - val_accuracy: 0.9495 - val_cost: 6.3927\n",
            "Epoch 25/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1310 - auc: 0.9882 - accuracy: 0.9544 - cost: 5.7838 - val_loss: 0.1506 - val_auc: 0.9847 - val_accuracy: 0.9492 - val_cost: 6.3439\n",
            "Epoch 26/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1286 - auc: 0.9885 - accuracy: 0.9559 - cost: 5.5962 - val_loss: 0.1504 - val_auc: 0.9848 - val_accuracy: 0.9502 - val_cost: 6.0772\n",
            "Epoch 27/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1266 - auc: 0.9888 - accuracy: 0.9565 - cost: 5.5150 - val_loss: 0.1486 - val_auc: 0.9850 - val_accuracy: 0.9500 - val_cost: 6.2387\n",
            "Epoch 28/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1253 - auc: 0.9889 - accuracy: 0.9574 - cost: 5.3975 - val_loss: 0.1473 - val_auc: 0.9851 - val_accuracy: 0.9509 - val_cost: 6.1373\n",
            "Epoch 29/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1233 - auc: 0.9893 - accuracy: 0.9580 - cost: 5.3339 - val_loss: 0.1461 - val_auc: 0.9854 - val_accuracy: 0.9532 - val_cost: 5.8218\n",
            "Epoch 30/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1219 - auc: 0.9894 - accuracy: 0.9587 - cost: 5.2419 - val_loss: 0.1455 - val_auc: 0.9855 - val_accuracy: 0.9519 - val_cost: 5.9871\n",
            "Epoch 31/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1207 - auc: 0.9895 - accuracy: 0.9592 - cost: 5.1775 - val_loss: 0.1455 - val_auc: 0.9858 - val_accuracy: 0.9523 - val_cost: 5.7918\n",
            "Epoch 32/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1202 - auc: 0.9897 - accuracy: 0.9595 - cost: 5.1334 - val_loss: 0.1440 - val_auc: 0.9857 - val_accuracy: 0.9527 - val_cost: 5.8706\n",
            "Epoch 33/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1186 - auc: 0.9898 - accuracy: 0.9601 - cost: 5.0461 - val_loss: 0.1415 - val_auc: 0.9861 - val_accuracy: 0.9538 - val_cost: 5.9157\n",
            "Epoch 34/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1176 - auc: 0.9901 - accuracy: 0.9605 - cost: 5.0198 - val_loss: 0.1412 - val_auc: 0.9862 - val_accuracy: 0.9541 - val_cost: 5.7580\n",
            "Epoch 35/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1157 - auc: 0.9903 - accuracy: 0.9609 - cost: 4.9857 - val_loss: 0.1399 - val_auc: 0.9867 - val_accuracy: 0.9545 - val_cost: 5.6190\n",
            "Epoch 36/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1150 - auc: 0.9904 - accuracy: 0.9614 - cost: 4.8988 - val_loss: 0.1389 - val_auc: 0.9867 - val_accuracy: 0.9553 - val_cost: 5.7054\n",
            "Epoch 37/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1124 - auc: 0.9908 - accuracy: 0.9621 - cost: 4.7947 - val_loss: 0.1381 - val_auc: 0.9866 - val_accuracy: 0.9553 - val_cost: 5.6340\n",
            "Epoch 38/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1121 - auc: 0.9908 - accuracy: 0.9630 - cost: 4.6966 - val_loss: 0.1376 - val_auc: 0.9869 - val_accuracy: 0.9563 - val_cost: 5.4913\n",
            "Epoch 39/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1116 - auc: 0.9907 - accuracy: 0.9630 - cost: 4.6974 - val_loss: 0.1373 - val_auc: 0.9865 - val_accuracy: 0.9563 - val_cost: 5.5288\n",
            "Epoch 40/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1098 - auc: 0.9911 - accuracy: 0.9634 - cost: 4.6499 - val_loss: 0.1372 - val_auc: 0.9867 - val_accuracy: 0.9569 - val_cost: 5.3786\n",
            "Epoch 41/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1086 - auc: 0.9912 - accuracy: 0.9644 - cost: 4.5289 - val_loss: 0.1364 - val_auc: 0.9868 - val_accuracy: 0.9581 - val_cost: 5.1946\n",
            "Epoch 42/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1069 - auc: 0.9914 - accuracy: 0.9650 - cost: 4.4377 - val_loss: 0.1357 - val_auc: 0.9870 - val_accuracy: 0.9577 - val_cost: 5.3448\n",
            "Epoch 43/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1049 - auc: 0.9917 - accuracy: 0.9654 - cost: 4.3958 - val_loss: 0.1353 - val_auc: 0.9870 - val_accuracy: 0.9581 - val_cost: 5.3561\n",
            "Epoch 44/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1050 - auc: 0.9916 - accuracy: 0.9660 - cost: 4.3163 - val_loss: 0.1333 - val_auc: 0.9873 - val_accuracy: 0.9583 - val_cost: 5.2659\n",
            "Epoch 45/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1058 - auc: 0.9915 - accuracy: 0.9651 - cost: 4.4326 - val_loss: 0.1316 - val_auc: 0.9874 - val_accuracy: 0.9586 - val_cost: 5.2960\n",
            "Epoch 46/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1042 - auc: 0.9917 - accuracy: 0.9662 - cost: 4.3124 - val_loss: 0.1325 - val_auc: 0.9878 - val_accuracy: 0.9587 - val_cost: 5.1082\n",
            "Epoch 47/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1024 - auc: 0.9919 - accuracy: 0.9666 - cost: 4.2269 - val_loss: 0.1310 - val_auc: 0.9876 - val_accuracy: 0.9602 - val_cost: 5.0218\n",
            "Epoch 48/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1020 - auc: 0.9920 - accuracy: 0.9670 - cost: 4.1880 - val_loss: 0.1291 - val_auc: 0.9879 - val_accuracy: 0.9591 - val_cost: 5.1420\n",
            "Epoch 49/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1002 - auc: 0.9923 - accuracy: 0.9670 - cost: 4.1828 - val_loss: 0.1296 - val_auc: 0.9878 - val_accuracy: 0.9598 - val_cost: 5.0593\n",
            "Epoch 50/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1002 - auc: 0.9922 - accuracy: 0.9676 - cost: 4.1275 - val_loss: 0.1282 - val_auc: 0.9880 - val_accuracy: 0.9602 - val_cost: 4.9730\n",
            "Epoch 51/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0995 - auc: 0.9922 - accuracy: 0.9678 - cost: 4.0895 - val_loss: 0.1289 - val_auc: 0.9878 - val_accuracy: 0.9605 - val_cost: 4.9842\n",
            "Epoch 52/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0981 - auc: 0.9925 - accuracy: 0.9684 - cost: 4.0121 - val_loss: 0.1298 - val_auc: 0.9879 - val_accuracy: 0.9610 - val_cost: 4.7589\n",
            "Epoch 53/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0976 - auc: 0.9925 - accuracy: 0.9684 - cost: 4.0208 - val_loss: 0.1280 - val_auc: 0.9878 - val_accuracy: 0.9615 - val_cost: 4.7589\n",
            "Epoch 54/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0962 - auc: 0.9926 - accuracy: 0.9690 - cost: 3.9508 - val_loss: 0.1288 - val_auc: 0.9878 - val_accuracy: 0.9605 - val_cost: 4.8715\n",
            "Epoch 55/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0967 - auc: 0.9925 - accuracy: 0.9686 - cost: 3.9879 - val_loss: 0.1268 - val_auc: 0.9882 - val_accuracy: 0.9613 - val_cost: 4.7814\n",
            "Epoch 56/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0952 - auc: 0.9928 - accuracy: 0.9692 - cost: 3.9201 - val_loss: 0.1267 - val_auc: 0.9879 - val_accuracy: 0.9610 - val_cost: 4.8190\n",
            "Epoch 57/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0945 - auc: 0.9927 - accuracy: 0.9702 - cost: 3.8000 - val_loss: 0.1265 - val_auc: 0.9881 - val_accuracy: 0.9624 - val_cost: 4.5898\n",
            "Epoch 58/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0937 - auc: 0.9928 - accuracy: 0.9697 - cost: 3.8717 - val_loss: 0.1255 - val_auc: 0.9882 - val_accuracy: 0.9627 - val_cost: 4.6612\n",
            "Epoch 59/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0936 - auc: 0.9930 - accuracy: 0.9701 - cost: 3.8090 - val_loss: 0.1253 - val_auc: 0.9878 - val_accuracy: 0.9615 - val_cost: 4.9091\n",
            "Epoch 60/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0930 - auc: 0.9930 - accuracy: 0.9704 - cost: 3.7611 - val_loss: 0.1246 - val_auc: 0.9880 - val_accuracy: 0.9625 - val_cost: 4.6837\n",
            "Epoch 61/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0916 - auc: 0.9931 - accuracy: 0.9709 - cost: 3.7010 - val_loss: 0.1252 - val_auc: 0.9882 - val_accuracy: 0.9622 - val_cost: 4.6988\n",
            "Epoch 62/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0915 - auc: 0.9932 - accuracy: 0.9709 - cost: 3.6988 - val_loss: 0.1242 - val_auc: 0.9884 - val_accuracy: 0.9628 - val_cost: 4.6086\n",
            "Epoch 63/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0906 - auc: 0.9932 - accuracy: 0.9714 - cost: 3.6435 - val_loss: 0.1229 - val_auc: 0.9884 - val_accuracy: 0.9638 - val_cost: 4.5523\n",
            "Epoch 64/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0897 - auc: 0.9933 - accuracy: 0.9716 - cost: 3.6314 - val_loss: 0.1223 - val_auc: 0.9885 - val_accuracy: 0.9634 - val_cost: 4.6650\n",
            "Epoch 65/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0893 - auc: 0.9934 - accuracy: 0.9717 - cost: 3.6116 - val_loss: 0.1245 - val_auc: 0.9883 - val_accuracy: 0.9640 - val_cost: 4.4584\n",
            "Epoch 66/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0891 - auc: 0.9934 - accuracy: 0.9720 - cost: 3.5714 - val_loss: 0.1236 - val_auc: 0.9883 - val_accuracy: 0.9638 - val_cost: 4.5110\n",
            "Epoch 67/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0878 - auc: 0.9937 - accuracy: 0.9722 - cost: 3.5476 - val_loss: 0.1227 - val_auc: 0.9886 - val_accuracy: 0.9638 - val_cost: 4.5410\n",
            "Epoch 68/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0877 - auc: 0.9935 - accuracy: 0.9721 - cost: 3.5454 - val_loss: 0.1228 - val_auc: 0.9885 - val_accuracy: 0.9639 - val_cost: 4.4471\n",
            "Epoch 69/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0878 - auc: 0.9935 - accuracy: 0.9725 - cost: 3.5053 - val_loss: 0.1225 - val_auc: 0.9887 - val_accuracy: 0.9645 - val_cost: 4.3833\n",
            "Epoch 70/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0866 - auc: 0.9936 - accuracy: 0.9726 - cost: 3.4975 - val_loss: 0.1230 - val_auc: 0.9886 - val_accuracy: 0.9641 - val_cost: 4.3232\n",
            "Epoch 71/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0857 - auc: 0.9938 - accuracy: 0.9729 - cost: 3.4586 - val_loss: 0.1217 - val_auc: 0.9888 - val_accuracy: 0.9644 - val_cost: 4.4171\n",
            "Epoch 72/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0861 - auc: 0.9938 - accuracy: 0.9732 - cost: 3.4223 - val_loss: 0.1225 - val_auc: 0.9884 - val_accuracy: 0.9638 - val_cost: 4.4358\n",
            "Epoch 73/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0857 - auc: 0.9937 - accuracy: 0.9735 - cost: 3.4003 - val_loss: 0.1228 - val_auc: 0.9888 - val_accuracy: 0.9642 - val_cost: 4.3532\n",
            "Epoch 74/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0847 - auc: 0.9938 - accuracy: 0.9733 - cost: 3.3985 - val_loss: 0.1215 - val_auc: 0.9888 - val_accuracy: 0.9648 - val_cost: 4.2631\n",
            "Epoch 75/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0844 - auc: 0.9938 - accuracy: 0.9738 - cost: 3.3415 - val_loss: 0.1207 - val_auc: 0.9886 - val_accuracy: 0.9654 - val_cost: 4.3232\n",
            "Epoch 76/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0834 - auc: 0.9940 - accuracy: 0.9742 - cost: 3.2857 - val_loss: 0.1215 - val_auc: 0.9887 - val_accuracy: 0.9652 - val_cost: 4.2631\n",
            "Epoch 77/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0830 - auc: 0.9939 - accuracy: 0.9745 - cost: 3.2490 - val_loss: 0.1210 - val_auc: 0.9886 - val_accuracy: 0.9648 - val_cost: 4.4884\n",
            "Epoch 78/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0833 - auc: 0.9939 - accuracy: 0.9740 - cost: 3.3290 - val_loss: 0.1204 - val_auc: 0.9887 - val_accuracy: 0.9655 - val_cost: 4.2255\n",
            "Epoch 79/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0825 - auc: 0.9941 - accuracy: 0.9744 - cost: 3.2780 - val_loss: 0.1196 - val_auc: 0.9891 - val_accuracy: 0.9650 - val_cost: 4.3269\n",
            "Epoch 80/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0815 - auc: 0.9942 - accuracy: 0.9746 - cost: 3.2520 - val_loss: 0.1194 - val_auc: 0.9890 - val_accuracy: 0.9650 - val_cost: 4.3157\n",
            "Epoch 81/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0822 - auc: 0.9940 - accuracy: 0.9743 - cost: 3.2793 - val_loss: 0.1200 - val_auc: 0.9889 - val_accuracy: 0.9653 - val_cost: 4.3044\n",
            "Epoch 82/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0819 - auc: 0.9941 - accuracy: 0.9745 - cost: 3.2585 - val_loss: 0.1200 - val_auc: 0.9890 - val_accuracy: 0.9652 - val_cost: 4.2743\n",
            "Epoch 83/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0807 - auc: 0.9942 - accuracy: 0.9750 - cost: 3.1967 - val_loss: 0.1204 - val_auc: 0.9889 - val_accuracy: 0.9661 - val_cost: 4.1767\n",
            "Epoch 84/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0804 - auc: 0.9942 - accuracy: 0.9756 - cost: 3.1306 - val_loss: 0.1188 - val_auc: 0.9891 - val_accuracy: 0.9647 - val_cost: 4.3607\n",
            "Epoch 85/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0790 - auc: 0.9943 - accuracy: 0.9759 - cost: 3.0827 - val_loss: 0.1219 - val_auc: 0.9892 - val_accuracy: 0.9653 - val_cost: 4.0941\n",
            "Epoch 86/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0797 - auc: 0.9944 - accuracy: 0.9749 - cost: 3.2097 - val_loss: 0.1210 - val_auc: 0.9887 - val_accuracy: 0.9652 - val_cost: 4.3908\n",
            "Epoch 87/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0797 - auc: 0.9943 - accuracy: 0.9754 - cost: 3.1457 - val_loss: 0.1187 - val_auc: 0.9890 - val_accuracy: 0.9655 - val_cost: 4.2593\n",
            "Epoch 88/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0789 - auc: 0.9943 - accuracy: 0.9756 - cost: 3.1267 - val_loss: 0.1196 - val_auc: 0.9889 - val_accuracy: 0.9658 - val_cost: 4.2255\n",
            "Epoch 89/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0779 - auc: 0.9944 - accuracy: 0.9761 - cost: 3.0615 - val_loss: 0.1192 - val_auc: 0.9892 - val_accuracy: 0.9663 - val_cost: 4.1091\n",
            "Epoch 90/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0786 - auc: 0.9944 - accuracy: 0.9757 - cost: 3.1172 - val_loss: 0.1199 - val_auc: 0.9888 - val_accuracy: 0.9663 - val_cost: 4.0828\n",
            "Epoch 91/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0781 - auc: 0.9944 - accuracy: 0.9766 - cost: 3.0083 - val_loss: 0.1186 - val_auc: 0.9890 - val_accuracy: 0.9651 - val_cost: 4.3232\n",
            "Epoch 92/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0777 - auc: 0.9944 - accuracy: 0.9759 - cost: 3.0701 - val_loss: 0.1192 - val_auc: 0.9891 - val_accuracy: 0.9665 - val_cost: 4.2293\n",
            "Epoch 93/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0770 - auc: 0.9945 - accuracy: 0.9760 - cost: 3.0762 - val_loss: 0.1175 - val_auc: 0.9892 - val_accuracy: 0.9663 - val_cost: 4.1617\n",
            "Epoch 94/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0763 - auc: 0.9947 - accuracy: 0.9760 - cost: 3.0585 - val_loss: 0.1171 - val_auc: 0.9894 - val_accuracy: 0.9663 - val_cost: 4.2218\n",
            "Epoch 95/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0765 - auc: 0.9946 - accuracy: 0.9764 - cost: 3.0235 - val_loss: 0.1205 - val_auc: 0.9890 - val_accuracy: 0.9657 - val_cost: 4.2255\n",
            "Epoch 96/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0760 - auc: 0.9946 - accuracy: 0.9766 - cost: 2.9958 - val_loss: 0.1207 - val_auc: 0.9890 - val_accuracy: 0.9669 - val_cost: 4.0978\n",
            "Epoch 97/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0753 - auc: 0.9948 - accuracy: 0.9768 - cost: 2.9647 - val_loss: 0.1202 - val_auc: 0.9893 - val_accuracy: 0.9659 - val_cost: 4.1955\n",
            "Epoch 98/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0749 - auc: 0.9947 - accuracy: 0.9770 - cost: 2.9457 - val_loss: 0.1203 - val_auc: 0.9890 - val_accuracy: 0.9663 - val_cost: 4.2105\n",
            "Epoch 99/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0740 - auc: 0.9949 - accuracy: 0.9773 - cost: 2.9068 - val_loss: 0.1231 - val_auc: 0.9891 - val_accuracy: 0.9655 - val_cost: 4.1617\n",
            "Epoch 100/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0754 - auc: 0.9947 - accuracy: 0.9770 - cost: 2.9418 - val_loss: 0.1221 - val_auc: 0.9892 - val_accuracy: 0.9651 - val_cost: 4.2480\n",
            "Epoch 101/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0743 - auc: 0.9948 - accuracy: 0.9773 - cost: 2.9085 - val_loss: 0.1199 - val_auc: 0.9888 - val_accuracy: 0.9663 - val_cost: 4.2030\n",
            "Epoch 102/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0749 - auc: 0.9948 - accuracy: 0.9768 - cost: 2.9872 - val_loss: 0.1209 - val_auc: 0.9890 - val_accuracy: 0.9659 - val_cost: 4.1166\n",
            "Epoch 103/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0748 - auc: 0.9948 - accuracy: 0.9773 - cost: 2.9120 - val_loss: 0.1193 - val_auc: 0.9889 - val_accuracy: 0.9669 - val_cost: 4.1016\n",
            "Epoch 104/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0738 - auc: 0.9948 - accuracy: 0.9773 - cost: 2.9042 - val_loss: 0.1229 - val_auc: 0.9890 - val_accuracy: 0.9665 - val_cost: 4.1917\n",
            "Epoch 105/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0739 - auc: 0.9949 - accuracy: 0.9772 - cost: 2.9197 - val_loss: 0.1202 - val_auc: 0.9892 - val_accuracy: 0.9660 - val_cost: 4.1279\n",
            "Epoch 106/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0732 - auc: 0.9951 - accuracy: 0.9777 - cost: 2.8541 - val_loss: 0.1228 - val_auc: 0.9890 - val_accuracy: 0.9659 - val_cost: 4.1053\n",
            "Epoch 107/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0732 - auc: 0.9950 - accuracy: 0.9775 - cost: 2.8947 - val_loss: 0.1263 - val_auc: 0.9886 - val_accuracy: 0.9664 - val_cost: 4.0189\n",
            "Epoch 108/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0736 - auc: 0.9950 - accuracy: 0.9772 - cost: 2.9219 - val_loss: 0.1231 - val_auc: 0.9889 - val_accuracy: 0.9663 - val_cost: 4.1955\n",
            "Epoch 109/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0729 - auc: 0.9948 - accuracy: 0.9778 - cost: 2.8255 - val_loss: 0.1224 - val_auc: 0.9893 - val_accuracy: 0.9663 - val_cost: 4.0828\n",
            "Epoch 110/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0722 - auc: 0.9951 - accuracy: 0.9784 - cost: 2.7452 - val_loss: 0.1224 - val_auc: 0.9888 - val_accuracy: 0.9663 - val_cost: 4.2067\n",
            "Epoch 111/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0724 - auc: 0.9950 - accuracy: 0.9779 - cost: 2.8407 - val_loss: 0.1220 - val_auc: 0.9890 - val_accuracy: 0.9669 - val_cost: 4.0527\n",
            "Epoch 112/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0722 - auc: 0.9951 - accuracy: 0.9778 - cost: 2.8281 - val_loss: 0.1228 - val_auc: 0.9888 - val_accuracy: 0.9663 - val_cost: 4.1880\n",
            "Epoch 113/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0719 - auc: 0.9951 - accuracy: 0.9782 - cost: 2.7901 - val_loss: 0.1237 - val_auc: 0.9891 - val_accuracy: 0.9670 - val_cost: 3.9551\n",
            "Epoch 114/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0719 - auc: 0.9950 - accuracy: 0.9783 - cost: 2.7789 - val_loss: 0.1218 - val_auc: 0.9891 - val_accuracy: 0.9677 - val_cost: 4.0377\n",
            "Epoch 115/1000\n",
            "113/113 [==============================] - 1s 4ms/step - loss: 0.0720 - auc: 0.9950 - accuracy: 0.9779 - cost: 2.8212 - val_loss: 0.1232 - val_auc: 0.9891 - val_accuracy: 0.9653 - val_cost: 4.1917\n",
            "Epoch 116/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0712 - auc: 0.9951 - accuracy: 0.9781 - cost: 2.7897 - val_loss: 0.1215 - val_auc: 0.9891 - val_accuracy: 0.9668 - val_cost: 4.0678\n",
            "Epoch 117/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0717 - auc: 0.9951 - accuracy: 0.9778 - cost: 2.8372 - val_loss: 0.1216 - val_auc: 0.9889 - val_accuracy: 0.9675 - val_cost: 4.0039\n",
            "Epoch 118/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0712 - auc: 0.9951 - accuracy: 0.9780 - cost: 2.8255 - val_loss: 0.1229 - val_auc: 0.9890 - val_accuracy: 0.9673 - val_cost: 4.0377\n",
            "Epoch 119/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0708 - auc: 0.9952 - accuracy: 0.9782 - cost: 2.7785 - val_loss: 0.1211 - val_auc: 0.9890 - val_accuracy: 0.9676 - val_cost: 4.0828\n",
            "Epoch 120/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0710 - auc: 0.9952 - accuracy: 0.9782 - cost: 2.7962 - val_loss: 0.1228 - val_auc: 0.9887 - val_accuracy: 0.9670 - val_cost: 4.1354\n",
            "Epoch 121/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0709 - auc: 0.9951 - accuracy: 0.9783 - cost: 2.7720 - val_loss: 0.1186 - val_auc: 0.9895 - val_accuracy: 0.9673 - val_cost: 4.1016\n",
            "Epoch 122/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0699 - auc: 0.9953 - accuracy: 0.9786 - cost: 2.7491 - val_loss: 0.1227 - val_auc: 0.9889 - val_accuracy: 0.9672 - val_cost: 4.0002\n",
            "Epoch 123/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0700 - auc: 0.9953 - accuracy: 0.9784 - cost: 2.7681 - val_loss: 0.1227 - val_auc: 0.9888 - val_accuracy: 0.9669 - val_cost: 4.1016\n",
            "Epoch 124/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0702 - auc: 0.9953 - accuracy: 0.9785 - cost: 2.7594 - val_loss: 0.1242 - val_auc: 0.9887 - val_accuracy: 0.9662 - val_cost: 4.3457\n",
            "Epoch 125/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0697 - auc: 0.9953 - accuracy: 0.9792 - cost: 2.6601 - val_loss: 0.1228 - val_auc: 0.9888 - val_accuracy: 0.9677 - val_cost: 4.0790\n",
            "Epoch 126/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0691 - auc: 0.9954 - accuracy: 0.9795 - cost: 2.6311 - val_loss: 0.1243 - val_auc: 0.9888 - val_accuracy: 0.9675 - val_cost: 4.0189\n",
            "Epoch 127/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0704 - auc: 0.9952 - accuracy: 0.9787 - cost: 2.7331 - val_loss: 0.1274 - val_auc: 0.9884 - val_accuracy: 0.9659 - val_cost: 4.2218\n",
            "Epoch 128/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0698 - auc: 0.9953 - accuracy: 0.9788 - cost: 2.7106 - val_loss: 0.1231 - val_auc: 0.9890 - val_accuracy: 0.9670 - val_cost: 4.1091\n",
            "Epoch 129/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0700 - auc: 0.9952 - accuracy: 0.9785 - cost: 2.7581 - val_loss: 0.1214 - val_auc: 0.9892 - val_accuracy: 0.9669 - val_cost: 4.0302\n",
            "Epoch 130/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0690 - auc: 0.9954 - accuracy: 0.9791 - cost: 2.6726 - val_loss: 0.1273 - val_auc: 0.9887 - val_accuracy: 0.9663 - val_cost: 4.1203\n",
            "Epoch 131/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0684 - auc: 0.9955 - accuracy: 0.9793 - cost: 2.6540 - val_loss: 0.1263 - val_auc: 0.9887 - val_accuracy: 0.9659 - val_cost: 4.2368\n",
            "Epoch 132/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0686 - auc: 0.9954 - accuracy: 0.9791 - cost: 2.6834 - val_loss: 0.1265 - val_auc: 0.9890 - val_accuracy: 0.9665 - val_cost: 4.0678\n",
            "Epoch 133/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0687 - auc: 0.9954 - accuracy: 0.9792 - cost: 2.6652 - val_loss: 0.1246 - val_auc: 0.9888 - val_accuracy: 0.9670 - val_cost: 4.0941\n",
            "Epoch 134/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0681 - auc: 0.9955 - accuracy: 0.9793 - cost: 2.6531 - val_loss: 0.1245 - val_auc: 0.9887 - val_accuracy: 0.9674 - val_cost: 4.0640\n",
            "Epoch 135/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0684 - auc: 0.9955 - accuracy: 0.9790 - cost: 2.6946 - val_loss: 0.1235 - val_auc: 0.9888 - val_accuracy: 0.9672 - val_cost: 4.0415\n",
            "Epoch 136/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0676 - auc: 0.9955 - accuracy: 0.9793 - cost: 2.6605 - val_loss: 0.1234 - val_auc: 0.9890 - val_accuracy: 0.9670 - val_cost: 4.0941\n",
            "Epoch 137/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0680 - auc: 0.9954 - accuracy: 0.9796 - cost: 2.6039 - val_loss: 0.1283 - val_auc: 0.9885 - val_accuracy: 0.9662 - val_cost: 4.1241\n",
            "Epoch 138/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0684 - auc: 0.9955 - accuracy: 0.9790 - cost: 2.7037 - val_loss: 0.1246 - val_auc: 0.9890 - val_accuracy: 0.9664 - val_cost: 4.2142\n",
            "Epoch 139/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0682 - auc: 0.9954 - accuracy: 0.9796 - cost: 2.6121 - val_loss: 0.1258 - val_auc: 0.9887 - val_accuracy: 0.9668 - val_cost: 4.1654\n",
            "Epoch 140/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0672 - auc: 0.9956 - accuracy: 0.9794 - cost: 2.6462 - val_loss: 0.1265 - val_auc: 0.9881 - val_accuracy: 0.9678 - val_cost: 3.9739\n",
            "Epoch 141/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0670 - auc: 0.9955 - accuracy: 0.9803 - cost: 2.5265 - val_loss: 0.1275 - val_auc: 0.9884 - val_accuracy: 0.9666 - val_cost: 4.0903\n",
            "Epoch 142/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0677 - auc: 0.9956 - accuracy: 0.9794 - cost: 2.6562 - val_loss: 0.1254 - val_auc: 0.9888 - val_accuracy: 0.9664 - val_cost: 4.1316\n",
            "Epoch 143/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0678 - auc: 0.9956 - accuracy: 0.9793 - cost: 2.6605 - val_loss: 0.1283 - val_auc: 0.9887 - val_accuracy: 0.9655 - val_cost: 4.1880\n",
            "Epoch 144/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0669 - auc: 0.9956 - accuracy: 0.9792 - cost: 2.6691 - val_loss: 0.1269 - val_auc: 0.9887 - val_accuracy: 0.9665 - val_cost: 4.1241\n",
            "Epoch 145/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0672 - auc: 0.9956 - accuracy: 0.9795 - cost: 2.6363 - val_loss: 0.1257 - val_auc: 0.9884 - val_accuracy: 0.9674 - val_cost: 4.0790\n",
            "Epoch 146/1000\n",
            "113/113 [==============================] - 1s 4ms/step - loss: 0.0671 - auc: 0.9955 - accuracy: 0.9796 - cost: 2.6069 - val_loss: 0.1283 - val_auc: 0.9885 - val_accuracy: 0.9665 - val_cost: 4.1466\n",
            "Epoch 147/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0668 - auc: 0.9955 - accuracy: 0.9801 - cost: 2.5399 - val_loss: 0.1265 - val_auc: 0.9883 - val_accuracy: 0.9666 - val_cost: 4.2743\n",
            "Epoch 148/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0658 - auc: 0.9958 - accuracy: 0.9803 - cost: 2.5304 - val_loss: 0.1275 - val_auc: 0.9886 - val_accuracy: 0.9668 - val_cost: 4.1128\n",
            "Epoch 149/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0667 - auc: 0.9957 - accuracy: 0.9800 - cost: 2.5671 - val_loss: 0.1255 - val_auc: 0.9886 - val_accuracy: 0.9666 - val_cost: 4.1617\n",
            "Epoch 150/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0647 - auc: 0.9958 - accuracy: 0.9805 - cost: 2.5036 - val_loss: 0.1261 - val_auc: 0.9884 - val_accuracy: 0.9680 - val_cost: 3.9814\n",
            "Epoch 151/1000\n",
            "113/113 [==============================] - 1s 4ms/step - loss: 0.0671 - auc: 0.9956 - accuracy: 0.9797 - cost: 2.6095 - val_loss: 0.1259 - val_auc: 0.9887 - val_accuracy: 0.9663 - val_cost: 4.1429\n",
            "Epoch 152/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0661 - auc: 0.9957 - accuracy: 0.9798 - cost: 2.5935 - val_loss: 0.1260 - val_auc: 0.9886 - val_accuracy: 0.9659 - val_cost: 4.2293\n",
            "Epoch 153/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0663 - auc: 0.9956 - accuracy: 0.9795 - cost: 2.6307 - val_loss: 0.1260 - val_auc: 0.9887 - val_accuracy: 0.9669 - val_cost: 4.1091\n",
            "Epoch 154/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0660 - auc: 0.9956 - accuracy: 0.9798 - cost: 2.6026 - val_loss: 0.1270 - val_auc: 0.9883 - val_accuracy: 0.9663 - val_cost: 4.2781\n",
            "Epoch 155/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0661 - auc: 0.9957 - accuracy: 0.9801 - cost: 2.5602 - val_loss: 0.1259 - val_auc: 0.9886 - val_accuracy: 0.9663 - val_cost: 4.1804\n",
            "Epoch 156/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0655 - auc: 0.9958 - accuracy: 0.9799 - cost: 2.5831 - val_loss: 0.1284 - val_auc: 0.9885 - val_accuracy: 0.9667 - val_cost: 4.0452\n",
            "Epoch 157/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0655 - auc: 0.9957 - accuracy: 0.9800 - cost: 2.5805 - val_loss: 0.1274 - val_auc: 0.9883 - val_accuracy: 0.9677 - val_cost: 4.0452\n",
            "Epoch 158/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0650 - auc: 0.9957 - accuracy: 0.9804 - cost: 2.5097 - val_loss: 0.1279 - val_auc: 0.9884 - val_accuracy: 0.9677 - val_cost: 4.0002\n",
            "Epoch 159/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0649 - auc: 0.9958 - accuracy: 0.9801 - cost: 2.5620 - val_loss: 0.1284 - val_auc: 0.9882 - val_accuracy: 0.9664 - val_cost: 4.1692\n",
            "Epoch 160/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0653 - auc: 0.9957 - accuracy: 0.9802 - cost: 2.5494 - val_loss: 0.1288 - val_auc: 0.9885 - val_accuracy: 0.9670 - val_cost: 4.1128\n",
            "Epoch 161/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0654 - auc: 0.9958 - accuracy: 0.9803 - cost: 2.5153 - val_loss: 0.1274 - val_auc: 0.9882 - val_accuracy: 0.9670 - val_cost: 4.1016\n",
            "Epoch 162/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0654 - auc: 0.9957 - accuracy: 0.9800 - cost: 2.5563 - val_loss: 0.1283 - val_auc: 0.9882 - val_accuracy: 0.9666 - val_cost: 4.0941\n",
            "Epoch 163/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0642 - auc: 0.9959 - accuracy: 0.9806 - cost: 2.4971 - val_loss: 0.1263 - val_auc: 0.9885 - val_accuracy: 0.9668 - val_cost: 4.1541\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1131 - auc: 0.9902 - accuracy: 0.9673 - cost: 4.0453\n",
            "1000/1000 [==============================] - 2s 2ms/step\n",
            "fold train/predict time: 0:01:26.449254\n",
            "fold accuracy: 0.9672812223434448 - fold cost: 4.045312404632568\n",
            "x_train shape: (128000, 67)\n",
            "Epoch 1/1000\n",
            "113/113 [==============================] - 2s 7ms/step - loss: 0.5358 - auc: 0.7922 - accuracy: 0.7249 - cost: 36.5999 - val_loss: 0.4097 - val_auc: 0.8931 - val_accuracy: 0.8180 - val_cost: 23.3699\n",
            "Epoch 2/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.3606 - auc: 0.9171 - accuracy: 0.8451 - cost: 19.7499 - val_loss: 0.3225 - val_auc: 0.9348 - val_accuracy: 0.8643 - val_cost: 16.8532\n",
            "Epoch 3/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.3097 - auc: 0.9392 - accuracy: 0.8714 - cost: 16.3177 - val_loss: 0.2945 - val_auc: 0.9459 - val_accuracy: 0.8779 - val_cost: 14.8926\n",
            "Epoch 4/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2830 - auc: 0.9493 - accuracy: 0.8836 - cost: 14.7232 - val_loss: 0.2692 - val_auc: 0.9547 - val_accuracy: 0.8915 - val_cost: 13.4766\n",
            "Epoch 5/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2605 - auc: 0.9572 - accuracy: 0.8954 - cost: 13.2398 - val_loss: 0.2482 - val_auc: 0.9614 - val_accuracy: 0.9002 - val_cost: 12.7742\n",
            "Epoch 6/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2419 - auc: 0.9630 - accuracy: 0.9034 - cost: 12.2373 - val_loss: 0.2326 - val_auc: 0.9660 - val_accuracy: 0.9096 - val_cost: 11.2417\n",
            "Epoch 7/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.2249 - auc: 0.9680 - accuracy: 0.9121 - cost: 11.1065 - val_loss: 0.2183 - val_auc: 0.9704 - val_accuracy: 0.9160 - val_cost: 10.1750\n",
            "Epoch 8/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.2118 - auc: 0.9715 - accuracy: 0.9181 - cost: 10.3421 - val_loss: 0.2058 - val_auc: 0.9730 - val_accuracy: 0.9220 - val_cost: 9.8332\n",
            "Epoch 9/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1989 - auc: 0.9748 - accuracy: 0.9243 - cost: 9.5720 - val_loss: 0.1962 - val_auc: 0.9753 - val_accuracy: 0.9276 - val_cost: 8.9769\n",
            "Epoch 10/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.1892 - auc: 0.9772 - accuracy: 0.9283 - cost: 9.0552 - val_loss: 0.1888 - val_auc: 0.9770 - val_accuracy: 0.9302 - val_cost: 8.9393\n",
            "Epoch 11/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1808 - auc: 0.9789 - accuracy: 0.9326 - cost: 8.5268 - val_loss: 0.1810 - val_auc: 0.9785 - val_accuracy: 0.9333 - val_cost: 8.4285\n",
            "Epoch 12/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1731 - auc: 0.9806 - accuracy: 0.9362 - cost: 8.0791 - val_loss: 0.1757 - val_auc: 0.9797 - val_accuracy: 0.9373 - val_cost: 7.9289\n",
            "Epoch 13/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1682 - auc: 0.9815 - accuracy: 0.9376 - cost: 7.9037 - val_loss: 0.1696 - val_auc: 0.9808 - val_accuracy: 0.9392 - val_cost: 7.6623\n",
            "Epoch 14/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1627 - auc: 0.9827 - accuracy: 0.9405 - cost: 7.5187 - val_loss: 0.1673 - val_auc: 0.9813 - val_accuracy: 0.9416 - val_cost: 7.2791\n",
            "Epoch 15/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1576 - auc: 0.9837 - accuracy: 0.9431 - cost: 7.2054 - val_loss: 0.1625 - val_auc: 0.9821 - val_accuracy: 0.9434 - val_cost: 7.1176\n",
            "Epoch 16/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1540 - auc: 0.9842 - accuracy: 0.9440 - cost: 7.0831 - val_loss: 0.1598 - val_auc: 0.9827 - val_accuracy: 0.9436 - val_cost: 7.1214\n",
            "Epoch 17/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1492 - auc: 0.9851 - accuracy: 0.9475 - cost: 6.6570 - val_loss: 0.1585 - val_auc: 0.9833 - val_accuracy: 0.9446 - val_cost: 6.7420\n",
            "Epoch 18/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1462 - auc: 0.9856 - accuracy: 0.9478 - cost: 6.6264 - val_loss: 0.1541 - val_auc: 0.9840 - val_accuracy: 0.9470 - val_cost: 6.5279\n",
            "Epoch 19/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1439 - auc: 0.9860 - accuracy: 0.9491 - cost: 6.4674 - val_loss: 0.1529 - val_auc: 0.9843 - val_accuracy: 0.9470 - val_cost: 6.5279\n",
            "Epoch 20/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1395 - auc: 0.9867 - accuracy: 0.9513 - cost: 6.1727 - val_loss: 0.1509 - val_auc: 0.9844 - val_accuracy: 0.9473 - val_cost: 6.6031\n",
            "Epoch 21/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1374 - auc: 0.9871 - accuracy: 0.9519 - cost: 6.1178 - val_loss: 0.1495 - val_auc: 0.9845 - val_accuracy: 0.9488 - val_cost: 6.4528\n",
            "Epoch 22/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1353 - auc: 0.9874 - accuracy: 0.9530 - cost: 5.9626 - val_loss: 0.1482 - val_auc: 0.9848 - val_accuracy: 0.9496 - val_cost: 6.3289\n",
            "Epoch 23/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1319 - auc: 0.9879 - accuracy: 0.9545 - cost: 5.7596 - val_loss: 0.1457 - val_auc: 0.9852 - val_accuracy: 0.9497 - val_cost: 6.2725\n",
            "Epoch 24/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1297 - auc: 0.9883 - accuracy: 0.9552 - cost: 5.6878 - val_loss: 0.1438 - val_auc: 0.9853 - val_accuracy: 0.9516 - val_cost: 6.1223\n",
            "Epoch 25/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1278 - auc: 0.9886 - accuracy: 0.9564 - cost: 5.5405 - val_loss: 0.1425 - val_auc: 0.9858 - val_accuracy: 0.9525 - val_cost: 5.8406\n",
            "Epoch 26/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1263 - auc: 0.9888 - accuracy: 0.9566 - cost: 5.5046 - val_loss: 0.1407 - val_auc: 0.9859 - val_accuracy: 0.9536 - val_cost: 5.8331\n",
            "Epoch 27/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1249 - auc: 0.9890 - accuracy: 0.9569 - cost: 5.4666 - val_loss: 0.1385 - val_auc: 0.9863 - val_accuracy: 0.9540 - val_cost: 5.7204\n",
            "Epoch 28/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1238 - auc: 0.9891 - accuracy: 0.9575 - cost: 5.3970 - val_loss: 0.1393 - val_auc: 0.9864 - val_accuracy: 0.9533 - val_cost: 5.7091\n",
            "Epoch 29/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1225 - auc: 0.9893 - accuracy: 0.9588 - cost: 5.2618 - val_loss: 0.1378 - val_auc: 0.9865 - val_accuracy: 0.9516 - val_cost: 6.1448\n",
            "Epoch 30/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1206 - auc: 0.9896 - accuracy: 0.9591 - cost: 5.2021 - val_loss: 0.1365 - val_auc: 0.9865 - val_accuracy: 0.9563 - val_cost: 5.4650\n",
            "Epoch 31/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1186 - auc: 0.9899 - accuracy: 0.9597 - cost: 5.1291 - val_loss: 0.1353 - val_auc: 0.9869 - val_accuracy: 0.9548 - val_cost: 5.6303\n",
            "Epoch 32/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1163 - auc: 0.9903 - accuracy: 0.9607 - cost: 4.9857 - val_loss: 0.1339 - val_auc: 0.9870 - val_accuracy: 0.9571 - val_cost: 5.3110\n",
            "Epoch 33/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1156 - auc: 0.9902 - accuracy: 0.9619 - cost: 4.8573 - val_loss: 0.1337 - val_auc: 0.9872 - val_accuracy: 0.9562 - val_cost: 5.5176\n",
            "Epoch 34/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1139 - auc: 0.9905 - accuracy: 0.9621 - cost: 4.8193 - val_loss: 0.1319 - val_auc: 0.9872 - val_accuracy: 0.9574 - val_cost: 5.3072\n",
            "Epoch 35/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1126 - auc: 0.9906 - accuracy: 0.9629 - cost: 4.7303 - val_loss: 0.1317 - val_auc: 0.9874 - val_accuracy: 0.9583 - val_cost: 5.3185\n",
            "Epoch 36/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1111 - auc: 0.9908 - accuracy: 0.9631 - cost: 4.7009 - val_loss: 0.1314 - val_auc: 0.9873 - val_accuracy: 0.9577 - val_cost: 5.2133\n",
            "Epoch 37/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1096 - auc: 0.9910 - accuracy: 0.9638 - cost: 4.5968 - val_loss: 0.1301 - val_auc: 0.9877 - val_accuracy: 0.9583 - val_cost: 5.3185\n",
            "Epoch 38/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1090 - auc: 0.9910 - accuracy: 0.9641 - cost: 4.5635 - val_loss: 0.1292 - val_auc: 0.9876 - val_accuracy: 0.9592 - val_cost: 5.0331\n",
            "Epoch 39/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1080 - auc: 0.9913 - accuracy: 0.9645 - cost: 4.5181 - val_loss: 0.1294 - val_auc: 0.9876 - val_accuracy: 0.9586 - val_cost: 5.2096\n",
            "Epoch 40/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1060 - auc: 0.9915 - accuracy: 0.9648 - cost: 4.4645 - val_loss: 0.1271 - val_auc: 0.9879 - val_accuracy: 0.9591 - val_cost: 5.2021\n",
            "Epoch 41/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1056 - auc: 0.9915 - accuracy: 0.9653 - cost: 4.4179 - val_loss: 0.1276 - val_auc: 0.9879 - val_accuracy: 0.9605 - val_cost: 4.8978\n",
            "Epoch 42/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.1048 - auc: 0.9916 - accuracy: 0.9661 - cost: 4.3068 - val_loss: 0.1264 - val_auc: 0.9882 - val_accuracy: 0.9605 - val_cost: 4.8866\n",
            "Epoch 43/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1038 - auc: 0.9918 - accuracy: 0.9663 - cost: 4.2835 - val_loss: 0.1256 - val_auc: 0.9880 - val_accuracy: 0.9610 - val_cost: 4.8903\n",
            "Epoch 44/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1035 - auc: 0.9917 - accuracy: 0.9663 - cost: 4.2856 - val_loss: 0.1258 - val_auc: 0.9883 - val_accuracy: 0.9607 - val_cost: 5.0331\n",
            "Epoch 45/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1019 - auc: 0.9920 - accuracy: 0.9669 - cost: 4.2260 - val_loss: 0.1261 - val_auc: 0.9882 - val_accuracy: 0.9609 - val_cost: 4.8227\n",
            "Epoch 46/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.1014 - auc: 0.9920 - accuracy: 0.9674 - cost: 4.1538 - val_loss: 0.1260 - val_auc: 0.9883 - val_accuracy: 0.9613 - val_cost: 4.7739\n",
            "Epoch 47/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0998 - auc: 0.9922 - accuracy: 0.9680 - cost: 4.0778 - val_loss: 0.1251 - val_auc: 0.9884 - val_accuracy: 0.9615 - val_cost: 4.7438\n",
            "Epoch 48/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0996 - auc: 0.9923 - accuracy: 0.9675 - cost: 4.1383 - val_loss: 0.1244 - val_auc: 0.9882 - val_accuracy: 0.9620 - val_cost: 4.7514\n",
            "Epoch 49/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0988 - auc: 0.9924 - accuracy: 0.9680 - cost: 4.0761 - val_loss: 0.1232 - val_auc: 0.9885 - val_accuracy: 0.9628 - val_cost: 4.5823\n",
            "Epoch 50/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0972 - auc: 0.9925 - accuracy: 0.9686 - cost: 3.9918 - val_loss: 0.1228 - val_auc: 0.9885 - val_accuracy: 0.9621 - val_cost: 4.7138\n",
            "Epoch 51/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0967 - auc: 0.9925 - accuracy: 0.9692 - cost: 3.9283 - val_loss: 0.1228 - val_auc: 0.9887 - val_accuracy: 0.9630 - val_cost: 4.5636\n",
            "Epoch 52/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0969 - auc: 0.9926 - accuracy: 0.9688 - cost: 3.9741 - val_loss: 0.1225 - val_auc: 0.9889 - val_accuracy: 0.9638 - val_cost: 4.4396\n",
            "Epoch 53/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0955 - auc: 0.9927 - accuracy: 0.9697 - cost: 3.8592 - val_loss: 0.1227 - val_auc: 0.9887 - val_accuracy: 0.9618 - val_cost: 4.8302\n",
            "Epoch 54/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0942 - auc: 0.9929 - accuracy: 0.9696 - cost: 3.8613 - val_loss: 0.1211 - val_auc: 0.9890 - val_accuracy: 0.9638 - val_cost: 4.4884\n",
            "Epoch 55/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0946 - auc: 0.9928 - accuracy: 0.9701 - cost: 3.8172 - val_loss: 0.1244 - val_auc: 0.9883 - val_accuracy: 0.9627 - val_cost: 4.5523\n",
            "Epoch 56/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0935 - auc: 0.9929 - accuracy: 0.9704 - cost: 3.7904 - val_loss: 0.1211 - val_auc: 0.9889 - val_accuracy: 0.9628 - val_cost: 4.5861\n",
            "Epoch 57/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0929 - auc: 0.9930 - accuracy: 0.9703 - cost: 3.7917 - val_loss: 0.1213 - val_auc: 0.9890 - val_accuracy: 0.9630 - val_cost: 4.5297\n",
            "Epoch 58/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0926 - auc: 0.9930 - accuracy: 0.9707 - cost: 3.7377 - val_loss: 0.1201 - val_auc: 0.9891 - val_accuracy: 0.9638 - val_cost: 4.5260\n",
            "Epoch 59/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0915 - auc: 0.9930 - accuracy: 0.9713 - cost: 3.6690 - val_loss: 0.1194 - val_auc: 0.9891 - val_accuracy: 0.9633 - val_cost: 4.6762\n",
            "Epoch 60/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0914 - auc: 0.9932 - accuracy: 0.9711 - cost: 3.6863 - val_loss: 0.1196 - val_auc: 0.9891 - val_accuracy: 0.9633 - val_cost: 4.6011\n",
            "Epoch 61/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0900 - auc: 0.9932 - accuracy: 0.9716 - cost: 3.6396 - val_loss: 0.1207 - val_auc: 0.9888 - val_accuracy: 0.9639 - val_cost: 4.5485\n",
            "Epoch 62/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0897 - auc: 0.9933 - accuracy: 0.9714 - cost: 3.6496 - val_loss: 0.1210 - val_auc: 0.9890 - val_accuracy: 0.9644 - val_cost: 4.4396\n",
            "Epoch 63/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0885 - auc: 0.9934 - accuracy: 0.9719 - cost: 3.5899 - val_loss: 0.1211 - val_auc: 0.9890 - val_accuracy: 0.9637 - val_cost: 4.5110\n",
            "Epoch 64/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0892 - auc: 0.9933 - accuracy: 0.9716 - cost: 3.6198 - val_loss: 0.1208 - val_auc: 0.9891 - val_accuracy: 0.9632 - val_cost: 4.5748\n",
            "Epoch 65/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0888 - auc: 0.9933 - accuracy: 0.9722 - cost: 3.5437 - val_loss: 0.1193 - val_auc: 0.9892 - val_accuracy: 0.9644 - val_cost: 4.6124\n",
            "Epoch 66/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0885 - auc: 0.9935 - accuracy: 0.9721 - cost: 3.5675 - val_loss: 0.1194 - val_auc: 0.9890 - val_accuracy: 0.9645 - val_cost: 4.5297\n",
            "Epoch 67/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0868 - auc: 0.9936 - accuracy: 0.9730 - cost: 3.4452 - val_loss: 0.1201 - val_auc: 0.9889 - val_accuracy: 0.9642 - val_cost: 4.4434\n",
            "Epoch 68/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0865 - auc: 0.9936 - accuracy: 0.9731 - cost: 3.4340 - val_loss: 0.1207 - val_auc: 0.9889 - val_accuracy: 0.9637 - val_cost: 4.6988\n",
            "Epoch 69/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0866 - auc: 0.9936 - accuracy: 0.9728 - cost: 3.4750 - val_loss: 0.1170 - val_auc: 0.9891 - val_accuracy: 0.9661 - val_cost: 4.3157\n",
            "Epoch 70/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0853 - auc: 0.9938 - accuracy: 0.9731 - cost: 3.4383 - val_loss: 0.1190 - val_auc: 0.9892 - val_accuracy: 0.9652 - val_cost: 4.4321\n",
            "Epoch 71/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0863 - auc: 0.9936 - accuracy: 0.9725 - cost: 3.5066 - val_loss: 0.1179 - val_auc: 0.9891 - val_accuracy: 0.9645 - val_cost: 4.4471\n",
            "Epoch 72/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0854 - auc: 0.9938 - accuracy: 0.9733 - cost: 3.3985 - val_loss: 0.1173 - val_auc: 0.9892 - val_accuracy: 0.9655 - val_cost: 4.3307\n",
            "Epoch 73/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0843 - auc: 0.9938 - accuracy: 0.9736 - cost: 3.3614 - val_loss: 0.1175 - val_auc: 0.9892 - val_accuracy: 0.9654 - val_cost: 4.3232\n",
            "Epoch 74/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0847 - auc: 0.9938 - accuracy: 0.9736 - cost: 3.3674 - val_loss: 0.1181 - val_auc: 0.9891 - val_accuracy: 0.9648 - val_cost: 4.4133\n",
            "Epoch 75/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0828 - auc: 0.9938 - accuracy: 0.9741 - cost: 3.3026 - val_loss: 0.1181 - val_auc: 0.9893 - val_accuracy: 0.9655 - val_cost: 4.2330\n",
            "Epoch 76/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0832 - auc: 0.9940 - accuracy: 0.9742 - cost: 3.2888 - val_loss: 0.1175 - val_auc: 0.9892 - val_accuracy: 0.9660 - val_cost: 4.3194\n",
            "Epoch 77/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0836 - auc: 0.9939 - accuracy: 0.9741 - cost: 3.3207 - val_loss: 0.1168 - val_auc: 0.9890 - val_accuracy: 0.9655 - val_cost: 4.3344\n",
            "Epoch 78/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0821 - auc: 0.9941 - accuracy: 0.9744 - cost: 3.2758 - val_loss: 0.1166 - val_auc: 0.9894 - val_accuracy: 0.9656 - val_cost: 4.3795\n",
            "Epoch 79/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0818 - auc: 0.9941 - accuracy: 0.9745 - cost: 3.2607 - val_loss: 0.1172 - val_auc: 0.9892 - val_accuracy: 0.9660 - val_cost: 4.3645\n",
            "Epoch 80/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0833 - auc: 0.9939 - accuracy: 0.9739 - cost: 3.3462 - val_loss: 0.1168 - val_auc: 0.9891 - val_accuracy: 0.9655 - val_cost: 4.3532\n",
            "Epoch 81/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0814 - auc: 0.9942 - accuracy: 0.9745 - cost: 3.2590 - val_loss: 0.1182 - val_auc: 0.9890 - val_accuracy: 0.9652 - val_cost: 4.4659\n",
            "Epoch 82/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0805 - auc: 0.9942 - accuracy: 0.9753 - cost: 3.1596 - val_loss: 0.1158 - val_auc: 0.9893 - val_accuracy: 0.9673 - val_cost: 4.0678\n",
            "Epoch 83/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0807 - auc: 0.9942 - accuracy: 0.9749 - cost: 3.2028 - val_loss: 0.1178 - val_auc: 0.9892 - val_accuracy: 0.9652 - val_cost: 4.3419\n",
            "Epoch 84/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0800 - auc: 0.9943 - accuracy: 0.9754 - cost: 3.1336 - val_loss: 0.1159 - val_auc: 0.9895 - val_accuracy: 0.9659 - val_cost: 4.3344\n",
            "Epoch 85/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0802 - auc: 0.9942 - accuracy: 0.9753 - cost: 3.1686 - val_loss: 0.1175 - val_auc: 0.9892 - val_accuracy: 0.9661 - val_cost: 4.2255\n",
            "Epoch 86/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0797 - auc: 0.9944 - accuracy: 0.9753 - cost: 3.1479 - val_loss: 0.1169 - val_auc: 0.9890 - val_accuracy: 0.9673 - val_cost: 4.0565\n",
            "Epoch 87/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0797 - auc: 0.9944 - accuracy: 0.9750 - cost: 3.1894 - val_loss: 0.1160 - val_auc: 0.9894 - val_accuracy: 0.9662 - val_cost: 4.3044\n",
            "Epoch 88/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0786 - auc: 0.9944 - accuracy: 0.9755 - cost: 3.1211 - val_loss: 0.1173 - val_auc: 0.9891 - val_accuracy: 0.9663 - val_cost: 4.1842\n",
            "Epoch 89/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0784 - auc: 0.9944 - accuracy: 0.9757 - cost: 3.0973 - val_loss: 0.1169 - val_auc: 0.9893 - val_accuracy: 0.9663 - val_cost: 4.2368\n",
            "Epoch 90/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0786 - auc: 0.9944 - accuracy: 0.9758 - cost: 3.1012 - val_loss: 0.1157 - val_auc: 0.9892 - val_accuracy: 0.9684 - val_cost: 3.9926\n",
            "Epoch 91/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0778 - auc: 0.9945 - accuracy: 0.9760 - cost: 3.0779 - val_loss: 0.1162 - val_auc: 0.9893 - val_accuracy: 0.9660 - val_cost: 4.2969\n",
            "Epoch 92/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0780 - auc: 0.9945 - accuracy: 0.9757 - cost: 3.1004 - val_loss: 0.1167 - val_auc: 0.9893 - val_accuracy: 0.9654 - val_cost: 4.3607\n",
            "Epoch 93/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0776 - auc: 0.9945 - accuracy: 0.9762 - cost: 3.0528 - val_loss: 0.1176 - val_auc: 0.9893 - val_accuracy: 0.9661 - val_cost: 4.1992\n",
            "Epoch 94/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0776 - auc: 0.9946 - accuracy: 0.9761 - cost: 3.0693 - val_loss: 0.1153 - val_auc: 0.9893 - val_accuracy: 0.9659 - val_cost: 4.2668\n",
            "Epoch 95/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0767 - auc: 0.9946 - accuracy: 0.9762 - cost: 3.0498 - val_loss: 0.1147 - val_auc: 0.9895 - val_accuracy: 0.9675 - val_cost: 4.0527\n",
            "Epoch 96/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0778 - auc: 0.9944 - accuracy: 0.9762 - cost: 3.0299 - val_loss: 0.1149 - val_auc: 0.9894 - val_accuracy: 0.9676 - val_cost: 4.0527\n",
            "Epoch 97/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0761 - auc: 0.9947 - accuracy: 0.9769 - cost: 2.9591 - val_loss: 0.1152 - val_auc: 0.9894 - val_accuracy: 0.9670 - val_cost: 4.2293\n",
            "Epoch 98/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0766 - auc: 0.9947 - accuracy: 0.9759 - cost: 3.0822 - val_loss: 0.1149 - val_auc: 0.9896 - val_accuracy: 0.9673 - val_cost: 4.1579\n",
            "Epoch 99/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0758 - auc: 0.9947 - accuracy: 0.9769 - cost: 2.9483 - val_loss: 0.1156 - val_auc: 0.9893 - val_accuracy: 0.9661 - val_cost: 4.2819\n",
            "Epoch 100/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0751 - auc: 0.9947 - accuracy: 0.9771 - cost: 2.9228 - val_loss: 0.1162 - val_auc: 0.9894 - val_accuracy: 0.9668 - val_cost: 4.1804\n",
            "Epoch 101/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0763 - auc: 0.9947 - accuracy: 0.9766 - cost: 2.9919 - val_loss: 0.1180 - val_auc: 0.9890 - val_accuracy: 0.9661 - val_cost: 4.3983\n",
            "Epoch 102/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0749 - auc: 0.9948 - accuracy: 0.9772 - cost: 2.9262 - val_loss: 0.1157 - val_auc: 0.9894 - val_accuracy: 0.9670 - val_cost: 4.1692\n",
            "Epoch 103/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0742 - auc: 0.9949 - accuracy: 0.9770 - cost: 2.9513 - val_loss: 0.1178 - val_auc: 0.9890 - val_accuracy: 0.9670 - val_cost: 4.1429\n",
            "Epoch 104/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0744 - auc: 0.9949 - accuracy: 0.9768 - cost: 2.9738 - val_loss: 0.1161 - val_auc: 0.9895 - val_accuracy: 0.9665 - val_cost: 4.2330\n",
            "Epoch 105/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0743 - auc: 0.9949 - accuracy: 0.9770 - cost: 2.9422 - val_loss: 0.1155 - val_auc: 0.9895 - val_accuracy: 0.9672 - val_cost: 4.1729\n",
            "Epoch 106/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0739 - auc: 0.9949 - accuracy: 0.9774 - cost: 2.8921 - val_loss: 0.1154 - val_auc: 0.9894 - val_accuracy: 0.9680 - val_cost: 4.0264\n",
            "Epoch 107/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0745 - auc: 0.9949 - accuracy: 0.9769 - cost: 2.9621 - val_loss: 0.1152 - val_auc: 0.9894 - val_accuracy: 0.9680 - val_cost: 4.0941\n",
            "Epoch 108/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0746 - auc: 0.9949 - accuracy: 0.9773 - cost: 2.9120 - val_loss: 0.1177 - val_auc: 0.9893 - val_accuracy: 0.9669 - val_cost: 4.1279\n",
            "Epoch 109/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0731 - auc: 0.9950 - accuracy: 0.9778 - cost: 2.8420 - val_loss: 0.1169 - val_auc: 0.9895 - val_accuracy: 0.9681 - val_cost: 3.9551\n",
            "Epoch 110/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0735 - auc: 0.9950 - accuracy: 0.9776 - cost: 2.8683 - val_loss: 0.1161 - val_auc: 0.9895 - val_accuracy: 0.9673 - val_cost: 4.0828\n",
            "Epoch 111/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0736 - auc: 0.9950 - accuracy: 0.9768 - cost: 2.9565 - val_loss: 0.1164 - val_auc: 0.9895 - val_accuracy: 0.9678 - val_cost: 4.1654\n",
            "Epoch 112/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0727 - auc: 0.9950 - accuracy: 0.9780 - cost: 2.8221 - val_loss: 0.1149 - val_auc: 0.9897 - val_accuracy: 0.9674 - val_cost: 4.0790\n",
            "Epoch 113/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0729 - auc: 0.9949 - accuracy: 0.9778 - cost: 2.8588 - val_loss: 0.1157 - val_auc: 0.9894 - val_accuracy: 0.9688 - val_cost: 3.9325\n",
            "Epoch 114/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0716 - auc: 0.9951 - accuracy: 0.9782 - cost: 2.7875 - val_loss: 0.1175 - val_auc: 0.9893 - val_accuracy: 0.9677 - val_cost: 4.0377\n",
            "Epoch 115/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0720 - auc: 0.9951 - accuracy: 0.9781 - cost: 2.8039 - val_loss: 0.1166 - val_auc: 0.9896 - val_accuracy: 0.9663 - val_cost: 4.2819\n",
            "Epoch 116/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0720 - auc: 0.9951 - accuracy: 0.9778 - cost: 2.8402 - val_loss: 0.1176 - val_auc: 0.9893 - val_accuracy: 0.9683 - val_cost: 3.9288\n",
            "Epoch 117/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0716 - auc: 0.9952 - accuracy: 0.9780 - cost: 2.8083 - val_loss: 0.1161 - val_auc: 0.9895 - val_accuracy: 0.9671 - val_cost: 4.1804\n",
            "Epoch 118/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0720 - auc: 0.9951 - accuracy: 0.9779 - cost: 2.8368 - val_loss: 0.1144 - val_auc: 0.9896 - val_accuracy: 0.9671 - val_cost: 4.2443\n",
            "Epoch 119/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0719 - auc: 0.9952 - accuracy: 0.9779 - cost: 2.8424 - val_loss: 0.1169 - val_auc: 0.9893 - val_accuracy: 0.9678 - val_cost: 4.0227\n",
            "Epoch 120/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0715 - auc: 0.9952 - accuracy: 0.9782 - cost: 2.7979 - val_loss: 0.1147 - val_auc: 0.9899 - val_accuracy: 0.9673 - val_cost: 4.1166\n",
            "Epoch 121/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0708 - auc: 0.9953 - accuracy: 0.9787 - cost: 2.7335 - val_loss: 0.1160 - val_auc: 0.9895 - val_accuracy: 0.9677 - val_cost: 4.1504\n",
            "Epoch 122/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0705 - auc: 0.9952 - accuracy: 0.9783 - cost: 2.7802 - val_loss: 0.1162 - val_auc: 0.9898 - val_accuracy: 0.9688 - val_cost: 3.9175\n",
            "Epoch 123/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0698 - auc: 0.9954 - accuracy: 0.9784 - cost: 2.7612 - val_loss: 0.1174 - val_auc: 0.9896 - val_accuracy: 0.9680 - val_cost: 4.0264\n",
            "Epoch 124/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0700 - auc: 0.9952 - accuracy: 0.9789 - cost: 2.7132 - val_loss: 0.1168 - val_auc: 0.9894 - val_accuracy: 0.9677 - val_cost: 4.1241\n",
            "Epoch 125/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0706 - auc: 0.9953 - accuracy: 0.9782 - cost: 2.7992 - val_loss: 0.1185 - val_auc: 0.9894 - val_accuracy: 0.9679 - val_cost: 4.1729\n",
            "Epoch 126/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0704 - auc: 0.9953 - accuracy: 0.9784 - cost: 2.7733 - val_loss: 0.1178 - val_auc: 0.9894 - val_accuracy: 0.9684 - val_cost: 3.9889\n",
            "Epoch 127/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0707 - auc: 0.9953 - accuracy: 0.9782 - cost: 2.7910 - val_loss: 0.1176 - val_auc: 0.9895 - val_accuracy: 0.9680 - val_cost: 4.1316\n",
            "Epoch 128/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0695 - auc: 0.9954 - accuracy: 0.9782 - cost: 2.8009 - val_loss: 0.1207 - val_auc: 0.9892 - val_accuracy: 0.9671 - val_cost: 4.0490\n",
            "Epoch 129/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0692 - auc: 0.9954 - accuracy: 0.9787 - cost: 2.7244 - val_loss: 0.1162 - val_auc: 0.9896 - val_accuracy: 0.9685 - val_cost: 4.0527\n",
            "Epoch 130/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0698 - auc: 0.9954 - accuracy: 0.9783 - cost: 2.7763 - val_loss: 0.1172 - val_auc: 0.9892 - val_accuracy: 0.9680 - val_cost: 4.1016\n",
            "Epoch 131/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0682 - auc: 0.9956 - accuracy: 0.9795 - cost: 2.6285 - val_loss: 0.1166 - val_auc: 0.9895 - val_accuracy: 0.9687 - val_cost: 4.0189\n",
            "Epoch 132/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0694 - auc: 0.9954 - accuracy: 0.9788 - cost: 2.7102 - val_loss: 0.1165 - val_auc: 0.9897 - val_accuracy: 0.9680 - val_cost: 4.0302\n",
            "Epoch 133/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0687 - auc: 0.9954 - accuracy: 0.9792 - cost: 2.6605 - val_loss: 0.1171 - val_auc: 0.9894 - val_accuracy: 0.9680 - val_cost: 4.0264\n",
            "Epoch 134/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0690 - auc: 0.9954 - accuracy: 0.9791 - cost: 2.6864 - val_loss: 0.1186 - val_auc: 0.9895 - val_accuracy: 0.9679 - val_cost: 3.9776\n",
            "Epoch 135/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0691 - auc: 0.9953 - accuracy: 0.9790 - cost: 2.6890 - val_loss: 0.1169 - val_auc: 0.9896 - val_accuracy: 0.9678 - val_cost: 4.0978\n",
            "Epoch 136/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0692 - auc: 0.9953 - accuracy: 0.9792 - cost: 2.6592 - val_loss: 0.1181 - val_auc: 0.9893 - val_accuracy: 0.9681 - val_cost: 3.9062\n",
            "Epoch 137/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0683 - auc: 0.9955 - accuracy: 0.9791 - cost: 2.6791 - val_loss: 0.1180 - val_auc: 0.9894 - val_accuracy: 0.9670 - val_cost: 4.1654\n",
            "Epoch 138/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0683 - auc: 0.9954 - accuracy: 0.9790 - cost: 2.6812 - val_loss: 0.1183 - val_auc: 0.9894 - val_accuracy: 0.9683 - val_cost: 3.9814\n",
            "Epoch 139/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0686 - auc: 0.9954 - accuracy: 0.9789 - cost: 2.7037 - val_loss: 0.1173 - val_auc: 0.9895 - val_accuracy: 0.9677 - val_cost: 4.1203\n",
            "Epoch 140/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0674 - auc: 0.9956 - accuracy: 0.9795 - cost: 2.6384 - val_loss: 0.1187 - val_auc: 0.9897 - val_accuracy: 0.9673 - val_cost: 4.1279\n",
            "Epoch 141/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0680 - auc: 0.9956 - accuracy: 0.9795 - cost: 2.6186 - val_loss: 0.1188 - val_auc: 0.9897 - val_accuracy: 0.9672 - val_cost: 4.1842\n",
            "Epoch 142/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0681 - auc: 0.9956 - accuracy: 0.9791 - cost: 2.6713 - val_loss: 0.1178 - val_auc: 0.9894 - val_accuracy: 0.9673 - val_cost: 4.0941\n",
            "Epoch 143/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0665 - auc: 0.9956 - accuracy: 0.9800 - cost: 2.5671 - val_loss: 0.1165 - val_auc: 0.9895 - val_accuracy: 0.9681 - val_cost: 4.0189\n",
            "Epoch 144/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0672 - auc: 0.9956 - accuracy: 0.9798 - cost: 2.5939 - val_loss: 0.1198 - val_auc: 0.9897 - val_accuracy: 0.9677 - val_cost: 4.0565\n",
            "Epoch 145/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0671 - auc: 0.9957 - accuracy: 0.9792 - cost: 2.6639 - val_loss: 0.1179 - val_auc: 0.9896 - val_accuracy: 0.9691 - val_cost: 3.9100\n",
            "Epoch 146/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0677 - auc: 0.9955 - accuracy: 0.9798 - cost: 2.5784 - val_loss: 0.1183 - val_auc: 0.9895 - val_accuracy: 0.9681 - val_cost: 4.0377\n",
            "Epoch 147/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0676 - auc: 0.9956 - accuracy: 0.9791 - cost: 2.6700 - val_loss: 0.1183 - val_auc: 0.9895 - val_accuracy: 0.9681 - val_cost: 4.0490\n",
            "Epoch 148/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0672 - auc: 0.9955 - accuracy: 0.9799 - cost: 2.5732 - val_loss: 0.1180 - val_auc: 0.9896 - val_accuracy: 0.9683 - val_cost: 4.0527\n",
            "Epoch 149/1000\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.0673 - auc: 0.9954 - accuracy: 0.9798 - cost: 2.5749 - val_loss: 0.1175 - val_auc: 0.9894 - val_accuracy: 0.9688 - val_cost: 3.9551\n",
            "Epoch 150/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0666 - auc: 0.9958 - accuracy: 0.9799 - cost: 2.5702 - val_loss: 0.1170 - val_auc: 0.9896 - val_accuracy: 0.9685 - val_cost: 3.9926\n",
            "Epoch 151/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0673 - auc: 0.9956 - accuracy: 0.9796 - cost: 2.6155 - val_loss: 0.1208 - val_auc: 0.9890 - val_accuracy: 0.9685 - val_cost: 3.9926\n",
            "Epoch 152/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0677 - auc: 0.9956 - accuracy: 0.9793 - cost: 2.6544 - val_loss: 0.1190 - val_auc: 0.9895 - val_accuracy: 0.9689 - val_cost: 3.9325\n",
            "Epoch 153/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0663 - auc: 0.9958 - accuracy: 0.9798 - cost: 2.5935 - val_loss: 0.1203 - val_auc: 0.9891 - val_accuracy: 0.9677 - val_cost: 4.1166\n",
            "Epoch 154/1000\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.0667 - auc: 0.9956 - accuracy: 0.9797 - cost: 2.6073 - val_loss: 0.1209 - val_auc: 0.9891 - val_accuracy: 0.9677 - val_cost: 3.9964\n",
            "Epoch 155/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0665 - auc: 0.9957 - accuracy: 0.9797 - cost: 2.6060 - val_loss: 0.1194 - val_auc: 0.9894 - val_accuracy: 0.9679 - val_cost: 4.0077\n",
            "Epoch 156/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0662 - auc: 0.9958 - accuracy: 0.9802 - cost: 2.5321 - val_loss: 0.1184 - val_auc: 0.9895 - val_accuracy: 0.9672 - val_cost: 4.1692\n",
            "Epoch 157/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0660 - auc: 0.9958 - accuracy: 0.9797 - cost: 2.6026 - val_loss: 0.1206 - val_auc: 0.9890 - val_accuracy: 0.9680 - val_cost: 4.0415\n",
            "Epoch 158/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0662 - auc: 0.9956 - accuracy: 0.9801 - cost: 2.5468 - val_loss: 0.1194 - val_auc: 0.9894 - val_accuracy: 0.9683 - val_cost: 4.0002\n",
            "Epoch 159/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0658 - auc: 0.9957 - accuracy: 0.9800 - cost: 2.5650 - val_loss: 0.1204 - val_auc: 0.9891 - val_accuracy: 0.9671 - val_cost: 4.2067\n",
            "Epoch 160/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0654 - auc: 0.9958 - accuracy: 0.9803 - cost: 2.5183 - val_loss: 0.1210 - val_auc: 0.9894 - val_accuracy: 0.9673 - val_cost: 3.9926\n",
            "Epoch 161/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0654 - auc: 0.9958 - accuracy: 0.9802 - cost: 2.5378 - val_loss: 0.1217 - val_auc: 0.9894 - val_accuracy: 0.9675 - val_cost: 3.9814\n",
            "Epoch 162/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0649 - auc: 0.9959 - accuracy: 0.9804 - cost: 2.5127 - val_loss: 0.1191 - val_auc: 0.9896 - val_accuracy: 0.9687 - val_cost: 3.9250\n",
            "Epoch 163/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0657 - auc: 0.9958 - accuracy: 0.9800 - cost: 2.5576 - val_loss: 0.1196 - val_auc: 0.9896 - val_accuracy: 0.9684 - val_cost: 3.9814\n",
            "Epoch 164/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0645 - auc: 0.9960 - accuracy: 0.9803 - cost: 2.5170 - val_loss: 0.1208 - val_auc: 0.9891 - val_accuracy: 0.9667 - val_cost: 4.2819\n",
            "Epoch 165/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0646 - auc: 0.9958 - accuracy: 0.9805 - cost: 2.5041 - val_loss: 0.1199 - val_auc: 0.9895 - val_accuracy: 0.9680 - val_cost: 4.1579\n",
            "Epoch 166/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0654 - auc: 0.9958 - accuracy: 0.9803 - cost: 2.5447 - val_loss: 0.1219 - val_auc: 0.9893 - val_accuracy: 0.9675 - val_cost: 4.0452\n",
            "Epoch 167/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0652 - auc: 0.9959 - accuracy: 0.9803 - cost: 2.5136 - val_loss: 0.1205 - val_auc: 0.9895 - val_accuracy: 0.9691 - val_cost: 4.0077\n",
            "Epoch 168/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0652 - auc: 0.9957 - accuracy: 0.9803 - cost: 2.5140 - val_loss: 0.1208 - val_auc: 0.9893 - val_accuracy: 0.9680 - val_cost: 4.0715\n",
            "Epoch 169/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0635 - auc: 0.9960 - accuracy: 0.9805 - cost: 2.4872 - val_loss: 0.1209 - val_auc: 0.9895 - val_accuracy: 0.9683 - val_cost: 4.0152\n",
            "Epoch 170/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0658 - auc: 0.9958 - accuracy: 0.9801 - cost: 2.5542 - val_loss: 0.1212 - val_auc: 0.9895 - val_accuracy: 0.9672 - val_cost: 4.2142\n",
            "Epoch 171/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0653 - auc: 0.9958 - accuracy: 0.9803 - cost: 2.5309 - val_loss: 0.1222 - val_auc: 0.9891 - val_accuracy: 0.9682 - val_cost: 4.0114\n",
            "Epoch 172/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0648 - auc: 0.9958 - accuracy: 0.9807 - cost: 2.4794 - val_loss: 0.1216 - val_auc: 0.9892 - val_accuracy: 0.9673 - val_cost: 4.0602\n",
            "Epoch 173/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0646 - auc: 0.9958 - accuracy: 0.9802 - cost: 2.5343 - val_loss: 0.1214 - val_auc: 0.9893 - val_accuracy: 0.9680 - val_cost: 4.0377\n",
            "Epoch 174/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0645 - auc: 0.9958 - accuracy: 0.9803 - cost: 2.5334 - val_loss: 0.1221 - val_auc: 0.9891 - val_accuracy: 0.9684 - val_cost: 4.0565\n",
            "Epoch 175/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0645 - auc: 0.9958 - accuracy: 0.9804 - cost: 2.5002 - val_loss: 0.1217 - val_auc: 0.9895 - val_accuracy: 0.9678 - val_cost: 4.0527\n",
            "Epoch 176/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0651 - auc: 0.9958 - accuracy: 0.9802 - cost: 2.5343 - val_loss: 0.1218 - val_auc: 0.9891 - val_accuracy: 0.9678 - val_cost: 4.0678\n",
            "Epoch 177/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0641 - auc: 0.9959 - accuracy: 0.9805 - cost: 2.5058 - val_loss: 0.1233 - val_auc: 0.9892 - val_accuracy: 0.9677 - val_cost: 4.0903\n",
            "Epoch 178/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0643 - auc: 0.9959 - accuracy: 0.9801 - cost: 2.5352 - val_loss: 0.1206 - val_auc: 0.9892 - val_accuracy: 0.9676 - val_cost: 4.1804\n",
            "Epoch 179/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0645 - auc: 0.9959 - accuracy: 0.9806 - cost: 2.4850 - val_loss: 0.1232 - val_auc: 0.9896 - val_accuracy: 0.9677 - val_cost: 4.0527\n",
            "Epoch 180/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0639 - auc: 0.9960 - accuracy: 0.9807 - cost: 2.4777 - val_loss: 0.1232 - val_auc: 0.9890 - val_accuracy: 0.9670 - val_cost: 4.2218\n",
            "Epoch 181/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0626 - auc: 0.9961 - accuracy: 0.9809 - cost: 2.4483 - val_loss: 0.1239 - val_auc: 0.9892 - val_accuracy: 0.9677 - val_cost: 4.1617\n",
            "Epoch 182/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0644 - auc: 0.9959 - accuracy: 0.9805 - cost: 2.5019 - val_loss: 0.1242 - val_auc: 0.9891 - val_accuracy: 0.9666 - val_cost: 4.2668\n",
            "Epoch 183/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0641 - auc: 0.9958 - accuracy: 0.9807 - cost: 2.4591 - val_loss: 0.1215 - val_auc: 0.9894 - val_accuracy: 0.9676 - val_cost: 4.1203\n",
            "Epoch 184/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0622 - auc: 0.9960 - accuracy: 0.9814 - cost: 2.3913 - val_loss: 0.1243 - val_auc: 0.9891 - val_accuracy: 0.9673 - val_cost: 4.1429\n",
            "Epoch 185/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0629 - auc: 0.9960 - accuracy: 0.9809 - cost: 2.4427 - val_loss: 0.1204 - val_auc: 0.9891 - val_accuracy: 0.9684 - val_cost: 4.0039\n",
            "Epoch 186/1000\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.0643 - auc: 0.9958 - accuracy: 0.9805 - cost: 2.4907 - val_loss: 0.1227 - val_auc: 0.9893 - val_accuracy: 0.9680 - val_cost: 4.0490\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1127 - auc: 0.9903 - accuracy: 0.9682 - cost: 3.9062\n",
            "1000/1000 [==============================] - 1s 985us/step\n",
            "fold train/predict time: 0:01:42.628245\n",
            "fold accuracy: 0.9681875109672546 - fold cost: 3.90625\n",
            "total train/predict time: 0:08:38.863641\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m5_results = fold_results"
      ],
      "metadata": {
        "id": "h8ySkCi9mPHh"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_m5 = np.zeros(len(y))\n",
        "for i in fold_results.keys():\n",
        "  for j in range(len(fold_results.get(i).get('predictions'))):\n",
        "    idx = fold_results.get(i).get('index')[j]\n",
        "    preds_m5[idx] = np.round(fold_results.get(i).get('predictions')[j],0)\n",
        "\n",
        "m5_cost = cost_func(y,preds_m5)\n",
        "m5_cost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkrG6or3mRV4",
        "outputId": "372f809e-bfbd-4132-9988-4396f5aa6b94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "629100"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_new = np.zeros(len(y))\n",
        "for i in fold_results.keys():\n",
        "  for j in range(len(fold_results.get(i).get('predictions'))):\n",
        "    idx = fold_results.get(i).get('index')[j]\n",
        "    if fold_results.get(i).get('predictions')[j] > 0.6:\n",
        "      preds_new[idx] = 1\n",
        "    else:\n",
        "      preds_new[idx] = 0\n",
        "\n",
        "m5_cost_t = cost_func(y,preds_new)\n",
        "m5_cost_t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YGSE-MSmS5Q",
        "outputId": "b4d20a0d-d845-4776-897b-b6cdc5df4366"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "609350"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model5.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xhEJqvbmWkK",
        "outputId": "14139bc6-8bd5-4bff-cdf3-17cd1798f4d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Relu1 (Dense)               (None, 64)                4352      \n",
            "                                                                 \n",
            " Relu2 (Dense)               (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " Activation (Dense)          (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,577\n",
            "Trainable params: 8,577\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model5.save('model5.keras')"
      ],
      "metadata": {
        "id": "bmq9o4ehJjIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost"
      ],
      "metadata": {
        "id": "kf48YNxF5eEk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#setting up a hyperparameter dataframe\n",
        "\n",
        "learning_rates = [0.1, 0.25, 0.35]\n",
        "max_depths = [3, 5, 10, 20]\n",
        "gamma = [0,1,3]\n",
        "lambda_ls = [1,2,3]\n",
        "alpha = [0,0.1,1]\n",
        "\n",
        "xgb_param = pd.DataFrame(list(product(learning_rates, max_depths, gamma, lambda_ls, alpha)), columns=['learning_rate', 'max_depth', 'gamma', 'lambda', 'alpha'])\n",
        "\n",
        "#randomizing the dataframe order\n",
        "xgb_param = shuffle(xgb_param)\n",
        "xgb_param = xgb_param.reset_index()\n",
        "xgb_param=xgb_param.drop(['index'], axis=1)\n",
        "xgb_param"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "crFxa8d68wBQ",
        "outputId": "b15aaf95-050b-41cc-d058-d3734fb23abc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     learning_rate  max_depth  gamma  lambda  alpha\n",
              "0             0.10         20      3       1    0.0\n",
              "1             0.25         20      1       3    0.0\n",
              "2             0.35         20      1       3    0.0\n",
              "3             0.35          3      0       2    0.0\n",
              "4             0.25          5      3       1    0.1\n",
              "..             ...        ...    ...     ...    ...\n",
              "319           0.25         20      0       3    0.1\n",
              "320           0.10          3      1       2    1.0\n",
              "321           0.25         10      3       2    1.0\n",
              "322           0.25          5      1       1    0.0\n",
              "323           0.25          3      0       3    0.1\n",
              "\n",
              "[324 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-c3d091ef-80fa-4745-8f71-54c43ba7eb27\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>max_depth</th>\n",
              "      <th>gamma</th>\n",
              "      <th>lambda</th>\n",
              "      <th>alpha</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.10</td>\n",
              "      <td>20</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.25</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.35</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.35</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.25</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319</th>\n",
              "      <td>0.25</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320</th>\n",
              "      <td>0.10</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321</th>\n",
              "      <td>0.25</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>322</th>\n",
              "      <td>0.25</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323</th>\n",
              "      <td>0.25</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>324 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c3d091ef-80fa-4745-8f71-54c43ba7eb27')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-b1b1a599-f754-46e9-a83e-11693c67c937\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b1b1a599-f754-46e9-a83e-11693c67c937')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-b1b1a599-f754-46e9-a83e-11693c67c937 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c3d091ef-80fa-4745-8f71-54c43ba7eb27 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c3d091ef-80fa-4745-8f71-54c43ba7eb27');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#setting up a hyperparameter dataframe\n",
        "\n",
        "learning_rates = [0.1, 0.25]\n",
        "max_depths = [3, 5, 10, 20]\n",
        "gamma = [0,1,3]\n",
        "lambda_ls = [1,2,3]\n",
        "alpha = [0,0.1,1]\n",
        "\n",
        "xgb_param = pd.DataFrame(list(product(learning_rates, max_depths, gamma, lambda_ls, alpha)), columns=['learning_rate', 'max_depth', 'gamma', 'lambda', 'alpha'])\n",
        "\n",
        "#randomizing the dataframe order\n",
        "xgb_param = shuffle(xgb_param)\n",
        "xgb_param = xgb_param.reset_index()\n",
        "xgb_param=xgb_param.drop(['index'], axis=1)\n",
        "xgb_param"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Kn5Hv4-4YeKH",
        "outputId": "b3551b6c-f15f-46bb-a453-1a26b490587d"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-67ab67fa-04b3-4f3f-a50a-570001f40e53\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>max_depth</th>\n",
              "      <th>gamma</th>\n",
              "      <th>lambda</th>\n",
              "      <th>alpha</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.25</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.25</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.10</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.10</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.10</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211</th>\n",
              "      <td>0.10</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>212</th>\n",
              "      <td>0.25</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>213</th>\n",
              "      <td>0.25</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>214</th>\n",
              "      <td>0.25</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>215</th>\n",
              "      <td>0.25</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>216 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-67ab67fa-04b3-4f3f-a50a-570001f40e53')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-a47afd49-f8e2-4262-9bbf-415f9bb0069e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a47afd49-f8e2-4262-9bbf-415f9bb0069e')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-a47afd49-f8e2-4262-9bbf-415f9bb0069e button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-67ab67fa-04b3-4f3f-a50a-570001f40e53 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-67ab67fa-04b3-4f3f-a50a-570001f40e53');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     learning_rate  max_depth  gamma  lambda  alpha\n",
              "0             0.25          3      0       2    0.1\n",
              "1             0.25          5      0       3    1.0\n",
              "2             0.10         10      3       1    0.0\n",
              "3             0.10          3      0       3    0.0\n",
              "4             0.10         20      0       3    1.0\n",
              "..             ...        ...    ...     ...    ...\n",
              "211           0.10         10      1       1    0.1\n",
              "212           0.25         20      0       1    0.0\n",
              "213           0.25          5      3       1    0.0\n",
              "214           0.25         10      0       1    1.0\n",
              "215           0.25          5      1       2    1.0\n",
              "\n",
              "[216 rows x 5 columns]"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dtrain = xgb.DMatrix(X[train_index], label=y[train_index])\n",
        "dtest = xgb.DMatrix(X[test_index], label=y[test_index])\n",
        "\n",
        "trials = 30\n",
        "best_params = {}\n",
        "i=0\n",
        "\n",
        "for i in range(trials):\n",
        "  #random sampling from paramdf\n",
        "  hyperparams = {'objective': 'binary:logistic',\n",
        "                 'eta': xgb_param['learning_rate'][i],\n",
        "                 'max_depth': xgb_param['max_depth'][i],\n",
        "                 'gamma': xgb_param['gamma'][i],\n",
        "                 'lambda': xgb_param['lambda'][i],\n",
        "                 'alpha': xgb_param['alpha'][i],\n",
        "                 'eval_metric': 'aucpr'\n",
        "                 }\n",
        "\n",
        "  print(hyperparams)\n",
        "  out=xgb.cv(params=hyperparams,\n",
        "             num_boost_round=20,\n",
        "             dtrain=dtrain,\n",
        "             nfold=5,\n",
        "             stratified=True,\n",
        "             early_stopping_rounds=3,\n",
        "             verbose_eval=1\n",
        "             )\n",
        "\n",
        "  index=out.shape[0]-1\n",
        "  result=out.iloc[index,2]\n",
        "  if i< 1.1:\n",
        "    best_result = result\n",
        "    best_params = hyperparams\n",
        "\n",
        "  if result> best_result:\n",
        "      best_result = result\n",
        "      best_params = hyperparams\n",
        "      print('result: ' ,result)\n",
        "      print('best result: ' ,best_result)\n",
        "      print('hyperparameters: ' ,hyperparams)\n",
        "      print('best hyperparameters: ' ,best_params)\n",
        "      i+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejnx8bTi5lsU",
        "outputId": "35897351-2785-4c1d-d03a-faa23ff501af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 3, 'gamma': 0, 'lambda': 2, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64563+0.00181\ttest-aucpr:0.64315+0.00505\n",
            "[1]\ttrain-aucpr:0.69980+0.00174\ttest-aucpr:0.69633+0.00534\n",
            "[2]\ttrain-aucpr:0.72409+0.00755\ttest-aucpr:0.71974+0.01007\n",
            "[3]\ttrain-aucpr:0.73761+0.00208\ttest-aucpr:0.73401+0.00555\n",
            "[4]\ttrain-aucpr:0.74850+0.00132\ttest-aucpr:0.74449+0.00515\n",
            "[5]\ttrain-aucpr:0.75308+0.00284\ttest-aucpr:0.74841+0.00202\n",
            "[6]\ttrain-aucpr:0.76401+0.00358\ttest-aucpr:0.75897+0.00562\n",
            "[7]\ttrain-aucpr:0.77443+0.00387\ttest-aucpr:0.76929+0.00501\n",
            "[8]\ttrain-aucpr:0.78353+0.00227\ttest-aucpr:0.77830+0.00214\n",
            "[9]\ttrain-aucpr:0.79100+0.00270\ttest-aucpr:0.78574+0.00044\n",
            "[10]\ttrain-aucpr:0.79796+0.00160\ttest-aucpr:0.79272+0.00191\n",
            "[11]\ttrain-aucpr:0.80414+0.00166\ttest-aucpr:0.79894+0.00328\n",
            "[12]\ttrain-aucpr:0.80805+0.00231\ttest-aucpr:0.80253+0.00271\n",
            "[13]\ttrain-aucpr:0.81465+0.00377\ttest-aucpr:0.80908+0.00378\n",
            "[14]\ttrain-aucpr:0.81993+0.00351\ttest-aucpr:0.81426+0.00372\n",
            "[15]\ttrain-aucpr:0.82332+0.00361\ttest-aucpr:0.81784+0.00370\n",
            "[16]\ttrain-aucpr:0.82662+0.00381\ttest-aucpr:0.82082+0.00337\n",
            "[17]\ttrain-aucpr:0.83062+0.00327\ttest-aucpr:0.82481+0.00400\n",
            "[18]\ttrain-aucpr:0.83598+0.00418\ttest-aucpr:0.83030+0.00522\n",
            "[19]\ttrain-aucpr:0.83916+0.00467\ttest-aucpr:0.83345+0.00572\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 5, 'gamma': 0, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76550+0.00235\ttest-aucpr:0.75927+0.00435\n",
            "[1]\ttrain-aucpr:0.81318+0.00225\ttest-aucpr:0.80539+0.00334\n",
            "[2]\ttrain-aucpr:0.83318+0.00295\ttest-aucpr:0.82591+0.00336\n",
            "[3]\ttrain-aucpr:0.84939+0.00145\ttest-aucpr:0.84225+0.00267\n",
            "[4]\ttrain-aucpr:0.85931+0.00101\ttest-aucpr:0.85189+0.00276\n",
            "[5]\ttrain-aucpr:0.86673+0.00230\ttest-aucpr:0.85947+0.00362\n",
            "[6]\ttrain-aucpr:0.87432+0.00233\ttest-aucpr:0.86671+0.00337\n",
            "[7]\ttrain-aucpr:0.88360+0.00369\ttest-aucpr:0.87603+0.00496\n",
            "[8]\ttrain-aucpr:0.89029+0.00271\ttest-aucpr:0.88296+0.00332\n",
            "[9]\ttrain-aucpr:0.89450+0.00311\ttest-aucpr:0.88709+0.00372\n",
            "[10]\ttrain-aucpr:0.89871+0.00108\ttest-aucpr:0.89103+0.00216\n",
            "[11]\ttrain-aucpr:0.90387+0.00182\ttest-aucpr:0.89611+0.00226\n",
            "[12]\ttrain-aucpr:0.90796+0.00308\ttest-aucpr:0.90005+0.00332\n",
            "[13]\ttrain-aucpr:0.91089+0.00251\ttest-aucpr:0.90283+0.00223\n",
            "[14]\ttrain-aucpr:0.91468+0.00190\ttest-aucpr:0.90639+0.00206\n",
            "[15]\ttrain-aucpr:0.91783+0.00235\ttest-aucpr:0.90934+0.00278\n",
            "[16]\ttrain-aucpr:0.91965+0.00216\ttest-aucpr:0.91114+0.00209\n",
            "[17]\ttrain-aucpr:0.92165+0.00265\ttest-aucpr:0.91322+0.00278\n",
            "[18]\ttrain-aucpr:0.92351+0.00273\ttest-aucpr:0.91509+0.00272\n",
            "[19]\ttrain-aucpr:0.92562+0.00328\ttest-aucpr:0.91723+0.00321\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 10, 'gamma': 3, 'lambda': 1, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90560+0.00136\ttest-aucpr:0.87281+0.00246\n",
            "[1]\ttrain-aucpr:0.93138+0.00371\ttest-aucpr:0.90324+0.00377\n",
            "[2]\ttrain-aucpr:0.94181+0.00295\ttest-aucpr:0.91546+0.00261\n",
            "[3]\ttrain-aucpr:0.94852+0.00280\ttest-aucpr:0.92354+0.00318\n",
            "[4]\ttrain-aucpr:0.95339+0.00224\ttest-aucpr:0.92893+0.00228\n",
            "[5]\ttrain-aucpr:0.95770+0.00096\ttest-aucpr:0.93427+0.00122\n",
            "[6]\ttrain-aucpr:0.96061+0.00112\ttest-aucpr:0.93722+0.00081\n",
            "[7]\ttrain-aucpr:0.96275+0.00110\ttest-aucpr:0.93929+0.00083\n",
            "[8]\ttrain-aucpr:0.96501+0.00076\ttest-aucpr:0.94173+0.00098\n",
            "[9]\ttrain-aucpr:0.96701+0.00047\ttest-aucpr:0.94391+0.00050\n",
            "[10]\ttrain-aucpr:0.96869+0.00022\ttest-aucpr:0.94571+0.00087\n",
            "[11]\ttrain-aucpr:0.97022+0.00020\ttest-aucpr:0.94726+0.00064\n",
            "[12]\ttrain-aucpr:0.97141+0.00024\ttest-aucpr:0.94847+0.00048\n",
            "[13]\ttrain-aucpr:0.97253+0.00035\ttest-aucpr:0.94970+0.00024\n",
            "[14]\ttrain-aucpr:0.97353+0.00022\ttest-aucpr:0.95084+0.00033\n",
            "[15]\ttrain-aucpr:0.97467+0.00022\ttest-aucpr:0.95221+0.00034\n",
            "[16]\ttrain-aucpr:0.97580+0.00040\ttest-aucpr:0.95340+0.00038\n",
            "[17]\ttrain-aucpr:0.97659+0.00038\ttest-aucpr:0.95420+0.00039\n",
            "[18]\ttrain-aucpr:0.97736+0.00026\ttest-aucpr:0.95502+0.00038\n",
            "[19]\ttrain-aucpr:0.97818+0.00021\ttest-aucpr:0.95586+0.00038\n",
            "result:  0.9558574813295282\n",
            "best result:  0.9558574813295282\n",
            "hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 10, 'gamma': 3, 'lambda': 1, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "best hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 10, 'gamma': 3, 'lambda': 1, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 3, 'gamma': 0, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64563+0.00181\ttest-aucpr:0.64315+0.00505\n",
            "[1]\ttrain-aucpr:0.68916+0.00516\ttest-aucpr:0.68605+0.00458\n",
            "[2]\ttrain-aucpr:0.70762+0.00244\ttest-aucpr:0.70463+0.00583\n",
            "[3]\ttrain-aucpr:0.71815+0.00233\ttest-aucpr:0.71444+0.00571\n",
            "[4]\ttrain-aucpr:0.72935+0.00507\ttest-aucpr:0.72481+0.00983\n",
            "[5]\ttrain-aucpr:0.73475+0.00403\ttest-aucpr:0.73041+0.00907\n",
            "[6]\ttrain-aucpr:0.74144+0.00197\ttest-aucpr:0.73730+0.00612\n",
            "[7]\ttrain-aucpr:0.74512+0.00232\ttest-aucpr:0.74078+0.00549\n",
            "[8]\ttrain-aucpr:0.74908+0.00173\ttest-aucpr:0.74434+0.00441\n",
            "[9]\ttrain-aucpr:0.75073+0.00079\ttest-aucpr:0.74618+0.00414\n",
            "[10]\ttrain-aucpr:0.75240+0.00215\ttest-aucpr:0.74759+0.00479\n",
            "[11]\ttrain-aucpr:0.75616+0.00265\ttest-aucpr:0.75156+0.00445\n",
            "[12]\ttrain-aucpr:0.75850+0.00161\ttest-aucpr:0.75370+0.00417\n",
            "[13]\ttrain-aucpr:0.76290+0.00245\ttest-aucpr:0.75780+0.00201\n",
            "[14]\ttrain-aucpr:0.76493+0.00215\ttest-aucpr:0.76010+0.00309\n",
            "[15]\ttrain-aucpr:0.76779+0.00324\ttest-aucpr:0.76279+0.00328\n",
            "[16]\ttrain-aucpr:0.77002+0.00213\ttest-aucpr:0.76497+0.00301\n",
            "[17]\ttrain-aucpr:0.77335+0.00251\ttest-aucpr:0.76821+0.00227\n",
            "[18]\ttrain-aucpr:0.77641+0.00283\ttest-aucpr:0.77114+0.00366\n",
            "[19]\ttrain-aucpr:0.78056+0.00281\ttest-aucpr:0.77480+0.00361\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 20, 'gamma': 0, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.94669+0.00203\ttest-aucpr:0.88450+0.00314\n",
            "[1]\ttrain-aucpr:0.96495+0.00291\ttest-aucpr:0.90774+0.00501\n",
            "[2]\ttrain-aucpr:0.97536+0.00234\ttest-aucpr:0.92202+0.00414\n",
            "[3]\ttrain-aucpr:0.98032+0.00163\ttest-aucpr:0.93012+0.00276\n",
            "[4]\ttrain-aucpr:0.98418+0.00137\ttest-aucpr:0.93630+0.00233\n",
            "[5]\ttrain-aucpr:0.98717+0.00084\ttest-aucpr:0.94131+0.00210\n",
            "[6]\ttrain-aucpr:0.98915+0.00069\ttest-aucpr:0.94423+0.00167\n",
            "[7]\ttrain-aucpr:0.99068+0.00046\ttest-aucpr:0.94685+0.00141\n",
            "[8]\ttrain-aucpr:0.99197+0.00040\ttest-aucpr:0.94973+0.00114\n",
            "[9]\ttrain-aucpr:0.99287+0.00039\ttest-aucpr:0.95147+0.00103\n",
            "[10]\ttrain-aucpr:0.99371+0.00029\ttest-aucpr:0.95323+0.00086\n",
            "[11]\ttrain-aucpr:0.99441+0.00025\ttest-aucpr:0.95485+0.00099\n",
            "[12]\ttrain-aucpr:0.99495+0.00024\ttest-aucpr:0.95595+0.00082\n",
            "[13]\ttrain-aucpr:0.99545+0.00025\ttest-aucpr:0.95708+0.00062\n",
            "[14]\ttrain-aucpr:0.99591+0.00014\ttest-aucpr:0.95810+0.00051\n",
            "[15]\ttrain-aucpr:0.99630+0.00016\ttest-aucpr:0.95899+0.00044\n",
            "[16]\ttrain-aucpr:0.99667+0.00015\ttest-aucpr:0.96003+0.00033\n",
            "[17]\ttrain-aucpr:0.99693+0.00014\ttest-aucpr:0.96072+0.00034\n",
            "[18]\ttrain-aucpr:0.99719+0.00012\ttest-aucpr:0.96160+0.00054\n",
            "[19]\ttrain-aucpr:0.99744+0.00010\ttest-aucpr:0.96219+0.00056\n",
            "result:  0.9621872731832992\n",
            "best result:  0.9621872731832992\n",
            "hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 20, 'gamma': 0, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "best hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 20, 'gamma': 0, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 1, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.95555+0.00089\ttest-aucpr:0.88733+0.00278\n",
            "[1]\ttrain-aucpr:0.97987+0.00160\ttest-aucpr:0.91923+0.00264\n",
            "[2]\ttrain-aucpr:0.98830+0.00110\ttest-aucpr:0.93501+0.00291\n",
            "[3]\ttrain-aucpr:0.99182+0.00061\ttest-aucpr:0.94304+0.00234\n",
            "[4]\ttrain-aucpr:0.99392+0.00043\ttest-aucpr:0.94862+0.00150\n",
            "[5]\ttrain-aucpr:0.99538+0.00020\ttest-aucpr:0.95260+0.00105\n",
            "[6]\ttrain-aucpr:0.99631+0.00019\ttest-aucpr:0.95589+0.00121\n",
            "[7]\ttrain-aucpr:0.99709+0.00013\ttest-aucpr:0.95838+0.00098\n",
            "[8]\ttrain-aucpr:0.99762+0.00009\ttest-aucpr:0.96050+0.00092\n",
            "[9]\ttrain-aucpr:0.99804+0.00010\ttest-aucpr:0.96232+0.00086\n",
            "[10]\ttrain-aucpr:0.99837+0.00010\ttest-aucpr:0.96367+0.00061\n",
            "[11]\ttrain-aucpr:0.99866+0.00007\ttest-aucpr:0.96515+0.00070\n",
            "[12]\ttrain-aucpr:0.99888+0.00006\ttest-aucpr:0.96616+0.00060\n",
            "[13]\ttrain-aucpr:0.99906+0.00005\ttest-aucpr:0.96717+0.00058\n",
            "[14]\ttrain-aucpr:0.99920+0.00004\ttest-aucpr:0.96818+0.00077\n",
            "[15]\ttrain-aucpr:0.99932+0.00004\ttest-aucpr:0.96891+0.00079\n",
            "[16]\ttrain-aucpr:0.99941+0.00004\ttest-aucpr:0.96963+0.00084\n",
            "[17]\ttrain-aucpr:0.99949+0.00003\ttest-aucpr:0.97036+0.00089\n",
            "[18]\ttrain-aucpr:0.99957+0.00003\ttest-aucpr:0.97084+0.00094\n",
            "[19]\ttrain-aucpr:0.99962+0.00002\ttest-aucpr:0.97134+0.00099\n",
            "result:  0.9713368907046164\n",
            "best result:  0.9713368907046164\n",
            "hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 1, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "best hyperparameters:  {'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 1, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 3, 'gamma': 0, 'lambda': 3, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64563+0.00181\ttest-aucpr:0.64315+0.00505\n",
            "[1]\ttrain-aucpr:0.69979+0.00174\ttest-aucpr:0.69633+0.00534\n",
            "[2]\ttrain-aucpr:0.72408+0.00754\ttest-aucpr:0.71973+0.01007\n",
            "[3]\ttrain-aucpr:0.73763+0.00209\ttest-aucpr:0.73403+0.00556\n",
            "[4]\ttrain-aucpr:0.74849+0.00131\ttest-aucpr:0.74449+0.00515\n",
            "[5]\ttrain-aucpr:0.75306+0.00284\ttest-aucpr:0.74839+0.00202\n",
            "[6]\ttrain-aucpr:0.76399+0.00358\ttest-aucpr:0.75896+0.00563\n",
            "[7]\ttrain-aucpr:0.77440+0.00388\ttest-aucpr:0.76927+0.00502\n",
            "[8]\ttrain-aucpr:0.78349+0.00228\ttest-aucpr:0.77828+0.00214\n",
            "[9]\ttrain-aucpr:0.79097+0.00270\ttest-aucpr:0.78570+0.00044\n",
            "[10]\ttrain-aucpr:0.79791+0.00161\ttest-aucpr:0.79267+0.00191\n",
            "[11]\ttrain-aucpr:0.80409+0.00166\ttest-aucpr:0.79890+0.00328\n",
            "[12]\ttrain-aucpr:0.80800+0.00232\ttest-aucpr:0.80247+0.00270\n",
            "[13]\ttrain-aucpr:0.81439+0.00355\ttest-aucpr:0.80880+0.00373\n",
            "[14]\ttrain-aucpr:0.81976+0.00349\ttest-aucpr:0.81392+0.00393\n",
            "[15]\ttrain-aucpr:0.82372+0.00387\ttest-aucpr:0.81764+0.00323\n",
            "[16]\ttrain-aucpr:0.82728+0.00452\ttest-aucpr:0.82121+0.00374\n",
            "[17]\ttrain-aucpr:0.83238+0.00400\ttest-aucpr:0.82622+0.00430\n",
            "[18]\ttrain-aucpr:0.83627+0.00462\ttest-aucpr:0.83022+0.00562\n",
            "[19]\ttrain-aucpr:0.83893+0.00416\ttest-aucpr:0.83280+0.00508\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 1, 'lambda': 2, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.95752+0.00066\ttest-aucpr:0.88951+0.00308\n",
            "[1]\ttrain-aucpr:0.98161+0.00142\ttest-aucpr:0.91862+0.00349\n",
            "[2]\ttrain-aucpr:0.98959+0.00056\ttest-aucpr:0.93323+0.00072\n",
            "[3]\ttrain-aucpr:0.99333+0.00038\ttest-aucpr:0.94294+0.00132\n",
            "[4]\ttrain-aucpr:0.99539+0.00007\ttest-aucpr:0.94884+0.00132\n",
            "[5]\ttrain-aucpr:0.99661+0.00009\ttest-aucpr:0.95324+0.00085\n",
            "[6]\ttrain-aucpr:0.99741+0.00007\ttest-aucpr:0.95635+0.00081\n",
            "[7]\ttrain-aucpr:0.99804+0.00008\ttest-aucpr:0.95861+0.00074\n",
            "[8]\ttrain-aucpr:0.99847+0.00005\ttest-aucpr:0.96095+0.00071\n",
            "[9]\ttrain-aucpr:0.99878+0.00003\ttest-aucpr:0.96255+0.00080\n",
            "[10]\ttrain-aucpr:0.99904+0.00005\ttest-aucpr:0.96405+0.00047\n",
            "[11]\ttrain-aucpr:0.99925+0.00001\ttest-aucpr:0.96533+0.00057\n",
            "[12]\ttrain-aucpr:0.99941+0.00001\ttest-aucpr:0.96634+0.00042\n",
            "[13]\ttrain-aucpr:0.99953+0.00002\ttest-aucpr:0.96736+0.00042\n",
            "[14]\ttrain-aucpr:0.99963+0.00002\ttest-aucpr:0.96824+0.00051\n",
            "[15]\ttrain-aucpr:0.99970+0.00002\ttest-aucpr:0.96896+0.00047\n",
            "[16]\ttrain-aucpr:0.99975+0.00002\ttest-aucpr:0.96960+0.00051\n",
            "[17]\ttrain-aucpr:0.99980+0.00001\ttest-aucpr:0.97020+0.00048\n",
            "[18]\ttrain-aucpr:0.99984+0.00001\ttest-aucpr:0.97081+0.00037\n",
            "[19]\ttrain-aucpr:0.99987+0.00001\ttest-aucpr:0.97130+0.00041\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 5, 'gamma': 0, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76550+0.00231\ttest-aucpr:0.75917+0.00435\n",
            "[1]\ttrain-aucpr:0.79807+0.00432\ttest-aucpr:0.79129+0.00387\n",
            "[2]\ttrain-aucpr:0.81769+0.00272\ttest-aucpr:0.81111+0.00389\n",
            "[3]\ttrain-aucpr:0.82860+0.00115\ttest-aucpr:0.82209+0.00434\n",
            "[4]\ttrain-aucpr:0.83620+0.00319\ttest-aucpr:0.82952+0.00443\n",
            "[5]\ttrain-aucpr:0.84293+0.00181\ttest-aucpr:0.83648+0.00364\n",
            "[6]\ttrain-aucpr:0.84708+0.00196\ttest-aucpr:0.84017+0.00392\n",
            "[7]\ttrain-aucpr:0.85182+0.00140\ttest-aucpr:0.84437+0.00225\n",
            "[8]\ttrain-aucpr:0.85580+0.00098\ttest-aucpr:0.84853+0.00285\n",
            "[9]\ttrain-aucpr:0.85999+0.00095\ttest-aucpr:0.85280+0.00295\n",
            "[10]\ttrain-aucpr:0.86374+0.00037\ttest-aucpr:0.85669+0.00256\n",
            "[11]\ttrain-aucpr:0.86764+0.00160\ttest-aucpr:0.86035+0.00308\n",
            "[12]\ttrain-aucpr:0.87089+0.00103\ttest-aucpr:0.86341+0.00286\n",
            "[13]\ttrain-aucpr:0.87371+0.00092\ttest-aucpr:0.86620+0.00279\n",
            "[14]\ttrain-aucpr:0.87702+0.00092\ttest-aucpr:0.86956+0.00251\n",
            "[15]\ttrain-aucpr:0.87958+0.00084\ttest-aucpr:0.87198+0.00259\n",
            "[16]\ttrain-aucpr:0.88188+0.00096\ttest-aucpr:0.87414+0.00281\n",
            "[17]\ttrain-aucpr:0.88406+0.00114\ttest-aucpr:0.87609+0.00280\n",
            "[18]\ttrain-aucpr:0.88744+0.00130\ttest-aucpr:0.87926+0.00249\n",
            "[19]\ttrain-aucpr:0.88949+0.00149\ttest-aucpr:0.88124+0.00284\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 3, 'gamma': 0, 'lambda': 1, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64571+0.00171\ttest-aucpr:0.64300+0.00505\n",
            "[1]\ttrain-aucpr:0.68945+0.00533\ttest-aucpr:0.68631+0.00481\n",
            "[2]\ttrain-aucpr:0.70779+0.00228\ttest-aucpr:0.70469+0.00584\n",
            "[3]\ttrain-aucpr:0.71829+0.00226\ttest-aucpr:0.71451+0.00574\n",
            "[4]\ttrain-aucpr:0.72944+0.00515\ttest-aucpr:0.72491+0.00992\n",
            "[5]\ttrain-aucpr:0.73478+0.00406\ttest-aucpr:0.73042+0.00908\n",
            "[6]\ttrain-aucpr:0.74147+0.00198\ttest-aucpr:0.73732+0.00612\n",
            "[7]\ttrain-aucpr:0.74517+0.00230\ttest-aucpr:0.74083+0.00550\n",
            "[8]\ttrain-aucpr:0.74914+0.00175\ttest-aucpr:0.74438+0.00441\n",
            "[9]\ttrain-aucpr:0.75080+0.00085\ttest-aucpr:0.74623+0.00417\n",
            "[10]\ttrain-aucpr:0.75245+0.00215\ttest-aucpr:0.74762+0.00479\n",
            "[11]\ttrain-aucpr:0.75622+0.00268\ttest-aucpr:0.75159+0.00444\n",
            "[12]\ttrain-aucpr:0.75858+0.00165\ttest-aucpr:0.75371+0.00411\n",
            "[13]\ttrain-aucpr:0.76305+0.00231\ttest-aucpr:0.75788+0.00194\n",
            "[14]\ttrain-aucpr:0.76508+0.00199\ttest-aucpr:0.76020+0.00303\n",
            "[15]\ttrain-aucpr:0.76758+0.00364\ttest-aucpr:0.76262+0.00341\n",
            "[16]\ttrain-aucpr:0.76989+0.00242\ttest-aucpr:0.76480+0.00301\n",
            "[17]\ttrain-aucpr:0.77372+0.00206\ttest-aucpr:0.76851+0.00204\n",
            "[18]\ttrain-aucpr:0.77671+0.00247\ttest-aucpr:0.77134+0.00347\n",
            "[19]\ttrain-aucpr:0.78047+0.00316\ttest-aucpr:0.77465+0.00370\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 5, 'gamma': 3, 'lambda': 1, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76569+0.00223\ttest-aucpr:0.75902+0.00403\n",
            "[1]\ttrain-aucpr:0.81349+0.00249\ttest-aucpr:0.80541+0.00348\n",
            "[2]\ttrain-aucpr:0.83384+0.00283\ttest-aucpr:0.82622+0.00343\n",
            "[3]\ttrain-aucpr:0.84957+0.00175\ttest-aucpr:0.84230+0.00258\n",
            "[4]\ttrain-aucpr:0.85957+0.00124\ttest-aucpr:0.85205+0.00262\n",
            "[5]\ttrain-aucpr:0.86772+0.00294\ttest-aucpr:0.86016+0.00411\n",
            "[6]\ttrain-aucpr:0.87563+0.00216\ttest-aucpr:0.86792+0.00401\n",
            "[7]\ttrain-aucpr:0.88307+0.00263\ttest-aucpr:0.87529+0.00418\n",
            "[8]\ttrain-aucpr:0.88884+0.00110\ttest-aucpr:0.88119+0.00137\n",
            "[9]\ttrain-aucpr:0.89481+0.00136\ttest-aucpr:0.88704+0.00242\n",
            "[10]\ttrain-aucpr:0.89810+0.00080\ttest-aucpr:0.89005+0.00161\n",
            "[11]\ttrain-aucpr:0.90183+0.00033\ttest-aucpr:0.89373+0.00146\n",
            "[12]\ttrain-aucpr:0.90700+0.00128\ttest-aucpr:0.89889+0.00060\n",
            "[13]\ttrain-aucpr:0.91026+0.00239\ttest-aucpr:0.90216+0.00215\n",
            "[14]\ttrain-aucpr:0.91400+0.00227\ttest-aucpr:0.90591+0.00184\n",
            "[15]\ttrain-aucpr:0.91630+0.00253\ttest-aucpr:0.90810+0.00227\n",
            "[16]\ttrain-aucpr:0.91886+0.00255\ttest-aucpr:0.91071+0.00266\n",
            "[17]\ttrain-aucpr:0.92122+0.00209\ttest-aucpr:0.91296+0.00211\n",
            "[18]\ttrain-aucpr:0.92320+0.00226\ttest-aucpr:0.91482+0.00221\n",
            "[19]\ttrain-aucpr:0.92519+0.00272\ttest-aucpr:0.91667+0.00267\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 3, 'gamma': 3, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64563+0.00181\ttest-aucpr:0.64315+0.00505\n",
            "[1]\ttrain-aucpr:0.68919+0.00517\ttest-aucpr:0.68607+0.00460\n",
            "[2]\ttrain-aucpr:0.70762+0.00244\ttest-aucpr:0.70463+0.00583\n",
            "[3]\ttrain-aucpr:0.71817+0.00233\ttest-aucpr:0.71445+0.00572\n",
            "[4]\ttrain-aucpr:0.72933+0.00507\ttest-aucpr:0.72479+0.00983\n",
            "[5]\ttrain-aucpr:0.73475+0.00404\ttest-aucpr:0.73041+0.00907\n",
            "[6]\ttrain-aucpr:0.74145+0.00197\ttest-aucpr:0.73730+0.00612\n",
            "[7]\ttrain-aucpr:0.74513+0.00231\ttest-aucpr:0.74078+0.00549\n",
            "[8]\ttrain-aucpr:0.74910+0.00172\ttest-aucpr:0.74436+0.00439\n",
            "[9]\ttrain-aucpr:0.75074+0.00078\ttest-aucpr:0.74619+0.00414\n",
            "[10]\ttrain-aucpr:0.75242+0.00215\ttest-aucpr:0.74761+0.00479\n",
            "[11]\ttrain-aucpr:0.75617+0.00265\ttest-aucpr:0.75156+0.00443\n",
            "[12]\ttrain-aucpr:0.75852+0.00161\ttest-aucpr:0.75368+0.00411\n",
            "[13]\ttrain-aucpr:0.76302+0.00235\ttest-aucpr:0.75786+0.00194\n",
            "[14]\ttrain-aucpr:0.76505+0.00199\ttest-aucpr:0.76018+0.00302\n",
            "[15]\ttrain-aucpr:0.76754+0.00363\ttest-aucpr:0.76257+0.00343\n",
            "[16]\ttrain-aucpr:0.76984+0.00241\ttest-aucpr:0.76475+0.00305\n",
            "[17]\ttrain-aucpr:0.77368+0.00206\ttest-aucpr:0.76847+0.00208\n",
            "[18]\ttrain-aucpr:0.77667+0.00245\ttest-aucpr:0.77129+0.00352\n",
            "[19]\ttrain-aucpr:0.78042+0.00315\ttest-aucpr:0.77460+0.00373\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 3, 'gamma': 3, 'lambda': 1, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64571+0.00171\ttest-aucpr:0.64300+0.00505\n",
            "[1]\ttrain-aucpr:0.69996+0.00178\ttest-aucpr:0.69634+0.00534\n",
            "[2]\ttrain-aucpr:0.72428+0.00732\ttest-aucpr:0.71979+0.01005\n",
            "[3]\ttrain-aucpr:0.73812+0.00237\ttest-aucpr:0.73389+0.00550\n",
            "[4]\ttrain-aucpr:0.74914+0.00187\ttest-aucpr:0.74508+0.00522\n",
            "[5]\ttrain-aucpr:0.75370+0.00235\ttest-aucpr:0.74899+0.00137\n",
            "[6]\ttrain-aucpr:0.76480+0.00353\ttest-aucpr:0.75970+0.00542\n",
            "[7]\ttrain-aucpr:0.77330+0.00225\ttest-aucpr:0.76828+0.00398\n",
            "[8]\ttrain-aucpr:0.78143+0.00403\ttest-aucpr:0.77629+0.00409\n",
            "[9]\ttrain-aucpr:0.78920+0.00341\ttest-aucpr:0.78401+0.00238\n",
            "[10]\ttrain-aucpr:0.79564+0.00400\ttest-aucpr:0.79041+0.00363\n",
            "[11]\ttrain-aucpr:0.80268+0.00379\ttest-aucpr:0.79778+0.00413\n",
            "[12]\ttrain-aucpr:0.80901+0.00186\ttest-aucpr:0.80386+0.00164\n",
            "[13]\ttrain-aucpr:0.81633+0.00264\ttest-aucpr:0.81099+0.00205\n",
            "[14]\ttrain-aucpr:0.82101+0.00283\ttest-aucpr:0.81542+0.00336\n",
            "[15]\ttrain-aucpr:0.82425+0.00309\ttest-aucpr:0.81874+0.00328\n",
            "[16]\ttrain-aucpr:0.82800+0.00388\ttest-aucpr:0.82251+0.00443\n",
            "[17]\ttrain-aucpr:0.83153+0.00326\ttest-aucpr:0.82601+0.00497\n",
            "[18]\ttrain-aucpr:0.83714+0.00166\ttest-aucpr:0.83188+0.00329\n",
            "[19]\ttrain-aucpr:0.83971+0.00204\ttest-aucpr:0.83441+0.00379\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 3, 'gamma': 3, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64563+0.00181\ttest-aucpr:0.64315+0.00505\n",
            "[1]\ttrain-aucpr:0.69980+0.00174\ttest-aucpr:0.69634+0.00534\n",
            "[2]\ttrain-aucpr:0.72409+0.00755\ttest-aucpr:0.71974+0.01007\n",
            "[3]\ttrain-aucpr:0.73762+0.00207\ttest-aucpr:0.73401+0.00555\n",
            "[4]\ttrain-aucpr:0.74851+0.00130\ttest-aucpr:0.74450+0.00514\n",
            "[5]\ttrain-aucpr:0.75307+0.00283\ttest-aucpr:0.74840+0.00201\n",
            "[6]\ttrain-aucpr:0.76401+0.00358\ttest-aucpr:0.75897+0.00562\n",
            "[7]\ttrain-aucpr:0.77443+0.00387\ttest-aucpr:0.76929+0.00502\n",
            "[8]\ttrain-aucpr:0.78353+0.00228\ttest-aucpr:0.77830+0.00214\n",
            "[9]\ttrain-aucpr:0.79100+0.00270\ttest-aucpr:0.78574+0.00044\n",
            "[10]\ttrain-aucpr:0.79796+0.00161\ttest-aucpr:0.79272+0.00191\n",
            "[11]\ttrain-aucpr:0.80414+0.00167\ttest-aucpr:0.79894+0.00328\n",
            "[12]\ttrain-aucpr:0.80805+0.00231\ttest-aucpr:0.80253+0.00271\n",
            "[13]\ttrain-aucpr:0.81445+0.00354\ttest-aucpr:0.80886+0.00372\n",
            "[14]\ttrain-aucpr:0.81982+0.00349\ttest-aucpr:0.81398+0.00393\n",
            "[15]\ttrain-aucpr:0.82378+0.00386\ttest-aucpr:0.81770+0.00322\n",
            "[16]\ttrain-aucpr:0.82735+0.00451\ttest-aucpr:0.82128+0.00374\n",
            "[17]\ttrain-aucpr:0.83244+0.00400\ttest-aucpr:0.82628+0.00430\n",
            "[18]\ttrain-aucpr:0.83634+0.00463\ttest-aucpr:0.83028+0.00562\n",
            "[19]\ttrain-aucpr:0.83899+0.00417\ttest-aucpr:0.83285+0.00509\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 10, 'gamma': 3, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90143+0.00174\ttest-aucpr:0.87209+0.00410\n",
            "[1]\ttrain-aucpr:0.93481+0.00131\ttest-aucpr:0.90821+0.00184\n",
            "[2]\ttrain-aucpr:0.94936+0.00095\ttest-aucpr:0.92508+0.00082\n",
            "[3]\ttrain-aucpr:0.95746+0.00102\ttest-aucpr:0.93383+0.00131\n",
            "[4]\ttrain-aucpr:0.96245+0.00090\ttest-aucpr:0.93935+0.00062\n",
            "[5]\ttrain-aucpr:0.96621+0.00108\ttest-aucpr:0.94336+0.00079\n",
            "[6]\ttrain-aucpr:0.96954+0.00123\ttest-aucpr:0.94693+0.00100\n",
            "[7]\ttrain-aucpr:0.97212+0.00130\ttest-aucpr:0.94966+0.00105\n",
            "[8]\ttrain-aucpr:0.97436+0.00095\ttest-aucpr:0.95238+0.00065\n",
            "[9]\ttrain-aucpr:0.97658+0.00079\ttest-aucpr:0.95482+0.00055\n",
            "[10]\ttrain-aucpr:0.97821+0.00052\ttest-aucpr:0.95685+0.00037\n",
            "[11]\ttrain-aucpr:0.97939+0.00044\ttest-aucpr:0.95822+0.00038\n",
            "[12]\ttrain-aucpr:0.98029+0.00047\ttest-aucpr:0.95936+0.00071\n",
            "[13]\ttrain-aucpr:0.98130+0.00051\ttest-aucpr:0.96064+0.00049\n",
            "[14]\ttrain-aucpr:0.98255+0.00043\ttest-aucpr:0.96222+0.00027\n",
            "[15]\ttrain-aucpr:0.98318+0.00046\ttest-aucpr:0.96309+0.00020\n",
            "[16]\ttrain-aucpr:0.98392+0.00052\ttest-aucpr:0.96400+0.00053\n",
            "[17]\ttrain-aucpr:0.98439+0.00054\ttest-aucpr:0.96476+0.00050\n",
            "[18]\ttrain-aucpr:0.98489+0.00075\ttest-aucpr:0.96538+0.00043\n",
            "[19]\ttrain-aucpr:0.98532+0.00061\ttest-aucpr:0.96596+0.00042\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 10, 'gamma': 3, 'lambda': 2, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90107+0.00181\ttest-aucpr:0.87201+0.00406\n",
            "[1]\ttrain-aucpr:0.92761+0.00399\ttest-aucpr:0.90065+0.00401\n",
            "[2]\ttrain-aucpr:0.93951+0.00295\ttest-aucpr:0.91439+0.00244\n",
            "[3]\ttrain-aucpr:0.94586+0.00238\ttest-aucpr:0.92160+0.00217\n",
            "[4]\ttrain-aucpr:0.95245+0.00125\ttest-aucpr:0.92944+0.00152\n",
            "[5]\ttrain-aucpr:0.95588+0.00136\ttest-aucpr:0.93315+0.00114\n",
            "[6]\ttrain-aucpr:0.95862+0.00086\ttest-aucpr:0.93630+0.00085\n",
            "[7]\ttrain-aucpr:0.96064+0.00092\ttest-aucpr:0.93849+0.00088\n",
            "[8]\ttrain-aucpr:0.96290+0.00077\ttest-aucpr:0.94087+0.00073\n",
            "[9]\ttrain-aucpr:0.96449+0.00072\ttest-aucpr:0.94249+0.00027\n",
            "[10]\ttrain-aucpr:0.96624+0.00031\ttest-aucpr:0.94429+0.00045\n",
            "[11]\ttrain-aucpr:0.96761+0.00043\ttest-aucpr:0.94576+0.00045\n",
            "[12]\ttrain-aucpr:0.96890+0.00046\ttest-aucpr:0.94701+0.00049\n",
            "[13]\ttrain-aucpr:0.97039+0.00061\ttest-aucpr:0.94880+0.00062\n",
            "[14]\ttrain-aucpr:0.97154+0.00062\ttest-aucpr:0.95004+0.00067\n",
            "[15]\ttrain-aucpr:0.97263+0.00084\ttest-aucpr:0.95115+0.00068\n",
            "[16]\ttrain-aucpr:0.97373+0.00100\ttest-aucpr:0.95239+0.00095\n",
            "[17]\ttrain-aucpr:0.97459+0.00088\ttest-aucpr:0.95338+0.00108\n",
            "[18]\ttrain-aucpr:0.97543+0.00085\ttest-aucpr:0.95435+0.00087\n",
            "[19]\ttrain-aucpr:0.97630+0.00102\ttest-aucpr:0.95526+0.00108\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 3, 'gamma': 0, 'lambda': 2, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64563+0.00181\ttest-aucpr:0.64315+0.00505\n",
            "[1]\ttrain-aucpr:0.69979+0.00174\ttest-aucpr:0.69633+0.00534\n",
            "[2]\ttrain-aucpr:0.72408+0.00755\ttest-aucpr:0.71973+0.01008\n",
            "[3]\ttrain-aucpr:0.73762+0.00208\ttest-aucpr:0.73402+0.00557\n",
            "[4]\ttrain-aucpr:0.74849+0.00131\ttest-aucpr:0.74448+0.00515\n",
            "[5]\ttrain-aucpr:0.75305+0.00284\ttest-aucpr:0.74838+0.00202\n",
            "[6]\ttrain-aucpr:0.76399+0.00358\ttest-aucpr:0.75895+0.00563\n",
            "[7]\ttrain-aucpr:0.77439+0.00388\ttest-aucpr:0.76926+0.00502\n",
            "[8]\ttrain-aucpr:0.78349+0.00228\ttest-aucpr:0.77827+0.00214\n",
            "[9]\ttrain-aucpr:0.79096+0.00271\ttest-aucpr:0.78570+0.00045\n",
            "[10]\ttrain-aucpr:0.79791+0.00161\ttest-aucpr:0.79267+0.00191\n",
            "[11]\ttrain-aucpr:0.80409+0.00166\ttest-aucpr:0.79889+0.00328\n",
            "[12]\ttrain-aucpr:0.80800+0.00232\ttest-aucpr:0.80247+0.00270\n",
            "[13]\ttrain-aucpr:0.81439+0.00355\ttest-aucpr:0.80880+0.00372\n",
            "[14]\ttrain-aucpr:0.81976+0.00349\ttest-aucpr:0.81392+0.00392\n",
            "[15]\ttrain-aucpr:0.82411+0.00447\ttest-aucpr:0.81813+0.00418\n",
            "[16]\ttrain-aucpr:0.82775+0.00520\ttest-aucpr:0.82170+0.00470\n",
            "[17]\ttrain-aucpr:0.83303+0.00484\ttest-aucpr:0.82689+0.00525\n",
            "[18]\ttrain-aucpr:0.83699+0.00510\ttest-aucpr:0.83099+0.00622\n",
            "[19]\ttrain-aucpr:0.83933+0.00456\ttest-aucpr:0.83319+0.00548\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 20, 'gamma': 1, 'lambda': 1, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.96995+0.00060\ttest-aucpr:0.89124+0.00327\n",
            "[1]\ttrain-aucpr:0.98800+0.00114\ttest-aucpr:0.91813+0.00197\n",
            "[2]\ttrain-aucpr:0.99404+0.00072\ttest-aucpr:0.93402+0.00240\n",
            "[3]\ttrain-aucpr:0.99648+0.00043\ttest-aucpr:0.94225+0.00277\n",
            "[4]\ttrain-aucpr:0.99777+0.00018\ttest-aucpr:0.94829+0.00208\n",
            "[5]\ttrain-aucpr:0.99853+0.00011\ttest-aucpr:0.95284+0.00202\n",
            "[6]\ttrain-aucpr:0.99897+0.00009\ttest-aucpr:0.95597+0.00165\n",
            "[7]\ttrain-aucpr:0.99924+0.00008\ttest-aucpr:0.95835+0.00148\n",
            "[8]\ttrain-aucpr:0.99945+0.00005\ttest-aucpr:0.96022+0.00134\n",
            "[9]\ttrain-aucpr:0.99961+0.00006\ttest-aucpr:0.96192+0.00110\n",
            "[10]\ttrain-aucpr:0.99970+0.00005\ttest-aucpr:0.96339+0.00106\n",
            "[11]\ttrain-aucpr:0.99979+0.00003\ttest-aucpr:0.96457+0.00105\n",
            "[12]\ttrain-aucpr:0.99985+0.00002\ttest-aucpr:0.96563+0.00095\n",
            "[13]\ttrain-aucpr:0.99989+0.00001\ttest-aucpr:0.96666+0.00111\n",
            "[14]\ttrain-aucpr:0.99992+0.00001\ttest-aucpr:0.96772+0.00087\n",
            "[15]\ttrain-aucpr:0.99994+0.00001\ttest-aucpr:0.96842+0.00079\n",
            "[16]\ttrain-aucpr:0.99996+0.00001\ttest-aucpr:0.96922+0.00078\n",
            "[17]\ttrain-aucpr:0.99997+0.00001\ttest-aucpr:0.96981+0.00091\n",
            "[18]\ttrain-aucpr:0.99998+0.00000\ttest-aucpr:0.97035+0.00095\n",
            "[19]\ttrain-aucpr:0.99998+0.00000\ttest-aucpr:0.97082+0.00099\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 5, 'gamma': 3, 'lambda': 1, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76569+0.00223\ttest-aucpr:0.75902+0.00402\n",
            "[1]\ttrain-aucpr:0.79887+0.00361\ttest-aucpr:0.79184+0.00372\n",
            "[2]\ttrain-aucpr:0.81831+0.00312\ttest-aucpr:0.81134+0.00402\n",
            "[3]\ttrain-aucpr:0.82970+0.00179\ttest-aucpr:0.82294+0.00487\n",
            "[4]\ttrain-aucpr:0.83700+0.00306\ttest-aucpr:0.83006+0.00456\n",
            "[5]\ttrain-aucpr:0.84354+0.00213\ttest-aucpr:0.83694+0.00378\n",
            "[6]\ttrain-aucpr:0.84714+0.00189\ttest-aucpr:0.84010+0.00377\n",
            "[7]\ttrain-aucpr:0.85265+0.00180\ttest-aucpr:0.84523+0.00248\n",
            "[8]\ttrain-aucpr:0.85632+0.00130\ttest-aucpr:0.84904+0.00272\n",
            "[9]\ttrain-aucpr:0.86071+0.00142\ttest-aucpr:0.85347+0.00328\n",
            "[10]\ttrain-aucpr:0.86405+0.00092\ttest-aucpr:0.85671+0.00278\n",
            "[11]\ttrain-aucpr:0.86777+0.00084\ttest-aucpr:0.86032+0.00215\n",
            "[12]\ttrain-aucpr:0.87107+0.00076\ttest-aucpr:0.86358+0.00222\n",
            "[13]\ttrain-aucpr:0.87356+0.00068\ttest-aucpr:0.86599+0.00242\n",
            "[14]\ttrain-aucpr:0.87669+0.00070\ttest-aucpr:0.86923+0.00258\n",
            "[15]\ttrain-aucpr:0.87924+0.00058\ttest-aucpr:0.87175+0.00216\n",
            "[16]\ttrain-aucpr:0.88214+0.00103\ttest-aucpr:0.87452+0.00221\n",
            "[17]\ttrain-aucpr:0.88479+0.00100\ttest-aucpr:0.87706+0.00226\n",
            "[18]\ttrain-aucpr:0.88692+0.00113\ttest-aucpr:0.87919+0.00265\n",
            "[19]\ttrain-aucpr:0.89032+0.00092\ttest-aucpr:0.88262+0.00212\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 10, 'gamma': 1, 'lambda': 1, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90648+0.00131\ttest-aucpr:0.87250+0.00255\n",
            "[1]\ttrain-aucpr:0.93227+0.00376\ttest-aucpr:0.90315+0.00362\n",
            "[2]\ttrain-aucpr:0.94224+0.00211\ttest-aucpr:0.91512+0.00145\n",
            "[3]\ttrain-aucpr:0.94845+0.00199\ttest-aucpr:0.92203+0.00166\n",
            "[4]\ttrain-aucpr:0.95365+0.00173\ttest-aucpr:0.92839+0.00185\n",
            "[5]\ttrain-aucpr:0.95819+0.00062\ttest-aucpr:0.93349+0.00071\n",
            "[6]\ttrain-aucpr:0.96129+0.00099\ttest-aucpr:0.93693+0.00075\n",
            "[7]\ttrain-aucpr:0.96351+0.00087\ttest-aucpr:0.93913+0.00053\n",
            "[8]\ttrain-aucpr:0.96553+0.00085\ttest-aucpr:0.94118+0.00069\n",
            "[9]\ttrain-aucpr:0.96761+0.00101\ttest-aucpr:0.94329+0.00088\n",
            "[10]\ttrain-aucpr:0.96913+0.00080\ttest-aucpr:0.94480+0.00058\n",
            "[11]\ttrain-aucpr:0.97052+0.00081\ttest-aucpr:0.94627+0.00069\n",
            "[12]\ttrain-aucpr:0.97201+0.00057\ttest-aucpr:0.94783+0.00054\n",
            "[13]\ttrain-aucpr:0.97308+0.00060\ttest-aucpr:0.94886+0.00061\n",
            "[14]\ttrain-aucpr:0.97422+0.00055\ttest-aucpr:0.95007+0.00057\n",
            "[15]\ttrain-aucpr:0.97536+0.00053\ttest-aucpr:0.95115+0.00067\n",
            "[16]\ttrain-aucpr:0.97624+0.00042\ttest-aucpr:0.95221+0.00063\n",
            "[17]\ttrain-aucpr:0.97729+0.00049\ttest-aucpr:0.95323+0.00072\n",
            "[18]\ttrain-aucpr:0.97820+0.00044\ttest-aucpr:0.95427+0.00081\n",
            "[19]\ttrain-aucpr:0.97899+0.00050\ttest-aucpr:0.95510+0.00080\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 5, 'gamma': 3, 'lambda': 2, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76562+0.00227\ttest-aucpr:0.75887+0.00420\n",
            "[1]\ttrain-aucpr:0.81337+0.00230\ttest-aucpr:0.80537+0.00343\n",
            "[2]\ttrain-aucpr:0.83328+0.00309\ttest-aucpr:0.82599+0.00338\n",
            "[3]\ttrain-aucpr:0.84947+0.00147\ttest-aucpr:0.84236+0.00255\n",
            "[4]\ttrain-aucpr:0.85936+0.00094\ttest-aucpr:0.85202+0.00250\n",
            "[5]\ttrain-aucpr:0.86762+0.00275\ttest-aucpr:0.86011+0.00398\n",
            "[6]\ttrain-aucpr:0.87499+0.00138\ttest-aucpr:0.86730+0.00306\n",
            "[7]\ttrain-aucpr:0.88209+0.00234\ttest-aucpr:0.87446+0.00337\n",
            "[8]\ttrain-aucpr:0.88837+0.00227\ttest-aucpr:0.88052+0.00217\n",
            "[9]\ttrain-aucpr:0.89361+0.00226\ttest-aucpr:0.88577+0.00276\n",
            "[10]\ttrain-aucpr:0.89709+0.00179\ttest-aucpr:0.88897+0.00235\n",
            "[11]\ttrain-aucpr:0.90149+0.00180\ttest-aucpr:0.89335+0.00287\n",
            "[12]\ttrain-aucpr:0.90548+0.00101\ttest-aucpr:0.89725+0.00195\n",
            "[13]\ttrain-aucpr:0.90933+0.00136\ttest-aucpr:0.90113+0.00241\n",
            "[14]\ttrain-aucpr:0.91240+0.00122\ttest-aucpr:0.90415+0.00211\n",
            "[15]\ttrain-aucpr:0.91515+0.00106\ttest-aucpr:0.90709+0.00146\n",
            "[16]\ttrain-aucpr:0.91742+0.00093\ttest-aucpr:0.90934+0.00074\n",
            "[17]\ttrain-aucpr:0.91991+0.00190\ttest-aucpr:0.91169+0.00258\n",
            "[18]\ttrain-aucpr:0.92227+0.00253\ttest-aucpr:0.91407+0.00346\n",
            "[19]\ttrain-aucpr:0.92493+0.00176\ttest-aucpr:0.91673+0.00257\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 3, 'gamma': 0, 'lambda': 1, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64563+0.00181\ttest-aucpr:0.64315+0.00505\n",
            "[1]\ttrain-aucpr:0.68919+0.00517\ttest-aucpr:0.68607+0.00460\n",
            "[2]\ttrain-aucpr:0.70762+0.00244\ttest-aucpr:0.70463+0.00583\n",
            "[3]\ttrain-aucpr:0.71817+0.00233\ttest-aucpr:0.71445+0.00572\n",
            "[4]\ttrain-aucpr:0.72933+0.00507\ttest-aucpr:0.72479+0.00983\n",
            "[5]\ttrain-aucpr:0.73475+0.00404\ttest-aucpr:0.73041+0.00907\n",
            "[6]\ttrain-aucpr:0.74145+0.00197\ttest-aucpr:0.73730+0.00612\n",
            "[7]\ttrain-aucpr:0.74513+0.00231\ttest-aucpr:0.74078+0.00549\n",
            "[8]\ttrain-aucpr:0.74910+0.00172\ttest-aucpr:0.74436+0.00439\n",
            "[9]\ttrain-aucpr:0.75074+0.00078\ttest-aucpr:0.74619+0.00414\n",
            "[10]\ttrain-aucpr:0.75242+0.00215\ttest-aucpr:0.74761+0.00479\n",
            "[11]\ttrain-aucpr:0.75617+0.00265\ttest-aucpr:0.75156+0.00443\n",
            "[12]\ttrain-aucpr:0.75852+0.00161\ttest-aucpr:0.75368+0.00411\n",
            "[13]\ttrain-aucpr:0.76302+0.00235\ttest-aucpr:0.75786+0.00194\n",
            "[14]\ttrain-aucpr:0.76505+0.00199\ttest-aucpr:0.76018+0.00302\n",
            "[15]\ttrain-aucpr:0.76754+0.00363\ttest-aucpr:0.76257+0.00343\n",
            "[16]\ttrain-aucpr:0.76984+0.00241\ttest-aucpr:0.76475+0.00305\n",
            "[17]\ttrain-aucpr:0.77368+0.00206\ttest-aucpr:0.76847+0.00208\n",
            "[18]\ttrain-aucpr:0.77667+0.00245\ttest-aucpr:0.77129+0.00352\n",
            "[19]\ttrain-aucpr:0.78042+0.00315\ttest-aucpr:0.77460+0.00373\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 5, 'gamma': 1, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76550+0.00231\ttest-aucpr:0.75917+0.00435\n",
            "[1]\ttrain-aucpr:0.81329+0.00228\ttest-aucpr:0.80537+0.00332\n",
            "[2]\ttrain-aucpr:0.83322+0.00300\ttest-aucpr:0.82593+0.00336\n",
            "[3]\ttrain-aucpr:0.84949+0.00146\ttest-aucpr:0.84230+0.00261\n",
            "[4]\ttrain-aucpr:0.85945+0.00091\ttest-aucpr:0.85195+0.00265\n",
            "[5]\ttrain-aucpr:0.86692+0.00230\ttest-aucpr:0.85960+0.00352\n",
            "[6]\ttrain-aucpr:0.87440+0.00160\ttest-aucpr:0.86668+0.00273\n",
            "[7]\ttrain-aucpr:0.88236+0.00259\ttest-aucpr:0.87460+0.00358\n",
            "[8]\ttrain-aucpr:0.88904+0.00102\ttest-aucpr:0.88132+0.00140\n",
            "[9]\ttrain-aucpr:0.89339+0.00155\ttest-aucpr:0.88553+0.00096\n",
            "[10]\ttrain-aucpr:0.89747+0.00144\ttest-aucpr:0.88909+0.00035\n",
            "[11]\ttrain-aucpr:0.90172+0.00147\ttest-aucpr:0.89324+0.00101\n",
            "[12]\ttrain-aucpr:0.90622+0.00147\ttest-aucpr:0.89768+0.00166\n",
            "[13]\ttrain-aucpr:0.90929+0.00095\ttest-aucpr:0.90087+0.00141\n",
            "[14]\ttrain-aucpr:0.91321+0.00120\ttest-aucpr:0.90473+0.00176\n",
            "[15]\ttrain-aucpr:0.91442+0.00125\ttest-aucpr:0.90591+0.00146\n",
            "[16]\ttrain-aucpr:0.91721+0.00164\ttest-aucpr:0.90866+0.00221\n",
            "[17]\ttrain-aucpr:0.91923+0.00122\ttest-aucpr:0.91073+0.00159\n",
            "[18]\ttrain-aucpr:0.92139+0.00105\ttest-aucpr:0.91275+0.00176\n",
            "[19]\ttrain-aucpr:0.92425+0.00164\ttest-aucpr:0.91547+0.00245\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 10, 'gamma': 1, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.89849+0.00177\ttest-aucpr:0.87056+0.00377\n",
            "[1]\ttrain-aucpr:0.93193+0.00123\ttest-aucpr:0.90645+0.00169\n",
            "[2]\ttrain-aucpr:0.94755+0.00104\ttest-aucpr:0.92373+0.00150\n",
            "[3]\ttrain-aucpr:0.95520+0.00059\ttest-aucpr:0.93160+0.00064\n",
            "[4]\ttrain-aucpr:0.96071+0.00090\ttest-aucpr:0.93729+0.00133\n",
            "[5]\ttrain-aucpr:0.96499+0.00070\ttest-aucpr:0.94206+0.00123\n",
            "[6]\ttrain-aucpr:0.96854+0.00088\ttest-aucpr:0.94574+0.00152\n",
            "[7]\ttrain-aucpr:0.97151+0.00058\ttest-aucpr:0.94880+0.00119\n",
            "[8]\ttrain-aucpr:0.97394+0.00070\ttest-aucpr:0.95135+0.00139\n",
            "[9]\ttrain-aucpr:0.97615+0.00045\ttest-aucpr:0.95399+0.00116\n",
            "[10]\ttrain-aucpr:0.97832+0.00037\ttest-aucpr:0.95645+0.00075\n",
            "[11]\ttrain-aucpr:0.97989+0.00039\ttest-aucpr:0.95818+0.00089\n",
            "[12]\ttrain-aucpr:0.98078+0.00026\ttest-aucpr:0.95929+0.00091\n",
            "[13]\ttrain-aucpr:0.98195+0.00048\ttest-aucpr:0.96090+0.00116\n",
            "[14]\ttrain-aucpr:0.98258+0.00058\ttest-aucpr:0.96176+0.00131\n",
            "[15]\ttrain-aucpr:0.98339+0.00061\ttest-aucpr:0.96265+0.00120\n",
            "[16]\ttrain-aucpr:0.98418+0.00073\ttest-aucpr:0.96355+0.00134\n",
            "[17]\ttrain-aucpr:0.98478+0.00075\ttest-aucpr:0.96423+0.00111\n",
            "[18]\ttrain-aucpr:0.98530+0.00067\ttest-aucpr:0.96492+0.00109\n",
            "[19]\ttrain-aucpr:0.98581+0.00087\ttest-aucpr:0.96544+0.00112\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 10, 'gamma': 0, 'lambda': 2, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90305+0.00167\ttest-aucpr:0.87212+0.00414\n",
            "[1]\ttrain-aucpr:0.93640+0.00176\ttest-aucpr:0.90820+0.00217\n",
            "[2]\ttrain-aucpr:0.95121+0.00103\ttest-aucpr:0.92526+0.00195\n",
            "[3]\ttrain-aucpr:0.95965+0.00132\ttest-aucpr:0.93387+0.00168\n",
            "[4]\ttrain-aucpr:0.96405+0.00153\ttest-aucpr:0.93858+0.00170\n",
            "[5]\ttrain-aucpr:0.96849+0.00128\ttest-aucpr:0.94290+0.00118\n",
            "[6]\ttrain-aucpr:0.97222+0.00117\ttest-aucpr:0.94680+0.00126\n",
            "[7]\ttrain-aucpr:0.97505+0.00130\ttest-aucpr:0.94980+0.00143\n",
            "[8]\ttrain-aucpr:0.97770+0.00099\ttest-aucpr:0.95274+0.00096\n",
            "[9]\ttrain-aucpr:0.97967+0.00112\ttest-aucpr:0.95493+0.00126\n",
            "[10]\ttrain-aucpr:0.98132+0.00109\ttest-aucpr:0.95688+0.00152\n",
            "[11]\ttrain-aucpr:0.98311+0.00078\ttest-aucpr:0.95913+0.00084\n",
            "[12]\ttrain-aucpr:0.98395+0.00060\ttest-aucpr:0.96028+0.00083\n",
            "[13]\ttrain-aucpr:0.98502+0.00041\ttest-aucpr:0.96144+0.00070\n",
            "[14]\ttrain-aucpr:0.98573+0.00061\ttest-aucpr:0.96227+0.00103\n",
            "[15]\ttrain-aucpr:0.98654+0.00060\ttest-aucpr:0.96336+0.00119\n",
            "[16]\ttrain-aucpr:0.98711+0.00074\ttest-aucpr:0.96418+0.00105\n",
            "[17]\ttrain-aucpr:0.98769+0.00039\ttest-aucpr:0.96486+0.00093\n",
            "[18]\ttrain-aucpr:0.98833+0.00033\ttest-aucpr:0.96551+0.00101\n",
            "[19]\ttrain-aucpr:0.98875+0.00046\ttest-aucpr:0.96602+0.00107\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 5, 'gamma': 3, 'lambda': 3, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76550+0.00231\ttest-aucpr:0.75917+0.00435\n",
            "[1]\ttrain-aucpr:0.79807+0.00432\ttest-aucpr:0.79129+0.00387\n",
            "[2]\ttrain-aucpr:0.81769+0.00272\ttest-aucpr:0.81111+0.00389\n",
            "[3]\ttrain-aucpr:0.82860+0.00115\ttest-aucpr:0.82209+0.00434\n",
            "[4]\ttrain-aucpr:0.83620+0.00319\ttest-aucpr:0.82952+0.00443\n",
            "[5]\ttrain-aucpr:0.84293+0.00181\ttest-aucpr:0.83648+0.00364\n",
            "[6]\ttrain-aucpr:0.84708+0.00196\ttest-aucpr:0.84017+0.00392\n",
            "[7]\ttrain-aucpr:0.85182+0.00140\ttest-aucpr:0.84437+0.00225\n",
            "[8]\ttrain-aucpr:0.85580+0.00098\ttest-aucpr:0.84853+0.00285\n",
            "[9]\ttrain-aucpr:0.85999+0.00095\ttest-aucpr:0.85280+0.00295\n",
            "[10]\ttrain-aucpr:0.86374+0.00037\ttest-aucpr:0.85669+0.00256\n",
            "[11]\ttrain-aucpr:0.86764+0.00160\ttest-aucpr:0.86035+0.00308\n",
            "[12]\ttrain-aucpr:0.87089+0.00103\ttest-aucpr:0.86341+0.00286\n",
            "[13]\ttrain-aucpr:0.87371+0.00092\ttest-aucpr:0.86620+0.00279\n",
            "[14]\ttrain-aucpr:0.87702+0.00092\ttest-aucpr:0.86956+0.00251\n",
            "[15]\ttrain-aucpr:0.87958+0.00084\ttest-aucpr:0.87198+0.00259\n",
            "[16]\ttrain-aucpr:0.88188+0.00096\ttest-aucpr:0.87414+0.00281\n",
            "[17]\ttrain-aucpr:0.88406+0.00114\ttest-aucpr:0.87609+0.00280\n",
            "[18]\ttrain-aucpr:0.88744+0.00130\ttest-aucpr:0.87926+0.00249\n",
            "[19]\ttrain-aucpr:0.88949+0.00149\ttest-aucpr:0.88124+0.00284\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 3, 'gamma': 0, 'lambda': 2, 'alpha': 0.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.64563+0.00181\ttest-aucpr:0.64315+0.00505\n",
            "[1]\ttrain-aucpr:0.68919+0.00517\ttest-aucpr:0.68607+0.00460\n",
            "[2]\ttrain-aucpr:0.70763+0.00244\ttest-aucpr:0.70463+0.00584\n",
            "[3]\ttrain-aucpr:0.71817+0.00233\ttest-aucpr:0.71445+0.00571\n",
            "[4]\ttrain-aucpr:0.72935+0.00507\ttest-aucpr:0.72481+0.00983\n",
            "[5]\ttrain-aucpr:0.73475+0.00403\ttest-aucpr:0.73041+0.00907\n",
            "[6]\ttrain-aucpr:0.74145+0.00197\ttest-aucpr:0.73731+0.00612\n",
            "[7]\ttrain-aucpr:0.74513+0.00231\ttest-aucpr:0.74079+0.00549\n",
            "[8]\ttrain-aucpr:0.74910+0.00173\ttest-aucpr:0.74436+0.00439\n",
            "[9]\ttrain-aucpr:0.75075+0.00079\ttest-aucpr:0.74620+0.00414\n",
            "[10]\ttrain-aucpr:0.75242+0.00215\ttest-aucpr:0.74760+0.00479\n",
            "[11]\ttrain-aucpr:0.75618+0.00265\ttest-aucpr:0.75157+0.00444\n",
            "[12]\ttrain-aucpr:0.75853+0.00161\ttest-aucpr:0.75369+0.00411\n",
            "[13]\ttrain-aucpr:0.76292+0.00245\ttest-aucpr:0.75780+0.00197\n",
            "[14]\ttrain-aucpr:0.76496+0.00215\ttest-aucpr:0.76011+0.00306\n",
            "[15]\ttrain-aucpr:0.76782+0.00325\ttest-aucpr:0.76280+0.00325\n",
            "[16]\ttrain-aucpr:0.77006+0.00213\ttest-aucpr:0.76498+0.00299\n",
            "[17]\ttrain-aucpr:0.77340+0.00251\ttest-aucpr:0.76823+0.00224\n",
            "[18]\ttrain-aucpr:0.77646+0.00284\ttest-aucpr:0.77114+0.00363\n",
            "[19]\ttrain-aucpr:0.78061+0.00282\ttest-aucpr:0.77482+0.00358\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 10, 'gamma': 0, 'lambda': 3, 'alpha': 1.0, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.89869+0.00174\ttest-aucpr:0.87054+0.00378\n",
            "[1]\ttrain-aucpr:0.93221+0.00151\ttest-aucpr:0.90655+0.00175\n",
            "[2]\ttrain-aucpr:0.94847+0.00128\ttest-aucpr:0.92439+0.00122\n",
            "[3]\ttrain-aucpr:0.95545+0.00099\ttest-aucpr:0.93159+0.00098\n",
            "[4]\ttrain-aucpr:0.96087+0.00136\ttest-aucpr:0.93693+0.00165\n",
            "[5]\ttrain-aucpr:0.96482+0.00103\ttest-aucpr:0.94152+0.00102\n",
            "[6]\ttrain-aucpr:0.96890+0.00035\ttest-aucpr:0.94608+0.00079\n",
            "[7]\ttrain-aucpr:0.97211+0.00055\ttest-aucpr:0.94953+0.00104\n",
            "[8]\ttrain-aucpr:0.97421+0.00047\ttest-aucpr:0.95171+0.00110\n",
            "[9]\ttrain-aucpr:0.97655+0.00073\ttest-aucpr:0.95413+0.00107\n",
            "[10]\ttrain-aucpr:0.97834+0.00080\ttest-aucpr:0.95619+0.00091\n",
            "[11]\ttrain-aucpr:0.97995+0.00083\ttest-aucpr:0.95788+0.00092\n",
            "[12]\ttrain-aucpr:0.98132+0.00041\ttest-aucpr:0.95939+0.00059\n",
            "[13]\ttrain-aucpr:0.98210+0.00050\ttest-aucpr:0.96042+0.00041\n",
            "[14]\ttrain-aucpr:0.98291+0.00029\ttest-aucpr:0.96147+0.00041\n",
            "[15]\ttrain-aucpr:0.98385+0.00040\ttest-aucpr:0.96264+0.00058\n",
            "[16]\ttrain-aucpr:0.98435+0.00029\ttest-aucpr:0.96326+0.00061\n",
            "[17]\ttrain-aucpr:0.98538+0.00039\ttest-aucpr:0.96453+0.00039\n",
            "[18]\ttrain-aucpr:0.98589+0.00026\ttest-aucpr:0.96519+0.00044\n",
            "[19]\ttrain-aucpr:0.98640+0.00040\ttest-aucpr:0.96565+0.00039\n",
            "{'objective': 'binary:logistic', 'eta': 0.1, 'max_depth': 5, 'gamma': 3, 'lambda': 2, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.76562+0.00227\ttest-aucpr:0.75886+0.00421\n",
            "[1]\ttrain-aucpr:0.79813+0.00424\ttest-aucpr:0.79127+0.00391\n",
            "[2]\ttrain-aucpr:0.81796+0.00286\ttest-aucpr:0.81121+0.00397\n",
            "[3]\ttrain-aucpr:0.82899+0.00115\ttest-aucpr:0.82236+0.00436\n",
            "[4]\ttrain-aucpr:0.83654+0.00304\ttest-aucpr:0.82981+0.00439\n",
            "[5]\ttrain-aucpr:0.84330+0.00201\ttest-aucpr:0.83689+0.00376\n",
            "[6]\ttrain-aucpr:0.84729+0.00198\ttest-aucpr:0.84033+0.00403\n",
            "[7]\ttrain-aucpr:0.85277+0.00198\ttest-aucpr:0.84548+0.00243\n",
            "[8]\ttrain-aucpr:0.85683+0.00174\ttest-aucpr:0.84967+0.00322\n",
            "[9]\ttrain-aucpr:0.86067+0.00139\ttest-aucpr:0.85345+0.00318\n",
            "[10]\ttrain-aucpr:0.86454+0.00093\ttest-aucpr:0.85746+0.00260\n",
            "[11]\ttrain-aucpr:0.86742+0.00127\ttest-aucpr:0.86016+0.00288\n",
            "[12]\ttrain-aucpr:0.87021+0.00102\ttest-aucpr:0.86290+0.00295\n",
            "[13]\ttrain-aucpr:0.87331+0.00072\ttest-aucpr:0.86599+0.00267\n",
            "[14]\ttrain-aucpr:0.87622+0.00084\ttest-aucpr:0.86906+0.00260\n",
            "[15]\ttrain-aucpr:0.87910+0.00068\ttest-aucpr:0.87181+0.00249\n",
            "[16]\ttrain-aucpr:0.88170+0.00080\ttest-aucpr:0.87431+0.00248\n",
            "[17]\ttrain-aucpr:0.88430+0.00055\ttest-aucpr:0.87661+0.00221\n",
            "[18]\ttrain-aucpr:0.88698+0.00147\ttest-aucpr:0.87933+0.00311\n",
            "[19]\ttrain-aucpr:0.88954+0.00129\ttest-aucpr:0.88184+0.00317\n",
            "{'objective': 'binary:logistic', 'eta': 0.25, 'max_depth': 10, 'gamma': 1, 'lambda': 1, 'alpha': 0.1, 'eval_metric': 'aucpr'}\n",
            "[0]\ttrain-aucpr:0.90627+0.00135\ttest-aucpr:0.87263+0.00253\n",
            "[1]\ttrain-aucpr:0.93801+0.00154\ttest-aucpr:0.90831+0.00187\n",
            "[2]\ttrain-aucpr:0.95256+0.00107\ttest-aucpr:0.92557+0.00231\n",
            "[3]\ttrain-aucpr:0.95948+0.00160\ttest-aucpr:0.93293+0.00203\n",
            "[4]\ttrain-aucpr:0.96529+0.00061\ttest-aucpr:0.93917+0.00055\n",
            "[5]\ttrain-aucpr:0.96986+0.00122\ttest-aucpr:0.94438+0.00087\n",
            "[6]\ttrain-aucpr:0.97279+0.00092\ttest-aucpr:0.94755+0.00095\n",
            "[7]\ttrain-aucpr:0.97572+0.00101\ttest-aucpr:0.95070+0.00101\n",
            "[8]\ttrain-aucpr:0.97791+0.00105\ttest-aucpr:0.95308+0.00078\n",
            "[9]\ttrain-aucpr:0.98033+0.00082\ttest-aucpr:0.95589+0.00064\n",
            "[10]\ttrain-aucpr:0.98231+0.00070\ttest-aucpr:0.95785+0.00077\n",
            "[11]\ttrain-aucpr:0.98357+0.00065\ttest-aucpr:0.95941+0.00082\n",
            "[12]\ttrain-aucpr:0.98467+0.00040\ttest-aucpr:0.96085+0.00075\n",
            "[13]\ttrain-aucpr:0.98563+0.00033\ttest-aucpr:0.96189+0.00089\n",
            "[14]\ttrain-aucpr:0.98628+0.00032\ttest-aucpr:0.96274+0.00083\n",
            "[15]\ttrain-aucpr:0.98689+0.00035\ttest-aucpr:0.96344+0.00072\n",
            "[16]\ttrain-aucpr:0.98750+0.00048\ttest-aucpr:0.96415+0.00064\n",
            "[17]\ttrain-aucpr:0.98818+0.00063\ttest-aucpr:0.96501+0.00067\n",
            "[18]\ttrain-aucpr:0.98885+0.00057\ttest-aucpr:0.96576+0.00079\n",
            "[19]\ttrain-aucpr:0.98941+0.00084\ttest-aucpr:0.96626+0.00092\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_params"
      ],
      "metadata": {
        "id": "xXJEj4W_8T-H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69863b78-b66d-45ff-bb28-49504e4cb18d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'objective': 'binary:logistic',\n",
              " 'eta': 0.25,\n",
              " 'max_depth': 20,\n",
              " 'gamma': 1,\n",
              " 'lambda': 1,\n",
              " 'alpha': 1.0,\n",
              " 'eval_metric': 'aucpr'}"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aucpr_params = {'objective': 'binary:logistic',\n",
        "         'eta': 0.25,\n",
        "         'max_depth': 20,\n",
        "         'gamma': 1,\n",
        "         'lambda': 1,\n",
        "         'alpha': 1.0,\n",
        "         'eval_metric': 'aucpr'}"
      ],
      "metadata": {
        "id": "_RjSFnb1SXl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fold_results = {}\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(skf.split(X,y)):\n",
        "    dtrain = xgb.DMatrix(X[train_index], label=y[train_index])\n",
        "    dtest = xgb.DMatrix(X[test_index], label=y[test_index])\n",
        "    evallist = [(dtrain, 'train'), (dtest, 'eval')]\n",
        "\n",
        "    tr=xgb.train(params=aucpr_params,\n",
        "                 num_boost_round=222,\n",
        "                 dtrain=dtrain,\n",
        "                 verbose_eval=1,\n",
        "                 evals=evallist,\n",
        "                 early_stopping_rounds = 3\n",
        "             )\n",
        "\n",
        "    preds_XGB = np.round(tr.predict(dtest), 0)\n",
        "\n",
        "    classification_report(y[test_index],np.round(preds_XGB, 0),output_dict=True)\n",
        "    fold_results.update({i:{'predictions':preds_XGB,'index':test_index,'y_true':y[test_index]}})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eY58xAj3XqoL",
        "outputId": "cd600deb-5928-4083-d466-473595f8e229"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\ttrain-aucpr:0.95637\teval-aucpr:0.88765\n",
            "[1]\ttrain-aucpr:0.98006\teval-aucpr:0.92214\n",
            "[2]\ttrain-aucpr:0.98894\teval-aucpr:0.93891\n",
            "[3]\ttrain-aucpr:0.99180\teval-aucpr:0.94592\n",
            "[4]\ttrain-aucpr:0.99410\teval-aucpr:0.95182\n",
            "[5]\ttrain-aucpr:0.99541\teval-aucpr:0.95523\n",
            "[6]\ttrain-aucpr:0.99629\teval-aucpr:0.95760\n",
            "[7]\ttrain-aucpr:0.99683\teval-aucpr:0.95925\n",
            "[8]\ttrain-aucpr:0.99741\teval-aucpr:0.96116\n",
            "[9]\ttrain-aucpr:0.99792\teval-aucpr:0.96266\n",
            "[10]\ttrain-aucpr:0.99828\teval-aucpr:0.96439\n",
            "[11]\ttrain-aucpr:0.99858\teval-aucpr:0.96591\n",
            "[12]\ttrain-aucpr:0.99881\teval-aucpr:0.96730\n",
            "[13]\ttrain-aucpr:0.99902\teval-aucpr:0.96824\n",
            "[14]\ttrain-aucpr:0.99916\teval-aucpr:0.96904\n",
            "[15]\ttrain-aucpr:0.99928\teval-aucpr:0.96988\n",
            "[16]\ttrain-aucpr:0.99937\teval-aucpr:0.97065\n",
            "[17]\ttrain-aucpr:0.99945\teval-aucpr:0.97132\n",
            "[18]\ttrain-aucpr:0.99952\teval-aucpr:0.97186\n",
            "[19]\ttrain-aucpr:0.99957\teval-aucpr:0.97254\n",
            "[20]\ttrain-aucpr:0.99960\teval-aucpr:0.97293\n",
            "[21]\ttrain-aucpr:0.99966\teval-aucpr:0.97307\n",
            "[22]\ttrain-aucpr:0.99970\teval-aucpr:0.97341\n",
            "[23]\ttrain-aucpr:0.99975\teval-aucpr:0.97361\n",
            "[24]\ttrain-aucpr:0.99979\teval-aucpr:0.97368\n",
            "[25]\ttrain-aucpr:0.99981\teval-aucpr:0.97377\n",
            "[26]\ttrain-aucpr:0.99984\teval-aucpr:0.97416\n",
            "[27]\ttrain-aucpr:0.99986\teval-aucpr:0.97417\n",
            "[28]\ttrain-aucpr:0.99988\teval-aucpr:0.97444\n",
            "[29]\ttrain-aucpr:0.99989\teval-aucpr:0.97455\n",
            "[30]\ttrain-aucpr:0.99990\teval-aucpr:0.97467\n",
            "[31]\ttrain-aucpr:0.99992\teval-aucpr:0.97456\n",
            "[32]\ttrain-aucpr:0.99992\teval-aucpr:0.97460\n",
            "[0]\ttrain-aucpr:0.95389\teval-aucpr:0.89182\n",
            "[1]\ttrain-aucpr:0.97926\teval-aucpr:0.92293\n",
            "[2]\ttrain-aucpr:0.98804\teval-aucpr:0.94113\n",
            "[3]\ttrain-aucpr:0.99160\teval-aucpr:0.94954\n",
            "[4]\ttrain-aucpr:0.99359\teval-aucpr:0.95398\n",
            "[5]\ttrain-aucpr:0.99518\teval-aucpr:0.95768\n",
            "[6]\ttrain-aucpr:0.99611\teval-aucpr:0.95992\n",
            "[7]\ttrain-aucpr:0.99687\teval-aucpr:0.96207\n",
            "[8]\ttrain-aucpr:0.99743\teval-aucpr:0.96387\n",
            "[9]\ttrain-aucpr:0.99787\teval-aucpr:0.96550\n",
            "[10]\ttrain-aucpr:0.99821\teval-aucpr:0.96689\n",
            "[11]\ttrain-aucpr:0.99849\teval-aucpr:0.96811\n",
            "[12]\ttrain-aucpr:0.99871\teval-aucpr:0.96917\n",
            "[13]\ttrain-aucpr:0.99892\teval-aucpr:0.96982\n",
            "[14]\ttrain-aucpr:0.99910\teval-aucpr:0.97061\n",
            "[15]\ttrain-aucpr:0.99922\teval-aucpr:0.97151\n",
            "[16]\ttrain-aucpr:0.99934\teval-aucpr:0.97218\n",
            "[17]\ttrain-aucpr:0.99942\teval-aucpr:0.97272\n",
            "[18]\ttrain-aucpr:0.99950\teval-aucpr:0.97318\n",
            "[19]\ttrain-aucpr:0.99955\teval-aucpr:0.97359\n",
            "[20]\ttrain-aucpr:0.99960\teval-aucpr:0.97393\n",
            "[21]\ttrain-aucpr:0.99965\teval-aucpr:0.97421\n",
            "[22]\ttrain-aucpr:0.99971\teval-aucpr:0.97466\n",
            "[23]\ttrain-aucpr:0.99976\teval-aucpr:0.97477\n",
            "[24]\ttrain-aucpr:0.99979\teval-aucpr:0.97494\n",
            "[25]\ttrain-aucpr:0.99982\teval-aucpr:0.97510\n",
            "[26]\ttrain-aucpr:0.99985\teval-aucpr:0.97519\n",
            "[27]\ttrain-aucpr:0.99987\teval-aucpr:0.97508\n",
            "[28]\ttrain-aucpr:0.99989\teval-aucpr:0.97510\n",
            "[29]\ttrain-aucpr:0.99990\teval-aucpr:0.97524\n",
            "[30]\ttrain-aucpr:0.99992\teval-aucpr:0.97532\n",
            "[31]\ttrain-aucpr:0.99992\teval-aucpr:0.97540\n",
            "[32]\ttrain-aucpr:0.99994\teval-aucpr:0.97543\n",
            "[33]\ttrain-aucpr:0.99995\teval-aucpr:0.97546\n",
            "[34]\ttrain-aucpr:0.99996\teval-aucpr:0.97538\n",
            "[35]\ttrain-aucpr:0.99996\teval-aucpr:0.97542\n",
            "[36]\ttrain-aucpr:0.99997\teval-aucpr:0.97559\n",
            "[37]\ttrain-aucpr:0.99997\teval-aucpr:0.97573\n",
            "[38]\ttrain-aucpr:0.99997\teval-aucpr:0.97585\n",
            "[39]\ttrain-aucpr:0.99998\teval-aucpr:0.97588\n",
            "[40]\ttrain-aucpr:0.99998\teval-aucpr:0.97606\n",
            "[41]\ttrain-aucpr:0.99998\teval-aucpr:0.97605\n",
            "[42]\ttrain-aucpr:0.99998\teval-aucpr:0.97608\n",
            "[43]\ttrain-aucpr:0.99999\teval-aucpr:0.97617\n",
            "[44]\ttrain-aucpr:0.99999\teval-aucpr:0.97615\n",
            "[45]\ttrain-aucpr:0.99999\teval-aucpr:0.97626\n",
            "[46]\ttrain-aucpr:0.99999\teval-aucpr:0.97627\n",
            "[47]\ttrain-aucpr:0.99999\teval-aucpr:0.97628\n",
            "[48]\ttrain-aucpr:0.99999\teval-aucpr:0.97625\n",
            "[49]\ttrain-aucpr:0.99999\teval-aucpr:0.97625\n",
            "[0]\ttrain-aucpr:0.95668\teval-aucpr:0.89415\n",
            "[1]\ttrain-aucpr:0.98030\teval-aucpr:0.92624\n",
            "[2]\ttrain-aucpr:0.98831\teval-aucpr:0.94263\n",
            "[3]\ttrain-aucpr:0.99196\teval-aucpr:0.94928\n",
            "[4]\ttrain-aucpr:0.99399\teval-aucpr:0.95456\n",
            "[5]\ttrain-aucpr:0.99531\teval-aucpr:0.95837\n",
            "[6]\ttrain-aucpr:0.99618\teval-aucpr:0.96045\n",
            "[7]\ttrain-aucpr:0.99676\teval-aucpr:0.96272\n",
            "[8]\ttrain-aucpr:0.99727\teval-aucpr:0.96439\n",
            "[9]\ttrain-aucpr:0.99772\teval-aucpr:0.96607\n",
            "[10]\ttrain-aucpr:0.99814\teval-aucpr:0.96754\n",
            "[11]\ttrain-aucpr:0.99844\teval-aucpr:0.96860\n",
            "[12]\ttrain-aucpr:0.99872\teval-aucpr:0.96976\n",
            "[13]\ttrain-aucpr:0.99892\teval-aucpr:0.97070\n",
            "[14]\ttrain-aucpr:0.99908\teval-aucpr:0.97156\n",
            "[15]\ttrain-aucpr:0.99920\teval-aucpr:0.97240\n",
            "[16]\ttrain-aucpr:0.99931\teval-aucpr:0.97307\n",
            "[17]\ttrain-aucpr:0.99939\teval-aucpr:0.97372\n",
            "[18]\ttrain-aucpr:0.99947\teval-aucpr:0.97418\n",
            "[19]\ttrain-aucpr:0.99954\teval-aucpr:0.97455\n",
            "[20]\ttrain-aucpr:0.99961\teval-aucpr:0.97491\n",
            "[21]\ttrain-aucpr:0.99966\teval-aucpr:0.97538\n",
            "[22]\ttrain-aucpr:0.99971\teval-aucpr:0.97567\n",
            "[23]\ttrain-aucpr:0.99975\teval-aucpr:0.97590\n",
            "[24]\ttrain-aucpr:0.99979\teval-aucpr:0.97590\n",
            "[25]\ttrain-aucpr:0.99981\teval-aucpr:0.97627\n",
            "[26]\ttrain-aucpr:0.99984\teval-aucpr:0.97651\n",
            "[27]\ttrain-aucpr:0.99986\teval-aucpr:0.97662\n",
            "[28]\ttrain-aucpr:0.99988\teval-aucpr:0.97660\n",
            "[29]\ttrain-aucpr:0.99989\teval-aucpr:0.97669\n",
            "[30]\ttrain-aucpr:0.99991\teval-aucpr:0.97669\n",
            "[31]\ttrain-aucpr:0.99992\teval-aucpr:0.97689\n",
            "[32]\ttrain-aucpr:0.99993\teval-aucpr:0.97691\n",
            "[33]\ttrain-aucpr:0.99994\teval-aucpr:0.97693\n",
            "[34]\ttrain-aucpr:0.99995\teval-aucpr:0.97701\n",
            "[35]\ttrain-aucpr:0.99996\teval-aucpr:0.97704\n",
            "[36]\ttrain-aucpr:0.99996\teval-aucpr:0.97710\n",
            "[37]\ttrain-aucpr:0.99997\teval-aucpr:0.97718\n",
            "[38]\ttrain-aucpr:0.99997\teval-aucpr:0.97715\n",
            "[39]\ttrain-aucpr:0.99997\teval-aucpr:0.97725\n",
            "[40]\ttrain-aucpr:0.99998\teval-aucpr:0.97723\n",
            "[41]\ttrain-aucpr:0.99998\teval-aucpr:0.97723\n",
            "[0]\ttrain-aucpr:0.96050\teval-aucpr:0.90412\n",
            "[1]\ttrain-aucpr:0.98301\teval-aucpr:0.93362\n",
            "[2]\ttrain-aucpr:0.98861\teval-aucpr:0.94422\n",
            "[3]\ttrain-aucpr:0.99201\teval-aucpr:0.95020\n",
            "[4]\ttrain-aucpr:0.99432\teval-aucpr:0.95433\n",
            "[5]\ttrain-aucpr:0.99537\teval-aucpr:0.95783\n",
            "[6]\ttrain-aucpr:0.99637\teval-aucpr:0.96039\n",
            "[7]\ttrain-aucpr:0.99708\teval-aucpr:0.96250\n",
            "[8]\ttrain-aucpr:0.99760\teval-aucpr:0.96421\n",
            "[9]\ttrain-aucpr:0.99804\teval-aucpr:0.96558\n",
            "[10]\ttrain-aucpr:0.99836\teval-aucpr:0.96678\n",
            "[11]\ttrain-aucpr:0.99866\teval-aucpr:0.96805\n",
            "[12]\ttrain-aucpr:0.99888\teval-aucpr:0.96879\n",
            "[13]\ttrain-aucpr:0.99903\teval-aucpr:0.96957\n",
            "[14]\ttrain-aucpr:0.99916\teval-aucpr:0.97067\n",
            "[15]\ttrain-aucpr:0.99926\teval-aucpr:0.97144\n",
            "[16]\ttrain-aucpr:0.99937\teval-aucpr:0.97214\n",
            "[17]\ttrain-aucpr:0.99947\teval-aucpr:0.97274\n",
            "[18]\ttrain-aucpr:0.99954\teval-aucpr:0.97309\n",
            "[19]\ttrain-aucpr:0.99960\teval-aucpr:0.97352\n",
            "[20]\ttrain-aucpr:0.99965\teval-aucpr:0.97406\n",
            "[21]\ttrain-aucpr:0.99968\teval-aucpr:0.97437\n",
            "[22]\ttrain-aucpr:0.99972\teval-aucpr:0.97473\n",
            "[23]\ttrain-aucpr:0.99976\teval-aucpr:0.97504\n",
            "[24]\ttrain-aucpr:0.99978\teval-aucpr:0.97514\n",
            "[25]\ttrain-aucpr:0.99981\teval-aucpr:0.97537\n",
            "[26]\ttrain-aucpr:0.99984\teval-aucpr:0.97548\n",
            "[27]\ttrain-aucpr:0.99987\teval-aucpr:0.97540\n",
            "[28]\ttrain-aucpr:0.99989\teval-aucpr:0.97537\n",
            "[29]\ttrain-aucpr:0.99991\teval-aucpr:0.97552\n",
            "[30]\ttrain-aucpr:0.99992\teval-aucpr:0.97552\n",
            "[31]\ttrain-aucpr:0.99993\teval-aucpr:0.97582\n",
            "[32]\ttrain-aucpr:0.99994\teval-aucpr:0.97592\n",
            "[33]\ttrain-aucpr:0.99995\teval-aucpr:0.97597\n",
            "[34]\ttrain-aucpr:0.99995\teval-aucpr:0.97606\n",
            "[35]\ttrain-aucpr:0.99996\teval-aucpr:0.97620\n",
            "[36]\ttrain-aucpr:0.99997\teval-aucpr:0.97616\n",
            "[37]\ttrain-aucpr:0.99997\teval-aucpr:0.97637\n",
            "[38]\ttrain-aucpr:0.99997\teval-aucpr:0.97643\n",
            "[39]\ttrain-aucpr:0.99998\teval-aucpr:0.97648\n",
            "[40]\ttrain-aucpr:0.99998\teval-aucpr:0.97656\n",
            "[41]\ttrain-aucpr:0.99998\teval-aucpr:0.97653\n",
            "[42]\ttrain-aucpr:0.99999\teval-aucpr:0.97656\n",
            "[43]\ttrain-aucpr:0.99999\teval-aucpr:0.97672\n",
            "[44]\ttrain-aucpr:0.99999\teval-aucpr:0.97683\n",
            "[45]\ttrain-aucpr:0.99999\teval-aucpr:0.97683\n",
            "[46]\ttrain-aucpr:0.99999\teval-aucpr:0.97674\n",
            "[47]\ttrain-aucpr:0.99999\teval-aucpr:0.97680\n",
            "[48]\ttrain-aucpr:0.99999\teval-aucpr:0.97686\n",
            "[49]\ttrain-aucpr:0.99999\teval-aucpr:0.97690\n",
            "[50]\ttrain-aucpr:1.00000\teval-aucpr:0.97692\n",
            "[51]\ttrain-aucpr:1.00000\teval-aucpr:0.97692\n",
            "[52]\ttrain-aucpr:1.00000\teval-aucpr:0.97694\n",
            "[53]\ttrain-aucpr:1.00000\teval-aucpr:0.97696\n",
            "[54]\ttrain-aucpr:1.00000\teval-aucpr:0.97695\n",
            "[55]\ttrain-aucpr:1.00000\teval-aucpr:0.97700\n",
            "[56]\ttrain-aucpr:1.00000\teval-aucpr:0.97708\n",
            "[57]\ttrain-aucpr:1.00000\teval-aucpr:0.97707\n",
            "[58]\ttrain-aucpr:1.00000\teval-aucpr:0.97707\n",
            "[0]\ttrain-aucpr:0.95526\teval-aucpr:0.89207\n",
            "[1]\ttrain-aucpr:0.98053\teval-aucpr:0.92346\n",
            "[2]\ttrain-aucpr:0.98756\teval-aucpr:0.93581\n",
            "[3]\ttrain-aucpr:0.99154\teval-aucpr:0.94481\n",
            "[4]\ttrain-aucpr:0.99347\teval-aucpr:0.95028\n",
            "[5]\ttrain-aucpr:0.99505\teval-aucpr:0.95517\n",
            "[6]\ttrain-aucpr:0.99602\teval-aucpr:0.95844\n",
            "[7]\ttrain-aucpr:0.99678\teval-aucpr:0.96033\n",
            "[8]\ttrain-aucpr:0.99731\teval-aucpr:0.96246\n",
            "[9]\ttrain-aucpr:0.99775\teval-aucpr:0.96381\n",
            "[10]\ttrain-aucpr:0.99818\teval-aucpr:0.96490\n",
            "[11]\ttrain-aucpr:0.99852\teval-aucpr:0.96617\n",
            "[12]\ttrain-aucpr:0.99875\teval-aucpr:0.96750\n",
            "[13]\ttrain-aucpr:0.99893\teval-aucpr:0.96857\n",
            "[14]\ttrain-aucpr:0.99911\teval-aucpr:0.96964\n",
            "[15]\ttrain-aucpr:0.99923\teval-aucpr:0.97056\n",
            "[16]\ttrain-aucpr:0.99935\teval-aucpr:0.97086\n",
            "[17]\ttrain-aucpr:0.99941\teval-aucpr:0.97151\n",
            "[18]\ttrain-aucpr:0.99949\teval-aucpr:0.97189\n",
            "[19]\ttrain-aucpr:0.99956\teval-aucpr:0.97235\n",
            "[20]\ttrain-aucpr:0.99962\teval-aucpr:0.97270\n",
            "[21]\ttrain-aucpr:0.99967\teval-aucpr:0.97309\n",
            "[22]\ttrain-aucpr:0.99971\teval-aucpr:0.97311\n",
            "[23]\ttrain-aucpr:0.99975\teval-aucpr:0.97344\n",
            "[24]\ttrain-aucpr:0.99979\teval-aucpr:0.97376\n",
            "[25]\ttrain-aucpr:0.99983\teval-aucpr:0.97370\n",
            "[26]\ttrain-aucpr:0.99985\teval-aucpr:0.97380\n",
            "[27]\ttrain-aucpr:0.99987\teval-aucpr:0.97411\n",
            "[28]\ttrain-aucpr:0.99989\teval-aucpr:0.97420\n",
            "[29]\ttrain-aucpr:0.99990\teval-aucpr:0.97440\n",
            "[30]\ttrain-aucpr:0.99992\teval-aucpr:0.97464\n",
            "[31]\ttrain-aucpr:0.99993\teval-aucpr:0.97469\n",
            "[32]\ttrain-aucpr:0.99994\teval-aucpr:0.97480\n",
            "[33]\ttrain-aucpr:0.99995\teval-aucpr:0.97476\n",
            "[34]\ttrain-aucpr:0.99995\teval-aucpr:0.97488\n",
            "[35]\ttrain-aucpr:0.99996\teval-aucpr:0.97492\n",
            "[36]\ttrain-aucpr:0.99997\teval-aucpr:0.97516\n",
            "[37]\ttrain-aucpr:0.99997\teval-aucpr:0.97531\n",
            "[38]\ttrain-aucpr:0.99998\teval-aucpr:0.97536\n",
            "[39]\ttrain-aucpr:0.99998\teval-aucpr:0.97541\n",
            "[40]\ttrain-aucpr:0.99998\teval-aucpr:0.97534\n",
            "[41]\ttrain-aucpr:0.99998\teval-aucpr:0.97539\n",
            "[42]\ttrain-aucpr:0.99998\teval-aucpr:0.97534\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_m6 = np.zeros(len(y))\n",
        "for i in fold_results.keys():\n",
        "  for j in range(len(fold_results.get(i).get('predictions'))):\n",
        "    idx = fold_results.get(i).get('index')[j]\n",
        "    preds_m6[idx] = np.round(fold_results.get(i).get('predictions')[j], 0)"
      ],
      "metadata": {
        "id": "7hSFBjJSXmnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m6_cost = cost_func(preds_m6,y)\n",
        "m6_cost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSw-zr1_YDa6",
        "outputId": "d0959827-067b-4cc8-c6ee-1d592f14cf65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1203450"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results"
      ],
      "metadata": {
        "id": "OGDgxEMEAh0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cm2df(cm, labels):\n",
        "    df = pd.DataFrame()\n",
        "    # rows\n",
        "    for i, row_label in enumerate(labels):\n",
        "        rowdata={}\n",
        "        # columns\n",
        "        for j, col_label in enumerate(labels):\n",
        "            rowdata[col_label]=cm[i,j]\n",
        "        df = df.append(pd.DataFrame.from_dict({row_label:rowdata}, orient='index'))\n",
        "    return df[labels]"
      ],
      "metadata": {
        "id": "OEGpLW4wYtS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm_preds_m1 = confusion_matrix(y,preds_m1)\n",
        "cm_preds_m2 = confusion_matrix(y,preds_m2)\n",
        "cm_preds_m4 = confusion_matrix(y,preds_m4)\n",
        "cm_preds_m5 = confusion_matrix(y,preds_m5)\n",
        "cm_preds_m6 = confusion_matrix(y,preds_m6)\n",
        "\n",
        "\n",
        "cm_preds_m1 = cm_preds_m1 / cm_preds_m1.astype(np.float).sum(axis=1)\n",
        "cm_preds_m2 = cm_preds_m2 / cm_preds_m2.astype(np.float).sum(axis=1)\n",
        "cm_preds_m4 = cm_preds_m4 / cm_preds_m4.astype(np.float).sum(axis=1)\n",
        "cm_preds_m5 = cm_preds_m5 / cm_preds_m5.astype(np.float).sum(axis=1)\n",
        "cm_preds_m6 = cm_preds_m6 / cm_preds_m6.astype(np.float).sum(axis=1)"
      ],
      "metadata": {
        "id": "obpbAgIWm1En"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Pos = pd.DataFrame(cm_preds_m1[:1], columns=['True Positive', 'False Positive'])\n",
        "Neg = pd.DataFrame(cm_preds_m1[1:], columns=['False Negative', 'True Negative'])\n",
        "Model = pd.DataFrame(['Logistic Regression'], columns=['Model'])\n",
        "Summary = pd.concat([Model, Pos, Neg], axis=1)\n",
        "\n",
        "Pos = pd.DataFrame(cm_preds_m2[:1], columns=['True Positive', 'False Positive'])\n",
        "Neg = pd.DataFrame(cm_preds_m2[1:], columns=['False Negative', 'True Negative'])\n",
        "Model = pd.DataFrame(['Random Forest'], columns=['Model'])\n",
        "Summary1 = (pd.concat([Model, Pos, Neg], axis=1))\n",
        "\n",
        "Summary = pd.concat([Summary, Summary1])\n",
        "\n",
        "Pos = pd.DataFrame(cm_preds_m4[:1], columns=['True Positive', 'False Positive'])\n",
        "Neg = pd.DataFrame(cm_preds_m4[1:], columns=['False Negative', 'True Negative'])\n",
        "Model = pd.DataFrame(['Neural Network'], columns=['Model'])\n",
        "Summary1 = (pd.concat([Model, Pos, Neg], axis=1))\n",
        "\n",
        "Summary = pd.concat([Summary, Summary1])\n",
        "\n",
        "Pos = pd.DataFrame(cm_preds_m5[:1], columns=['True Positive', 'False Positive'])\n",
        "Neg = pd.DataFrame(cm_preds_m5[1:], columns=['False Negative', 'True Negative'])\n",
        "Model = pd.DataFrame(['Neural Network 2'], columns=['Model'])\n",
        "Summary1 = (pd.concat([Model, Pos, Neg], axis=1))\n",
        "\n",
        "Summary = pd.concat([Summary, Summary1])\n",
        "\n",
        "Pos = pd.DataFrame(cm_preds_m6[:1], columns=['True Positive', 'False Positive'])\n",
        "Neg = pd.DataFrame(cm_preds_m6[1:], columns=['False Negative', 'True Negative'])\n",
        "Model = pd.DataFrame(['XGBoost'], columns=['Model'])\n",
        "Summary1 = (pd.concat([Model, Pos, Neg], axis=1))\n",
        "\n",
        "Summary = pd.concat([Summary, Summary1])\n",
        "Summary = Summary.reset_index()\n",
        "Summary = Summary.drop(columns=['index'])\n",
        "Summary = Summary.set_index('Model')\n",
        "\n",
        "Summary = Summary[['True Positive', 'True Negative', 'False Positive', 'False Negative']]\n",
        "\n",
        "\n",
        "Summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "vlrp5F7J_LqM",
        "outputId": "2944722d-96ea-4e36-8eac-81591faefed7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     True Positive  True Negative  False Positive  \\\n",
              "Model                                                               \n",
              "Logistic Regression            50%            85%             51%   \n",
              "Random Forest                  94%            91%              6%   \n",
              "Neural Network                 96%            97%              4%   \n",
              "Neural Network 2               96%            97%              4%   \n",
              "XGBoost                        94%            94%              6%   \n",
              "\n",
              "                     False Negative  \n",
              "Model                                \n",
              "Logistic Regression             15%  \n",
              "Random Forest                    9%  \n",
              "Neural Network                   3%  \n",
              "Neural Network 2                 3%  \n",
              "XGBoost                          5%  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-fc6ac2b6-4ed9-48c5-bcd3-ddd3a72365d9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>True Positive</th>\n",
              "      <th>True Negative</th>\n",
              "      <th>False Positive</th>\n",
              "      <th>False Negative</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Model</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Logistic Regression</th>\n",
              "      <td>50%</td>\n",
              "      <td>85%</td>\n",
              "      <td>51%</td>\n",
              "      <td>15%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random Forest</th>\n",
              "      <td>94%</td>\n",
              "      <td>91%</td>\n",
              "      <td>6%</td>\n",
              "      <td>9%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Neural Network</th>\n",
              "      <td>96%</td>\n",
              "      <td>97%</td>\n",
              "      <td>4%</td>\n",
              "      <td>3%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Neural Network 2</th>\n",
              "      <td>96%</td>\n",
              "      <td>97%</td>\n",
              "      <td>4%</td>\n",
              "      <td>3%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGBoost</th>\n",
              "      <td>94%</td>\n",
              "      <td>94%</td>\n",
              "      <td>6%</td>\n",
              "      <td>5%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc6ac2b6-4ed9-48c5-bcd3-ddd3a72365d9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-2c10bb2f-608b-40e1-bb03-1064604a59be\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2c10bb2f-608b-40e1-bb03-1064604a59be')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-2c10bb2f-608b-40e1-bb03-1064604a59be button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fc6ac2b6-4ed9-48c5-bcd3-ddd3a72365d9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fc6ac2b6-4ed9-48c5-bcd3-ddd3a72365d9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 287
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "def wrap_labels(ax, width, break_long_words=False):\n",
        "    labels = []\n",
        "    for label in ax.get_xticklabels():\n",
        "        text = label.get_text()\n",
        "        labels.append(textwrap.fill(text, width=width,\n",
        "                      break_long_words=break_long_words))\n",
        "    ax.set_xticklabels(labels, rotation=0)\n",
        "\n",
        "ax = sns.heatmap(Summary, cmap='Blues', linewidths=0.50, annot=True)\n",
        "wrap_labels(ax, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "id": "98yCyr-KCZjF",
        "outputId": "86130f0a-514f-4c5a-b4a9-e898f2dc4a74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 550x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Confusion Matrix of Results\n",
        "\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "cm_preds_m1 = confusion_matrix(y,preds_m1)\n",
        "cm_preds_m2 = confusion_matrix(y,preds_m2)\n",
        "cm_preds_m4 = confusion_matrix(y,preds_m4)\n",
        "cm_preds_m5 = confusion_matrix(y,preds_m5)\n",
        "cm_preds_m6 = confusion_matrix(y,preds_m6)\n",
        "\n",
        "fig, ax = plt.subplots(1,5,figsize= (20,4))\n",
        "\n",
        "disp1 = ConfusionMatrixDisplay(cm_preds_m1).plot(ax = ax[0],cmap = 'Blues', colorbar=False)\n",
        "ax[0].set_title('Logistic Regression'+ '\\n\\n' + ' Cost: '+ '$'+ str(f'{cost_m1:,}'), fontsize = 12)\n",
        "ax[0].grid(False)\n",
        "\n",
        "disp2 = ConfusionMatrixDisplay(cm_preds_m2).plot(ax= ax[1],cmap='Blues', colorbar=False)\n",
        "ax[1].set_title('Random Forest'+ '\\n\\n' + ' Cost: '+ '$'+ str(f'{cost_m2:,}'), fontsize = 12)\n",
        "ax[1].grid(False)\n",
        "\n",
        "\n",
        "disp3 = ConfusionMatrixDisplay(cm_preds_m4).plot(ax= ax[2],cmap='Blues', colorbar=False)\n",
        "ax[2].set_title('Neural Network'+ '\\n\\n' + ' Cost: '+ '$'+ str(f'{m4_cost:,}'), fontsize = 12)\n",
        "ax[2].grid(False)\n",
        "\n",
        "disp4 = ConfusionMatrixDisplay(cm_preds_m5).plot(ax= ax[3],cmap='Blues', colorbar=False)\n",
        "ax[3].set_title('Neural Network 2'+ '\\n\\n' + ' Cost: '+ '$'+ str(f'{m5_cost:,}'), fontsize = 12)\n",
        "ax[3].grid(False)\n",
        "\n",
        "disp5 = ConfusionMatrixDisplay(cm_preds_m6).plot(ax= ax[4],cmap='Blues', colorbar=False)\n",
        "ax[4].set_title('XGBoost'+ '\\n\\n' + ' Cost: '+ '$'+ str(f'{m6_cost:,}'), fontsize = 12)\n",
        "ax[4].grid(False)\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "hYPzNzlQ36Ct",
        "outputId": "e3c7e8de-09d3-4b0f-fb61-b7b673352f8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x400 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ensembling"
      ],
      "metadata": {
        "id": "lV6Za3-7SvNI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Combination of Neural Networks\n",
        "preds_nn = (preds_m4+ preds_m5)/2\n",
        "cost_nn= cost_func(np.round(preds_nn, 0), y)\n",
        "cm_preds_nn = confusion_matrix(y,np.round(preds_nn, 0))\n",
        "\n",
        "#Combination of Neural Networks and XGBoost\n",
        "preds_ens = (preds_m4+ preds_m5+preds_m6)/3\n",
        "cost_ens = cost_func(np.round(preds_ens, 0), y)\n",
        "cm_preds_ens = confusion_matrix(y,np.round(preds_ens, 0))\n",
        "\n",
        "#Combination of Neural Networks, XGBoost, and RF\n",
        "preds_ens2 = (preds_m2 + preds_m4+ preds_m5+preds_m6)/4\n",
        "cost_ens2 = cost_func(np.round(preds_ens2, 0), y)\n",
        "cm_preds_ens2= confusion_matrix(y,np.round(preds_ens2, 0))"
      ],
      "metadata": {
        "id": "2oJ4cy59VAFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,3,figsize= (20,4))\n",
        "\n",
        "disp1 = ConfusionMatrixDisplay(cm_preds_nn).plot(ax = ax[0],cmap = 'Blues', colorbar=False)\n",
        "ax[0].set_title('Combined Neural Networks'+ '\\n\\n' + ' Cost: '+ '$'+ str(f'{cost_nn:,}'), fontsize = 12)\n",
        "ax[0].grid(False)\n",
        "\n",
        "disp1 = ConfusionMatrixDisplay(cm_preds_ens).plot(ax = ax[1],cmap = 'Blues', colorbar=False)\n",
        "ax[1].set_title('Neural Networks and XGBoost'+ '\\n\\n' + ' Cost: '+ '$'+ str(f'{cost_ens:,}'), fontsize = 12)\n",
        "ax[1].grid(False)\n",
        "\n",
        "disp1 = ConfusionMatrixDisplay(cm_preds_ens2).plot(ax = ax[2],cmap = 'Blues', colorbar=False)\n",
        "ax[2].set_title('Neural Networks, XGBoost, and Random Forest'+ '\\n\\n' + ' Cost: '+ '$'+ str(f'{cost_ens2:,}'), fontsize = 12)\n",
        "ax[2].grid(False)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "J71VGqBYU7hF",
        "outputId": "47aba4f4-48a9-493e-a051-c4113650e4f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x400 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Combination of Neural Networks\n",
        "preds_nn = np.minimum(preds_m4,preds_m5)\n",
        "cost_nn= cost_func(np.round(preds_nn, 0), y)\n",
        "cm_preds_nn = confusion_matrix(y,np.round(preds_nn, 0))\n",
        "\n",
        "#Combination of Neural Networks and XGBoost\n",
        "preds_ens = np.minimum(preds_m5,preds_m6)\n",
        "cost_ens = cost_func(np.round(preds_ens, 0), y)\n",
        "cm_preds_ens = confusion_matrix(y,np.round(preds_ens, 0))\n",
        "\n",
        "#Combination of Neural Networks, XGBoost, and RF\n",
        "preds_ens2 = np.minimum(preds_m2,preds_ens)\n",
        "cost_ens2 = cost_func(np.round(preds_ens2, 0), y)\n",
        "cm_preds_ens2= confusion_matrix(y,np.round(preds_ens2, 0))"
      ],
      "metadata": {
        "id": "lAQC40zKZieU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}