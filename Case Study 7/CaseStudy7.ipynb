{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "mount_file_id": "https://github.com/KendallScott/QTW/blob/main/Case%20Study%207/CaseStudy7.ipynb",
      "authorship_tag": "ABX9TyMzDxh1cRKGQ436cxtghhkK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/boneeyah/QTW/blob/main/Case%20Study%207/CaseStudy7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OZryWKHR3JAd"
      },
      "outputs": [],
      "source": [
        "#!pip install scikit-learn-intelex\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearnex import patch_sklearn\n",
        "patch_sklearn()\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import NuSVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_val_predict\n",
        "import datetime"
      ],
      "metadata": {
        "id": "HrVUsV_b8Ezp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91b58fae-26c1-4226-a307-34051ae40035"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-07-29 18:01:04.969998: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-29 18:01:05.633976: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('drive')"
      ],
      "metadata": {
        "id": "T6H6L4bc8YlZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df = pd.read_csv(\"drive/My Drive/final_project(5).csv\")\n",
        "df = pd.read_csv(\"/home/migue/Downloads/final_project(5).csv\")"
      ],
      "metadata": {
        "id": "hngzaeNL-EXs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()\n",
        "#there are NAs will need handling"
      ],
      "metadata": {
        "id": "kjzOue9y_SuK",
        "outputId": "7d9618a6-3533-499a-afe3-97afe8a36a6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 160000 entries, 0 to 159999\n",
            "Data columns (total 51 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   x0      159974 non-null  float64\n",
            " 1   x1      159975 non-null  float64\n",
            " 2   x2      159962 non-null  float64\n",
            " 3   x3      159963 non-null  float64\n",
            " 4   x4      159974 non-null  float64\n",
            " 5   x5      159963 non-null  float64\n",
            " 6   x6      159974 non-null  float64\n",
            " 7   x7      159973 non-null  float64\n",
            " 8   x8      159979 non-null  float64\n",
            " 9   x9      159970 non-null  float64\n",
            " 10  x10     159957 non-null  float64\n",
            " 11  x11     159970 non-null  float64\n",
            " 12  x12     159964 non-null  float64\n",
            " 13  x13     159969 non-null  float64\n",
            " 14  x14     159966 non-null  float64\n",
            " 15  x15     159965 non-null  float64\n",
            " 16  x16     159974 non-null  float64\n",
            " 17  x17     159973 non-null  float64\n",
            " 18  x18     159960 non-null  float64\n",
            " 19  x19     159965 non-null  float64\n",
            " 20  x20     159962 non-null  float64\n",
            " 21  x21     159971 non-null  float64\n",
            " 22  x22     159973 non-null  float64\n",
            " 23  x23     159953 non-null  float64\n",
            " 24  x24     159972 non-null  object \n",
            " 25  x25     159978 non-null  float64\n",
            " 26  x26     159964 non-null  float64\n",
            " 27  x27     159970 non-null  float64\n",
            " 28  x28     159965 non-null  float64\n",
            " 29  x29     159970 non-null  object \n",
            " 30  x30     159970 non-null  object \n",
            " 31  x31     159961 non-null  float64\n",
            " 32  x32     159969 non-null  object \n",
            " 33  x33     159959 non-null  float64\n",
            " 34  x34     159959 non-null  float64\n",
            " 35  x35     159970 non-null  float64\n",
            " 36  x36     159973 non-null  float64\n",
            " 37  x37     159977 non-null  object \n",
            " 38  x38     159969 non-null  float64\n",
            " 39  x39     159977 non-null  float64\n",
            " 40  x40     159964 non-null  float64\n",
            " 41  x41     159960 non-null  float64\n",
            " 42  x42     159974 non-null  float64\n",
            " 43  x43     159963 non-null  float64\n",
            " 44  x44     159960 non-null  float64\n",
            " 45  x45     159971 non-null  float64\n",
            " 46  x46     159969 non-null  float64\n",
            " 47  x47     159963 non-null  float64\n",
            " 48  x48     159968 non-null  float64\n",
            " 49  x49     159968 non-null  float64\n",
            " 50  y       160000 non-null  int64  \n",
            "dtypes: float64(45), int64(1), object(5)\n",
            "memory usage: 62.3+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in df.columns:\n",
        "    if df[i].isna().sum() > 0:\n",
        "        print('{} has {}% NAs'.format(i,(df[i].isna().sum() / len(df))*100))"
      ],
      "metadata": {
        "id": "CC3yFJ6BzzOw",
        "outputId": "b42d9bbe-3951-4dfc-fb1a-86250108a71e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x0 has 0.01625% NAs\n",
            "x1 has 0.015625% NAs\n",
            "x2 has 0.02375% NAs\n",
            "x3 has 0.023125% NAs\n",
            "x4 has 0.01625% NAs\n",
            "x5 has 0.023125% NAs\n",
            "x6 has 0.01625% NAs\n",
            "x7 has 0.016875% NAs\n",
            "x8 has 0.013125% NAs\n",
            "x9 has 0.01875% NAs\n",
            "x10 has 0.026875% NAs\n",
            "x11 has 0.01875% NAs\n",
            "x12 has 0.0225% NAs\n",
            "x13 has 0.019375% NAs\n",
            "x14 has 0.021249999999999998% NAs\n",
            "x15 has 0.021875000000000002% NAs\n",
            "x16 has 0.01625% NAs\n",
            "x17 has 0.016875% NAs\n",
            "x18 has 0.025% NAs\n",
            "x19 has 0.021875000000000002% NAs\n",
            "x20 has 0.02375% NAs\n",
            "x21 has 0.018125% NAs\n",
            "x22 has 0.016875% NAs\n",
            "x23 has 0.029375000000000002% NAs\n",
            "x24 has 0.017499999999999998% NAs\n",
            "x25 has 0.01375% NAs\n",
            "x26 has 0.0225% NAs\n",
            "x27 has 0.01875% NAs\n",
            "x28 has 0.021875000000000002% NAs\n",
            "x29 has 0.01875% NAs\n",
            "x30 has 0.01875% NAs\n",
            "x31 has 0.024374999999999997% NAs\n",
            "x32 has 0.019375% NAs\n",
            "x33 has 0.025625000000000002% NAs\n",
            "x34 has 0.025625000000000002% NAs\n",
            "x35 has 0.01875% NAs\n",
            "x36 has 0.016875% NAs\n",
            "x37 has 0.014374999999999999% NAs\n",
            "x38 has 0.019375% NAs\n",
            "x39 has 0.014374999999999999% NAs\n",
            "x40 has 0.0225% NAs\n",
            "x41 has 0.025% NAs\n",
            "x42 has 0.01625% NAs\n",
            "x43 has 0.023125% NAs\n",
            "x44 has 0.025% NAs\n",
            "x45 has 0.018125% NAs\n",
            "x46 has 0.019375% NAs\n",
            "x47 has 0.023125% NAs\n",
            "x48 has 0.02% NAs\n",
            "x49 has 0.02% NAs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['x24'].value_counts()"
      ],
      "metadata": {
        "id": "TybuIbMLz6Ng",
        "outputId": "e6a1018f-7e65-4d99-eb7e-3093c0d550f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "x24\n",
              "asia       138965\n",
              "euorpe      16538\n",
              "america      4469\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(x=df['x24'].value_counts().index,height=df['x24'].value_counts().values)"
      ],
      "metadata": {
        "id": "ME56MKaIz7sN",
        "outputId": "75ba7d5e-15f8-4e9e-9161-42d6a5cbcb64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 3 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['x29'].value_counts()"
      ],
      "metadata": {
        "id": "P7rMlCalz9WH",
        "outputId": "b9c22c13-69dc-4257-fcad-4087c4e332ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "x29\n",
              "July       45569\n",
              "Jun        41329\n",
              "Aug        29406\n",
              "May        21939\n",
              "sept.      10819\n",
              "Apr         6761\n",
              "Oct         2407\n",
              "Mar         1231\n",
              "Nov          337\n",
              "Feb          140\n",
              "Dev           23\n",
              "January        9\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#clean up month formatting to standard 3 letters\n",
        "df['x29'].replace(to_replace=['July','sept.','Dev','January'],value=['Jul','Sep','Dec','Jan'],inplace=True)"
      ],
      "metadata": {
        "id": "gB-gkjC2z_fK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mo = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
        "heights = []\n",
        "for i in mo:\n",
        "    x = df['x29'].to_list().count(i)\n",
        "    heights.append(x)\n",
        "plt.bar(x=mo,height=heights)"
      ],
      "metadata": {
        "id": "eZTNOL9P0CM3",
        "outputId": "d34c53a3-3418-4c18-f694-20ab30a680a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 12 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['x30'].value_counts()"
      ],
      "metadata": {
        "id": "_1LSKgy80ENF",
        "outputId": "3e28dbd5-b03f-4fae-c220-19378d453c55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "x30\n",
              "wednesday    101535\n",
              "thurday       29429\n",
              "tuesday       27954\n",
              "friday          564\n",
              "monday          488\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# thursday is incorrect\n",
        "df['x30'].replace(to_replace = 'thurday',value='thursday')\n",
        "days = ['monday','tuesday','wednesday','thursday','friday']\n",
        "d_heights = []\n",
        "for i in days:\n",
        "    x = df['x30'].to_list().count(i)\n",
        "    d_heights.append(x)\n",
        "plt.bar(x=days,height = d_heights)"
      ],
      "metadata": {
        "id": "3hFwgArL0GAB",
        "outputId": "1e75e9a2-2ecc-458d-d7b4-d4c8352b5b8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 5 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['x32'].value_counts()"
      ],
      "metadata": {
        "id": "WErTHaJ70Ia2",
        "outputId": "247996e1-dd92-4745-8128-8510b01d2a70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "x32\n",
              "0.01%     40767\n",
              "-0.01%    34094\n",
              "0.0%      33923\n",
              "-0.0%     30492\n",
              "-0.02%     9924\n",
              "0.02%      7987\n",
              "-0.03%     1727\n",
              "0.03%       855\n",
              "-0.04%      138\n",
              "0.04%        55\n",
              "-0.05%        6\n",
              "0.05%         1\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['x37'].value_counts()\n"
      ],
      "metadata": {
        "id": "r98Zehw50LS1",
        "outputId": "b1de88dc-5c2b-4ba7-ab15-091cc996e11a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "x37\n",
              "$-311.26     6\n",
              "$-336.77     6\n",
              "$237.4       6\n",
              "$72.42       6\n",
              "$341.26      6\n",
              "            ..\n",
              "$-505.21     1\n",
              "$770.07      1\n",
              "$74.62       1\n",
              "$-1082.96    1\n",
              "$-1229.34    1\n",
              "Name: count, Length: 129198, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### x32 and x37 are actually numeric with string format (even though x32 has few \"levels\" or possible values)\n",
        "### x32 is in percentage, but don't think it needs to be transformed to proportion since data will be scaled later (will double check, but should make no difference)\n",
        "\n",
        "df['x32'] = df['x32'].transform(lambda x: float(str(x).replace('%','')))\n",
        "df['x37'] = df['x37'].transform(lambda x: float(str(x).replace('$','')))"
      ],
      "metadata": {
        "id": "-8HSIli70VDX"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#all significanlty less than 5%, should be no issue imputing,\n",
        "#imputing categorical features with modes\n",
        "# imputing continent with mode, then dates by mode grouped by continent\n",
        "\n",
        "print('imputing continent with mode: {}'.format(df['x24'].aggregate(pd.Series.mode)))\n",
        "df['x24'] = df['x24'].transform(lambda x: x.fillna(pd.Series.mode(x)[0]))\n",
        "\n",
        "print('imputing month with mode by cont: {}'.format(df[['x24','x29']].groupby(by='x24').aggregate(pd.Series.mode)))\n",
        "idx_29 = df.loc[df['x29'].isna(),:].index #saving NAs indices to quick check what they've been imputed with\n",
        "df['x29'] = df[['x24','x29']].groupby(by='x24').transform(lambda grp: grp.fillna(pd.Series.mode(grp)[0]))\n",
        "\n",
        "# will fix index showing on print later\n"
      ],
      "metadata": {
        "id": "qyAc5R1u209T",
        "outputId": "73e125f3-3ea3-42f3-ac4c-9572e6fc2415",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "imputing continent with mode: 0    asia\n",
            "Name: x24, dtype: object\n",
            "imputing month with mode by cont:          x29\n",
            "x24         \n",
            "america  Jul\n",
            "asia     Jul\n",
            "euorpe   Jul\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[['x24','x29','x30']].groupby(by=['x24','x29']).aggregate(pd.Series.mode)\n",
        "# could just impute with wednesday since Wed is mode per month, but adding continent gives more context and different days for some months"
      ],
      "metadata": {
        "id": "2iV02zDI3Emu",
        "outputId": "45e0a7f5-7c58-4be9-c7ce-48280cdd5206",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   x30\n",
              "x24     x29           \n",
              "america Apr  wednesday\n",
              "        Aug  wednesday\n",
              "        Feb    tuesday\n",
              "        Jul  wednesday\n",
              "        Jun  wednesday\n",
              "        Mar  wednesday\n",
              "        May  wednesday\n",
              "        Nov  wednesday\n",
              "        Oct  wednesday\n",
              "        Sep  wednesday\n",
              "asia    Apr  wednesday\n",
              "        Aug  wednesday\n",
              "        Dec  wednesday\n",
              "        Feb  wednesday\n",
              "        Jan  wednesday\n",
              "        Jul  wednesday\n",
              "        Jun  wednesday\n",
              "        Mar  wednesday\n",
              "        May  wednesday\n",
              "        Nov  wednesday\n",
              "        Oct  wednesday\n",
              "        Sep  wednesday\n",
              "euorpe  Apr  wednesday\n",
              "        Aug  wednesday\n",
              "        Dec  wednesday\n",
              "        Feb    tuesday\n",
              "        Jul  wednesday\n",
              "        Jun  wednesday\n",
              "        Mar  wednesday\n",
              "        May  wednesday\n",
              "        Nov  wednesday\n",
              "        Oct  wednesday\n",
              "        Sep  wednesday"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>x30</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x24</th>\n",
              "      <th>x29</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"10\" valign=\"top\">america</th>\n",
              "      <th>Apr</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Aug</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feb</th>\n",
              "      <td>tuesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jul</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jun</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mar</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>May</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nov</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Oct</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sep</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"12\" valign=\"top\">asia</th>\n",
              "      <th>Apr</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Aug</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dec</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feb</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jan</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jul</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jun</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mar</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>May</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nov</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Oct</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sep</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"11\" valign=\"top\">euorpe</th>\n",
              "      <th>Apr</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Aug</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dec</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feb</th>\n",
              "      <td>tuesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jul</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jun</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mar</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>May</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nov</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Oct</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sep</th>\n",
              "      <td>wednesday</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# impute day\n",
        "df['x30'] = df[['x24','x29','x30']].groupby(by=['x24','x29']).transform(lambda grp: grp.fillna(pd.Series.mode(grp)[0]))"
      ],
      "metadata": {
        "id": "HVQavir8IV9m"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.loc[:,df.columns != 'y']\n",
        "y = df['y'].values.flatten()\n",
        "\n",
        "df_num = X.select_dtypes(exclude='object')\n",
        "num_cols = df_num.columns\n",
        "\n",
        "# impute numeric with median\n",
        "for i in num_cols:\n",
        "    df_num[i] = df_num[i].transform(lambda x: x.fillna(pd.Series.mode(x)[0]))\n",
        "df_num.info()\n",
        "\n",
        "df_cat = X.select_dtypes(include='object')\n",
        "cat_cols = df_cat.columns\n",
        "\n",
        "# scale numerical data\n",
        "scaler = StandardScaler()\n",
        "df_num = scaler.fit_transform(df_num)\n",
        "\n",
        "#one hot encode cat data\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "df_cat = encoder.fit_transform(df_cat)"
      ],
      "metadata": {
        "id": "w8Uy9xG3Iern",
        "outputId": "8a49f41a-4ae8-405f-8a7f-dde12f3a66ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 160000 entries, 0 to 159999\n",
            "Data columns (total 47 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   x0      160000 non-null  float64\n",
            " 1   x1      160000 non-null  float64\n",
            " 2   x2      160000 non-null  float64\n",
            " 3   x3      160000 non-null  float64\n",
            " 4   x4      160000 non-null  float64\n",
            " 5   x5      160000 non-null  float64\n",
            " 6   x6      160000 non-null  float64\n",
            " 7   x7      160000 non-null  float64\n",
            " 8   x8      160000 non-null  float64\n",
            " 9   x9      160000 non-null  float64\n",
            " 10  x10     160000 non-null  float64\n",
            " 11  x11     160000 non-null  float64\n",
            " 12  x12     160000 non-null  float64\n",
            " 13  x13     160000 non-null  float64\n",
            " 14  x14     160000 non-null  float64\n",
            " 15  x15     160000 non-null  float64\n",
            " 16  x16     160000 non-null  float64\n",
            " 17  x17     160000 non-null  float64\n",
            " 18  x18     160000 non-null  float64\n",
            " 19  x19     160000 non-null  float64\n",
            " 20  x20     160000 non-null  float64\n",
            " 21  x21     160000 non-null  float64\n",
            " 22  x22     160000 non-null  float64\n",
            " 23  x23     160000 non-null  float64\n",
            " 24  x25     160000 non-null  float64\n",
            " 25  x26     160000 non-null  float64\n",
            " 26  x27     160000 non-null  float64\n",
            " 27  x28     160000 non-null  float64\n",
            " 28  x31     160000 non-null  float64\n",
            " 29  x32     160000 non-null  float64\n",
            " 30  x33     160000 non-null  float64\n",
            " 31  x34     160000 non-null  float64\n",
            " 32  x35     160000 non-null  float64\n",
            " 33  x36     160000 non-null  float64\n",
            " 34  x37     160000 non-null  float64\n",
            " 35  x38     160000 non-null  float64\n",
            " 36  x39     160000 non-null  float64\n",
            " 37  x40     160000 non-null  float64\n",
            " 38  x41     160000 non-null  float64\n",
            " 39  x42     160000 non-null  float64\n",
            " 40  x43     160000 non-null  float64\n",
            " 41  x44     160000 non-null  float64\n",
            " 42  x45     160000 non-null  float64\n",
            " 43  x46     160000 non-null  float64\n",
            " 44  x47     160000 non-null  float64\n",
            " 45  x48     160000 non-null  float64\n",
            " 46  x49     160000 non-null  float64\n",
            "dtypes: float64(47)\n",
            "memory usage: 57.4 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.hstack([df_num,df_cat])"
      ],
      "metadata": {
        "id": "R4oaw8CgIkXV"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['y'].value_counts() # not balanced"
      ],
      "metadata": {
        "id": "xbzdACUdImVy",
        "outputId": "fc49c2f5-bba7-45d7-ec23-ab6eae374e8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "y\n",
              "0    95803\n",
              "1    64197\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#add y plot"
      ],
      "metadata": {
        "id": "vUXTcWUZIoot"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## define cost function\n",
        "def cost(y_true,y_pred):\n",
        "    diff = y_pred - y_true\n",
        "    x = 0\n",
        "    for i in diff:\n",
        "        #false pos (y_pred -y_true == 1)\n",
        "        if i == 1:\n",
        "            x += 100\n",
        "        #false neg (y_pred -y_true ==-1)\n",
        "        elif i == -1:\n",
        "            x += 150\n",
        "    return(x)"
      ],
      "metadata": {
        "id": "HRJz__nu_bxm"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skf = StratifiedKFold(n_splits=5,random_state=807,shuffle=True)\n",
        "skf.get_n_splits(X,y)"
      ],
      "metadata": {
        "id": "qIgBnSnHIqjU",
        "outputId": "ee13ffb3-a398-4dc4-ff88-4df52a8d6f4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logR = LogisticRegression(random_state=807,penalty='elasticnet',class_weight='balanced',solver='saga')\n",
        "params = {'C':[0.00001,0.0001,0.001,0.01,0.1,1,2,5,10],'l1_ratio':[0,0.001,0.01,0.1,0.25,0.5,0.75,0.9,0.99,1],'max_iter':[25,50,75]}\n",
        "\n",
        "lr_clf = GridSearchCV(estimator=logR,param_grid=params,n_jobs=-1,cv=skf)\n",
        "lr_clf.fit(X,y)"
      ],
      "metadata": {
        "id": "AcpquSzJO6SF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_params = lr_clf.best_params_\n",
        "lr_params"
      ],
      "metadata": {
        "id": "Eb5e2xOvO8pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "{'C': 0.001, 'l1_ratio': 0.5, 'max_iter': 50}"
      ],
      "metadata": {
        "id": "gfllGKF4pUMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = LogisticRegression(random_state=807,penalty='elasticnet',class_weight='balanced',solver='saga')\n",
        "model1.set_params(**lr_params)\n",
        "model1.fit(X,y)\n",
        "\n",
        "preds_m1 = cross_val_predict(model1,X,y,cv=skf)"
      ],
      "metadata": {
        "id": "RHUkzlw2PATu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cr_m1 = classification_report(y,preds_m1,output_dict=True)\n",
        "cr_m1\n"
      ],
      "metadata": {
        "id": "3katCHeBPQB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ConfusionMatrixDisplay.from_predictions(y,preds_m1)\n"
      ],
      "metadata": {
        "id": "ent8XHdUPayB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cost_m1 = cost(preds_m1,y)\n",
        "cost_m1"
      ],
      "metadata": {
        "id": "zawbBlwk_fbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(random_state=807,criterion='gini',class_weight='balanced')\n",
        "params = {'n_estimators':[200,250,500],'max_features':['sqrt','log2',20]}\n",
        "rf_clf = GridSearchCV(rf,param_grid=params,cv=skf,n_jobs = -1)"
      ],
      "metadata": {
        "id": "4HWotr_VPhhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_clf.fit(X,y)"
      ],
      "metadata": {
        "id": "soQp5nQ8PkUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_params = rf_clf.best_params_\n",
        "rf_params"
      ],
      "metadata": {
        "id": "Hz6owkMTPlOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = RandomForestClassifier(random_state=807,criterion='gini',class_weight='balanced')\n",
        "model2.set_params(**rf_params)\n",
        "preds_m2 = cross_val_predict(model2,X,y,cv=skf)"
      ],
      "metadata": {
        "id": "hvIbks5bPnfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cr_m2 = classification_report(y,preds_m2,output_dict=True)\n",
        "cr_m2"
      ],
      "metadata": {
        "id": "Aaw8aFI7PpCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ConfusionMatrixDisplay.from_predictions(y,preds_m2)"
      ],
      "metadata": {
        "id": "BK6zSOo4Pq_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cost_m2 = cost(preds_m2,y)\n",
        "cost_m2\n"
      ],
      "metadata": {
        "id": "XqmhfmAx9Ge2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "id": "Fdw5gLOk9oBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svc = NuSVC(random_state=807,class_weight='balanced',cache_size = 8192)\n",
        "params = {'nu':[0.0001,0.01, 0.1, 0.25, 0.5, 0.75, 0.99,1],'kernel':['linear','rbf','sigmoid']}\n",
        "svc_clf = GridSearchCV(svc,param_grid=params,cv=skf,n_jobs=-1)"
      ],
      "metadata": {
        "id": "zYBX6GGsPwEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svc_clf.fit(X,y)"
      ],
      "metadata": {
        "id": "EjZRywoCP6hm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svc_params = svc_clf.best_params_\n",
        "svc_params"
      ],
      "metadata": {
        "id": "yYiNL9AlP98A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = NuSVC(random_state=807,class_weight='balanced',cache_size = 2048)\n",
        "model3.set_params(**svc_params)\n",
        "preds_m3 = cross_val_predict(model3,X,y,cv=skf)"
      ],
      "metadata": {
        "id": "_58pwDIoQGHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cr_m3 = classification_report(y,preds_m3,output_dict=True)\n",
        "cr_m3"
      ],
      "metadata": {
        "id": "5AVAi2z8QPOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ConfusionMatrixDisplay.from_predictions(y,preds_m3)"
      ],
      "metadata": {
        "id": "j5nGHzRUQUOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cost_m3 = cost(preds_m3,y)\n",
        "cost_m3"
      ],
      "metadata": {
        "id": "sefhH4BT-Rd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "8946dca4-81fe-4bfb-be64-a384b53f9eb4"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cost_m3 \u001b[38;5;241m=\u001b[39m cost(\u001b[43mpreds_m3\u001b[49m,y)\n\u001b[1;32m      2\u001b[0m cost_m3\n",
            "\u001b[0;31mNameError\u001b[0m: name 'preds_m3' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "now = datetime.datetime.now\n"
      ],
      "metadata": {
        "id": "b04x7Mf5dBDd"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.set_random_seed(807)\n",
        "es = EarlyStopping(monitor='val_loss', mode='min',patience=10,restore_best_weights=True,start_from_epoch=10)\n",
        "fold_results = {}\n",
        "t_tot = now()\n",
        "for i, (train_index, test_index) in enumerate(skf.split(X,y)):\n",
        "  # building model within loop to reset weights each time\n",
        "  tf.keras.backend.clear_session()\n",
        "  model4 = tf.keras.Sequential()\n",
        "  model4.add(tf.keras.Input(shape=(X.shape[1],)))\n",
        "  model4.add(tf.keras.layers.Dense(64, activation='relu',name=\"Relu1\"))\n",
        "  model4.add(tf.keras.layers.Dense(64, activation='relu', name=\"Relu2\"))\n",
        "  model4.add(tf.keras.layers.Dropout(0.4))\n",
        "  model4.add(tf.keras.layers.Dense(1, activation='sigmoid', name=\"Activation\"))\n",
        "  model4.compile(optimizer='adam',\n",
        "                loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "                metrics = [tf.keras.metrics.AUC(from_logits=False), 'accuracy'])\n",
        "  t_fold = now()\n",
        "  print('x_train shape:', X[train_index].shape)\n",
        "  model4.fit(X[train_index],y[train_index],epochs=100,batch_size=64,validation_split=0.2,callbacks=[es])\n",
        "  fold_results.update({i:{'predictions':model4.predict(X[test_index]).flatten(),'index':test_index,'y_true':y[test_index]}})\n",
        "  print('fold train/predict time: %s' % (now()-t_fold))\n",
        "print('total train/predict time: %s' % (now()-t_tot))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEjPIqNtVPF1",
        "outputId": "11a1dd6b-44b4-4f30-f49d-3667b30d8a04"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-07-29 18:01:19.403444: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-29 18:01:19.409010: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-29 18:01:19.409423: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-29 18:01:19.410778: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-29 18:01:19.411200: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-29 18:01:19.411591: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-29 18:01:20.001024: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-29 18:01:20.001357: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-29 18:01:20.001609: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-29 18:01:20.001820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3326 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050 Ti with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (128000, 67)\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-07-29 18:01:21.029674: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f7213581f60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2023-07-29 18:01:21.029696: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce GTX 1050 Ti with Max-Q Design, Compute Capability 6.1\n",
            "2023-07-29 18:01:21.034010: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2023-07-29 18:01:21.183556: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
            "2023-07-29 18:01:21.303801: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1600/1600 [==============================] - 7s 3ms/step - loss: 0.3797 - auc: 0.9067 - accuracy: 0.8289 - val_loss: 0.2840 - val_auc: 0.9493 - val_accuracy: 0.8816\n",
            "Epoch 2/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2641 - auc: 0.9560 - accuracy: 0.8947 - val_loss: 0.2302 - val_auc: 0.9666 - val_accuracy: 0.9101\n",
            "Epoch 3/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2246 - auc: 0.9681 - accuracy: 0.9130 - val_loss: 0.1983 - val_auc: 0.9750 - val_accuracy: 0.9253\n",
            "Epoch 4/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1993 - auc: 0.9747 - accuracy: 0.9263 - val_loss: 0.1779 - val_auc: 0.9799 - val_accuracy: 0.9350\n",
            "Epoch 5/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1825 - auc: 0.9785 - accuracy: 0.9345 - val_loss: 0.1679 - val_auc: 0.9816 - val_accuracy: 0.9401\n",
            "Epoch 6/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1710 - auc: 0.9810 - accuracy: 0.9388 - val_loss: 0.1587 - val_auc: 0.9833 - val_accuracy: 0.9454\n",
            "Epoch 7/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1629 - auc: 0.9825 - accuracy: 0.9426 - val_loss: 0.1560 - val_auc: 0.9838 - val_accuracy: 0.9446\n",
            "Epoch 8/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1574 - auc: 0.9836 - accuracy: 0.9445 - val_loss: 0.1497 - val_auc: 0.9851 - val_accuracy: 0.9477\n",
            "Epoch 9/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1521 - auc: 0.9846 - accuracy: 0.9476 - val_loss: 0.1466 - val_auc: 0.9856 - val_accuracy: 0.9492\n",
            "Epoch 10/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1465 - auc: 0.9856 - accuracy: 0.9503 - val_loss: 0.1452 - val_auc: 0.9858 - val_accuracy: 0.9508\n",
            "Epoch 11/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1435 - auc: 0.9860 - accuracy: 0.9510 - val_loss: 0.1405 - val_auc: 0.9863 - val_accuracy: 0.9539\n",
            "Epoch 12/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1402 - auc: 0.9866 - accuracy: 0.9527 - val_loss: 0.1379 - val_auc: 0.9870 - val_accuracy: 0.9543\n",
            "Epoch 13/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1372 - auc: 0.9872 - accuracy: 0.9541 - val_loss: 0.1389 - val_auc: 0.9867 - val_accuracy: 0.9547\n",
            "Epoch 14/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1325 - auc: 0.9879 - accuracy: 0.9557 - val_loss: 0.1322 - val_auc: 0.9878 - val_accuracy: 0.9579\n",
            "Epoch 15/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1311 - auc: 0.9880 - accuracy: 0.9560 - val_loss: 0.1334 - val_auc: 0.9877 - val_accuracy: 0.9571\n",
            "Epoch 16/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1273 - auc: 0.9886 - accuracy: 0.9582 - val_loss: 0.1286 - val_auc: 0.9881 - val_accuracy: 0.9594\n",
            "Epoch 17/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1259 - auc: 0.9888 - accuracy: 0.9581 - val_loss: 0.1309 - val_auc: 0.9881 - val_accuracy: 0.9581\n",
            "Epoch 18/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1251 - auc: 0.9889 - accuracy: 0.9588 - val_loss: 0.1319 - val_auc: 0.9880 - val_accuracy: 0.9588\n",
            "Epoch 19/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1224 - auc: 0.9891 - accuracy: 0.9600 - val_loss: 0.1262 - val_auc: 0.9882 - val_accuracy: 0.9609\n",
            "Epoch 20/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1191 - auc: 0.9897 - accuracy: 0.9606 - val_loss: 0.1240 - val_auc: 0.9888 - val_accuracy: 0.9630\n",
            "Epoch 21/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1195 - auc: 0.9896 - accuracy: 0.9614 - val_loss: 0.1249 - val_auc: 0.9887 - val_accuracy: 0.9608\n",
            "Epoch 22/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1163 - auc: 0.9901 - accuracy: 0.9628 - val_loss: 0.1246 - val_auc: 0.9888 - val_accuracy: 0.9607\n",
            "Epoch 23/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1144 - auc: 0.9903 - accuracy: 0.9627 - val_loss: 0.1224 - val_auc: 0.9894 - val_accuracy: 0.9635\n",
            "Epoch 24/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1126 - auc: 0.9905 - accuracy: 0.9638 - val_loss: 0.1214 - val_auc: 0.9891 - val_accuracy: 0.9632\n",
            "Epoch 25/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1118 - auc: 0.9906 - accuracy: 0.9642 - val_loss: 0.1208 - val_auc: 0.9891 - val_accuracy: 0.9637\n",
            "Epoch 26/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1110 - auc: 0.9908 - accuracy: 0.9647 - val_loss: 0.1199 - val_auc: 0.9894 - val_accuracy: 0.9639\n",
            "Epoch 27/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1088 - auc: 0.9909 - accuracy: 0.9647 - val_loss: 0.1191 - val_auc: 0.9893 - val_accuracy: 0.9642\n",
            "Epoch 28/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1088 - auc: 0.9910 - accuracy: 0.9658 - val_loss: 0.1173 - val_auc: 0.9897 - val_accuracy: 0.9655\n",
            "Epoch 29/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1076 - auc: 0.9912 - accuracy: 0.9664 - val_loss: 0.1180 - val_auc: 0.9894 - val_accuracy: 0.9648\n",
            "Epoch 30/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1060 - auc: 0.9914 - accuracy: 0.9666 - val_loss: 0.1168 - val_auc: 0.9896 - val_accuracy: 0.9655\n",
            "Epoch 31/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1055 - auc: 0.9914 - accuracy: 0.9666 - val_loss: 0.1181 - val_auc: 0.9892 - val_accuracy: 0.9657\n",
            "Epoch 32/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1033 - auc: 0.9917 - accuracy: 0.9679 - val_loss: 0.1189 - val_auc: 0.9894 - val_accuracy: 0.9647\n",
            "Epoch 33/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1026 - auc: 0.9918 - accuracy: 0.9676 - val_loss: 0.1170 - val_auc: 0.9894 - val_accuracy: 0.9646\n",
            "Epoch 34/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1026 - auc: 0.9917 - accuracy: 0.9679 - val_loss: 0.1192 - val_auc: 0.9895 - val_accuracy: 0.9652\n",
            "Epoch 35/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1003 - auc: 0.9920 - accuracy: 0.9688 - val_loss: 0.1161 - val_auc: 0.9893 - val_accuracy: 0.9667\n",
            "Epoch 36/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1004 - auc: 0.9920 - accuracy: 0.9686 - val_loss: 0.1185 - val_auc: 0.9894 - val_accuracy: 0.9643\n",
            "Epoch 37/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0999 - auc: 0.9921 - accuracy: 0.9690 - val_loss: 0.1130 - val_auc: 0.9901 - val_accuracy: 0.9671\n",
            "Epoch 38/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1005 - auc: 0.9919 - accuracy: 0.9688 - val_loss: 0.1138 - val_auc: 0.9900 - val_accuracy: 0.9668\n",
            "Epoch 39/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0982 - auc: 0.9922 - accuracy: 0.9699 - val_loss: 0.1139 - val_auc: 0.9898 - val_accuracy: 0.9656\n",
            "Epoch 40/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0979 - auc: 0.9922 - accuracy: 0.9701 - val_loss: 0.1197 - val_auc: 0.9894 - val_accuracy: 0.9650\n",
            "Epoch 41/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0983 - auc: 0.9922 - accuracy: 0.9697 - val_loss: 0.1139 - val_auc: 0.9899 - val_accuracy: 0.9663\n",
            "Epoch 42/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0966 - auc: 0.9924 - accuracy: 0.9704 - val_loss: 0.1128 - val_auc: 0.9902 - val_accuracy: 0.9664\n",
            "Epoch 43/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0957 - auc: 0.9924 - accuracy: 0.9711 - val_loss: 0.1147 - val_auc: 0.9900 - val_accuracy: 0.9675\n",
            "Epoch 44/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0947 - auc: 0.9925 - accuracy: 0.9707 - val_loss: 0.1123 - val_auc: 0.9900 - val_accuracy: 0.9673\n",
            "Epoch 45/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0953 - auc: 0.9926 - accuracy: 0.9710 - val_loss: 0.1110 - val_auc: 0.9902 - val_accuracy: 0.9680\n",
            "Epoch 46/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0944 - auc: 0.9927 - accuracy: 0.9711 - val_loss: 0.1124 - val_auc: 0.9901 - val_accuracy: 0.9679\n",
            "Epoch 47/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0937 - auc: 0.9928 - accuracy: 0.9715 - val_loss: 0.1156 - val_auc: 0.9897 - val_accuracy: 0.9664\n",
            "Epoch 48/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0936 - auc: 0.9928 - accuracy: 0.9713 - val_loss: 0.1132 - val_auc: 0.9901 - val_accuracy: 0.9674\n",
            "Epoch 49/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0929 - auc: 0.9928 - accuracy: 0.9714 - val_loss: 0.1138 - val_auc: 0.9900 - val_accuracy: 0.9675\n",
            "Epoch 50/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0926 - auc: 0.9930 - accuracy: 0.9720 - val_loss: 0.1127 - val_auc: 0.9904 - val_accuracy: 0.9668\n",
            "Epoch 51/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0913 - auc: 0.9930 - accuracy: 0.9722 - val_loss: 0.1128 - val_auc: 0.9905 - val_accuracy: 0.9671\n",
            "Epoch 52/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0908 - auc: 0.9931 - accuracy: 0.9731 - val_loss: 0.1124 - val_auc: 0.9901 - val_accuracy: 0.9682\n",
            "Epoch 53/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0923 - auc: 0.9928 - accuracy: 0.9717 - val_loss: 0.1127 - val_auc: 0.9901 - val_accuracy: 0.9666\n",
            "Epoch 54/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0917 - auc: 0.9929 - accuracy: 0.9726 - val_loss: 0.1111 - val_auc: 0.9903 - val_accuracy: 0.9679\n",
            "Epoch 55/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0906 - auc: 0.9931 - accuracy: 0.9723 - val_loss: 0.1116 - val_auc: 0.9902 - val_accuracy: 0.9675\n",
            "1000/1000 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:04:10.470474\n",
            "x_train shape: (128000, 67)\n",
            "Epoch 1/100\n",
            "1600/1600 [==============================] - 6s 3ms/step - loss: 0.3807 - auc: 0.9055 - accuracy: 0.8283 - val_loss: 0.2730 - val_auc: 0.9530 - val_accuracy: 0.8870\n",
            "Epoch 2/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2564 - auc: 0.9586 - accuracy: 0.8980 - val_loss: 0.2186 - val_auc: 0.9698 - val_accuracy: 0.9155\n",
            "Epoch 3/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2146 - auc: 0.9708 - accuracy: 0.9192 - val_loss: 0.1924 - val_auc: 0.9767 - val_accuracy: 0.9286\n",
            "Epoch 4/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1896 - auc: 0.9770 - accuracy: 0.9307 - val_loss: 0.1803 - val_auc: 0.9792 - val_accuracy: 0.9337\n",
            "Epoch 5/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1747 - auc: 0.9801 - accuracy: 0.9377 - val_loss: 0.1688 - val_auc: 0.9819 - val_accuracy: 0.9393\n",
            "Epoch 6/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1635 - auc: 0.9824 - accuracy: 0.9425 - val_loss: 0.1617 - val_auc: 0.9827 - val_accuracy: 0.9436\n",
            "Epoch 7/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1550 - auc: 0.9839 - accuracy: 0.9468 - val_loss: 0.1488 - val_auc: 0.9850 - val_accuracy: 0.9502\n",
            "Epoch 8/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1484 - auc: 0.9852 - accuracy: 0.9503 - val_loss: 0.1407 - val_auc: 0.9861 - val_accuracy: 0.9533\n",
            "Epoch 9/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1415 - auc: 0.9863 - accuracy: 0.9528 - val_loss: 0.1354 - val_auc: 0.9870 - val_accuracy: 0.9555\n",
            "Epoch 10/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1359 - auc: 0.9870 - accuracy: 0.9560 - val_loss: 0.1340 - val_auc: 0.9874 - val_accuracy: 0.9555\n",
            "Epoch 11/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1323 - auc: 0.9878 - accuracy: 0.9569 - val_loss: 0.1299 - val_auc: 0.9879 - val_accuracy: 0.9575\n",
            "Epoch 12/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1276 - auc: 0.9883 - accuracy: 0.9586 - val_loss: 0.1265 - val_auc: 0.9881 - val_accuracy: 0.9591\n",
            "Epoch 13/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1255 - auc: 0.9888 - accuracy: 0.9597 - val_loss: 0.1249 - val_auc: 0.9885 - val_accuracy: 0.9605\n",
            "Epoch 14/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1214 - auc: 0.9893 - accuracy: 0.9613 - val_loss: 0.1247 - val_auc: 0.9886 - val_accuracy: 0.9616\n",
            "Epoch 15/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1194 - auc: 0.9895 - accuracy: 0.9625 - val_loss: 0.1246 - val_auc: 0.9885 - val_accuracy: 0.9618\n",
            "Epoch 16/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1174 - auc: 0.9899 - accuracy: 0.9631 - val_loss: 0.1219 - val_auc: 0.9888 - val_accuracy: 0.9616\n",
            "Epoch 17/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1157 - auc: 0.9900 - accuracy: 0.9638 - val_loss: 0.1221 - val_auc: 0.9889 - val_accuracy: 0.9626\n",
            "Epoch 18/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1134 - auc: 0.9902 - accuracy: 0.9646 - val_loss: 0.1205 - val_auc: 0.9892 - val_accuracy: 0.9625\n",
            "Epoch 19/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1116 - auc: 0.9906 - accuracy: 0.9657 - val_loss: 0.1194 - val_auc: 0.9895 - val_accuracy: 0.9643\n",
            "Epoch 20/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1090 - auc: 0.9910 - accuracy: 0.9663 - val_loss: 0.1175 - val_auc: 0.9896 - val_accuracy: 0.9646\n",
            "Epoch 21/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1104 - auc: 0.9907 - accuracy: 0.9663 - val_loss: 0.1171 - val_auc: 0.9894 - val_accuracy: 0.9645\n",
            "Epoch 22/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1073 - auc: 0.9911 - accuracy: 0.9667 - val_loss: 0.1155 - val_auc: 0.9895 - val_accuracy: 0.9657\n",
            "Epoch 23/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1071 - auc: 0.9911 - accuracy: 0.9670 - val_loss: 0.1156 - val_auc: 0.9897 - val_accuracy: 0.9660\n",
            "Epoch 24/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1053 - auc: 0.9914 - accuracy: 0.9681 - val_loss: 0.1128 - val_auc: 0.9899 - val_accuracy: 0.9665\n",
            "Epoch 25/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1040 - auc: 0.9915 - accuracy: 0.9684 - val_loss: 0.1144 - val_auc: 0.9897 - val_accuracy: 0.9661\n",
            "Epoch 26/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1035 - auc: 0.9916 - accuracy: 0.9685 - val_loss: 0.1119 - val_auc: 0.9900 - val_accuracy: 0.9666\n",
            "Epoch 27/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1018 - auc: 0.9918 - accuracy: 0.9690 - val_loss: 0.1123 - val_auc: 0.9899 - val_accuracy: 0.9674\n",
            "Epoch 28/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1003 - auc: 0.9919 - accuracy: 0.9696 - val_loss: 0.1129 - val_auc: 0.9898 - val_accuracy: 0.9671\n",
            "Epoch 29/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1001 - auc: 0.9920 - accuracy: 0.9697 - val_loss: 0.1109 - val_auc: 0.9897 - val_accuracy: 0.9669\n",
            "Epoch 30/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0987 - auc: 0.9921 - accuracy: 0.9703 - val_loss: 0.1103 - val_auc: 0.9902 - val_accuracy: 0.9686\n",
            "Epoch 31/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0979 - auc: 0.9922 - accuracy: 0.9707 - val_loss: 0.1102 - val_auc: 0.9900 - val_accuracy: 0.9681\n",
            "Epoch 32/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0978 - auc: 0.9923 - accuracy: 0.9708 - val_loss: 0.1123 - val_auc: 0.9895 - val_accuracy: 0.9675\n",
            "Epoch 33/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0976 - auc: 0.9923 - accuracy: 0.9709 - val_loss: 0.1109 - val_auc: 0.9904 - val_accuracy: 0.9674\n",
            "Epoch 34/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0967 - auc: 0.9923 - accuracy: 0.9712 - val_loss: 0.1114 - val_auc: 0.9899 - val_accuracy: 0.9682\n",
            "Epoch 35/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0946 - auc: 0.9924 - accuracy: 0.9720 - val_loss: 0.1124 - val_auc: 0.9901 - val_accuracy: 0.9679\n",
            "Epoch 36/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0938 - auc: 0.9927 - accuracy: 0.9723 - val_loss: 0.1112 - val_auc: 0.9904 - val_accuracy: 0.9681\n",
            "Epoch 37/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0937 - auc: 0.9926 - accuracy: 0.9720 - val_loss: 0.1107 - val_auc: 0.9901 - val_accuracy: 0.9676\n",
            "Epoch 38/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0935 - auc: 0.9926 - accuracy: 0.9726 - val_loss: 0.1110 - val_auc: 0.9900 - val_accuracy: 0.9676\n",
            "Epoch 39/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0930 - auc: 0.9927 - accuracy: 0.9718 - val_loss: 0.1105 - val_auc: 0.9901 - val_accuracy: 0.9678\n",
            "Epoch 40/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0924 - auc: 0.9928 - accuracy: 0.9724 - val_loss: 0.1088 - val_auc: 0.9903 - val_accuracy: 0.9689\n",
            "Epoch 41/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0922 - auc: 0.9927 - accuracy: 0.9730 - val_loss: 0.1083 - val_auc: 0.9905 - val_accuracy: 0.9688\n",
            "Epoch 42/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0928 - auc: 0.9928 - accuracy: 0.9728 - val_loss: 0.1073 - val_auc: 0.9904 - val_accuracy: 0.9689\n",
            "Epoch 43/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0899 - auc: 0.9931 - accuracy: 0.9735 - val_loss: 0.1107 - val_auc: 0.9902 - val_accuracy: 0.9685\n",
            "Epoch 44/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0907 - auc: 0.9930 - accuracy: 0.9735 - val_loss: 0.1096 - val_auc: 0.9901 - val_accuracy: 0.9692\n",
            "Epoch 45/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0912 - auc: 0.9929 - accuracy: 0.9733 - val_loss: 0.1088 - val_auc: 0.9905 - val_accuracy: 0.9687\n",
            "Epoch 46/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0901 - auc: 0.9930 - accuracy: 0.9734 - val_loss: 0.1095 - val_auc: 0.9903 - val_accuracy: 0.9693\n",
            "Epoch 47/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0895 - auc: 0.9930 - accuracy: 0.9734 - val_loss: 0.1100 - val_auc: 0.9902 - val_accuracy: 0.9686\n",
            "Epoch 48/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0892 - auc: 0.9931 - accuracy: 0.9736 - val_loss: 0.1118 - val_auc: 0.9900 - val_accuracy: 0.9699\n",
            "Epoch 49/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0896 - auc: 0.9931 - accuracy: 0.9738 - val_loss: 0.1096 - val_auc: 0.9901 - val_accuracy: 0.9690\n",
            "Epoch 50/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0892 - auc: 0.9932 - accuracy: 0.9738 - val_loss: 0.1110 - val_auc: 0.9903 - val_accuracy: 0.9691\n",
            "Epoch 51/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0883 - auc: 0.9933 - accuracy: 0.9737 - val_loss: 0.1111 - val_auc: 0.9900 - val_accuracy: 0.9692\n",
            "Epoch 52/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0872 - auc: 0.9934 - accuracy: 0.9742 - val_loss: 0.1092 - val_auc: 0.9904 - val_accuracy: 0.9701\n",
            "1000/1000 [==============================] - 1s 930us/step\n",
            "fold train/predict time: 0:03:43.189871\n",
            "x_train shape: (128000, 67)\n",
            "Epoch 1/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3787 - auc: 0.9070 - accuracy: 0.8302 - val_loss: 0.2714 - val_auc: 0.9538 - val_accuracy: 0.8896\n",
            "Epoch 2/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2540 - auc: 0.9592 - accuracy: 0.8989 - val_loss: 0.2160 - val_auc: 0.9707 - val_accuracy: 0.9155\n",
            "Epoch 3/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2134 - auc: 0.9712 - accuracy: 0.9192 - val_loss: 0.1871 - val_auc: 0.9776 - val_accuracy: 0.9298\n",
            "Epoch 4/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1895 - auc: 0.9768 - accuracy: 0.9304 - val_loss: 0.1697 - val_auc: 0.9814 - val_accuracy: 0.9371\n",
            "Epoch 5/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1736 - auc: 0.9804 - accuracy: 0.9376 - val_loss: 0.1612 - val_auc: 0.9829 - val_accuracy: 0.9417\n",
            "Epoch 6/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1642 - auc: 0.9821 - accuracy: 0.9418 - val_loss: 0.1530 - val_auc: 0.9844 - val_accuracy: 0.9456\n",
            "Epoch 7/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1567 - auc: 0.9835 - accuracy: 0.9459 - val_loss: 0.1478 - val_auc: 0.9854 - val_accuracy: 0.9491\n",
            "Epoch 8/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1503 - auc: 0.9847 - accuracy: 0.9487 - val_loss: 0.1424 - val_auc: 0.9862 - val_accuracy: 0.9507\n",
            "Epoch 9/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1441 - auc: 0.9858 - accuracy: 0.9517 - val_loss: 0.1408 - val_auc: 0.9866 - val_accuracy: 0.9519\n",
            "Epoch 10/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1393 - auc: 0.9865 - accuracy: 0.9535 - val_loss: 0.1337 - val_auc: 0.9875 - val_accuracy: 0.9557\n",
            "Epoch 11/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1358 - auc: 0.9871 - accuracy: 0.9544 - val_loss: 0.1325 - val_auc: 0.9877 - val_accuracy: 0.9552\n",
            "Epoch 12/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1326 - auc: 0.9876 - accuracy: 0.9559 - val_loss: 0.1290 - val_auc: 0.9882 - val_accuracy: 0.9570\n",
            "Epoch 13/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1297 - auc: 0.9880 - accuracy: 0.9575 - val_loss: 0.1270 - val_auc: 0.9884 - val_accuracy: 0.9588\n",
            "Epoch 14/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1258 - auc: 0.9885 - accuracy: 0.9593 - val_loss: 0.1242 - val_auc: 0.9889 - val_accuracy: 0.9609\n",
            "Epoch 15/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1238 - auc: 0.9889 - accuracy: 0.9603 - val_loss: 0.1254 - val_auc: 0.9889 - val_accuracy: 0.9588\n",
            "Epoch 16/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1197 - auc: 0.9894 - accuracy: 0.9608 - val_loss: 0.1225 - val_auc: 0.9890 - val_accuracy: 0.9598\n",
            "Epoch 17/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1180 - auc: 0.9896 - accuracy: 0.9628 - val_loss: 0.1185 - val_auc: 0.9896 - val_accuracy: 0.9614\n",
            "Epoch 18/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1159 - auc: 0.9898 - accuracy: 0.9631 - val_loss: 0.1197 - val_auc: 0.9893 - val_accuracy: 0.9623\n",
            "Epoch 19/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1144 - auc: 0.9901 - accuracy: 0.9638 - val_loss: 0.1171 - val_auc: 0.9895 - val_accuracy: 0.9636\n",
            "Epoch 20/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1122 - auc: 0.9903 - accuracy: 0.9646 - val_loss: 0.1198 - val_auc: 0.9894 - val_accuracy: 0.9627\n",
            "Epoch 21/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1115 - auc: 0.9905 - accuracy: 0.9647 - val_loss: 0.1165 - val_auc: 0.9897 - val_accuracy: 0.9638\n",
            "Epoch 22/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1112 - auc: 0.9905 - accuracy: 0.9654 - val_loss: 0.1159 - val_auc: 0.9898 - val_accuracy: 0.9634\n",
            "Epoch 23/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1086 - auc: 0.9908 - accuracy: 0.9658 - val_loss: 0.1175 - val_auc: 0.9896 - val_accuracy: 0.9643\n",
            "Epoch 24/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1077 - auc: 0.9909 - accuracy: 0.9662 - val_loss: 0.1161 - val_auc: 0.9898 - val_accuracy: 0.9648\n",
            "Epoch 25/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1055 - auc: 0.9910 - accuracy: 0.9671 - val_loss: 0.1144 - val_auc: 0.9900 - val_accuracy: 0.9649\n",
            "Epoch 26/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1077 - auc: 0.9909 - accuracy: 0.9670 - val_loss: 0.1138 - val_auc: 0.9900 - val_accuracy: 0.9648\n",
            "Epoch 27/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1057 - auc: 0.9912 - accuracy: 0.9673 - val_loss: 0.1149 - val_auc: 0.9899 - val_accuracy: 0.9646\n",
            "Epoch 28/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1046 - auc: 0.9913 - accuracy: 0.9678 - val_loss: 0.1144 - val_auc: 0.9899 - val_accuracy: 0.9655\n",
            "Epoch 29/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1043 - auc: 0.9912 - accuracy: 0.9681 - val_loss: 0.1134 - val_auc: 0.9901 - val_accuracy: 0.9659\n",
            "Epoch 30/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1025 - auc: 0.9917 - accuracy: 0.9676 - val_loss: 0.1121 - val_auc: 0.9904 - val_accuracy: 0.9663\n",
            "Epoch 31/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1014 - auc: 0.9917 - accuracy: 0.9684 - val_loss: 0.1131 - val_auc: 0.9900 - val_accuracy: 0.9654\n",
            "Epoch 32/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1009 - auc: 0.9918 - accuracy: 0.9688 - val_loss: 0.1122 - val_auc: 0.9903 - val_accuracy: 0.9669\n",
            "Epoch 33/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1003 - auc: 0.9919 - accuracy: 0.9688 - val_loss: 0.1144 - val_auc: 0.9902 - val_accuracy: 0.9653\n",
            "Epoch 34/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0990 - auc: 0.9921 - accuracy: 0.9691 - val_loss: 0.1148 - val_auc: 0.9900 - val_accuracy: 0.9655\n",
            "Epoch 35/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0988 - auc: 0.9921 - accuracy: 0.9697 - val_loss: 0.1125 - val_auc: 0.9900 - val_accuracy: 0.9656\n",
            "Epoch 36/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0985 - auc: 0.9922 - accuracy: 0.9695 - val_loss: 0.1157 - val_auc: 0.9900 - val_accuracy: 0.9657\n",
            "Epoch 37/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0970 - auc: 0.9923 - accuracy: 0.9698 - val_loss: 0.1151 - val_auc: 0.9901 - val_accuracy: 0.9659\n",
            "Epoch 38/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0979 - auc: 0.9923 - accuracy: 0.9699 - val_loss: 0.1145 - val_auc: 0.9900 - val_accuracy: 0.9654\n",
            "Epoch 39/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0952 - auc: 0.9926 - accuracy: 0.9708 - val_loss: 0.1130 - val_auc: 0.9898 - val_accuracy: 0.9661\n",
            "Epoch 40/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0960 - auc: 0.9925 - accuracy: 0.9704 - val_loss: 0.1163 - val_auc: 0.9898 - val_accuracy: 0.9640\n",
            "1000/1000 [==============================] - 1s 902us/step\n",
            "fold train/predict time: 0:02:52.000931\n",
            "x_train shape: (128000, 67)\n",
            "Epoch 1/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3834 - auc: 0.9047 - accuracy: 0.8269 - val_loss: 0.2764 - val_auc: 0.9519 - val_accuracy: 0.8857\n",
            "Epoch 2/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2592 - auc: 0.9575 - accuracy: 0.8964 - val_loss: 0.2211 - val_auc: 0.9697 - val_accuracy: 0.9141\n",
            "Epoch 3/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2141 - auc: 0.9710 - accuracy: 0.9189 - val_loss: 0.1912 - val_auc: 0.9766 - val_accuracy: 0.9290\n",
            "Epoch 4/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1912 - auc: 0.9766 - accuracy: 0.9297 - val_loss: 0.1730 - val_auc: 0.9809 - val_accuracy: 0.9375\n",
            "Epoch 5/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1774 - auc: 0.9797 - accuracy: 0.9365 - val_loss: 0.1659 - val_auc: 0.9820 - val_accuracy: 0.9407\n",
            "Epoch 6/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1656 - auc: 0.9821 - accuracy: 0.9416 - val_loss: 0.1561 - val_auc: 0.9840 - val_accuracy: 0.9456\n",
            "Epoch 7/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1572 - auc: 0.9838 - accuracy: 0.9450 - val_loss: 0.1495 - val_auc: 0.9851 - val_accuracy: 0.9498\n",
            "Epoch 8/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1514 - auc: 0.9848 - accuracy: 0.9480 - val_loss: 0.1452 - val_auc: 0.9856 - val_accuracy: 0.9512\n",
            "Epoch 9/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1446 - auc: 0.9859 - accuracy: 0.9508 - val_loss: 0.1394 - val_auc: 0.9868 - val_accuracy: 0.9539\n",
            "Epoch 10/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1400 - auc: 0.9865 - accuracy: 0.9533 - val_loss: 0.1379 - val_auc: 0.9869 - val_accuracy: 0.9547\n",
            "Epoch 11/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1367 - auc: 0.9871 - accuracy: 0.9543 - val_loss: 0.1336 - val_auc: 0.9873 - val_accuracy: 0.9561\n",
            "Epoch 12/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1320 - auc: 0.9877 - accuracy: 0.9568 - val_loss: 0.1308 - val_auc: 0.9879 - val_accuracy: 0.9584\n",
            "Epoch 13/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1291 - auc: 0.9883 - accuracy: 0.9577 - val_loss: 0.1294 - val_auc: 0.9882 - val_accuracy: 0.9586\n",
            "Epoch 14/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1249 - auc: 0.9887 - accuracy: 0.9600 - val_loss: 0.1261 - val_auc: 0.9883 - val_accuracy: 0.9600\n",
            "Epoch 15/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1211 - auc: 0.9893 - accuracy: 0.9609 - val_loss: 0.1232 - val_auc: 0.9888 - val_accuracy: 0.9608\n",
            "Epoch 16/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1195 - auc: 0.9895 - accuracy: 0.9618 - val_loss: 0.1256 - val_auc: 0.9883 - val_accuracy: 0.9603\n",
            "Epoch 17/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1181 - auc: 0.9896 - accuracy: 0.9621 - val_loss: 0.1222 - val_auc: 0.9890 - val_accuracy: 0.9621\n",
            "Epoch 18/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1162 - auc: 0.9899 - accuracy: 0.9630 - val_loss: 0.1215 - val_auc: 0.9893 - val_accuracy: 0.9615\n",
            "Epoch 19/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1132 - auc: 0.9904 - accuracy: 0.9641 - val_loss: 0.1189 - val_auc: 0.9893 - val_accuracy: 0.9624\n",
            "Epoch 20/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1123 - auc: 0.9905 - accuracy: 0.9647 - val_loss: 0.1210 - val_auc: 0.9890 - val_accuracy: 0.9630\n",
            "Epoch 21/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1098 - auc: 0.9908 - accuracy: 0.9655 - val_loss: 0.1204 - val_auc: 0.9892 - val_accuracy: 0.9621\n",
            "Epoch 22/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1085 - auc: 0.9909 - accuracy: 0.9657 - val_loss: 0.1203 - val_auc: 0.9895 - val_accuracy: 0.9630\n",
            "Epoch 23/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1075 - auc: 0.9911 - accuracy: 0.9668 - val_loss: 0.1176 - val_auc: 0.9894 - val_accuracy: 0.9635\n",
            "Epoch 24/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1064 - auc: 0.9912 - accuracy: 0.9667 - val_loss: 0.1188 - val_auc: 0.9897 - val_accuracy: 0.9631\n",
            "Epoch 25/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1054 - auc: 0.9914 - accuracy: 0.9673 - val_loss: 0.1159 - val_auc: 0.9896 - val_accuracy: 0.9645\n",
            "Epoch 26/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1040 - auc: 0.9915 - accuracy: 0.9675 - val_loss: 0.1159 - val_auc: 0.9894 - val_accuracy: 0.9645\n",
            "Epoch 27/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1026 - auc: 0.9918 - accuracy: 0.9684 - val_loss: 0.1163 - val_auc: 0.9895 - val_accuracy: 0.9645\n",
            "Epoch 28/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1038 - auc: 0.9915 - accuracy: 0.9681 - val_loss: 0.1180 - val_auc: 0.9894 - val_accuracy: 0.9635\n",
            "Epoch 29/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1011 - auc: 0.9918 - accuracy: 0.9688 - val_loss: 0.1172 - val_auc: 0.9895 - val_accuracy: 0.9643\n",
            "Epoch 30/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1042 - auc: 0.9914 - accuracy: 0.9686 - val_loss: 0.1164 - val_auc: 0.9896 - val_accuracy: 0.9643\n",
            "Epoch 31/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1015 - auc: 0.9917 - accuracy: 0.9688 - val_loss: 0.1153 - val_auc: 0.9898 - val_accuracy: 0.9648\n",
            "Epoch 32/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1010 - auc: 0.9919 - accuracy: 0.9690 - val_loss: 0.1138 - val_auc: 0.9901 - val_accuracy: 0.9663\n",
            "Epoch 33/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0990 - auc: 0.9920 - accuracy: 0.9703 - val_loss: 0.1144 - val_auc: 0.9899 - val_accuracy: 0.9645\n",
            "Epoch 34/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0972 - auc: 0.9923 - accuracy: 0.9701 - val_loss: 0.1143 - val_auc: 0.9898 - val_accuracy: 0.9650\n",
            "Epoch 35/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0971 - auc: 0.9923 - accuracy: 0.9705 - val_loss: 0.1146 - val_auc: 0.9900 - val_accuracy: 0.9650\n",
            "Epoch 36/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0985 - auc: 0.9921 - accuracy: 0.9700 - val_loss: 0.1137 - val_auc: 0.9900 - val_accuracy: 0.9671\n",
            "Epoch 37/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0968 - auc: 0.9924 - accuracy: 0.9705 - val_loss: 0.1147 - val_auc: 0.9900 - val_accuracy: 0.9654\n",
            "Epoch 38/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0964 - auc: 0.9925 - accuracy: 0.9706 - val_loss: 0.1126 - val_auc: 0.9904 - val_accuracy: 0.9663\n",
            "Epoch 39/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0948 - auc: 0.9925 - accuracy: 0.9714 - val_loss: 0.1168 - val_auc: 0.9897 - val_accuracy: 0.9653\n",
            "Epoch 40/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0944 - auc: 0.9926 - accuracy: 0.9717 - val_loss: 0.1131 - val_auc: 0.9901 - val_accuracy: 0.9663\n",
            "Epoch 41/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0940 - auc: 0.9927 - accuracy: 0.9713 - val_loss: 0.1133 - val_auc: 0.9902 - val_accuracy: 0.9660\n",
            "Epoch 42/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0936 - auc: 0.9927 - accuracy: 0.9719 - val_loss: 0.1124 - val_auc: 0.9905 - val_accuracy: 0.9660\n",
            "Epoch 43/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0939 - auc: 0.9927 - accuracy: 0.9715 - val_loss: 0.1103 - val_auc: 0.9906 - val_accuracy: 0.9678\n",
            "Epoch 44/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0917 - auc: 0.9929 - accuracy: 0.9728 - val_loss: 0.1127 - val_auc: 0.9903 - val_accuracy: 0.9665\n",
            "Epoch 45/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0928 - auc: 0.9928 - accuracy: 0.9725 - val_loss: 0.1137 - val_auc: 0.9902 - val_accuracy: 0.9670\n",
            "Epoch 46/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0922 - auc: 0.9930 - accuracy: 0.9718 - val_loss: 0.1144 - val_auc: 0.9900 - val_accuracy: 0.9663\n",
            "Epoch 47/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0921 - auc: 0.9930 - accuracy: 0.9726 - val_loss: 0.1128 - val_auc: 0.9901 - val_accuracy: 0.9666\n",
            "Epoch 48/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0910 - auc: 0.9931 - accuracy: 0.9727 - val_loss: 0.1106 - val_auc: 0.9903 - val_accuracy: 0.9684\n",
            "Epoch 49/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0918 - auc: 0.9930 - accuracy: 0.9721 - val_loss: 0.1120 - val_auc: 0.9903 - val_accuracy: 0.9668\n",
            "Epoch 50/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0909 - auc: 0.9931 - accuracy: 0.9726 - val_loss: 0.1143 - val_auc: 0.9904 - val_accuracy: 0.9669\n",
            "Epoch 51/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0897 - auc: 0.9932 - accuracy: 0.9730 - val_loss: 0.1138 - val_auc: 0.9902 - val_accuracy: 0.9661\n",
            "Epoch 52/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0903 - auc: 0.9931 - accuracy: 0.9729 - val_loss: 0.1145 - val_auc: 0.9900 - val_accuracy: 0.9672\n",
            "Epoch 53/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0884 - auc: 0.9934 - accuracy: 0.9737 - val_loss: 0.1117 - val_auc: 0.9904 - val_accuracy: 0.9680\n",
            "1000/1000 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:03:45.238334\n",
            "x_train shape: (128000, 67)\n",
            "Epoch 1/100\n",
            "1600/1600 [==============================] - 6s 3ms/step - loss: 0.3865 - auc: 0.9030 - accuracy: 0.8267 - val_loss: 0.2836 - val_auc: 0.9510 - val_accuracy: 0.8825\n",
            "Epoch 2/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2600 - auc: 0.9574 - accuracy: 0.8957 - val_loss: 0.2214 - val_auc: 0.9693 - val_accuracy: 0.9145\n",
            "Epoch 3/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2163 - auc: 0.9703 - accuracy: 0.9174 - val_loss: 0.1920 - val_auc: 0.9764 - val_accuracy: 0.9282\n",
            "Epoch 4/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1912 - auc: 0.9765 - accuracy: 0.9297 - val_loss: 0.1745 - val_auc: 0.9803 - val_accuracy: 0.9353\n",
            "Epoch 5/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1756 - auc: 0.9801 - accuracy: 0.9359 - val_loss: 0.1645 - val_auc: 0.9823 - val_accuracy: 0.9408\n",
            "Epoch 6/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1659 - auc: 0.9821 - accuracy: 0.9402 - val_loss: 0.1592 - val_auc: 0.9831 - val_accuracy: 0.9431\n",
            "Epoch 7/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1596 - auc: 0.9831 - accuracy: 0.9435 - val_loss: 0.1526 - val_auc: 0.9845 - val_accuracy: 0.9473\n",
            "Epoch 8/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1534 - auc: 0.9843 - accuracy: 0.9467 - val_loss: 0.1507 - val_auc: 0.9849 - val_accuracy: 0.9484\n",
            "Epoch 9/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1477 - auc: 0.9854 - accuracy: 0.9489 - val_loss: 0.1428 - val_auc: 0.9860 - val_accuracy: 0.9518\n",
            "Epoch 10/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1448 - auc: 0.9859 - accuracy: 0.9501 - val_loss: 0.1421 - val_auc: 0.9862 - val_accuracy: 0.9525\n",
            "Epoch 11/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1414 - auc: 0.9863 - accuracy: 0.9520 - val_loss: 0.1404 - val_auc: 0.9869 - val_accuracy: 0.9532\n",
            "Epoch 12/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1372 - auc: 0.9871 - accuracy: 0.9536 - val_loss: 0.1381 - val_auc: 0.9871 - val_accuracy: 0.9538\n",
            "Epoch 13/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1342 - auc: 0.9875 - accuracy: 0.9544 - val_loss: 0.1345 - val_auc: 0.9875 - val_accuracy: 0.9561\n",
            "Epoch 14/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1313 - auc: 0.9880 - accuracy: 0.9566 - val_loss: 0.1303 - val_auc: 0.9880 - val_accuracy: 0.9583\n",
            "Epoch 15/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1282 - auc: 0.9884 - accuracy: 0.9570 - val_loss: 0.1317 - val_auc: 0.9880 - val_accuracy: 0.9570\n",
            "Epoch 16/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1260 - auc: 0.9886 - accuracy: 0.9585 - val_loss: 0.1304 - val_auc: 0.9881 - val_accuracy: 0.9594\n",
            "Epoch 17/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1234 - auc: 0.9890 - accuracy: 0.9595 - val_loss: 0.1277 - val_auc: 0.9885 - val_accuracy: 0.9596\n",
            "Epoch 18/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1225 - auc: 0.9892 - accuracy: 0.9603 - val_loss: 0.1277 - val_auc: 0.9886 - val_accuracy: 0.9600\n",
            "Epoch 19/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1203 - auc: 0.9895 - accuracy: 0.9610 - val_loss: 0.1227 - val_auc: 0.9890 - val_accuracy: 0.9618\n",
            "Epoch 20/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1180 - auc: 0.9899 - accuracy: 0.9614 - val_loss: 0.1252 - val_auc: 0.9887 - val_accuracy: 0.9608\n",
            "Epoch 21/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1183 - auc: 0.9897 - accuracy: 0.9614 - val_loss: 0.1233 - val_auc: 0.9890 - val_accuracy: 0.9623\n",
            "Epoch 22/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1161 - auc: 0.9900 - accuracy: 0.9626 - val_loss: 0.1224 - val_auc: 0.9889 - val_accuracy: 0.9629\n",
            "Epoch 23/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1148 - auc: 0.9903 - accuracy: 0.9624 - val_loss: 0.1231 - val_auc: 0.9889 - val_accuracy: 0.9619\n",
            "Epoch 24/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1136 - auc: 0.9904 - accuracy: 0.9645 - val_loss: 0.1220 - val_auc: 0.9889 - val_accuracy: 0.9635\n",
            "Epoch 25/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1114 - auc: 0.9907 - accuracy: 0.9642 - val_loss: 0.1227 - val_auc: 0.9889 - val_accuracy: 0.9629\n",
            "Epoch 26/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1111 - auc: 0.9907 - accuracy: 0.9644 - val_loss: 0.1217 - val_auc: 0.9893 - val_accuracy: 0.9634\n",
            "Epoch 27/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1110 - auc: 0.9907 - accuracy: 0.9643 - val_loss: 0.1198 - val_auc: 0.9892 - val_accuracy: 0.9637\n",
            "Epoch 28/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1094 - auc: 0.9910 - accuracy: 0.9656 - val_loss: 0.1204 - val_auc: 0.9892 - val_accuracy: 0.9636\n",
            "Epoch 29/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1079 - auc: 0.9912 - accuracy: 0.9661 - val_loss: 0.1258 - val_auc: 0.9884 - val_accuracy: 0.9621\n",
            "Epoch 30/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1094 - auc: 0.9909 - accuracy: 0.9650 - val_loss: 0.1223 - val_auc: 0.9889 - val_accuracy: 0.9640\n",
            "Epoch 31/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1066 - auc: 0.9911 - accuracy: 0.9662 - val_loss: 0.1199 - val_auc: 0.9893 - val_accuracy: 0.9655\n",
            "Epoch 32/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1060 - auc: 0.9914 - accuracy: 0.9660 - val_loss: 0.1169 - val_auc: 0.9897 - val_accuracy: 0.9647\n",
            "Epoch 33/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1044 - auc: 0.9916 - accuracy: 0.9673 - val_loss: 0.1204 - val_auc: 0.9895 - val_accuracy: 0.9643\n",
            "Epoch 34/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1036 - auc: 0.9914 - accuracy: 0.9674 - val_loss: 0.1207 - val_auc: 0.9894 - val_accuracy: 0.9637\n",
            "Epoch 35/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1029 - auc: 0.9916 - accuracy: 0.9682 - val_loss: 0.1231 - val_auc: 0.9894 - val_accuracy: 0.9643\n",
            "Epoch 36/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1030 - auc: 0.9918 - accuracy: 0.9676 - val_loss: 0.1169 - val_auc: 0.9895 - val_accuracy: 0.9664\n",
            "Epoch 37/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1027 - auc: 0.9917 - accuracy: 0.9679 - val_loss: 0.1200 - val_auc: 0.9892 - val_accuracy: 0.9642\n",
            "Epoch 38/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1019 - auc: 0.9919 - accuracy: 0.9683 - val_loss: 0.1194 - val_auc: 0.9895 - val_accuracy: 0.9655\n",
            "Epoch 39/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1002 - auc: 0.9920 - accuracy: 0.9684 - val_loss: 0.1185 - val_auc: 0.9897 - val_accuracy: 0.9649\n",
            "Epoch 40/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1003 - auc: 0.9920 - accuracy: 0.9692 - val_loss: 0.1237 - val_auc: 0.9888 - val_accuracy: 0.9634\n",
            "Epoch 41/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0989 - auc: 0.9922 - accuracy: 0.9688 - val_loss: 0.1198 - val_auc: 0.9898 - val_accuracy: 0.9655\n",
            "Epoch 42/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0992 - auc: 0.9920 - accuracy: 0.9687 - val_loss: 0.1200 - val_auc: 0.9891 - val_accuracy: 0.9658\n",
            "Epoch 43/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0981 - auc: 0.9923 - accuracy: 0.9696 - val_loss: 0.1206 - val_auc: 0.9894 - val_accuracy: 0.9652\n",
            "Epoch 44/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0971 - auc: 0.9923 - accuracy: 0.9700 - val_loss: 0.1169 - val_auc: 0.9899 - val_accuracy: 0.9664\n",
            "Epoch 45/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0964 - auc: 0.9925 - accuracy: 0.9705 - val_loss: 0.1177 - val_auc: 0.9897 - val_accuracy: 0.9657\n",
            "Epoch 46/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0969 - auc: 0.9924 - accuracy: 0.9703 - val_loss: 0.1183 - val_auc: 0.9894 - val_accuracy: 0.9654\n",
            "Epoch 47/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0962 - auc: 0.9924 - accuracy: 0.9701 - val_loss: 0.1200 - val_auc: 0.9894 - val_accuracy: 0.9664\n",
            "Epoch 48/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0950 - auc: 0.9926 - accuracy: 0.9707 - val_loss: 0.1170 - val_auc: 0.9899 - val_accuracy: 0.9660\n",
            "Epoch 49/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0952 - auc: 0.9925 - accuracy: 0.9712 - val_loss: 0.1228 - val_auc: 0.9890 - val_accuracy: 0.9648\n",
            "Epoch 50/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0945 - auc: 0.9927 - accuracy: 0.9706 - val_loss: 0.1205 - val_auc: 0.9895 - val_accuracy: 0.9666\n",
            "Epoch 51/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0927 - auc: 0.9929 - accuracy: 0.9713 - val_loss: 0.1199 - val_auc: 0.9894 - val_accuracy: 0.9665\n",
            "Epoch 52/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0943 - auc: 0.9926 - accuracy: 0.9715 - val_loss: 0.1209 - val_auc: 0.9892 - val_accuracy: 0.9654\n",
            "Epoch 53/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0927 - auc: 0.9928 - accuracy: 0.9722 - val_loss: 0.1210 - val_auc: 0.9894 - val_accuracy: 0.9658\n",
            "Epoch 54/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0915 - auc: 0.9930 - accuracy: 0.9728 - val_loss: 0.1173 - val_auc: 0.9894 - val_accuracy: 0.9670\n",
            "1000/1000 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:04:05.926914\n",
            "total train/predict time: 0:18:37.921843\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_m4 = np.zeros(len(y))\n",
        "for i in fold_results.keys():\n",
        "  for j in range(len(fold_results.get(i).get('predictions'))):\n",
        "    idx = fold_results.get(i).get('index')[j]\n",
        "    preds_m4[idx] = np.round(fold_results.get(i).get('predictions')[j],0)\n",
        "\n"
      ],
      "metadata": {
        "id": "WMZkaNGNeKT0"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_new = np.zeros(len(y))\n",
        "for i in fold_results.keys():\n",
        "  for j in range(len(fold_results.get(i).get('predictions'))):\n",
        "    idx = fold_results.get(i).get('index')[j]\n",
        "    if fold_results.get(i).get('predictions')[j] > 0.4:\n",
        "      preds_new[idx] = 1\n",
        "    else:\n",
        "      preds_new[idx] = 0"
      ],
      "metadata": {
        "id": "cRXVWMi0VKc3"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cost(preds_m4,y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkQAh6OMjjJp",
        "outputId": "931f1f9a-e039-4f2a-bf6e-192957ca2b5d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "666350"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cost(preds_new,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwnBY2J7fVHl",
        "outputId": "b6c97770-9408-4333-ec6f-44da0840bb12"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "641050"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cost(preds_new,y) #previous run for check"
      ],
      "metadata": {
        "id": "xT8_ekuQXJMs",
        "outputId": "8edee14d-cacd-4469-c143-6e885ea7f315",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "638250"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.set_random_seed(807)\n",
        "es = EarlyStopping(monitor='val_loss', mode='min',patience=20,restore_best_weights=True,start_from_epoch=100)\n",
        "fold_results = {}\n",
        "t_tot = now()\n",
        "for i, (train_index, test_index) in enumerate(skf.split(X,y)):\n",
        "  # building model within loop to reset weights each time\n",
        "  tf.keras.backend.clear_session()\n",
        "  adamM2 = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "  model4 = tf.keras.Sequential()\n",
        "  model4.add(tf.keras.Input(shape=(X.shape[1],)))\n",
        "  model4.add(tf.keras.layers.Dense(64, activation='relu',name=\"Relu1\"))\n",
        "  model4.add(tf.keras.layers.Dense(64, activation='relu', name=\"Relu2\"))\n",
        "  model4.add(tf.keras.layers.Dropout(0.4))\n",
        "  model4.add(tf.keras.layers.Dense(1, activation='sigmoid', name=\"Activation\"))\n",
        "  model4.compile(optimizer=adamM2,\n",
        "                loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "                metrics = [tf.keras.metrics.AUC(from_logits=False), 'accuracy'])\n",
        "  t_fold = now()\n",
        "  print('x_train shape:', X[train_index].shape)\n",
        "  model4.fit(X[train_index],y[train_index],epochs=1000,batch_size=64,validation_split=0.2,callbacks=[es])\n",
        "  fold_results.update({i:{'predictions':model4.predict(X[test_index]).flatten(),'index':test_index,'y_true':y[test_index]}})\n",
        "  print('fold train/predict time: %s' % (now()-t_fold))\n",
        "print('total train/predict time: %s' % (now()-t_tot))"
      ],
      "metadata": {
        "id": "9khDvGk8hp0_",
        "outputId": "6a7338af-cfea-4cba-b172-093a2647e341",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (128000, 67)\n",
            "Epoch 1/1000\n",
            "1600/1600 [==============================] - 6s 3ms/step - loss: 0.5999 - auc: 0.7144 - accuracy: 0.6713 - val_loss: 0.5147 - val_auc: 0.8193 - val_accuracy: 0.7486\n",
            "Epoch 2/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4765 - auc: 0.8470 - accuracy: 0.7738 - val_loss: 0.4115 - val_auc: 0.8937 - val_accuracy: 0.8187\n",
            "Epoch 3/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3990 - auc: 0.8976 - accuracy: 0.8242 - val_loss: 0.3590 - val_auc: 0.9186 - val_accuracy: 0.8445\n",
            "Epoch 4/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3591 - auc: 0.9181 - accuracy: 0.8476 - val_loss: 0.3349 - val_auc: 0.9291 - val_accuracy: 0.8550\n",
            "Epoch 5/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3373 - auc: 0.9280 - accuracy: 0.8578 - val_loss: 0.3187 - val_auc: 0.9356 - val_accuracy: 0.8644\n",
            "Epoch 6/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3233 - auc: 0.9339 - accuracy: 0.8658 - val_loss: 0.3076 - val_auc: 0.9402 - val_accuracy: 0.8698\n",
            "Epoch 7/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3130 - auc: 0.9381 - accuracy: 0.8698 - val_loss: 0.2987 - val_auc: 0.9435 - val_accuracy: 0.8734\n",
            "Epoch 8/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3018 - auc: 0.9424 - accuracy: 0.8756 - val_loss: 0.2898 - val_auc: 0.9469 - val_accuracy: 0.8781\n",
            "Epoch 9/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2935 - auc: 0.9457 - accuracy: 0.8799 - val_loss: 0.2817 - val_auc: 0.9499 - val_accuracy: 0.8833\n",
            "Epoch 10/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2853 - auc: 0.9487 - accuracy: 0.8836 - val_loss: 0.2744 - val_auc: 0.9525 - val_accuracy: 0.8866\n",
            "Epoch 11/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2771 - auc: 0.9516 - accuracy: 0.8878 - val_loss: 0.2671 - val_auc: 0.9550 - val_accuracy: 0.8907\n",
            "Epoch 12/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2710 - auc: 0.9538 - accuracy: 0.8919 - val_loss: 0.2616 - val_auc: 0.9569 - val_accuracy: 0.8931\n",
            "Epoch 13/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2646 - auc: 0.9560 - accuracy: 0.8945 - val_loss: 0.2552 - val_auc: 0.9590 - val_accuracy: 0.8971\n",
            "Epoch 14/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2577 - auc: 0.9583 - accuracy: 0.8970 - val_loss: 0.2497 - val_auc: 0.9607 - val_accuracy: 0.9003\n",
            "Epoch 15/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2520 - auc: 0.9600 - accuracy: 0.9002 - val_loss: 0.2446 - val_auc: 0.9622 - val_accuracy: 0.9032\n",
            "Epoch 16/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2472 - auc: 0.9615 - accuracy: 0.9021 - val_loss: 0.2395 - val_auc: 0.9637 - val_accuracy: 0.9052\n",
            "Epoch 17/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2419 - auc: 0.9631 - accuracy: 0.9046 - val_loss: 0.2351 - val_auc: 0.9650 - val_accuracy: 0.9075\n",
            "Epoch 18/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2380 - auc: 0.9643 - accuracy: 0.9071 - val_loss: 0.2305 - val_auc: 0.9666 - val_accuracy: 0.9105\n",
            "Epoch 19/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2331 - auc: 0.9657 - accuracy: 0.9091 - val_loss: 0.2265 - val_auc: 0.9676 - val_accuracy: 0.9120\n",
            "Epoch 20/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2287 - auc: 0.9669 - accuracy: 0.9118 - val_loss: 0.2227 - val_auc: 0.9687 - val_accuracy: 0.9137\n",
            "Epoch 21/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2257 - auc: 0.9679 - accuracy: 0.9130 - val_loss: 0.2188 - val_auc: 0.9698 - val_accuracy: 0.9156\n",
            "Epoch 22/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2203 - auc: 0.9693 - accuracy: 0.9160 - val_loss: 0.2148 - val_auc: 0.9708 - val_accuracy: 0.9184\n",
            "Epoch 23/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2170 - auc: 0.9702 - accuracy: 0.9172 - val_loss: 0.2118 - val_auc: 0.9715 - val_accuracy: 0.9188\n",
            "Epoch 24/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2125 - auc: 0.9714 - accuracy: 0.9181 - val_loss: 0.2077 - val_auc: 0.9726 - val_accuracy: 0.9213\n",
            "Epoch 25/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2096 - auc: 0.9722 - accuracy: 0.9208 - val_loss: 0.2042 - val_auc: 0.9735 - val_accuracy: 0.9225\n",
            "Epoch 26/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2057 - auc: 0.9732 - accuracy: 0.9223 - val_loss: 0.2010 - val_auc: 0.9742 - val_accuracy: 0.9229\n",
            "Epoch 27/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2024 - auc: 0.9738 - accuracy: 0.9242 - val_loss: 0.1980 - val_auc: 0.9751 - val_accuracy: 0.9241\n",
            "Epoch 28/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1987 - auc: 0.9748 - accuracy: 0.9255 - val_loss: 0.1943 - val_auc: 0.9759 - val_accuracy: 0.9268\n",
            "Epoch 29/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1952 - auc: 0.9757 - accuracy: 0.9271 - val_loss: 0.1914 - val_auc: 0.9766 - val_accuracy: 0.9287\n",
            "Epoch 30/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1930 - auc: 0.9762 - accuracy: 0.9277 - val_loss: 0.1885 - val_auc: 0.9773 - val_accuracy: 0.9300\n",
            "Epoch 31/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1906 - auc: 0.9768 - accuracy: 0.9286 - val_loss: 0.1863 - val_auc: 0.9778 - val_accuracy: 0.9309\n",
            "Epoch 32/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1879 - auc: 0.9774 - accuracy: 0.9303 - val_loss: 0.1839 - val_auc: 0.9784 - val_accuracy: 0.9320\n",
            "Epoch 33/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1849 - auc: 0.9781 - accuracy: 0.9320 - val_loss: 0.1819 - val_auc: 0.9788 - val_accuracy: 0.9334\n",
            "Epoch 34/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1831 - auc: 0.9784 - accuracy: 0.9326 - val_loss: 0.1797 - val_auc: 0.9792 - val_accuracy: 0.9346\n",
            "Epoch 35/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1799 - auc: 0.9792 - accuracy: 0.9340 - val_loss: 0.1773 - val_auc: 0.9797 - val_accuracy: 0.9349\n",
            "Epoch 36/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1781 - auc: 0.9796 - accuracy: 0.9351 - val_loss: 0.1759 - val_auc: 0.9801 - val_accuracy: 0.9358\n",
            "Epoch 37/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1764 - auc: 0.9798 - accuracy: 0.9353 - val_loss: 0.1734 - val_auc: 0.9806 - val_accuracy: 0.9373\n",
            "Epoch 38/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1745 - auc: 0.9802 - accuracy: 0.9367 - val_loss: 0.1716 - val_auc: 0.9810 - val_accuracy: 0.9380\n",
            "Epoch 39/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1723 - auc: 0.9807 - accuracy: 0.9384 - val_loss: 0.1703 - val_auc: 0.9812 - val_accuracy: 0.9381\n",
            "Epoch 40/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1703 - auc: 0.9812 - accuracy: 0.9385 - val_loss: 0.1683 - val_auc: 0.9817 - val_accuracy: 0.9394\n",
            "Epoch 41/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1688 - auc: 0.9814 - accuracy: 0.9392 - val_loss: 0.1671 - val_auc: 0.9818 - val_accuracy: 0.9398\n",
            "Epoch 42/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1667 - auc: 0.9819 - accuracy: 0.9402 - val_loss: 0.1653 - val_auc: 0.9822 - val_accuracy: 0.9406\n",
            "Epoch 43/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1654 - auc: 0.9821 - accuracy: 0.9409 - val_loss: 0.1648 - val_auc: 0.9823 - val_accuracy: 0.9408\n",
            "Epoch 44/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1629 - auc: 0.9826 - accuracy: 0.9414 - val_loss: 0.1622 - val_auc: 0.9827 - val_accuracy: 0.9429\n",
            "Epoch 45/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1623 - auc: 0.9827 - accuracy: 0.9421 - val_loss: 0.1616 - val_auc: 0.9829 - val_accuracy: 0.9427\n",
            "Epoch 46/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1611 - auc: 0.9830 - accuracy: 0.9431 - val_loss: 0.1604 - val_auc: 0.9831 - val_accuracy: 0.9436\n",
            "Epoch 47/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1593 - auc: 0.9833 - accuracy: 0.9435 - val_loss: 0.1594 - val_auc: 0.9832 - val_accuracy: 0.9436\n",
            "Epoch 48/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1576 - auc: 0.9837 - accuracy: 0.9445 - val_loss: 0.1584 - val_auc: 0.9834 - val_accuracy: 0.9441\n",
            "Epoch 49/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1559 - auc: 0.9839 - accuracy: 0.9445 - val_loss: 0.1572 - val_auc: 0.9836 - val_accuracy: 0.9451\n",
            "Epoch 50/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1552 - auc: 0.9841 - accuracy: 0.9451 - val_loss: 0.1570 - val_auc: 0.9836 - val_accuracy: 0.9440\n",
            "Epoch 51/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1541 - auc: 0.9842 - accuracy: 0.9454 - val_loss: 0.1558 - val_auc: 0.9838 - val_accuracy: 0.9446\n",
            "Epoch 52/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1522 - auc: 0.9846 - accuracy: 0.9465 - val_loss: 0.1542 - val_auc: 0.9841 - val_accuracy: 0.9453\n",
            "Epoch 53/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1528 - auc: 0.9845 - accuracy: 0.9464 - val_loss: 0.1541 - val_auc: 0.9842 - val_accuracy: 0.9455\n",
            "Epoch 54/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1508 - auc: 0.9849 - accuracy: 0.9476 - val_loss: 0.1527 - val_auc: 0.9844 - val_accuracy: 0.9457\n",
            "Epoch 55/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1500 - auc: 0.9850 - accuracy: 0.9483 - val_loss: 0.1521 - val_auc: 0.9845 - val_accuracy: 0.9463\n",
            "Epoch 56/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1468 - auc: 0.9856 - accuracy: 0.9487 - val_loss: 0.1513 - val_auc: 0.9847 - val_accuracy: 0.9467\n",
            "Epoch 57/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1475 - auc: 0.9854 - accuracy: 0.9490 - val_loss: 0.1500 - val_auc: 0.9848 - val_accuracy: 0.9476\n",
            "Epoch 58/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1458 - auc: 0.9858 - accuracy: 0.9497 - val_loss: 0.1497 - val_auc: 0.9848 - val_accuracy: 0.9477\n",
            "Epoch 59/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1454 - auc: 0.9857 - accuracy: 0.9493 - val_loss: 0.1495 - val_auc: 0.9848 - val_accuracy: 0.9484\n",
            "Epoch 60/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1448 - auc: 0.9858 - accuracy: 0.9493 - val_loss: 0.1482 - val_auc: 0.9850 - val_accuracy: 0.9480\n",
            "Epoch 61/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1438 - auc: 0.9860 - accuracy: 0.9506 - val_loss: 0.1481 - val_auc: 0.9850 - val_accuracy: 0.9483\n",
            "Epoch 62/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1428 - auc: 0.9862 - accuracy: 0.9511 - val_loss: 0.1472 - val_auc: 0.9853 - val_accuracy: 0.9488\n",
            "Epoch 63/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1411 - auc: 0.9865 - accuracy: 0.9513 - val_loss: 0.1467 - val_auc: 0.9853 - val_accuracy: 0.9495\n",
            "Epoch 64/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1402 - auc: 0.9867 - accuracy: 0.9512 - val_loss: 0.1460 - val_auc: 0.9854 - val_accuracy: 0.9493\n",
            "Epoch 65/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1402 - auc: 0.9866 - accuracy: 0.9517 - val_loss: 0.1455 - val_auc: 0.9855 - val_accuracy: 0.9494\n",
            "Epoch 66/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1393 - auc: 0.9867 - accuracy: 0.9520 - val_loss: 0.1445 - val_auc: 0.9857 - val_accuracy: 0.9497\n",
            "Epoch 67/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1381 - auc: 0.9870 - accuracy: 0.9534 - val_loss: 0.1445 - val_auc: 0.9857 - val_accuracy: 0.9501\n",
            "Epoch 68/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1372 - auc: 0.9871 - accuracy: 0.9530 - val_loss: 0.1440 - val_auc: 0.9858 - val_accuracy: 0.9509\n",
            "Epoch 69/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1381 - auc: 0.9871 - accuracy: 0.9525 - val_loss: 0.1441 - val_auc: 0.9857 - val_accuracy: 0.9507\n",
            "Epoch 70/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1365 - auc: 0.9872 - accuracy: 0.9529 - val_loss: 0.1425 - val_auc: 0.9861 - val_accuracy: 0.9514\n",
            "Epoch 71/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1362 - auc: 0.9873 - accuracy: 0.9535 - val_loss: 0.1433 - val_auc: 0.9860 - val_accuracy: 0.9513\n",
            "Epoch 72/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1349 - auc: 0.9876 - accuracy: 0.9538 - val_loss: 0.1416 - val_auc: 0.9861 - val_accuracy: 0.9522\n",
            "Epoch 73/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1348 - auc: 0.9875 - accuracy: 0.9540 - val_loss: 0.1419 - val_auc: 0.9862 - val_accuracy: 0.9518\n",
            "Epoch 74/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1336 - auc: 0.9876 - accuracy: 0.9546 - val_loss: 0.1406 - val_auc: 0.9863 - val_accuracy: 0.9519\n",
            "Epoch 75/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1335 - auc: 0.9876 - accuracy: 0.9546 - val_loss: 0.1413 - val_auc: 0.9862 - val_accuracy: 0.9519\n",
            "Epoch 76/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1325 - auc: 0.9879 - accuracy: 0.9552 - val_loss: 0.1398 - val_auc: 0.9864 - val_accuracy: 0.9527\n",
            "Epoch 77/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1317 - auc: 0.9880 - accuracy: 0.9556 - val_loss: 0.1399 - val_auc: 0.9864 - val_accuracy: 0.9523\n",
            "Epoch 78/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1323 - auc: 0.9879 - accuracy: 0.9555 - val_loss: 0.1392 - val_auc: 0.9865 - val_accuracy: 0.9533\n",
            "Epoch 79/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1306 - auc: 0.9882 - accuracy: 0.9552 - val_loss: 0.1385 - val_auc: 0.9866 - val_accuracy: 0.9536\n",
            "Epoch 80/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1300 - auc: 0.9882 - accuracy: 0.9564 - val_loss: 0.1382 - val_auc: 0.9866 - val_accuracy: 0.9534\n",
            "Epoch 81/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1306 - auc: 0.9882 - accuracy: 0.9560 - val_loss: 0.1378 - val_auc: 0.9868 - val_accuracy: 0.9535\n",
            "Epoch 82/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1290 - auc: 0.9884 - accuracy: 0.9566 - val_loss: 0.1380 - val_auc: 0.9867 - val_accuracy: 0.9543\n",
            "Epoch 83/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1292 - auc: 0.9884 - accuracy: 0.9567 - val_loss: 0.1378 - val_auc: 0.9867 - val_accuracy: 0.9538\n",
            "Epoch 84/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1281 - auc: 0.9885 - accuracy: 0.9569 - val_loss: 0.1379 - val_auc: 0.9868 - val_accuracy: 0.9540\n",
            "Epoch 85/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1277 - auc: 0.9886 - accuracy: 0.9564 - val_loss: 0.1369 - val_auc: 0.9870 - val_accuracy: 0.9546\n",
            "Epoch 86/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1271 - auc: 0.9886 - accuracy: 0.9570 - val_loss: 0.1364 - val_auc: 0.9870 - val_accuracy: 0.9541\n",
            "Epoch 87/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1268 - auc: 0.9887 - accuracy: 0.9578 - val_loss: 0.1366 - val_auc: 0.9871 - val_accuracy: 0.9537\n",
            "Epoch 88/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1270 - auc: 0.9887 - accuracy: 0.9577 - val_loss: 0.1359 - val_auc: 0.9871 - val_accuracy: 0.9550\n",
            "Epoch 89/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1244 - auc: 0.9890 - accuracy: 0.9584 - val_loss: 0.1353 - val_auc: 0.9871 - val_accuracy: 0.9550\n",
            "Epoch 90/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1250 - auc: 0.9888 - accuracy: 0.9585 - val_loss: 0.1356 - val_auc: 0.9871 - val_accuracy: 0.9558\n",
            "Epoch 91/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1247 - auc: 0.9890 - accuracy: 0.9585 - val_loss: 0.1361 - val_auc: 0.9870 - val_accuracy: 0.9550\n",
            "Epoch 92/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1246 - auc: 0.9891 - accuracy: 0.9589 - val_loss: 0.1347 - val_auc: 0.9872 - val_accuracy: 0.9555\n",
            "Epoch 93/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1246 - auc: 0.9890 - accuracy: 0.9588 - val_loss: 0.1352 - val_auc: 0.9872 - val_accuracy: 0.9557\n",
            "Epoch 94/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1231 - auc: 0.9892 - accuracy: 0.9584 - val_loss: 0.1346 - val_auc: 0.9874 - val_accuracy: 0.9559\n",
            "Epoch 95/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1234 - auc: 0.9892 - accuracy: 0.9590 - val_loss: 0.1345 - val_auc: 0.9873 - val_accuracy: 0.9552\n",
            "Epoch 96/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1233 - auc: 0.9893 - accuracy: 0.9590 - val_loss: 0.1338 - val_auc: 0.9874 - val_accuracy: 0.9563\n",
            "Epoch 97/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1222 - auc: 0.9895 - accuracy: 0.9588 - val_loss: 0.1332 - val_auc: 0.9875 - val_accuracy: 0.9568\n",
            "Epoch 98/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1208 - auc: 0.9896 - accuracy: 0.9602 - val_loss: 0.1327 - val_auc: 0.9876 - val_accuracy: 0.9565\n",
            "Epoch 99/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1208 - auc: 0.9897 - accuracy: 0.9597 - val_loss: 0.1325 - val_auc: 0.9877 - val_accuracy: 0.9561\n",
            "Epoch 100/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1205 - auc: 0.9896 - accuracy: 0.9602 - val_loss: 0.1322 - val_auc: 0.9877 - val_accuracy: 0.9566\n",
            "Epoch 101/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1191 - auc: 0.9898 - accuracy: 0.9606 - val_loss: 0.1323 - val_auc: 0.9876 - val_accuracy: 0.9569\n",
            "Epoch 102/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1204 - auc: 0.9896 - accuracy: 0.9602 - val_loss: 0.1317 - val_auc: 0.9876 - val_accuracy: 0.9572\n",
            "Epoch 103/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1197 - auc: 0.9898 - accuracy: 0.9607 - val_loss: 0.1312 - val_auc: 0.9879 - val_accuracy: 0.9573\n",
            "Epoch 104/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1190 - auc: 0.9899 - accuracy: 0.9608 - val_loss: 0.1310 - val_auc: 0.9879 - val_accuracy: 0.9576\n",
            "Epoch 105/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1187 - auc: 0.9899 - accuracy: 0.9613 - val_loss: 0.1308 - val_auc: 0.9879 - val_accuracy: 0.9577\n",
            "Epoch 106/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1185 - auc: 0.9899 - accuracy: 0.9614 - val_loss: 0.1311 - val_auc: 0.9878 - val_accuracy: 0.9572\n",
            "Epoch 107/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1181 - auc: 0.9900 - accuracy: 0.9605 - val_loss: 0.1307 - val_auc: 0.9879 - val_accuracy: 0.9568\n",
            "Epoch 108/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1177 - auc: 0.9900 - accuracy: 0.9616 - val_loss: 0.1307 - val_auc: 0.9879 - val_accuracy: 0.9580\n",
            "Epoch 109/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1168 - auc: 0.9901 - accuracy: 0.9617 - val_loss: 0.1303 - val_auc: 0.9878 - val_accuracy: 0.9579\n",
            "Epoch 110/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1160 - auc: 0.9902 - accuracy: 0.9622 - val_loss: 0.1295 - val_auc: 0.9881 - val_accuracy: 0.9577\n",
            "Epoch 111/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1148 - auc: 0.9904 - accuracy: 0.9624 - val_loss: 0.1296 - val_auc: 0.9882 - val_accuracy: 0.9585\n",
            "Epoch 112/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1147 - auc: 0.9905 - accuracy: 0.9625 - val_loss: 0.1291 - val_auc: 0.9882 - val_accuracy: 0.9587\n",
            "Epoch 113/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1147 - auc: 0.9904 - accuracy: 0.9619 - val_loss: 0.1296 - val_auc: 0.9881 - val_accuracy: 0.9581\n",
            "Epoch 114/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1146 - auc: 0.9904 - accuracy: 0.9625 - val_loss: 0.1283 - val_auc: 0.9883 - val_accuracy: 0.9585\n",
            "Epoch 115/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1145 - auc: 0.9904 - accuracy: 0.9625 - val_loss: 0.1287 - val_auc: 0.9883 - val_accuracy: 0.9586\n",
            "Epoch 116/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1137 - auc: 0.9904 - accuracy: 0.9632 - val_loss: 0.1282 - val_auc: 0.9883 - val_accuracy: 0.9592\n",
            "Epoch 117/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1132 - auc: 0.9907 - accuracy: 0.9633 - val_loss: 0.1278 - val_auc: 0.9883 - val_accuracy: 0.9584\n",
            "Epoch 118/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1144 - auc: 0.9905 - accuracy: 0.9630 - val_loss: 0.1280 - val_auc: 0.9884 - val_accuracy: 0.9588\n",
            "Epoch 119/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1133 - auc: 0.9905 - accuracy: 0.9635 - val_loss: 0.1279 - val_auc: 0.9883 - val_accuracy: 0.9594\n",
            "Epoch 120/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1140 - auc: 0.9904 - accuracy: 0.9628 - val_loss: 0.1272 - val_auc: 0.9884 - val_accuracy: 0.9591\n",
            "Epoch 121/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1130 - auc: 0.9906 - accuracy: 0.9633 - val_loss: 0.1276 - val_auc: 0.9885 - val_accuracy: 0.9589\n",
            "Epoch 122/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1111 - auc: 0.9909 - accuracy: 0.9644 - val_loss: 0.1270 - val_auc: 0.9885 - val_accuracy: 0.9590\n",
            "Epoch 123/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1120 - auc: 0.9907 - accuracy: 0.9640 - val_loss: 0.1268 - val_auc: 0.9885 - val_accuracy: 0.9588\n",
            "Epoch 124/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1121 - auc: 0.9907 - accuracy: 0.9639 - val_loss: 0.1268 - val_auc: 0.9885 - val_accuracy: 0.9594\n",
            "Epoch 125/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1103 - auc: 0.9910 - accuracy: 0.9635 - val_loss: 0.1264 - val_auc: 0.9886 - val_accuracy: 0.9599\n",
            "Epoch 126/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1097 - auc: 0.9911 - accuracy: 0.9648 - val_loss: 0.1258 - val_auc: 0.9887 - val_accuracy: 0.9593\n",
            "Epoch 127/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1104 - auc: 0.9910 - accuracy: 0.9641 - val_loss: 0.1260 - val_auc: 0.9886 - val_accuracy: 0.9590\n",
            "Epoch 128/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1106 - auc: 0.9909 - accuracy: 0.9643 - val_loss: 0.1263 - val_auc: 0.9885 - val_accuracy: 0.9594\n",
            "Epoch 129/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1107 - auc: 0.9909 - accuracy: 0.9638 - val_loss: 0.1253 - val_auc: 0.9887 - val_accuracy: 0.9598\n",
            "Epoch 130/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1094 - auc: 0.9911 - accuracy: 0.9646 - val_loss: 0.1252 - val_auc: 0.9886 - val_accuracy: 0.9595\n",
            "Epoch 131/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1090 - auc: 0.9911 - accuracy: 0.9652 - val_loss: 0.1258 - val_auc: 0.9887 - val_accuracy: 0.9596\n",
            "Epoch 132/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1085 - auc: 0.9912 - accuracy: 0.9648 - val_loss: 0.1245 - val_auc: 0.9888 - val_accuracy: 0.9596\n",
            "Epoch 133/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1075 - auc: 0.9913 - accuracy: 0.9655 - val_loss: 0.1242 - val_auc: 0.9888 - val_accuracy: 0.9597\n",
            "Epoch 134/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1076 - auc: 0.9914 - accuracy: 0.9652 - val_loss: 0.1248 - val_auc: 0.9888 - val_accuracy: 0.9602\n",
            "Epoch 135/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1073 - auc: 0.9913 - accuracy: 0.9652 - val_loss: 0.1245 - val_auc: 0.9889 - val_accuracy: 0.9602\n",
            "Epoch 136/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1072 - auc: 0.9913 - accuracy: 0.9656 - val_loss: 0.1239 - val_auc: 0.9889 - val_accuracy: 0.9598\n",
            "Epoch 137/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1059 - auc: 0.9916 - accuracy: 0.9658 - val_loss: 0.1240 - val_auc: 0.9888 - val_accuracy: 0.9598\n",
            "Epoch 138/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1068 - auc: 0.9914 - accuracy: 0.9662 - val_loss: 0.1242 - val_auc: 0.9889 - val_accuracy: 0.9599\n",
            "Epoch 139/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1064 - auc: 0.9914 - accuracy: 0.9659 - val_loss: 0.1240 - val_auc: 0.9888 - val_accuracy: 0.9603\n",
            "Epoch 140/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1053 - auc: 0.9917 - accuracy: 0.9654 - val_loss: 0.1238 - val_auc: 0.9888 - val_accuracy: 0.9613\n",
            "Epoch 141/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1058 - auc: 0.9914 - accuracy: 0.9660 - val_loss: 0.1231 - val_auc: 0.9890 - val_accuracy: 0.9605\n",
            "Epoch 142/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1055 - auc: 0.9915 - accuracy: 0.9660 - val_loss: 0.1231 - val_auc: 0.9890 - val_accuracy: 0.9609\n",
            "Epoch 143/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1050 - auc: 0.9916 - accuracy: 0.9665 - val_loss: 0.1238 - val_auc: 0.9888 - val_accuracy: 0.9607\n",
            "Epoch 144/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1055 - auc: 0.9915 - accuracy: 0.9663 - val_loss: 0.1232 - val_auc: 0.9890 - val_accuracy: 0.9607\n",
            "Epoch 145/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1042 - auc: 0.9918 - accuracy: 0.9659 - val_loss: 0.1224 - val_auc: 0.9890 - val_accuracy: 0.9600\n",
            "Epoch 146/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1048 - auc: 0.9917 - accuracy: 0.9668 - val_loss: 0.1220 - val_auc: 0.9890 - val_accuracy: 0.9612\n",
            "Epoch 147/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1044 - auc: 0.9917 - accuracy: 0.9664 - val_loss: 0.1227 - val_auc: 0.9890 - val_accuracy: 0.9611\n",
            "Epoch 148/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1040 - auc: 0.9917 - accuracy: 0.9664 - val_loss: 0.1226 - val_auc: 0.9890 - val_accuracy: 0.9608\n",
            "Epoch 149/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1048 - auc: 0.9916 - accuracy: 0.9670 - val_loss: 0.1223 - val_auc: 0.9891 - val_accuracy: 0.9601\n",
            "Epoch 150/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1025 - auc: 0.9919 - accuracy: 0.9679 - val_loss: 0.1219 - val_auc: 0.9892 - val_accuracy: 0.9607\n",
            "Epoch 151/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1034 - auc: 0.9918 - accuracy: 0.9672 - val_loss: 0.1219 - val_auc: 0.9892 - val_accuracy: 0.9609\n",
            "Epoch 152/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1032 - auc: 0.9918 - accuracy: 0.9672 - val_loss: 0.1217 - val_auc: 0.9892 - val_accuracy: 0.9610\n",
            "Epoch 153/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1031 - auc: 0.9918 - accuracy: 0.9669 - val_loss: 0.1206 - val_auc: 0.9892 - val_accuracy: 0.9619\n",
            "Epoch 154/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1027 - auc: 0.9918 - accuracy: 0.9673 - val_loss: 0.1209 - val_auc: 0.9893 - val_accuracy: 0.9611\n",
            "Epoch 155/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1027 - auc: 0.9918 - accuracy: 0.9677 - val_loss: 0.1222 - val_auc: 0.9890 - val_accuracy: 0.9609\n",
            "Epoch 156/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1029 - auc: 0.9920 - accuracy: 0.9669 - val_loss: 0.1218 - val_auc: 0.9892 - val_accuracy: 0.9614\n",
            "Epoch 157/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1023 - auc: 0.9918 - accuracy: 0.9673 - val_loss: 0.1207 - val_auc: 0.9891 - val_accuracy: 0.9616\n",
            "Epoch 158/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1012 - auc: 0.9920 - accuracy: 0.9679 - val_loss: 0.1212 - val_auc: 0.9893 - val_accuracy: 0.9613\n",
            "Epoch 159/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1023 - auc: 0.9919 - accuracy: 0.9679 - val_loss: 0.1208 - val_auc: 0.9892 - val_accuracy: 0.9614\n",
            "Epoch 160/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1012 - auc: 0.9921 - accuracy: 0.9679 - val_loss: 0.1211 - val_auc: 0.9893 - val_accuracy: 0.9613\n",
            "Epoch 161/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1008 - auc: 0.9921 - accuracy: 0.9680 - val_loss: 0.1201 - val_auc: 0.9895 - val_accuracy: 0.9623\n",
            "Epoch 162/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1008 - auc: 0.9922 - accuracy: 0.9680 - val_loss: 0.1208 - val_auc: 0.9892 - val_accuracy: 0.9621\n",
            "Epoch 163/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0993 - auc: 0.9923 - accuracy: 0.9683 - val_loss: 0.1191 - val_auc: 0.9896 - val_accuracy: 0.9617\n",
            "Epoch 164/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1007 - auc: 0.9920 - accuracy: 0.9688 - val_loss: 0.1208 - val_auc: 0.9895 - val_accuracy: 0.9616\n",
            "Epoch 165/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0999 - auc: 0.9922 - accuracy: 0.9686 - val_loss: 0.1199 - val_auc: 0.9894 - val_accuracy: 0.9618\n",
            "Epoch 166/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0996 - auc: 0.9922 - accuracy: 0.9689 - val_loss: 0.1200 - val_auc: 0.9895 - val_accuracy: 0.9618\n",
            "Epoch 167/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0998 - auc: 0.9922 - accuracy: 0.9689 - val_loss: 0.1194 - val_auc: 0.9895 - val_accuracy: 0.9623\n",
            "Epoch 168/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1003 - auc: 0.9921 - accuracy: 0.9682 - val_loss: 0.1195 - val_auc: 0.9895 - val_accuracy: 0.9620\n",
            "Epoch 169/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0994 - auc: 0.9922 - accuracy: 0.9685 - val_loss: 0.1184 - val_auc: 0.9896 - val_accuracy: 0.9623\n",
            "Epoch 170/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0993 - auc: 0.9922 - accuracy: 0.9682 - val_loss: 0.1194 - val_auc: 0.9895 - val_accuracy: 0.9617\n",
            "Epoch 171/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0990 - auc: 0.9923 - accuracy: 0.9695 - val_loss: 0.1190 - val_auc: 0.9895 - val_accuracy: 0.9621\n",
            "Epoch 172/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0980 - auc: 0.9924 - accuracy: 0.9693 - val_loss: 0.1196 - val_auc: 0.9895 - val_accuracy: 0.9622\n",
            "Epoch 173/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0992 - auc: 0.9923 - accuracy: 0.9687 - val_loss: 0.1196 - val_auc: 0.9894 - val_accuracy: 0.9624\n",
            "Epoch 174/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0986 - auc: 0.9923 - accuracy: 0.9688 - val_loss: 0.1194 - val_auc: 0.9895 - val_accuracy: 0.9618\n",
            "Epoch 175/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0980 - auc: 0.9924 - accuracy: 0.9688 - val_loss: 0.1192 - val_auc: 0.9895 - val_accuracy: 0.9626\n",
            "Epoch 176/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0991 - auc: 0.9922 - accuracy: 0.9695 - val_loss: 0.1181 - val_auc: 0.9897 - val_accuracy: 0.9629\n",
            "Epoch 177/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0977 - auc: 0.9925 - accuracy: 0.9691 - val_loss: 0.1184 - val_auc: 0.9898 - val_accuracy: 0.9621\n",
            "Epoch 178/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0990 - auc: 0.9923 - accuracy: 0.9687 - val_loss: 0.1186 - val_auc: 0.9894 - val_accuracy: 0.9623\n",
            "Epoch 179/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0977 - auc: 0.9925 - accuracy: 0.9692 - val_loss: 0.1193 - val_auc: 0.9894 - val_accuracy: 0.9625\n",
            "Epoch 180/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0980 - auc: 0.9924 - accuracy: 0.9695 - val_loss: 0.1184 - val_auc: 0.9897 - val_accuracy: 0.9633\n",
            "Epoch 181/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0978 - auc: 0.9924 - accuracy: 0.9698 - val_loss: 0.1186 - val_auc: 0.9897 - val_accuracy: 0.9630\n",
            "Epoch 182/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0983 - auc: 0.9923 - accuracy: 0.9695 - val_loss: 0.1177 - val_auc: 0.9897 - val_accuracy: 0.9628\n",
            "Epoch 183/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0970 - auc: 0.9925 - accuracy: 0.9697 - val_loss: 0.1182 - val_auc: 0.9897 - val_accuracy: 0.9623\n",
            "Epoch 184/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0965 - auc: 0.9926 - accuracy: 0.9700 - val_loss: 0.1185 - val_auc: 0.9896 - val_accuracy: 0.9627\n",
            "Epoch 185/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0966 - auc: 0.9925 - accuracy: 0.9697 - val_loss: 0.1183 - val_auc: 0.9897 - val_accuracy: 0.9630\n",
            "Epoch 186/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0961 - auc: 0.9927 - accuracy: 0.9707 - val_loss: 0.1179 - val_auc: 0.9897 - val_accuracy: 0.9634\n",
            "Epoch 187/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0960 - auc: 0.9927 - accuracy: 0.9700 - val_loss: 0.1176 - val_auc: 0.9894 - val_accuracy: 0.9638\n",
            "Epoch 188/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0962 - auc: 0.9925 - accuracy: 0.9699 - val_loss: 0.1174 - val_auc: 0.9897 - val_accuracy: 0.9634\n",
            "Epoch 189/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0964 - auc: 0.9926 - accuracy: 0.9697 - val_loss: 0.1175 - val_auc: 0.9897 - val_accuracy: 0.9639\n",
            "Epoch 190/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0949 - auc: 0.9928 - accuracy: 0.9702 - val_loss: 0.1170 - val_auc: 0.9898 - val_accuracy: 0.9631\n",
            "Epoch 191/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0949 - auc: 0.9928 - accuracy: 0.9708 - val_loss: 0.1168 - val_auc: 0.9898 - val_accuracy: 0.9632\n",
            "Epoch 192/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0953 - auc: 0.9928 - accuracy: 0.9701 - val_loss: 0.1171 - val_auc: 0.9898 - val_accuracy: 0.9632\n",
            "Epoch 193/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0953 - auc: 0.9927 - accuracy: 0.9704 - val_loss: 0.1164 - val_auc: 0.9898 - val_accuracy: 0.9634\n",
            "Epoch 194/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0950 - auc: 0.9928 - accuracy: 0.9703 - val_loss: 0.1176 - val_auc: 0.9897 - val_accuracy: 0.9631\n",
            "Epoch 195/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0950 - auc: 0.9929 - accuracy: 0.9705 - val_loss: 0.1168 - val_auc: 0.9898 - val_accuracy: 0.9637\n",
            "Epoch 196/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0941 - auc: 0.9929 - accuracy: 0.9706 - val_loss: 0.1171 - val_auc: 0.9898 - val_accuracy: 0.9641\n",
            "Epoch 197/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0956 - auc: 0.9927 - accuracy: 0.9699 - val_loss: 0.1165 - val_auc: 0.9897 - val_accuracy: 0.9634\n",
            "Epoch 198/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0945 - auc: 0.9927 - accuracy: 0.9709 - val_loss: 0.1168 - val_auc: 0.9897 - val_accuracy: 0.9641\n",
            "Epoch 199/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0942 - auc: 0.9928 - accuracy: 0.9703 - val_loss: 0.1170 - val_auc: 0.9898 - val_accuracy: 0.9632\n",
            "Epoch 200/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0938 - auc: 0.9929 - accuracy: 0.9708 - val_loss: 0.1161 - val_auc: 0.9898 - val_accuracy: 0.9640\n",
            "Epoch 201/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0932 - auc: 0.9930 - accuracy: 0.9712 - val_loss: 0.1157 - val_auc: 0.9899 - val_accuracy: 0.9641\n",
            "Epoch 202/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0929 - auc: 0.9930 - accuracy: 0.9713 - val_loss: 0.1156 - val_auc: 0.9899 - val_accuracy: 0.9645\n",
            "Epoch 203/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0946 - auc: 0.9928 - accuracy: 0.9706 - val_loss: 0.1161 - val_auc: 0.9899 - val_accuracy: 0.9638\n",
            "Epoch 204/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0932 - auc: 0.9930 - accuracy: 0.9712 - val_loss: 0.1167 - val_auc: 0.9899 - val_accuracy: 0.9637\n",
            "Epoch 205/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0937 - auc: 0.9927 - accuracy: 0.9708 - val_loss: 0.1161 - val_auc: 0.9899 - val_accuracy: 0.9640\n",
            "Epoch 206/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0929 - auc: 0.9929 - accuracy: 0.9710 - val_loss: 0.1149 - val_auc: 0.9899 - val_accuracy: 0.9647\n",
            "Epoch 207/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0930 - auc: 0.9929 - accuracy: 0.9710 - val_loss: 0.1151 - val_auc: 0.9900 - val_accuracy: 0.9638\n",
            "Epoch 208/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0929 - auc: 0.9931 - accuracy: 0.9712 - val_loss: 0.1160 - val_auc: 0.9899 - val_accuracy: 0.9646\n",
            "Epoch 209/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0927 - auc: 0.9931 - accuracy: 0.9709 - val_loss: 0.1152 - val_auc: 0.9899 - val_accuracy: 0.9643\n",
            "Epoch 210/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0929 - auc: 0.9929 - accuracy: 0.9714 - val_loss: 0.1154 - val_auc: 0.9900 - val_accuracy: 0.9641\n",
            "Epoch 211/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0928 - auc: 0.9931 - accuracy: 0.9714 - val_loss: 0.1167 - val_auc: 0.9898 - val_accuracy: 0.9643\n",
            "Epoch 212/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0908 - auc: 0.9933 - accuracy: 0.9716 - val_loss: 0.1147 - val_auc: 0.9900 - val_accuracy: 0.9650\n",
            "Epoch 213/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0925 - auc: 0.9931 - accuracy: 0.9712 - val_loss: 0.1159 - val_auc: 0.9900 - val_accuracy: 0.9641\n",
            "Epoch 214/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0931 - auc: 0.9930 - accuracy: 0.9713 - val_loss: 0.1154 - val_auc: 0.9899 - val_accuracy: 0.9645\n",
            "Epoch 215/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0925 - auc: 0.9930 - accuracy: 0.9715 - val_loss: 0.1149 - val_auc: 0.9899 - val_accuracy: 0.9651\n",
            "Epoch 216/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0929 - auc: 0.9930 - accuracy: 0.9712 - val_loss: 0.1148 - val_auc: 0.9899 - val_accuracy: 0.9646\n",
            "Epoch 217/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0917 - auc: 0.9931 - accuracy: 0.9714 - val_loss: 0.1160 - val_auc: 0.9899 - val_accuracy: 0.9645\n",
            "Epoch 218/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0907 - auc: 0.9932 - accuracy: 0.9722 - val_loss: 0.1158 - val_auc: 0.9898 - val_accuracy: 0.9641\n",
            "Epoch 219/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0928 - auc: 0.9930 - accuracy: 0.9708 - val_loss: 0.1153 - val_auc: 0.9900 - val_accuracy: 0.9643\n",
            "Epoch 220/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0911 - auc: 0.9931 - accuracy: 0.9720 - val_loss: 0.1162 - val_auc: 0.9898 - val_accuracy: 0.9643\n",
            "Epoch 221/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0904 - auc: 0.9933 - accuracy: 0.9722 - val_loss: 0.1149 - val_auc: 0.9901 - val_accuracy: 0.9646\n",
            "Epoch 222/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0904 - auc: 0.9933 - accuracy: 0.9718 - val_loss: 0.1149 - val_auc: 0.9900 - val_accuracy: 0.9646\n",
            "Epoch 223/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0907 - auc: 0.9934 - accuracy: 0.9715 - val_loss: 0.1159 - val_auc: 0.9898 - val_accuracy: 0.9640\n",
            "Epoch 224/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0904 - auc: 0.9932 - accuracy: 0.9717 - val_loss: 0.1151 - val_auc: 0.9901 - val_accuracy: 0.9646\n",
            "Epoch 225/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0902 - auc: 0.9935 - accuracy: 0.9714 - val_loss: 0.1153 - val_auc: 0.9900 - val_accuracy: 0.9645\n",
            "Epoch 226/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0906 - auc: 0.9931 - accuracy: 0.9721 - val_loss: 0.1159 - val_auc: 0.9899 - val_accuracy: 0.9650\n",
            "Epoch 227/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0898 - auc: 0.9935 - accuracy: 0.9721 - val_loss: 0.1155 - val_auc: 0.9899 - val_accuracy: 0.9652\n",
            "Epoch 228/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0904 - auc: 0.9933 - accuracy: 0.9721 - val_loss: 0.1154 - val_auc: 0.9899 - val_accuracy: 0.9654\n",
            "Epoch 229/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0908 - auc: 0.9932 - accuracy: 0.9720 - val_loss: 0.1146 - val_auc: 0.9900 - val_accuracy: 0.9652\n",
            "Epoch 230/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0898 - auc: 0.9934 - accuracy: 0.9722 - val_loss: 0.1150 - val_auc: 0.9900 - val_accuracy: 0.9655\n",
            "Epoch 231/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0904 - auc: 0.9932 - accuracy: 0.9722 - val_loss: 0.1148 - val_auc: 0.9901 - val_accuracy: 0.9652\n",
            "Epoch 232/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0891 - auc: 0.9934 - accuracy: 0.9720 - val_loss: 0.1151 - val_auc: 0.9901 - val_accuracy: 0.9652\n",
            "Epoch 233/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0887 - auc: 0.9936 - accuracy: 0.9721 - val_loss: 0.1154 - val_auc: 0.9900 - val_accuracy: 0.9653\n",
            "Epoch 234/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0897 - auc: 0.9933 - accuracy: 0.9723 - val_loss: 0.1143 - val_auc: 0.9901 - val_accuracy: 0.9655\n",
            "Epoch 235/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0902 - auc: 0.9933 - accuracy: 0.9724 - val_loss: 0.1146 - val_auc: 0.9899 - val_accuracy: 0.9652\n",
            "Epoch 236/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0896 - auc: 0.9934 - accuracy: 0.9726 - val_loss: 0.1147 - val_auc: 0.9901 - val_accuracy: 0.9655\n",
            "Epoch 237/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0890 - auc: 0.9935 - accuracy: 0.9723 - val_loss: 0.1143 - val_auc: 0.9901 - val_accuracy: 0.9650\n",
            "Epoch 238/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0882 - auc: 0.9935 - accuracy: 0.9725 - val_loss: 0.1145 - val_auc: 0.9902 - val_accuracy: 0.9652\n",
            "Epoch 239/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0895 - auc: 0.9933 - accuracy: 0.9726 - val_loss: 0.1142 - val_auc: 0.9902 - val_accuracy: 0.9655\n",
            "Epoch 240/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0881 - auc: 0.9934 - accuracy: 0.9733 - val_loss: 0.1148 - val_auc: 0.9901 - val_accuracy: 0.9652\n",
            "Epoch 241/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0889 - auc: 0.9934 - accuracy: 0.9730 - val_loss: 0.1134 - val_auc: 0.9902 - val_accuracy: 0.9655\n",
            "Epoch 242/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0875 - auc: 0.9936 - accuracy: 0.9734 - val_loss: 0.1154 - val_auc: 0.9901 - val_accuracy: 0.9655\n",
            "Epoch 243/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0887 - auc: 0.9935 - accuracy: 0.9725 - val_loss: 0.1152 - val_auc: 0.9901 - val_accuracy: 0.9657\n",
            "Epoch 244/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0882 - auc: 0.9936 - accuracy: 0.9725 - val_loss: 0.1144 - val_auc: 0.9902 - val_accuracy: 0.9657\n",
            "Epoch 245/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0881 - auc: 0.9935 - accuracy: 0.9731 - val_loss: 0.1148 - val_auc: 0.9902 - val_accuracy: 0.9659\n",
            "Epoch 246/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0876 - auc: 0.9937 - accuracy: 0.9729 - val_loss: 0.1141 - val_auc: 0.9902 - val_accuracy: 0.9651\n",
            "Epoch 247/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0888 - auc: 0.9935 - accuracy: 0.9726 - val_loss: 0.1145 - val_auc: 0.9901 - val_accuracy: 0.9655\n",
            "Epoch 248/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0878 - auc: 0.9936 - accuracy: 0.9731 - val_loss: 0.1149 - val_auc: 0.9900 - val_accuracy: 0.9654\n",
            "Epoch 249/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0877 - auc: 0.9935 - accuracy: 0.9732 - val_loss: 0.1137 - val_auc: 0.9902 - val_accuracy: 0.9659\n",
            "Epoch 250/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0876 - auc: 0.9937 - accuracy: 0.9735 - val_loss: 0.1140 - val_auc: 0.9902 - val_accuracy: 0.9661\n",
            "Epoch 251/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0876 - auc: 0.9936 - accuracy: 0.9731 - val_loss: 0.1147 - val_auc: 0.9901 - val_accuracy: 0.9652\n",
            "Epoch 252/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0873 - auc: 0.9937 - accuracy: 0.9732 - val_loss: 0.1141 - val_auc: 0.9903 - val_accuracy: 0.9663\n",
            "Epoch 253/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0882 - auc: 0.9934 - accuracy: 0.9726 - val_loss: 0.1151 - val_auc: 0.9901 - val_accuracy: 0.9661\n",
            "Epoch 254/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0872 - auc: 0.9936 - accuracy: 0.9737 - val_loss: 0.1149 - val_auc: 0.9901 - val_accuracy: 0.9655\n",
            "Epoch 255/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0869 - auc: 0.9937 - accuracy: 0.9736 - val_loss: 0.1143 - val_auc: 0.9903 - val_accuracy: 0.9656\n",
            "Epoch 256/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0863 - auc: 0.9938 - accuracy: 0.9735 - val_loss: 0.1145 - val_auc: 0.9902 - val_accuracy: 0.9658\n",
            "Epoch 257/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0870 - auc: 0.9937 - accuracy: 0.9730 - val_loss: 0.1146 - val_auc: 0.9902 - val_accuracy: 0.9656\n",
            "Epoch 258/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0879 - auc: 0.9936 - accuracy: 0.9726 - val_loss: 0.1152 - val_auc: 0.9900 - val_accuracy: 0.9658\n",
            "Epoch 259/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0856 - auc: 0.9940 - accuracy: 0.9736 - val_loss: 0.1142 - val_auc: 0.9902 - val_accuracy: 0.9658\n",
            "Epoch 260/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0860 - auc: 0.9939 - accuracy: 0.9732 - val_loss: 0.1140 - val_auc: 0.9902 - val_accuracy: 0.9657\n",
            "Epoch 261/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0861 - auc: 0.9938 - accuracy: 0.9734 - val_loss: 0.1143 - val_auc: 0.9902 - val_accuracy: 0.9660\n",
            "1000/1000 [==============================] - 1s 933us/step\n",
            "fold train/predict time: 0:19:06.984020\n",
            "x_train shape: (128000, 67)\n",
            "Epoch 1/1000\n",
            "1600/1600 [==============================] - 6s 3ms/step - loss: 0.6135 - auc: 0.6929 - accuracy: 0.6639 - val_loss: 0.5159 - val_auc: 0.8225 - val_accuracy: 0.7489\n",
            "Epoch 2/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4789 - auc: 0.8461 - accuracy: 0.7733 - val_loss: 0.4120 - val_auc: 0.8927 - val_accuracy: 0.8189\n",
            "Epoch 3/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3996 - auc: 0.8975 - accuracy: 0.8264 - val_loss: 0.3570 - val_auc: 0.9199 - val_accuracy: 0.8505\n",
            "Epoch 4/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3589 - auc: 0.9181 - accuracy: 0.8474 - val_loss: 0.3308 - val_auc: 0.9306 - val_accuracy: 0.8603\n",
            "Epoch 5/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3365 - auc: 0.9281 - accuracy: 0.8579 - val_loss: 0.3151 - val_auc: 0.9371 - val_accuracy: 0.8676\n",
            "Epoch 6/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3212 - auc: 0.9346 - accuracy: 0.8663 - val_loss: 0.3036 - val_auc: 0.9414 - val_accuracy: 0.8727\n",
            "Epoch 7/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3095 - auc: 0.9394 - accuracy: 0.8721 - val_loss: 0.2936 - val_auc: 0.9453 - val_accuracy: 0.8766\n",
            "Epoch 8/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2989 - auc: 0.9434 - accuracy: 0.8769 - val_loss: 0.2841 - val_auc: 0.9490 - val_accuracy: 0.8819\n",
            "Epoch 9/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2897 - auc: 0.9471 - accuracy: 0.8821 - val_loss: 0.2761 - val_auc: 0.9519 - val_accuracy: 0.8855\n",
            "Epoch 10/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2800 - auc: 0.9506 - accuracy: 0.8869 - val_loss: 0.2683 - val_auc: 0.9546 - val_accuracy: 0.8898\n",
            "Epoch 11/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2729 - auc: 0.9531 - accuracy: 0.8907 - val_loss: 0.2608 - val_auc: 0.9571 - val_accuracy: 0.8937\n",
            "Epoch 12/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2646 - auc: 0.9559 - accuracy: 0.8944 - val_loss: 0.2541 - val_auc: 0.9591 - val_accuracy: 0.8965\n",
            "Epoch 13/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2578 - auc: 0.9582 - accuracy: 0.8971 - val_loss: 0.2474 - val_auc: 0.9613 - val_accuracy: 0.9004\n",
            "Epoch 14/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2507 - auc: 0.9605 - accuracy: 0.9002 - val_loss: 0.2409 - val_auc: 0.9633 - val_accuracy: 0.9037\n",
            "Epoch 15/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2450 - auc: 0.9622 - accuracy: 0.9029 - val_loss: 0.2350 - val_auc: 0.9652 - val_accuracy: 0.9063\n",
            "Epoch 16/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2385 - auc: 0.9642 - accuracy: 0.9069 - val_loss: 0.2297 - val_auc: 0.9666 - val_accuracy: 0.9095\n",
            "Epoch 17/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2327 - auc: 0.9659 - accuracy: 0.9093 - val_loss: 0.2245 - val_auc: 0.9681 - val_accuracy: 0.9119\n",
            "Epoch 18/1000\n",
            "1600/1600 [==============================] - 6s 4ms/step - loss: 0.2278 - auc: 0.9673 - accuracy: 0.9121 - val_loss: 0.2193 - val_auc: 0.9696 - val_accuracy: 0.9146\n",
            "Epoch 19/1000\n",
            "1600/1600 [==============================] - 6s 4ms/step - loss: 0.2224 - auc: 0.9687 - accuracy: 0.9150 - val_loss: 0.2151 - val_auc: 0.9707 - val_accuracy: 0.9170\n",
            "Epoch 20/1000\n",
            "1600/1600 [==============================] - 6s 4ms/step - loss: 0.2165 - auc: 0.9704 - accuracy: 0.9174 - val_loss: 0.2107 - val_auc: 0.9717 - val_accuracy: 0.9198\n",
            "Epoch 21/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2132 - auc: 0.9713 - accuracy: 0.9192 - val_loss: 0.2070 - val_auc: 0.9727 - val_accuracy: 0.9220\n",
            "Epoch 22/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2095 - auc: 0.9723 - accuracy: 0.9209 - val_loss: 0.2035 - val_auc: 0.9736 - val_accuracy: 0.9238\n",
            "Epoch 23/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2050 - auc: 0.9733 - accuracy: 0.9231 - val_loss: 0.2000 - val_auc: 0.9744 - val_accuracy: 0.9243\n",
            "Epoch 24/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2017 - auc: 0.9742 - accuracy: 0.9243 - val_loss: 0.1971 - val_auc: 0.9752 - val_accuracy: 0.9273\n",
            "Epoch 25/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1985 - auc: 0.9750 - accuracy: 0.9262 - val_loss: 0.1942 - val_auc: 0.9757 - val_accuracy: 0.9277\n",
            "Epoch 26/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1947 - auc: 0.9759 - accuracy: 0.9277 - val_loss: 0.1914 - val_auc: 0.9764 - val_accuracy: 0.9287\n",
            "Epoch 27/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1910 - auc: 0.9767 - accuracy: 0.9292 - val_loss: 0.1877 - val_auc: 0.9773 - val_accuracy: 0.9312\n",
            "Epoch 28/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1887 - auc: 0.9773 - accuracy: 0.9305 - val_loss: 0.1855 - val_auc: 0.9777 - val_accuracy: 0.9321\n",
            "Epoch 29/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1856 - auc: 0.9780 - accuracy: 0.9312 - val_loss: 0.1839 - val_auc: 0.9780 - val_accuracy: 0.9335\n",
            "Epoch 30/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1828 - auc: 0.9786 - accuracy: 0.9330 - val_loss: 0.1805 - val_auc: 0.9788 - val_accuracy: 0.9346\n",
            "Epoch 31/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1797 - auc: 0.9793 - accuracy: 0.9346 - val_loss: 0.1792 - val_auc: 0.9791 - val_accuracy: 0.9347\n",
            "Epoch 32/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1792 - auc: 0.9795 - accuracy: 0.9351 - val_loss: 0.1775 - val_auc: 0.9794 - val_accuracy: 0.9351\n",
            "Epoch 33/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1768 - auc: 0.9799 - accuracy: 0.9362 - val_loss: 0.1752 - val_auc: 0.9799 - val_accuracy: 0.9371\n",
            "Epoch 34/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1738 - auc: 0.9805 - accuracy: 0.9376 - val_loss: 0.1733 - val_auc: 0.9803 - val_accuracy: 0.9380\n",
            "Epoch 35/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1719 - auc: 0.9809 - accuracy: 0.9384 - val_loss: 0.1719 - val_auc: 0.9805 - val_accuracy: 0.9386\n",
            "Epoch 36/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1687 - auc: 0.9815 - accuracy: 0.9393 - val_loss: 0.1702 - val_auc: 0.9809 - val_accuracy: 0.9394\n",
            "Epoch 37/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1685 - auc: 0.9816 - accuracy: 0.9396 - val_loss: 0.1683 - val_auc: 0.9813 - val_accuracy: 0.9398\n",
            "Epoch 38/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1646 - auc: 0.9824 - accuracy: 0.9415 - val_loss: 0.1667 - val_auc: 0.9816 - val_accuracy: 0.9413\n",
            "Epoch 39/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1647 - auc: 0.9823 - accuracy: 0.9414 - val_loss: 0.1655 - val_auc: 0.9818 - val_accuracy: 0.9414\n",
            "Epoch 40/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1621 - auc: 0.9829 - accuracy: 0.9428 - val_loss: 0.1640 - val_auc: 0.9820 - val_accuracy: 0.9420\n",
            "Epoch 41/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1600 - auc: 0.9832 - accuracy: 0.9433 - val_loss: 0.1623 - val_auc: 0.9824 - val_accuracy: 0.9430\n",
            "Epoch 42/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1601 - auc: 0.9832 - accuracy: 0.9438 - val_loss: 0.1615 - val_auc: 0.9825 - val_accuracy: 0.9441\n",
            "Epoch 43/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1565 - auc: 0.9839 - accuracy: 0.9456 - val_loss: 0.1598 - val_auc: 0.9828 - val_accuracy: 0.9449\n",
            "Epoch 44/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1552 - auc: 0.9841 - accuracy: 0.9455 - val_loss: 0.1587 - val_auc: 0.9831 - val_accuracy: 0.9447\n",
            "Epoch 45/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1542 - auc: 0.9842 - accuracy: 0.9465 - val_loss: 0.1573 - val_auc: 0.9832 - val_accuracy: 0.9457\n",
            "Epoch 46/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1532 - auc: 0.9845 - accuracy: 0.9475 - val_loss: 0.1564 - val_auc: 0.9833 - val_accuracy: 0.9463\n",
            "Epoch 47/1000\n",
            "1600/1600 [==============================] - 6s 4ms/step - loss: 0.1521 - auc: 0.9846 - accuracy: 0.9470 - val_loss: 0.1550 - val_auc: 0.9837 - val_accuracy: 0.9470\n",
            "Epoch 48/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1502 - auc: 0.9850 - accuracy: 0.9480 - val_loss: 0.1544 - val_auc: 0.9838 - val_accuracy: 0.9469\n",
            "Epoch 49/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1495 - auc: 0.9851 - accuracy: 0.9486 - val_loss: 0.1533 - val_auc: 0.9840 - val_accuracy: 0.9477\n",
            "Epoch 50/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1474 - auc: 0.9855 - accuracy: 0.9489 - val_loss: 0.1525 - val_auc: 0.9842 - val_accuracy: 0.9474\n",
            "Epoch 51/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1468 - auc: 0.9855 - accuracy: 0.9497 - val_loss: 0.1513 - val_auc: 0.9843 - val_accuracy: 0.9485\n",
            "Epoch 52/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1441 - auc: 0.9860 - accuracy: 0.9506 - val_loss: 0.1500 - val_auc: 0.9846 - val_accuracy: 0.9491\n",
            "Epoch 53/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1440 - auc: 0.9861 - accuracy: 0.9517 - val_loss: 0.1495 - val_auc: 0.9846 - val_accuracy: 0.9490\n",
            "Epoch 54/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1426 - auc: 0.9862 - accuracy: 0.9521 - val_loss: 0.1489 - val_auc: 0.9848 - val_accuracy: 0.9493\n",
            "Epoch 55/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1423 - auc: 0.9864 - accuracy: 0.9516 - val_loss: 0.1481 - val_auc: 0.9848 - val_accuracy: 0.9496\n",
            "Epoch 56/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1406 - auc: 0.9866 - accuracy: 0.9520 - val_loss: 0.1469 - val_auc: 0.9851 - val_accuracy: 0.9505\n",
            "Epoch 57/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1392 - auc: 0.9868 - accuracy: 0.9528 - val_loss: 0.1459 - val_auc: 0.9853 - val_accuracy: 0.9502\n",
            "Epoch 58/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1392 - auc: 0.9868 - accuracy: 0.9528 - val_loss: 0.1451 - val_auc: 0.9854 - val_accuracy: 0.9507\n",
            "Epoch 59/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1376 - auc: 0.9871 - accuracy: 0.9537 - val_loss: 0.1450 - val_auc: 0.9854 - val_accuracy: 0.9504\n",
            "Epoch 60/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1366 - auc: 0.9873 - accuracy: 0.9540 - val_loss: 0.1437 - val_auc: 0.9857 - val_accuracy: 0.9511\n",
            "Epoch 61/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1364 - auc: 0.9873 - accuracy: 0.9536 - val_loss: 0.1433 - val_auc: 0.9857 - val_accuracy: 0.9513\n",
            "Epoch 62/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1350 - auc: 0.9875 - accuracy: 0.9550 - val_loss: 0.1423 - val_auc: 0.9859 - val_accuracy: 0.9516\n",
            "Epoch 63/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1344 - auc: 0.9876 - accuracy: 0.9549 - val_loss: 0.1416 - val_auc: 0.9860 - val_accuracy: 0.9518\n",
            "Epoch 64/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1322 - auc: 0.9878 - accuracy: 0.9558 - val_loss: 0.1415 - val_auc: 0.9861 - val_accuracy: 0.9526\n",
            "Epoch 65/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1319 - auc: 0.9880 - accuracy: 0.9560 - val_loss: 0.1406 - val_auc: 0.9861 - val_accuracy: 0.9529\n",
            "Epoch 66/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1327 - auc: 0.9878 - accuracy: 0.9560 - val_loss: 0.1399 - val_auc: 0.9863 - val_accuracy: 0.9528\n",
            "Epoch 67/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1301 - auc: 0.9882 - accuracy: 0.9562 - val_loss: 0.1391 - val_auc: 0.9863 - val_accuracy: 0.9532\n",
            "Epoch 68/1000\n",
            "1600/1600 [==============================] - 6s 3ms/step - loss: 0.1305 - auc: 0.9882 - accuracy: 0.9571 - val_loss: 0.1393 - val_auc: 0.9863 - val_accuracy: 0.9536\n",
            "Epoch 69/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1290 - auc: 0.9884 - accuracy: 0.9572 - val_loss: 0.1382 - val_auc: 0.9866 - val_accuracy: 0.9538\n",
            "Epoch 70/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1273 - auc: 0.9887 - accuracy: 0.9586 - val_loss: 0.1384 - val_auc: 0.9865 - val_accuracy: 0.9545\n",
            "Epoch 71/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1266 - auc: 0.9888 - accuracy: 0.9583 - val_loss: 0.1372 - val_auc: 0.9867 - val_accuracy: 0.9546\n",
            "Epoch 72/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1268 - auc: 0.9887 - accuracy: 0.9580 - val_loss: 0.1367 - val_auc: 0.9868 - val_accuracy: 0.9555\n",
            "Epoch 73/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1260 - auc: 0.9888 - accuracy: 0.9583 - val_loss: 0.1365 - val_auc: 0.9869 - val_accuracy: 0.9554\n",
            "Epoch 74/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1256 - auc: 0.9889 - accuracy: 0.9589 - val_loss: 0.1362 - val_auc: 0.9868 - val_accuracy: 0.9555\n",
            "Epoch 75/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1252 - auc: 0.9890 - accuracy: 0.9594 - val_loss: 0.1352 - val_auc: 0.9871 - val_accuracy: 0.9555\n",
            "Epoch 76/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1229 - auc: 0.9893 - accuracy: 0.9594 - val_loss: 0.1344 - val_auc: 0.9872 - val_accuracy: 0.9557\n",
            "Epoch 77/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1231 - auc: 0.9892 - accuracy: 0.9595 - val_loss: 0.1345 - val_auc: 0.9870 - val_accuracy: 0.9559\n",
            "Epoch 78/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1227 - auc: 0.9894 - accuracy: 0.9595 - val_loss: 0.1344 - val_auc: 0.9871 - val_accuracy: 0.9557\n",
            "Epoch 79/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1230 - auc: 0.9893 - accuracy: 0.9600 - val_loss: 0.1340 - val_auc: 0.9871 - val_accuracy: 0.9563\n",
            "Epoch 80/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1216 - auc: 0.9895 - accuracy: 0.9607 - val_loss: 0.1332 - val_auc: 0.9873 - val_accuracy: 0.9565\n",
            "Epoch 81/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1208 - auc: 0.9894 - accuracy: 0.9608 - val_loss: 0.1333 - val_auc: 0.9872 - val_accuracy: 0.9564\n",
            "Epoch 82/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1207 - auc: 0.9896 - accuracy: 0.9598 - val_loss: 0.1336 - val_auc: 0.9873 - val_accuracy: 0.9568\n",
            "Epoch 83/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1179 - auc: 0.9900 - accuracy: 0.9619 - val_loss: 0.1326 - val_auc: 0.9874 - val_accuracy: 0.9571\n",
            "Epoch 84/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1185 - auc: 0.9899 - accuracy: 0.9610 - val_loss: 0.1320 - val_auc: 0.9875 - val_accuracy: 0.9571\n",
            "Epoch 85/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1178 - auc: 0.9899 - accuracy: 0.9619 - val_loss: 0.1313 - val_auc: 0.9875 - val_accuracy: 0.9567\n",
            "Epoch 86/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1178 - auc: 0.9899 - accuracy: 0.9622 - val_loss: 0.1316 - val_auc: 0.9875 - val_accuracy: 0.9574\n",
            "Epoch 87/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1175 - auc: 0.9901 - accuracy: 0.9617 - val_loss: 0.1305 - val_auc: 0.9876 - val_accuracy: 0.9575\n",
            "Epoch 88/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1167 - auc: 0.9901 - accuracy: 0.9621 - val_loss: 0.1305 - val_auc: 0.9876 - val_accuracy: 0.9578\n",
            "Epoch 89/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1165 - auc: 0.9901 - accuracy: 0.9617 - val_loss: 0.1308 - val_auc: 0.9876 - val_accuracy: 0.9579\n",
            "Epoch 90/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1159 - auc: 0.9902 - accuracy: 0.9625 - val_loss: 0.1305 - val_auc: 0.9877 - val_accuracy: 0.9579\n",
            "Epoch 91/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1145 - auc: 0.9904 - accuracy: 0.9633 - val_loss: 0.1297 - val_auc: 0.9878 - val_accuracy: 0.9585\n",
            "Epoch 92/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1146 - auc: 0.9904 - accuracy: 0.9629 - val_loss: 0.1306 - val_auc: 0.9876 - val_accuracy: 0.9578\n",
            "Epoch 93/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1141 - auc: 0.9904 - accuracy: 0.9632 - val_loss: 0.1292 - val_auc: 0.9879 - val_accuracy: 0.9581\n",
            "Epoch 94/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1131 - auc: 0.9906 - accuracy: 0.9636 - val_loss: 0.1287 - val_auc: 0.9880 - val_accuracy: 0.9582\n",
            "Epoch 95/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1131 - auc: 0.9905 - accuracy: 0.9640 - val_loss: 0.1285 - val_auc: 0.9880 - val_accuracy: 0.9580\n",
            "Epoch 96/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1126 - auc: 0.9906 - accuracy: 0.9642 - val_loss: 0.1293 - val_auc: 0.9878 - val_accuracy: 0.9586\n",
            "Epoch 97/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1112 - auc: 0.9909 - accuracy: 0.9642 - val_loss: 0.1280 - val_auc: 0.9879 - val_accuracy: 0.9588\n",
            "Epoch 98/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1115 - auc: 0.9909 - accuracy: 0.9638 - val_loss: 0.1290 - val_auc: 0.9878 - val_accuracy: 0.9589\n",
            "Epoch 99/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1118 - auc: 0.9907 - accuracy: 0.9646 - val_loss: 0.1288 - val_auc: 0.9880 - val_accuracy: 0.9587\n",
            "Epoch 100/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1111 - auc: 0.9908 - accuracy: 0.9648 - val_loss: 0.1278 - val_auc: 0.9881 - val_accuracy: 0.9589\n",
            "Epoch 101/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1110 - auc: 0.9910 - accuracy: 0.9643 - val_loss: 0.1280 - val_auc: 0.9879 - val_accuracy: 0.9595\n",
            "Epoch 102/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1109 - auc: 0.9909 - accuracy: 0.9650 - val_loss: 0.1275 - val_auc: 0.9880 - val_accuracy: 0.9589\n",
            "Epoch 103/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1096 - auc: 0.9909 - accuracy: 0.9652 - val_loss: 0.1284 - val_auc: 0.9879 - val_accuracy: 0.9584\n",
            "Epoch 104/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1086 - auc: 0.9912 - accuracy: 0.9655 - val_loss: 0.1279 - val_auc: 0.9881 - val_accuracy: 0.9587\n",
            "Epoch 105/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1101 - auc: 0.9910 - accuracy: 0.9653 - val_loss: 0.1271 - val_auc: 0.9882 - val_accuracy: 0.9591\n",
            "Epoch 106/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1096 - auc: 0.9911 - accuracy: 0.9652 - val_loss: 0.1269 - val_auc: 0.9882 - val_accuracy: 0.9595\n",
            "Epoch 107/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1085 - auc: 0.9912 - accuracy: 0.9651 - val_loss: 0.1276 - val_auc: 0.9881 - val_accuracy: 0.9591\n",
            "Epoch 108/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1082 - auc: 0.9912 - accuracy: 0.9658 - val_loss: 0.1266 - val_auc: 0.9882 - val_accuracy: 0.9599\n",
            "Epoch 109/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1087 - auc: 0.9912 - accuracy: 0.9656 - val_loss: 0.1273 - val_auc: 0.9882 - val_accuracy: 0.9598\n",
            "Epoch 110/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1076 - auc: 0.9913 - accuracy: 0.9660 - val_loss: 0.1268 - val_auc: 0.9883 - val_accuracy: 0.9596\n",
            "Epoch 111/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1081 - auc: 0.9911 - accuracy: 0.9663 - val_loss: 0.1271 - val_auc: 0.9882 - val_accuracy: 0.9595\n",
            "Epoch 112/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1070 - auc: 0.9913 - accuracy: 0.9662 - val_loss: 0.1279 - val_auc: 0.9882 - val_accuracy: 0.9591\n",
            "Epoch 113/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1068 - auc: 0.9914 - accuracy: 0.9654 - val_loss: 0.1277 - val_auc: 0.9881 - val_accuracy: 0.9590\n",
            "Epoch 114/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1056 - auc: 0.9915 - accuracy: 0.9668 - val_loss: 0.1262 - val_auc: 0.9883 - val_accuracy: 0.9594\n",
            "Epoch 115/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1070 - auc: 0.9913 - accuracy: 0.9662 - val_loss: 0.1272 - val_auc: 0.9882 - val_accuracy: 0.9598\n",
            "Epoch 116/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1064 - auc: 0.9914 - accuracy: 0.9661 - val_loss: 0.1264 - val_auc: 0.9883 - val_accuracy: 0.9595\n",
            "Epoch 117/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1053 - auc: 0.9916 - accuracy: 0.9663 - val_loss: 0.1266 - val_auc: 0.9884 - val_accuracy: 0.9601\n",
            "Epoch 118/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1055 - auc: 0.9915 - accuracy: 0.9672 - val_loss: 0.1269 - val_auc: 0.9883 - val_accuracy: 0.9593\n",
            "Epoch 119/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1046 - auc: 0.9917 - accuracy: 0.9673 - val_loss: 0.1258 - val_auc: 0.9883 - val_accuracy: 0.9601\n",
            "Epoch 120/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1046 - auc: 0.9916 - accuracy: 0.9671 - val_loss: 0.1258 - val_auc: 0.9885 - val_accuracy: 0.9600\n",
            "Epoch 121/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1040 - auc: 0.9918 - accuracy: 0.9666 - val_loss: 0.1267 - val_auc: 0.9884 - val_accuracy: 0.9591\n",
            "Epoch 122/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1052 - auc: 0.9915 - accuracy: 0.9672 - val_loss: 0.1257 - val_auc: 0.9884 - val_accuracy: 0.9597\n",
            "Epoch 123/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1039 - auc: 0.9918 - accuracy: 0.9679 - val_loss: 0.1261 - val_auc: 0.9884 - val_accuracy: 0.9598\n",
            "Epoch 124/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1023 - auc: 0.9920 - accuracy: 0.9682 - val_loss: 0.1262 - val_auc: 0.9884 - val_accuracy: 0.9598\n",
            "Epoch 125/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1036 - auc: 0.9918 - accuracy: 0.9679 - val_loss: 0.1255 - val_auc: 0.9885 - val_accuracy: 0.9604\n",
            "Epoch 126/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1031 - auc: 0.9919 - accuracy: 0.9681 - val_loss: 0.1254 - val_auc: 0.9886 - val_accuracy: 0.9605\n",
            "Epoch 127/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1031 - auc: 0.9919 - accuracy: 0.9675 - val_loss: 0.1249 - val_auc: 0.9886 - val_accuracy: 0.9608\n",
            "Epoch 128/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1028 - auc: 0.9918 - accuracy: 0.9680 - val_loss: 0.1254 - val_auc: 0.9885 - val_accuracy: 0.9605\n",
            "Epoch 129/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1029 - auc: 0.9919 - accuracy: 0.9676 - val_loss: 0.1248 - val_auc: 0.9885 - val_accuracy: 0.9600\n",
            "Epoch 130/1000\n",
            "1600/1600 [==============================] - 6s 3ms/step - loss: 0.1029 - auc: 0.9917 - accuracy: 0.9675 - val_loss: 0.1239 - val_auc: 0.9886 - val_accuracy: 0.9603\n",
            "Epoch 131/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1024 - auc: 0.9919 - accuracy: 0.9679 - val_loss: 0.1240 - val_auc: 0.9885 - val_accuracy: 0.9612\n",
            "Epoch 132/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1021 - auc: 0.9920 - accuracy: 0.9685 - val_loss: 0.1248 - val_auc: 0.9886 - val_accuracy: 0.9608\n",
            "Epoch 133/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1025 - auc: 0.9919 - accuracy: 0.9685 - val_loss: 0.1246 - val_auc: 0.9885 - val_accuracy: 0.9610\n",
            "Epoch 134/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1017 - auc: 0.9920 - accuracy: 0.9681 - val_loss: 0.1260 - val_auc: 0.9884 - val_accuracy: 0.9603\n",
            "Epoch 135/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1013 - auc: 0.9921 - accuracy: 0.9687 - val_loss: 0.1254 - val_auc: 0.9884 - val_accuracy: 0.9605\n",
            "Epoch 136/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1016 - auc: 0.9921 - accuracy: 0.9683 - val_loss: 0.1244 - val_auc: 0.9887 - val_accuracy: 0.9610\n",
            "Epoch 137/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1002 - auc: 0.9921 - accuracy: 0.9691 - val_loss: 0.1247 - val_auc: 0.9884 - val_accuracy: 0.9615\n",
            "Epoch 138/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1014 - auc: 0.9920 - accuracy: 0.9684 - val_loss: 0.1246 - val_auc: 0.9886 - val_accuracy: 0.9616\n",
            "Epoch 139/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1001 - auc: 0.9922 - accuracy: 0.9689 - val_loss: 0.1250 - val_auc: 0.9885 - val_accuracy: 0.9614\n",
            "Epoch 140/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1005 - auc: 0.9921 - accuracy: 0.9688 - val_loss: 0.1246 - val_auc: 0.9885 - val_accuracy: 0.9614\n",
            "Epoch 141/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0999 - auc: 0.9922 - accuracy: 0.9687 - val_loss: 0.1247 - val_auc: 0.9886 - val_accuracy: 0.9611\n",
            "Epoch 142/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1001 - auc: 0.9921 - accuracy: 0.9692 - val_loss: 0.1254 - val_auc: 0.9885 - val_accuracy: 0.9620\n",
            "Epoch 143/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0988 - auc: 0.9924 - accuracy: 0.9695 - val_loss: 0.1253 - val_auc: 0.9885 - val_accuracy: 0.9611\n",
            "Epoch 144/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0992 - auc: 0.9923 - accuracy: 0.9693 - val_loss: 0.1245 - val_auc: 0.9885 - val_accuracy: 0.9620\n",
            "Epoch 145/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1002 - auc: 0.9921 - accuracy: 0.9692 - val_loss: 0.1260 - val_auc: 0.9884 - val_accuracy: 0.9616\n",
            "Epoch 146/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0987 - auc: 0.9924 - accuracy: 0.9694 - val_loss: 0.1247 - val_auc: 0.9885 - val_accuracy: 0.9616\n",
            "Epoch 147/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0985 - auc: 0.9923 - accuracy: 0.9693 - val_loss: 0.1257 - val_auc: 0.9883 - val_accuracy: 0.9616\n",
            "Epoch 148/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0986 - auc: 0.9924 - accuracy: 0.9694 - val_loss: 0.1258 - val_auc: 0.9883 - val_accuracy: 0.9607\n",
            "Epoch 149/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0992 - auc: 0.9923 - accuracy: 0.9689 - val_loss: 0.1244 - val_auc: 0.9886 - val_accuracy: 0.9615\n",
            "Epoch 150/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0988 - auc: 0.9923 - accuracy: 0.9692 - val_loss: 0.1239 - val_auc: 0.9886 - val_accuracy: 0.9621\n",
            "1000/1000 [==============================] - 1s 938us/step\n",
            "fold train/predict time: 0:11:18.965090\n",
            "x_train shape: (128000, 67)\n",
            "Epoch 1/1000\n",
            "1600/1600 [==============================] - 6s 3ms/step - loss: 0.6043 - auc: 0.7050 - accuracy: 0.6686 - val_loss: 0.5030 - val_auc: 0.8330 - val_accuracy: 0.7562\n",
            "Epoch 2/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4747 - auc: 0.8488 - accuracy: 0.7769 - val_loss: 0.4101 - val_auc: 0.8953 - val_accuracy: 0.8227\n",
            "Epoch 3/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4011 - auc: 0.8971 - accuracy: 0.8257 - val_loss: 0.3592 - val_auc: 0.9191 - val_accuracy: 0.8495\n",
            "Epoch 4/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3606 - auc: 0.9172 - accuracy: 0.8468 - val_loss: 0.3320 - val_auc: 0.9305 - val_accuracy: 0.8621\n",
            "Epoch 5/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3372 - auc: 0.9282 - accuracy: 0.8597 - val_loss: 0.3152 - val_auc: 0.9371 - val_accuracy: 0.8678\n",
            "Epoch 6/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3217 - auc: 0.9343 - accuracy: 0.8667 - val_loss: 0.3031 - val_auc: 0.9419 - val_accuracy: 0.8723\n",
            "Epoch 7/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3085 - auc: 0.9397 - accuracy: 0.8733 - val_loss: 0.2925 - val_auc: 0.9459 - val_accuracy: 0.8773\n",
            "Epoch 8/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2973 - auc: 0.9442 - accuracy: 0.8779 - val_loss: 0.2834 - val_auc: 0.9491 - val_accuracy: 0.8819\n",
            "Epoch 9/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2880 - auc: 0.9475 - accuracy: 0.8821 - val_loss: 0.2751 - val_auc: 0.9522 - val_accuracy: 0.8862\n",
            "Epoch 10/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2784 - auc: 0.9511 - accuracy: 0.8888 - val_loss: 0.2663 - val_auc: 0.9552 - val_accuracy: 0.8909\n",
            "Epoch 11/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2713 - auc: 0.9536 - accuracy: 0.8913 - val_loss: 0.2585 - val_auc: 0.9580 - val_accuracy: 0.8946\n",
            "Epoch 12/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2628 - auc: 0.9564 - accuracy: 0.8957 - val_loss: 0.2518 - val_auc: 0.9600 - val_accuracy: 0.8980\n",
            "Epoch 13/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2558 - auc: 0.9587 - accuracy: 0.8993 - val_loss: 0.2449 - val_auc: 0.9623 - val_accuracy: 0.9020\n",
            "Epoch 14/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2489 - auc: 0.9609 - accuracy: 0.9013 - val_loss: 0.2388 - val_auc: 0.9640 - val_accuracy: 0.9046\n",
            "Epoch 15/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2436 - auc: 0.9626 - accuracy: 0.9054 - val_loss: 0.2336 - val_auc: 0.9655 - val_accuracy: 0.9069\n",
            "Epoch 16/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2370 - auc: 0.9645 - accuracy: 0.9084 - val_loss: 0.2282 - val_auc: 0.9670 - val_accuracy: 0.9100\n",
            "Epoch 17/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2327 - auc: 0.9658 - accuracy: 0.9100 - val_loss: 0.2236 - val_auc: 0.9684 - val_accuracy: 0.9118\n",
            "Epoch 18/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2280 - auc: 0.9671 - accuracy: 0.9121 - val_loss: 0.2191 - val_auc: 0.9695 - val_accuracy: 0.9144\n",
            "Epoch 19/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2225 - auc: 0.9687 - accuracy: 0.9145 - val_loss: 0.2150 - val_auc: 0.9706 - val_accuracy: 0.9171\n",
            "Epoch 20/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2190 - auc: 0.9696 - accuracy: 0.9162 - val_loss: 0.2120 - val_auc: 0.9714 - val_accuracy: 0.9178\n",
            "Epoch 21/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2151 - auc: 0.9707 - accuracy: 0.9182 - val_loss: 0.2078 - val_auc: 0.9725 - val_accuracy: 0.9204\n",
            "Epoch 22/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2121 - auc: 0.9714 - accuracy: 0.9193 - val_loss: 0.2046 - val_auc: 0.9734 - val_accuracy: 0.9221\n",
            "Epoch 23/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2072 - auc: 0.9727 - accuracy: 0.9215 - val_loss: 0.2012 - val_auc: 0.9741 - val_accuracy: 0.9237\n",
            "Epoch 24/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2034 - auc: 0.9736 - accuracy: 0.9234 - val_loss: 0.1978 - val_auc: 0.9750 - val_accuracy: 0.9247\n",
            "Epoch 25/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2014 - auc: 0.9742 - accuracy: 0.9245 - val_loss: 0.1947 - val_auc: 0.9758 - val_accuracy: 0.9265\n",
            "Epoch 26/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1986 - auc: 0.9748 - accuracy: 0.9257 - val_loss: 0.1919 - val_auc: 0.9765 - val_accuracy: 0.9270\n",
            "Epoch 27/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1959 - auc: 0.9755 - accuracy: 0.9269 - val_loss: 0.1895 - val_auc: 0.9770 - val_accuracy: 0.9288\n",
            "Epoch 28/1000\n",
            "1600/1600 [==============================] - 6s 3ms/step - loss: 0.1933 - auc: 0.9762 - accuracy: 0.9277 - val_loss: 0.1871 - val_auc: 0.9776 - val_accuracy: 0.9298\n",
            "Epoch 29/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1898 - auc: 0.9769 - accuracy: 0.9304 - val_loss: 0.1849 - val_auc: 0.9781 - val_accuracy: 0.9301\n",
            "Epoch 30/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1860 - auc: 0.9777 - accuracy: 0.9315 - val_loss: 0.1827 - val_auc: 0.9786 - val_accuracy: 0.9311\n",
            "Epoch 31/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1843 - auc: 0.9782 - accuracy: 0.9324 - val_loss: 0.1805 - val_auc: 0.9790 - val_accuracy: 0.9335\n",
            "Epoch 32/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1810 - auc: 0.9787 - accuracy: 0.9334 - val_loss: 0.1781 - val_auc: 0.9795 - val_accuracy: 0.9341\n",
            "Epoch 33/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1802 - auc: 0.9790 - accuracy: 0.9343 - val_loss: 0.1766 - val_auc: 0.9798 - val_accuracy: 0.9348\n",
            "Epoch 34/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1770 - auc: 0.9797 - accuracy: 0.9351 - val_loss: 0.1742 - val_auc: 0.9803 - val_accuracy: 0.9350\n",
            "Epoch 35/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1758 - auc: 0.9800 - accuracy: 0.9363 - val_loss: 0.1728 - val_auc: 0.9806 - val_accuracy: 0.9355\n",
            "Epoch 36/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1741 - auc: 0.9802 - accuracy: 0.9370 - val_loss: 0.1704 - val_auc: 0.9811 - val_accuracy: 0.9374\n",
            "Epoch 37/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1711 - auc: 0.9808 - accuracy: 0.9383 - val_loss: 0.1689 - val_auc: 0.9814 - val_accuracy: 0.9382\n",
            "Epoch 38/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1696 - auc: 0.9812 - accuracy: 0.9388 - val_loss: 0.1670 - val_auc: 0.9818 - val_accuracy: 0.9389\n",
            "Epoch 39/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1673 - auc: 0.9816 - accuracy: 0.9406 - val_loss: 0.1654 - val_auc: 0.9821 - val_accuracy: 0.9398\n",
            "Epoch 40/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1661 - auc: 0.9820 - accuracy: 0.9407 - val_loss: 0.1649 - val_auc: 0.9821 - val_accuracy: 0.9409\n",
            "Epoch 41/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1640 - auc: 0.9823 - accuracy: 0.9414 - val_loss: 0.1625 - val_auc: 0.9826 - val_accuracy: 0.9418\n",
            "Epoch 42/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1624 - auc: 0.9826 - accuracy: 0.9424 - val_loss: 0.1608 - val_auc: 0.9829 - val_accuracy: 0.9421\n",
            "Epoch 43/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1601 - auc: 0.9830 - accuracy: 0.9433 - val_loss: 0.1605 - val_auc: 0.9830 - val_accuracy: 0.9426\n",
            "Epoch 44/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1585 - auc: 0.9834 - accuracy: 0.9439 - val_loss: 0.1586 - val_auc: 0.9833 - val_accuracy: 0.9436\n",
            "Epoch 45/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1576 - auc: 0.9834 - accuracy: 0.9442 - val_loss: 0.1574 - val_auc: 0.9835 - val_accuracy: 0.9436\n",
            "Epoch 46/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1554 - auc: 0.9839 - accuracy: 0.9455 - val_loss: 0.1564 - val_auc: 0.9838 - val_accuracy: 0.9452\n",
            "Epoch 47/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1549 - auc: 0.9839 - accuracy: 0.9464 - val_loss: 0.1552 - val_auc: 0.9840 - val_accuracy: 0.9458\n",
            "Epoch 48/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1526 - auc: 0.9844 - accuracy: 0.9466 - val_loss: 0.1538 - val_auc: 0.9842 - val_accuracy: 0.9457\n",
            "Epoch 49/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1513 - auc: 0.9846 - accuracy: 0.9466 - val_loss: 0.1522 - val_auc: 0.9845 - val_accuracy: 0.9470\n",
            "Epoch 50/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1497 - auc: 0.9848 - accuracy: 0.9484 - val_loss: 0.1519 - val_auc: 0.9844 - val_accuracy: 0.9468\n",
            "Epoch 51/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1501 - auc: 0.9847 - accuracy: 0.9480 - val_loss: 0.1509 - val_auc: 0.9846 - val_accuracy: 0.9474\n",
            "Epoch 52/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1480 - auc: 0.9852 - accuracy: 0.9490 - val_loss: 0.1506 - val_auc: 0.9847 - val_accuracy: 0.9484\n",
            "Epoch 53/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1463 - auc: 0.9856 - accuracy: 0.9494 - val_loss: 0.1497 - val_auc: 0.9847 - val_accuracy: 0.9482\n",
            "Epoch 54/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1453 - auc: 0.9858 - accuracy: 0.9499 - val_loss: 0.1484 - val_auc: 0.9850 - val_accuracy: 0.9487\n",
            "Epoch 55/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1438 - auc: 0.9858 - accuracy: 0.9506 - val_loss: 0.1471 - val_auc: 0.9852 - val_accuracy: 0.9502\n",
            "Epoch 56/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1424 - auc: 0.9862 - accuracy: 0.9518 - val_loss: 0.1464 - val_auc: 0.9853 - val_accuracy: 0.9493\n",
            "Epoch 57/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1412 - auc: 0.9863 - accuracy: 0.9520 - val_loss: 0.1453 - val_auc: 0.9855 - val_accuracy: 0.9496\n",
            "Epoch 58/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1406 - auc: 0.9864 - accuracy: 0.9519 - val_loss: 0.1448 - val_auc: 0.9857 - val_accuracy: 0.9495\n",
            "Epoch 59/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1395 - auc: 0.9866 - accuracy: 0.9529 - val_loss: 0.1439 - val_auc: 0.9858 - val_accuracy: 0.9498\n",
            "Epoch 60/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1401 - auc: 0.9864 - accuracy: 0.9523 - val_loss: 0.1430 - val_auc: 0.9859 - val_accuracy: 0.9505\n",
            "Epoch 61/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1377 - auc: 0.9869 - accuracy: 0.9534 - val_loss: 0.1432 - val_auc: 0.9859 - val_accuracy: 0.9508\n",
            "Epoch 62/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1358 - auc: 0.9872 - accuracy: 0.9539 - val_loss: 0.1415 - val_auc: 0.9862 - val_accuracy: 0.9504\n",
            "Epoch 63/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1356 - auc: 0.9873 - accuracy: 0.9542 - val_loss: 0.1409 - val_auc: 0.9863 - val_accuracy: 0.9514\n",
            "Epoch 64/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1350 - auc: 0.9873 - accuracy: 0.9543 - val_loss: 0.1408 - val_auc: 0.9863 - val_accuracy: 0.9516\n",
            "Epoch 65/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1344 - auc: 0.9874 - accuracy: 0.9552 - val_loss: 0.1401 - val_auc: 0.9864 - val_accuracy: 0.9520\n",
            "Epoch 66/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1328 - auc: 0.9875 - accuracy: 0.9550 - val_loss: 0.1393 - val_auc: 0.9867 - val_accuracy: 0.9526\n",
            "Epoch 67/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1323 - auc: 0.9876 - accuracy: 0.9558 - val_loss: 0.1395 - val_auc: 0.9863 - val_accuracy: 0.9525\n",
            "Epoch 68/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1320 - auc: 0.9878 - accuracy: 0.9557 - val_loss: 0.1383 - val_auc: 0.9866 - val_accuracy: 0.9530\n",
            "Epoch 69/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1305 - auc: 0.9880 - accuracy: 0.9569 - val_loss: 0.1375 - val_auc: 0.9868 - val_accuracy: 0.9537\n",
            "Epoch 70/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1302 - auc: 0.9880 - accuracy: 0.9572 - val_loss: 0.1373 - val_auc: 0.9868 - val_accuracy: 0.9538\n",
            "Epoch 71/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1291 - auc: 0.9883 - accuracy: 0.9571 - val_loss: 0.1362 - val_auc: 0.9870 - val_accuracy: 0.9550\n",
            "Epoch 72/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1288 - auc: 0.9882 - accuracy: 0.9577 - val_loss: 0.1360 - val_auc: 0.9871 - val_accuracy: 0.9547\n",
            "Epoch 73/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1279 - auc: 0.9883 - accuracy: 0.9575 - val_loss: 0.1358 - val_auc: 0.9869 - val_accuracy: 0.9545\n",
            "Epoch 74/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1267 - auc: 0.9886 - accuracy: 0.9579 - val_loss: 0.1355 - val_auc: 0.9870 - val_accuracy: 0.9550\n",
            "Epoch 75/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1260 - auc: 0.9887 - accuracy: 0.9582 - val_loss: 0.1352 - val_auc: 0.9870 - val_accuracy: 0.9546\n",
            "Epoch 76/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1243 - auc: 0.9889 - accuracy: 0.9586 - val_loss: 0.1348 - val_auc: 0.9871 - val_accuracy: 0.9550\n",
            "Epoch 77/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1239 - auc: 0.9889 - accuracy: 0.9589 - val_loss: 0.1344 - val_auc: 0.9872 - val_accuracy: 0.9549\n",
            "Epoch 78/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1244 - auc: 0.9888 - accuracy: 0.9588 - val_loss: 0.1340 - val_auc: 0.9872 - val_accuracy: 0.9555\n",
            "Epoch 79/1000\n",
            "1600/1600 [==============================] - 6s 3ms/step - loss: 0.1233 - auc: 0.9889 - accuracy: 0.9599 - val_loss: 0.1338 - val_auc: 0.9873 - val_accuracy: 0.9552\n",
            "Epoch 80/1000\n",
            "1600/1600 [==============================] - 6s 4ms/step - loss: 0.1224 - auc: 0.9891 - accuracy: 0.9595 - val_loss: 0.1333 - val_auc: 0.9873 - val_accuracy: 0.9559\n",
            "Epoch 81/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1229 - auc: 0.9891 - accuracy: 0.9595 - val_loss: 0.1325 - val_auc: 0.9875 - val_accuracy: 0.9562\n",
            "Epoch 82/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1218 - auc: 0.9893 - accuracy: 0.9600 - val_loss: 0.1327 - val_auc: 0.9874 - val_accuracy: 0.9558\n",
            "Epoch 83/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1196 - auc: 0.9896 - accuracy: 0.9607 - val_loss: 0.1322 - val_auc: 0.9875 - val_accuracy: 0.9564\n",
            "Epoch 84/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1212 - auc: 0.9892 - accuracy: 0.9609 - val_loss: 0.1325 - val_auc: 0.9874 - val_accuracy: 0.9557\n",
            "Epoch 85/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1204 - auc: 0.9895 - accuracy: 0.9606 - val_loss: 0.1311 - val_auc: 0.9876 - val_accuracy: 0.9573\n",
            "Epoch 86/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1204 - auc: 0.9894 - accuracy: 0.9614 - val_loss: 0.1308 - val_auc: 0.9877 - val_accuracy: 0.9571\n",
            "Epoch 87/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1195 - auc: 0.9895 - accuracy: 0.9616 - val_loss: 0.1310 - val_auc: 0.9877 - val_accuracy: 0.9575\n",
            "Epoch 88/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1188 - auc: 0.9898 - accuracy: 0.9612 - val_loss: 0.1310 - val_auc: 0.9877 - val_accuracy: 0.9564\n",
            "Epoch 89/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1188 - auc: 0.9897 - accuracy: 0.9616 - val_loss: 0.1302 - val_auc: 0.9877 - val_accuracy: 0.9575\n",
            "Epoch 90/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1181 - auc: 0.9897 - accuracy: 0.9620 - val_loss: 0.1293 - val_auc: 0.9879 - val_accuracy: 0.9580\n",
            "Epoch 91/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1168 - auc: 0.9900 - accuracy: 0.9623 - val_loss: 0.1298 - val_auc: 0.9878 - val_accuracy: 0.9580\n",
            "Epoch 92/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1169 - auc: 0.9900 - accuracy: 0.9619 - val_loss: 0.1293 - val_auc: 0.9879 - val_accuracy: 0.9577\n",
            "Epoch 93/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1159 - auc: 0.9901 - accuracy: 0.9620 - val_loss: 0.1292 - val_auc: 0.9879 - val_accuracy: 0.9584\n",
            "Epoch 94/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1157 - auc: 0.9902 - accuracy: 0.9627 - val_loss: 0.1296 - val_auc: 0.9879 - val_accuracy: 0.9582\n",
            "Epoch 95/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1143 - auc: 0.9903 - accuracy: 0.9632 - val_loss: 0.1283 - val_auc: 0.9880 - val_accuracy: 0.9587\n",
            "Epoch 96/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1142 - auc: 0.9903 - accuracy: 0.9636 - val_loss: 0.1285 - val_auc: 0.9880 - val_accuracy: 0.9582\n",
            "Epoch 97/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1154 - auc: 0.9902 - accuracy: 0.9627 - val_loss: 0.1284 - val_auc: 0.9880 - val_accuracy: 0.9590\n",
            "Epoch 98/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1137 - auc: 0.9903 - accuracy: 0.9634 - val_loss: 0.1279 - val_auc: 0.9881 - val_accuracy: 0.9585\n",
            "Epoch 99/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1135 - auc: 0.9905 - accuracy: 0.9634 - val_loss: 0.1273 - val_auc: 0.9881 - val_accuracy: 0.9586\n",
            "Epoch 100/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1125 - auc: 0.9905 - accuracy: 0.9641 - val_loss: 0.1279 - val_auc: 0.9882 - val_accuracy: 0.9593\n",
            "Epoch 101/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1133 - auc: 0.9904 - accuracy: 0.9634 - val_loss: 0.1278 - val_auc: 0.9881 - val_accuracy: 0.9583\n",
            "Epoch 102/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1117 - auc: 0.9907 - accuracy: 0.9640 - val_loss: 0.1272 - val_auc: 0.9881 - val_accuracy: 0.9589\n",
            "Epoch 103/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1111 - auc: 0.9908 - accuracy: 0.9645 - val_loss: 0.1271 - val_auc: 0.9881 - val_accuracy: 0.9593\n",
            "Epoch 104/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1114 - auc: 0.9906 - accuracy: 0.9641 - val_loss: 0.1276 - val_auc: 0.9880 - val_accuracy: 0.9589\n",
            "Epoch 105/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1112 - auc: 0.9906 - accuracy: 0.9644 - val_loss: 0.1264 - val_auc: 0.9882 - val_accuracy: 0.9594\n",
            "Epoch 106/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1106 - auc: 0.9907 - accuracy: 0.9649 - val_loss: 0.1262 - val_auc: 0.9884 - val_accuracy: 0.9593\n",
            "Epoch 107/1000\n",
            "1600/1600 [==============================] - 6s 4ms/step - loss: 0.1113 - auc: 0.9906 - accuracy: 0.9646 - val_loss: 0.1260 - val_auc: 0.9883 - val_accuracy: 0.9591\n",
            "Epoch 108/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1090 - auc: 0.9909 - accuracy: 0.9658 - val_loss: 0.1263 - val_auc: 0.9883 - val_accuracy: 0.9600\n",
            "Epoch 109/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1085 - auc: 0.9911 - accuracy: 0.9652 - val_loss: 0.1258 - val_auc: 0.9883 - val_accuracy: 0.9593\n",
            "Epoch 110/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1088 - auc: 0.9911 - accuracy: 0.9659 - val_loss: 0.1255 - val_auc: 0.9884 - val_accuracy: 0.9593\n",
            "Epoch 111/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1101 - auc: 0.9908 - accuracy: 0.9652 - val_loss: 0.1258 - val_auc: 0.9882 - val_accuracy: 0.9594\n",
            "Epoch 112/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1083 - auc: 0.9910 - accuracy: 0.9657 - val_loss: 0.1250 - val_auc: 0.9885 - val_accuracy: 0.9604\n",
            "Epoch 113/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1080 - auc: 0.9910 - accuracy: 0.9660 - val_loss: 0.1252 - val_auc: 0.9884 - val_accuracy: 0.9599\n",
            "Epoch 114/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1063 - auc: 0.9912 - accuracy: 0.9668 - val_loss: 0.1248 - val_auc: 0.9885 - val_accuracy: 0.9596\n",
            "Epoch 115/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1082 - auc: 0.9910 - accuracy: 0.9652 - val_loss: 0.1244 - val_auc: 0.9885 - val_accuracy: 0.9600\n",
            "Epoch 116/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1073 - auc: 0.9912 - accuracy: 0.9660 - val_loss: 0.1247 - val_auc: 0.9885 - val_accuracy: 0.9600\n",
            "Epoch 117/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1056 - auc: 0.9914 - accuracy: 0.9671 - val_loss: 0.1246 - val_auc: 0.9884 - val_accuracy: 0.9594\n",
            "Epoch 118/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1062 - auc: 0.9913 - accuracy: 0.9667 - val_loss: 0.1237 - val_auc: 0.9886 - val_accuracy: 0.9604\n",
            "Epoch 119/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1058 - auc: 0.9914 - accuracy: 0.9665 - val_loss: 0.1241 - val_auc: 0.9885 - val_accuracy: 0.9595\n",
            "Epoch 120/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1070 - auc: 0.9912 - accuracy: 0.9661 - val_loss: 0.1239 - val_auc: 0.9885 - val_accuracy: 0.9605\n",
            "Epoch 121/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1049 - auc: 0.9914 - accuracy: 0.9671 - val_loss: 0.1242 - val_auc: 0.9886 - val_accuracy: 0.9596\n",
            "Epoch 122/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1054 - auc: 0.9914 - accuracy: 0.9669 - val_loss: 0.1232 - val_auc: 0.9887 - val_accuracy: 0.9607\n",
            "Epoch 123/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1042 - auc: 0.9916 - accuracy: 0.9672 - val_loss: 0.1234 - val_auc: 0.9886 - val_accuracy: 0.9609\n",
            "Epoch 124/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1042 - auc: 0.9917 - accuracy: 0.9676 - val_loss: 0.1234 - val_auc: 0.9887 - val_accuracy: 0.9605\n",
            "Epoch 125/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1043 - auc: 0.9916 - accuracy: 0.9672 - val_loss: 0.1227 - val_auc: 0.9887 - val_accuracy: 0.9613\n",
            "Epoch 126/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1045 - auc: 0.9915 - accuracy: 0.9670 - val_loss: 0.1222 - val_auc: 0.9888 - val_accuracy: 0.9609\n",
            "Epoch 127/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1049 - auc: 0.9915 - accuracy: 0.9672 - val_loss: 0.1230 - val_auc: 0.9889 - val_accuracy: 0.9609\n",
            "Epoch 128/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1044 - auc: 0.9915 - accuracy: 0.9671 - val_loss: 0.1229 - val_auc: 0.9888 - val_accuracy: 0.9610\n",
            "Epoch 129/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1040 - auc: 0.9916 - accuracy: 0.9673 - val_loss: 0.1225 - val_auc: 0.9887 - val_accuracy: 0.9612\n",
            "Epoch 130/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1029 - auc: 0.9917 - accuracy: 0.9682 - val_loss: 0.1223 - val_auc: 0.9888 - val_accuracy: 0.9612\n",
            "Epoch 131/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1025 - auc: 0.9918 - accuracy: 0.9678 - val_loss: 0.1220 - val_auc: 0.9888 - val_accuracy: 0.9611\n",
            "Epoch 132/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1025 - auc: 0.9918 - accuracy: 0.9680 - val_loss: 0.1228 - val_auc: 0.9887 - val_accuracy: 0.9613\n",
            "Epoch 133/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1017 - auc: 0.9919 - accuracy: 0.9682 - val_loss: 0.1224 - val_auc: 0.9887 - val_accuracy: 0.9613\n",
            "Epoch 134/1000\n",
            "1600/1600 [==============================] - 6s 4ms/step - loss: 0.1020 - auc: 0.9918 - accuracy: 0.9680 - val_loss: 0.1220 - val_auc: 0.9888 - val_accuracy: 0.9616\n",
            "Epoch 135/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1014 - auc: 0.9920 - accuracy: 0.9682 - val_loss: 0.1231 - val_auc: 0.9886 - val_accuracy: 0.9612\n",
            "Epoch 136/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1023 - auc: 0.9919 - accuracy: 0.9678 - val_loss: 0.1225 - val_auc: 0.9888 - val_accuracy: 0.9610\n",
            "Epoch 137/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1019 - auc: 0.9919 - accuracy: 0.9678 - val_loss: 0.1223 - val_auc: 0.9887 - val_accuracy: 0.9611\n",
            "Epoch 138/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1005 - auc: 0.9921 - accuracy: 0.9687 - val_loss: 0.1224 - val_auc: 0.9887 - val_accuracy: 0.9616\n",
            "Epoch 139/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1011 - auc: 0.9920 - accuracy: 0.9684 - val_loss: 0.1231 - val_auc: 0.9886 - val_accuracy: 0.9620\n",
            "Epoch 140/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1016 - auc: 0.9919 - accuracy: 0.9685 - val_loss: 0.1226 - val_auc: 0.9886 - val_accuracy: 0.9616\n",
            "Epoch 141/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1008 - auc: 0.9920 - accuracy: 0.9689 - val_loss: 0.1220 - val_auc: 0.9886 - val_accuracy: 0.9611\n",
            "Epoch 142/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1011 - auc: 0.9919 - accuracy: 0.9689 - val_loss: 0.1219 - val_auc: 0.9887 - val_accuracy: 0.9616\n",
            "Epoch 143/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1003 - auc: 0.9922 - accuracy: 0.9687 - val_loss: 0.1214 - val_auc: 0.9887 - val_accuracy: 0.9617\n",
            "Epoch 144/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0992 - auc: 0.9923 - accuracy: 0.9692 - val_loss: 0.1214 - val_auc: 0.9887 - val_accuracy: 0.9620\n",
            "Epoch 145/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1001 - auc: 0.9920 - accuracy: 0.9688 - val_loss: 0.1218 - val_auc: 0.9888 - val_accuracy: 0.9621\n",
            "Epoch 146/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0997 - auc: 0.9921 - accuracy: 0.9688 - val_loss: 0.1220 - val_auc: 0.9887 - val_accuracy: 0.9614\n",
            "Epoch 147/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0995 - auc: 0.9922 - accuracy: 0.9688 - val_loss: 0.1221 - val_auc: 0.9887 - val_accuracy: 0.9622\n",
            "Epoch 148/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0983 - auc: 0.9924 - accuracy: 0.9696 - val_loss: 0.1221 - val_auc: 0.9887 - val_accuracy: 0.9617\n",
            "Epoch 149/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0975 - auc: 0.9925 - accuracy: 0.9698 - val_loss: 0.1221 - val_auc: 0.9887 - val_accuracy: 0.9621\n",
            "Epoch 150/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0980 - auc: 0.9924 - accuracy: 0.9692 - val_loss: 0.1214 - val_auc: 0.9888 - val_accuracy: 0.9619\n",
            "Epoch 151/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0980 - auc: 0.9924 - accuracy: 0.9694 - val_loss: 0.1215 - val_auc: 0.9889 - val_accuracy: 0.9618\n",
            "Epoch 152/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0977 - auc: 0.9925 - accuracy: 0.9692 - val_loss: 0.1218 - val_auc: 0.9888 - val_accuracy: 0.9620\n",
            "Epoch 153/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0973 - auc: 0.9925 - accuracy: 0.9699 - val_loss: 0.1228 - val_auc: 0.9888 - val_accuracy: 0.9615\n",
            "Epoch 154/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0982 - auc: 0.9923 - accuracy: 0.9693 - val_loss: 0.1209 - val_auc: 0.9886 - val_accuracy: 0.9624\n",
            "Epoch 155/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0977 - auc: 0.9925 - accuracy: 0.9694 - val_loss: 0.1212 - val_auc: 0.9889 - val_accuracy: 0.9620\n",
            "Epoch 156/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0972 - auc: 0.9924 - accuracy: 0.9699 - val_loss: 0.1214 - val_auc: 0.9887 - val_accuracy: 0.9621\n",
            "Epoch 157/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0971 - auc: 0.9924 - accuracy: 0.9693 - val_loss: 0.1212 - val_auc: 0.9889 - val_accuracy: 0.9619\n",
            "Epoch 158/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0976 - auc: 0.9924 - accuracy: 0.9701 - val_loss: 0.1213 - val_auc: 0.9889 - val_accuracy: 0.9623\n",
            "Epoch 159/1000\n",
            "1600/1600 [==============================] - 6s 4ms/step - loss: 0.0969 - auc: 0.9925 - accuracy: 0.9700 - val_loss: 0.1212 - val_auc: 0.9887 - val_accuracy: 0.9620\n",
            "Epoch 160/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0973 - auc: 0.9926 - accuracy: 0.9697 - val_loss: 0.1205 - val_auc: 0.9889 - val_accuracy: 0.9626\n",
            "Epoch 161/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0959 - auc: 0.9927 - accuracy: 0.9707 - val_loss: 0.1207 - val_auc: 0.9889 - val_accuracy: 0.9630\n",
            "Epoch 162/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0947 - auc: 0.9927 - accuracy: 0.9711 - val_loss: 0.1222 - val_auc: 0.9889 - val_accuracy: 0.9625\n",
            "Epoch 163/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0963 - auc: 0.9924 - accuracy: 0.9705 - val_loss: 0.1220 - val_auc: 0.9887 - val_accuracy: 0.9621\n",
            "Epoch 164/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0964 - auc: 0.9924 - accuracy: 0.9705 - val_loss: 0.1218 - val_auc: 0.9886 - val_accuracy: 0.9624\n",
            "Epoch 165/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0960 - auc: 0.9926 - accuracy: 0.9703 - val_loss: 0.1211 - val_auc: 0.9888 - val_accuracy: 0.9630\n",
            "Epoch 166/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0962 - auc: 0.9926 - accuracy: 0.9701 - val_loss: 0.1203 - val_auc: 0.9890 - val_accuracy: 0.9632\n",
            "Epoch 167/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0952 - auc: 0.9927 - accuracy: 0.9704 - val_loss: 0.1205 - val_auc: 0.9889 - val_accuracy: 0.9627\n",
            "Epoch 168/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0953 - auc: 0.9927 - accuracy: 0.9713 - val_loss: 0.1209 - val_auc: 0.9890 - val_accuracy: 0.9634\n",
            "Epoch 169/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0943 - auc: 0.9927 - accuracy: 0.9709 - val_loss: 0.1206 - val_auc: 0.9890 - val_accuracy: 0.9628\n",
            "Epoch 170/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0953 - auc: 0.9927 - accuracy: 0.9709 - val_loss: 0.1204 - val_auc: 0.9888 - val_accuracy: 0.9624\n",
            "Epoch 171/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0936 - auc: 0.9928 - accuracy: 0.9717 - val_loss: 0.1205 - val_auc: 0.9889 - val_accuracy: 0.9626\n",
            "Epoch 172/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0941 - auc: 0.9928 - accuracy: 0.9711 - val_loss: 0.1206 - val_auc: 0.9889 - val_accuracy: 0.9635\n",
            "Epoch 173/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0936 - auc: 0.9929 - accuracy: 0.9714 - val_loss: 0.1211 - val_auc: 0.9889 - val_accuracy: 0.9639\n",
            "Epoch 174/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0939 - auc: 0.9928 - accuracy: 0.9712 - val_loss: 0.1208 - val_auc: 0.9890 - val_accuracy: 0.9631\n",
            "Epoch 175/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0936 - auc: 0.9930 - accuracy: 0.9713 - val_loss: 0.1207 - val_auc: 0.9889 - val_accuracy: 0.9630\n",
            "Epoch 176/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0935 - auc: 0.9928 - accuracy: 0.9711 - val_loss: 0.1202 - val_auc: 0.9888 - val_accuracy: 0.9637\n",
            "Epoch 177/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0923 - auc: 0.9930 - accuracy: 0.9716 - val_loss: 0.1207 - val_auc: 0.9889 - val_accuracy: 0.9638\n",
            "Epoch 178/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0934 - auc: 0.9929 - accuracy: 0.9712 - val_loss: 0.1200 - val_auc: 0.9891 - val_accuracy: 0.9631\n",
            "Epoch 179/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0931 - auc: 0.9929 - accuracy: 0.9713 - val_loss: 0.1212 - val_auc: 0.9890 - val_accuracy: 0.9639\n",
            "Epoch 180/1000\n",
            "1600/1600 [==============================] - 6s 4ms/step - loss: 0.0928 - auc: 0.9930 - accuracy: 0.9715 - val_loss: 0.1200 - val_auc: 0.9889 - val_accuracy: 0.9636\n",
            "Epoch 181/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0928 - auc: 0.9930 - accuracy: 0.9713 - val_loss: 0.1198 - val_auc: 0.9892 - val_accuracy: 0.9638\n",
            "Epoch 182/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0924 - auc: 0.9930 - accuracy: 0.9714 - val_loss: 0.1205 - val_auc: 0.9890 - val_accuracy: 0.9637\n",
            "Epoch 183/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0927 - auc: 0.9929 - accuracy: 0.9721 - val_loss: 0.1205 - val_auc: 0.9890 - val_accuracy: 0.9639\n",
            "Epoch 184/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0923 - auc: 0.9929 - accuracy: 0.9718 - val_loss: 0.1206 - val_auc: 0.9890 - val_accuracy: 0.9640\n",
            "Epoch 185/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0912 - auc: 0.9931 - accuracy: 0.9725 - val_loss: 0.1195 - val_auc: 0.9892 - val_accuracy: 0.9644\n",
            "Epoch 186/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0914 - auc: 0.9931 - accuracy: 0.9717 - val_loss: 0.1204 - val_auc: 0.9891 - val_accuracy: 0.9641\n",
            "Epoch 187/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0916 - auc: 0.9931 - accuracy: 0.9715 - val_loss: 0.1199 - val_auc: 0.9891 - val_accuracy: 0.9645\n",
            "Epoch 188/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0909 - auc: 0.9933 - accuracy: 0.9720 - val_loss: 0.1197 - val_auc: 0.9891 - val_accuracy: 0.9645\n",
            "Epoch 189/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0916 - auc: 0.9931 - accuracy: 0.9722 - val_loss: 0.1213 - val_auc: 0.9890 - val_accuracy: 0.9644\n",
            "Epoch 190/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0909 - auc: 0.9932 - accuracy: 0.9721 - val_loss: 0.1204 - val_auc: 0.9890 - val_accuracy: 0.9642\n",
            "Epoch 191/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0903 - auc: 0.9931 - accuracy: 0.9725 - val_loss: 0.1205 - val_auc: 0.9891 - val_accuracy: 0.9640\n",
            "Epoch 192/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0907 - auc: 0.9931 - accuracy: 0.9722 - val_loss: 0.1202 - val_auc: 0.9891 - val_accuracy: 0.9643\n",
            "Epoch 193/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0910 - auc: 0.9933 - accuracy: 0.9721 - val_loss: 0.1204 - val_auc: 0.9889 - val_accuracy: 0.9643\n",
            "Epoch 194/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0901 - auc: 0.9932 - accuracy: 0.9724 - val_loss: 0.1197 - val_auc: 0.9891 - val_accuracy: 0.9646\n",
            "Epoch 195/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0898 - auc: 0.9933 - accuracy: 0.9724 - val_loss: 0.1200 - val_auc: 0.9890 - val_accuracy: 0.9645\n",
            "Epoch 196/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0902 - auc: 0.9932 - accuracy: 0.9725 - val_loss: 0.1205 - val_auc: 0.9888 - val_accuracy: 0.9641\n",
            "Epoch 197/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0896 - auc: 0.9933 - accuracy: 0.9729 - val_loss: 0.1214 - val_auc: 0.9889 - val_accuracy: 0.9644\n",
            "Epoch 198/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0902 - auc: 0.9932 - accuracy: 0.9722 - val_loss: 0.1195 - val_auc: 0.9891 - val_accuracy: 0.9651\n",
            "Epoch 199/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0887 - auc: 0.9935 - accuracy: 0.9725 - val_loss: 0.1205 - val_auc: 0.9890 - val_accuracy: 0.9639\n",
            "Epoch 200/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0903 - auc: 0.9933 - accuracy: 0.9726 - val_loss: 0.1208 - val_auc: 0.9890 - val_accuracy: 0.9641\n",
            "Epoch 201/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0892 - auc: 0.9934 - accuracy: 0.9725 - val_loss: 0.1204 - val_auc: 0.9890 - val_accuracy: 0.9643\n",
            "Epoch 202/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0886 - auc: 0.9935 - accuracy: 0.9734 - val_loss: 0.1210 - val_auc: 0.9889 - val_accuracy: 0.9638\n",
            "Epoch 203/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0887 - auc: 0.9935 - accuracy: 0.9727 - val_loss: 0.1202 - val_auc: 0.9892 - val_accuracy: 0.9637\n",
            "Epoch 204/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0888 - auc: 0.9935 - accuracy: 0.9732 - val_loss: 0.1206 - val_auc: 0.9889 - val_accuracy: 0.9641\n",
            "Epoch 205/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0887 - auc: 0.9936 - accuracy: 0.9732 - val_loss: 0.1201 - val_auc: 0.9891 - val_accuracy: 0.9645\n",
            "Epoch 206/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0902 - auc: 0.9934 - accuracy: 0.9726 - val_loss: 0.1203 - val_auc: 0.9890 - val_accuracy: 0.9640\n",
            "Epoch 207/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0884 - auc: 0.9934 - accuracy: 0.9730 - val_loss: 0.1198 - val_auc: 0.9891 - val_accuracy: 0.9642\n",
            "Epoch 208/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0880 - auc: 0.9936 - accuracy: 0.9723 - val_loss: 0.1195 - val_auc: 0.9891 - val_accuracy: 0.9646\n",
            "Epoch 209/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0882 - auc: 0.9934 - accuracy: 0.9732 - val_loss: 0.1206 - val_auc: 0.9892 - val_accuracy: 0.9642\n",
            "Epoch 210/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0883 - auc: 0.9934 - accuracy: 0.9733 - val_loss: 0.1199 - val_auc: 0.9892 - val_accuracy: 0.9645\n",
            "Epoch 211/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0877 - auc: 0.9935 - accuracy: 0.9732 - val_loss: 0.1196 - val_auc: 0.9891 - val_accuracy: 0.9643\n",
            "Epoch 212/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0875 - auc: 0.9936 - accuracy: 0.9733 - val_loss: 0.1202 - val_auc: 0.9891 - val_accuracy: 0.9638\n",
            "Epoch 213/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0879 - auc: 0.9935 - accuracy: 0.9736 - val_loss: 0.1208 - val_auc: 0.9889 - val_accuracy: 0.9642\n",
            "Epoch 214/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0877 - auc: 0.9934 - accuracy: 0.9738 - val_loss: 0.1198 - val_auc: 0.9891 - val_accuracy: 0.9649\n",
            "Epoch 215/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0875 - auc: 0.9936 - accuracy: 0.9737 - val_loss: 0.1199 - val_auc: 0.9891 - val_accuracy: 0.9646\n",
            "Epoch 216/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0867 - auc: 0.9936 - accuracy: 0.9742 - val_loss: 0.1195 - val_auc: 0.9892 - val_accuracy: 0.9648\n",
            "Epoch 217/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0872 - auc: 0.9938 - accuracy: 0.9735 - val_loss: 0.1202 - val_auc: 0.9889 - val_accuracy: 0.9639\n",
            "Epoch 218/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0878 - auc: 0.9936 - accuracy: 0.9732 - val_loss: 0.1198 - val_auc: 0.9891 - val_accuracy: 0.9646\n",
            "1000/1000 [==============================] - 1s 928us/step\n",
            "fold train/predict time: 0:16:19.457943\n",
            "x_train shape: (128000, 67)\n",
            "Epoch 1/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.6032 - auc: 0.7064 - accuracy: 0.6647 - val_loss: 0.5093 - val_auc: 0.8248 - val_accuracy: 0.7515\n",
            "Epoch 2/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4797 - auc: 0.8450 - accuracy: 0.7714 - val_loss: 0.4200 - val_auc: 0.8893 - val_accuracy: 0.8143\n",
            "Epoch 3/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4087 - auc: 0.8926 - accuracy: 0.8194 - val_loss: 0.3668 - val_auc: 0.9156 - val_accuracy: 0.8427\n",
            "Epoch 4/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3698 - auc: 0.9131 - accuracy: 0.8434 - val_loss: 0.3396 - val_auc: 0.9273 - val_accuracy: 0.8564\n",
            "Epoch 5/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3451 - auc: 0.9244 - accuracy: 0.8550 - val_loss: 0.3216 - val_auc: 0.9345 - val_accuracy: 0.8642\n",
            "Epoch 6/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3281 - auc: 0.9317 - accuracy: 0.8632 - val_loss: 0.3090 - val_auc: 0.9397 - val_accuracy: 0.8691\n",
            "Epoch 7/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3149 - auc: 0.9372 - accuracy: 0.8699 - val_loss: 0.2985 - val_auc: 0.9437 - val_accuracy: 0.8746\n",
            "Epoch 8/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3050 - auc: 0.9411 - accuracy: 0.8748 - val_loss: 0.2901 - val_auc: 0.9468 - val_accuracy: 0.8782\n",
            "Epoch 9/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2942 - auc: 0.9451 - accuracy: 0.8796 - val_loss: 0.2815 - val_auc: 0.9499 - val_accuracy: 0.8820\n",
            "Epoch 10/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2857 - auc: 0.9482 - accuracy: 0.8843 - val_loss: 0.2740 - val_auc: 0.9525 - val_accuracy: 0.8856\n",
            "Epoch 11/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2781 - auc: 0.9510 - accuracy: 0.8870 - val_loss: 0.2669 - val_auc: 0.9551 - val_accuracy: 0.8891\n",
            "Epoch 12/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2713 - auc: 0.9535 - accuracy: 0.8912 - val_loss: 0.2603 - val_auc: 0.9572 - val_accuracy: 0.8918\n",
            "Epoch 13/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2651 - auc: 0.9557 - accuracy: 0.8951 - val_loss: 0.2537 - val_auc: 0.9594 - val_accuracy: 0.8959\n",
            "Epoch 14/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2572 - auc: 0.9582 - accuracy: 0.8975 - val_loss: 0.2475 - val_auc: 0.9612 - val_accuracy: 0.8994\n",
            "Epoch 15/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2497 - auc: 0.9606 - accuracy: 0.9010 - val_loss: 0.2419 - val_auc: 0.9631 - val_accuracy: 0.9016\n",
            "Epoch 16/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2446 - auc: 0.9622 - accuracy: 0.9034 - val_loss: 0.2366 - val_auc: 0.9646 - val_accuracy: 0.9054\n",
            "Epoch 17/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2388 - auc: 0.9639 - accuracy: 0.9067 - val_loss: 0.2306 - val_auc: 0.9664 - val_accuracy: 0.9079\n",
            "Epoch 18/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2346 - auc: 0.9651 - accuracy: 0.9095 - val_loss: 0.2260 - val_auc: 0.9678 - val_accuracy: 0.9106\n",
            "Epoch 19/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2268 - auc: 0.9674 - accuracy: 0.9129 - val_loss: 0.2209 - val_auc: 0.9691 - val_accuracy: 0.9139\n",
            "Epoch 20/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2223 - auc: 0.9686 - accuracy: 0.9141 - val_loss: 0.2163 - val_auc: 0.9703 - val_accuracy: 0.9162\n",
            "Epoch 21/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2171 - auc: 0.9701 - accuracy: 0.9162 - val_loss: 0.2126 - val_auc: 0.9713 - val_accuracy: 0.9180\n",
            "Epoch 22/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2129 - auc: 0.9712 - accuracy: 0.9194 - val_loss: 0.2084 - val_auc: 0.9725 - val_accuracy: 0.9211\n",
            "Epoch 23/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2090 - auc: 0.9722 - accuracy: 0.9208 - val_loss: 0.2044 - val_auc: 0.9733 - val_accuracy: 0.9221\n",
            "Epoch 24/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2050 - auc: 0.9732 - accuracy: 0.9225 - val_loss: 0.2009 - val_auc: 0.9743 - val_accuracy: 0.9248\n",
            "Epoch 25/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2009 - auc: 0.9744 - accuracy: 0.9243 - val_loss: 0.1970 - val_auc: 0.9752 - val_accuracy: 0.9252\n",
            "Epoch 26/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1960 - auc: 0.9755 - accuracy: 0.9263 - val_loss: 0.1944 - val_auc: 0.9758 - val_accuracy: 0.9271\n",
            "Epoch 27/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1938 - auc: 0.9760 - accuracy: 0.9283 - val_loss: 0.1907 - val_auc: 0.9766 - val_accuracy: 0.9281\n",
            "Epoch 28/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1914 - auc: 0.9766 - accuracy: 0.9285 - val_loss: 0.1886 - val_auc: 0.9772 - val_accuracy: 0.9295\n",
            "Epoch 29/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1880 - auc: 0.9775 - accuracy: 0.9303 - val_loss: 0.1857 - val_auc: 0.9777 - val_accuracy: 0.9308\n",
            "Epoch 30/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1860 - auc: 0.9779 - accuracy: 0.9313 - val_loss: 0.1835 - val_auc: 0.9783 - val_accuracy: 0.9313\n",
            "Epoch 31/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1830 - auc: 0.9785 - accuracy: 0.9326 - val_loss: 0.1815 - val_auc: 0.9787 - val_accuracy: 0.9330\n",
            "Epoch 32/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1812 - auc: 0.9790 - accuracy: 0.9336 - val_loss: 0.1796 - val_auc: 0.9791 - val_accuracy: 0.9330\n",
            "Epoch 33/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1787 - auc: 0.9795 - accuracy: 0.9343 - val_loss: 0.1779 - val_auc: 0.9794 - val_accuracy: 0.9343\n",
            "Epoch 34/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1762 - auc: 0.9800 - accuracy: 0.9357 - val_loss: 0.1759 - val_auc: 0.9799 - val_accuracy: 0.9350\n",
            "Epoch 35/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1748 - auc: 0.9803 - accuracy: 0.9375 - val_loss: 0.1743 - val_auc: 0.9803 - val_accuracy: 0.9364\n",
            "Epoch 36/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1729 - auc: 0.9807 - accuracy: 0.9374 - val_loss: 0.1725 - val_auc: 0.9806 - val_accuracy: 0.9375\n",
            "Epoch 37/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1708 - auc: 0.9811 - accuracy: 0.9382 - val_loss: 0.1711 - val_auc: 0.9809 - val_accuracy: 0.9381\n",
            "Epoch 38/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1706 - auc: 0.9812 - accuracy: 0.9393 - val_loss: 0.1694 - val_auc: 0.9812 - val_accuracy: 0.9386\n",
            "Epoch 39/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1671 - auc: 0.9818 - accuracy: 0.9401 - val_loss: 0.1682 - val_auc: 0.9815 - val_accuracy: 0.9395\n",
            "Epoch 40/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1656 - auc: 0.9822 - accuracy: 0.9408 - val_loss: 0.1670 - val_auc: 0.9817 - val_accuracy: 0.9403\n",
            "Epoch 41/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1639 - auc: 0.9824 - accuracy: 0.9414 - val_loss: 0.1659 - val_auc: 0.9819 - val_accuracy: 0.9404\n",
            "Epoch 42/1000\n",
            "1600/1600 [==============================] - 6s 4ms/step - loss: 0.1632 - auc: 0.9827 - accuracy: 0.9411 - val_loss: 0.1642 - val_auc: 0.9823 - val_accuracy: 0.9415\n",
            "Epoch 43/1000\n",
            "1600/1600 [==============================] - 6s 4ms/step - loss: 0.1608 - auc: 0.9831 - accuracy: 0.9431 - val_loss: 0.1633 - val_auc: 0.9824 - val_accuracy: 0.9416\n",
            "Epoch 44/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1600 - auc: 0.9832 - accuracy: 0.9431 - val_loss: 0.1622 - val_auc: 0.9826 - val_accuracy: 0.9426\n",
            "Epoch 45/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1578 - auc: 0.9837 - accuracy: 0.9439 - val_loss: 0.1610 - val_auc: 0.9829 - val_accuracy: 0.9434\n",
            "Epoch 46/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1579 - auc: 0.9836 - accuracy: 0.9442 - val_loss: 0.1600 - val_auc: 0.9831 - val_accuracy: 0.9431\n",
            "Epoch 47/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1558 - auc: 0.9840 - accuracy: 0.9454 - val_loss: 0.1588 - val_auc: 0.9832 - val_accuracy: 0.9442\n",
            "Epoch 48/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1548 - auc: 0.9842 - accuracy: 0.9462 - val_loss: 0.1584 - val_auc: 0.9834 - val_accuracy: 0.9445\n",
            "Epoch 49/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1528 - auc: 0.9845 - accuracy: 0.9464 - val_loss: 0.1570 - val_auc: 0.9836 - val_accuracy: 0.9453\n",
            "Epoch 50/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1522 - auc: 0.9846 - accuracy: 0.9467 - val_loss: 0.1565 - val_auc: 0.9836 - val_accuracy: 0.9446\n",
            "Epoch 51/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1523 - auc: 0.9846 - accuracy: 0.9467 - val_loss: 0.1554 - val_auc: 0.9838 - val_accuracy: 0.9456\n",
            "Epoch 52/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1504 - auc: 0.9850 - accuracy: 0.9472 - val_loss: 0.1545 - val_auc: 0.9840 - val_accuracy: 0.9464\n",
            "Epoch 53/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1482 - auc: 0.9853 - accuracy: 0.9483 - val_loss: 0.1537 - val_auc: 0.9841 - val_accuracy: 0.9463\n",
            "Epoch 54/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1480 - auc: 0.9854 - accuracy: 0.9482 - val_loss: 0.1532 - val_auc: 0.9841 - val_accuracy: 0.9475\n",
            "Epoch 55/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1467 - auc: 0.9857 - accuracy: 0.9489 - val_loss: 0.1526 - val_auc: 0.9842 - val_accuracy: 0.9479\n",
            "Epoch 56/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1467 - auc: 0.9856 - accuracy: 0.9484 - val_loss: 0.1518 - val_auc: 0.9844 - val_accuracy: 0.9473\n",
            "Epoch 57/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1453 - auc: 0.9859 - accuracy: 0.9496 - val_loss: 0.1516 - val_auc: 0.9844 - val_accuracy: 0.9473\n",
            "Epoch 58/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1452 - auc: 0.9858 - accuracy: 0.9498 - val_loss: 0.1504 - val_auc: 0.9846 - val_accuracy: 0.9489\n",
            "Epoch 59/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1430 - auc: 0.9863 - accuracy: 0.9503 - val_loss: 0.1497 - val_auc: 0.9846 - val_accuracy: 0.9492\n",
            "Epoch 60/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1428 - auc: 0.9863 - accuracy: 0.9503 - val_loss: 0.1491 - val_auc: 0.9848 - val_accuracy: 0.9484\n",
            "Epoch 61/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1417 - auc: 0.9864 - accuracy: 0.9507 - val_loss: 0.1485 - val_auc: 0.9849 - val_accuracy: 0.9498\n",
            "Epoch 62/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1409 - auc: 0.9865 - accuracy: 0.9511 - val_loss: 0.1485 - val_auc: 0.9850 - val_accuracy: 0.9492\n",
            "Epoch 63/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1391 - auc: 0.9869 - accuracy: 0.9524 - val_loss: 0.1477 - val_auc: 0.9850 - val_accuracy: 0.9498\n",
            "Epoch 64/1000\n",
            "1600/1600 [==============================] - 6s 4ms/step - loss: 0.1395 - auc: 0.9868 - accuracy: 0.9519 - val_loss: 0.1467 - val_auc: 0.9853 - val_accuracy: 0.9499\n",
            "Epoch 65/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1381 - auc: 0.9870 - accuracy: 0.9526 - val_loss: 0.1460 - val_auc: 0.9853 - val_accuracy: 0.9502\n",
            "Epoch 66/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1372 - auc: 0.9872 - accuracy: 0.9529 - val_loss: 0.1456 - val_auc: 0.9854 - val_accuracy: 0.9510\n",
            "Epoch 67/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1365 - auc: 0.9872 - accuracy: 0.9535 - val_loss: 0.1452 - val_auc: 0.9854 - val_accuracy: 0.9509\n",
            "Epoch 68/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1357 - auc: 0.9875 - accuracy: 0.9537 - val_loss: 0.1458 - val_auc: 0.9855 - val_accuracy: 0.9506\n",
            "Epoch 69/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1354 - auc: 0.9874 - accuracy: 0.9537 - val_loss: 0.1444 - val_auc: 0.9855 - val_accuracy: 0.9518\n",
            "Epoch 70/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1343 - auc: 0.9876 - accuracy: 0.9543 - val_loss: 0.1436 - val_auc: 0.9857 - val_accuracy: 0.9519\n",
            "Epoch 71/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1335 - auc: 0.9878 - accuracy: 0.9544 - val_loss: 0.1430 - val_auc: 0.9859 - val_accuracy: 0.9519\n",
            "Epoch 72/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1336 - auc: 0.9877 - accuracy: 0.9542 - val_loss: 0.1426 - val_auc: 0.9859 - val_accuracy: 0.9526\n",
            "Epoch 73/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1323 - auc: 0.9879 - accuracy: 0.9553 - val_loss: 0.1420 - val_auc: 0.9860 - val_accuracy: 0.9524\n",
            "Epoch 74/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1309 - auc: 0.9881 - accuracy: 0.9556 - val_loss: 0.1415 - val_auc: 0.9862 - val_accuracy: 0.9528\n",
            "Epoch 75/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1302 - auc: 0.9883 - accuracy: 0.9561 - val_loss: 0.1410 - val_auc: 0.9861 - val_accuracy: 0.9531\n",
            "Epoch 76/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1305 - auc: 0.9882 - accuracy: 0.9560 - val_loss: 0.1401 - val_auc: 0.9862 - val_accuracy: 0.9539\n",
            "Epoch 77/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1294 - auc: 0.9884 - accuracy: 0.9561 - val_loss: 0.1403 - val_auc: 0.9862 - val_accuracy: 0.9536\n",
            "Epoch 78/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1279 - auc: 0.9886 - accuracy: 0.9568 - val_loss: 0.1393 - val_auc: 0.9864 - val_accuracy: 0.9543\n",
            "Epoch 79/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1273 - auc: 0.9886 - accuracy: 0.9576 - val_loss: 0.1390 - val_auc: 0.9864 - val_accuracy: 0.9547\n",
            "Epoch 80/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1278 - auc: 0.9886 - accuracy: 0.9568 - val_loss: 0.1388 - val_auc: 0.9866 - val_accuracy: 0.9538\n",
            "Epoch 81/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1268 - auc: 0.9887 - accuracy: 0.9576 - val_loss: 0.1382 - val_auc: 0.9867 - val_accuracy: 0.9543\n",
            "Epoch 82/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1250 - auc: 0.9890 - accuracy: 0.9575 - val_loss: 0.1379 - val_auc: 0.9867 - val_accuracy: 0.9541\n",
            "Epoch 83/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1251 - auc: 0.9890 - accuracy: 0.9581 - val_loss: 0.1375 - val_auc: 0.9868 - val_accuracy: 0.9548\n",
            "Epoch 84/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1242 - auc: 0.9892 - accuracy: 0.9584 - val_loss: 0.1367 - val_auc: 0.9868 - val_accuracy: 0.9550\n",
            "Epoch 85/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1226 - auc: 0.9894 - accuracy: 0.9591 - val_loss: 0.1359 - val_auc: 0.9870 - val_accuracy: 0.9555\n",
            "Epoch 86/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1228 - auc: 0.9891 - accuracy: 0.9592 - val_loss: 0.1361 - val_auc: 0.9869 - val_accuracy: 0.9564\n",
            "Epoch 87/1000\n",
            "1600/1600 [==============================] - 6s 4ms/step - loss: 0.1229 - auc: 0.9893 - accuracy: 0.9592 - val_loss: 0.1359 - val_auc: 0.9870 - val_accuracy: 0.9563\n",
            "Epoch 88/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1217 - auc: 0.9894 - accuracy: 0.9596 - val_loss: 0.1350 - val_auc: 0.9872 - val_accuracy: 0.9559\n",
            "Epoch 89/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1216 - auc: 0.9894 - accuracy: 0.9598 - val_loss: 0.1356 - val_auc: 0.9872 - val_accuracy: 0.9565\n",
            "Epoch 90/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1210 - auc: 0.9895 - accuracy: 0.9596 - val_loss: 0.1339 - val_auc: 0.9871 - val_accuracy: 0.9566\n",
            "Epoch 91/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1198 - auc: 0.9898 - accuracy: 0.9601 - val_loss: 0.1336 - val_auc: 0.9873 - val_accuracy: 0.9574\n",
            "Epoch 92/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1184 - auc: 0.9899 - accuracy: 0.9609 - val_loss: 0.1342 - val_auc: 0.9871 - val_accuracy: 0.9574\n",
            "Epoch 93/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1192 - auc: 0.9897 - accuracy: 0.9605 - val_loss: 0.1332 - val_auc: 0.9874 - val_accuracy: 0.9574\n",
            "Epoch 94/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1182 - auc: 0.9899 - accuracy: 0.9607 - val_loss: 0.1337 - val_auc: 0.9874 - val_accuracy: 0.9569\n",
            "Epoch 95/1000\n",
            "1600/1600 [==============================] - 6s 4ms/step - loss: 0.1186 - auc: 0.9898 - accuracy: 0.9608 - val_loss: 0.1324 - val_auc: 0.9876 - val_accuracy: 0.9577\n",
            "Epoch 96/1000\n",
            "1600/1600 [==============================] - 6s 4ms/step - loss: 0.1164 - auc: 0.9902 - accuracy: 0.9614 - val_loss: 0.1322 - val_auc: 0.9873 - val_accuracy: 0.9575\n",
            "Epoch 97/1000\n",
            "1600/1600 [==============================] - 6s 4ms/step - loss: 0.1161 - auc: 0.9903 - accuracy: 0.9619 - val_loss: 0.1317 - val_auc: 0.9875 - val_accuracy: 0.9576\n",
            "Epoch 98/1000\n",
            "1600/1600 [==============================] - 6s 4ms/step - loss: 0.1159 - auc: 0.9902 - accuracy: 0.9618 - val_loss: 0.1318 - val_auc: 0.9875 - val_accuracy: 0.9577\n",
            "Epoch 99/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1143 - auc: 0.9904 - accuracy: 0.9621 - val_loss: 0.1314 - val_auc: 0.9876 - val_accuracy: 0.9582\n",
            "Epoch 100/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1147 - auc: 0.9904 - accuracy: 0.9622 - val_loss: 0.1307 - val_auc: 0.9876 - val_accuracy: 0.9579\n",
            "Epoch 101/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1152 - auc: 0.9904 - accuracy: 0.9626 - val_loss: 0.1310 - val_auc: 0.9877 - val_accuracy: 0.9577\n",
            "Epoch 102/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1135 - auc: 0.9905 - accuracy: 0.9630 - val_loss: 0.1303 - val_auc: 0.9878 - val_accuracy: 0.9580\n",
            "Epoch 103/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1139 - auc: 0.9904 - accuracy: 0.9632 - val_loss: 0.1300 - val_auc: 0.9879 - val_accuracy: 0.9581\n",
            "Epoch 104/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1122 - auc: 0.9907 - accuracy: 0.9635 - val_loss: 0.1293 - val_auc: 0.9878 - val_accuracy: 0.9584\n",
            "Epoch 105/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1126 - auc: 0.9906 - accuracy: 0.9635 - val_loss: 0.1288 - val_auc: 0.9880 - val_accuracy: 0.9582\n",
            "Epoch 106/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1114 - auc: 0.9908 - accuracy: 0.9636 - val_loss: 0.1286 - val_auc: 0.9880 - val_accuracy: 0.9586\n",
            "Epoch 107/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1115 - auc: 0.9909 - accuracy: 0.9637 - val_loss: 0.1286 - val_auc: 0.9880 - val_accuracy: 0.9591\n",
            "Epoch 108/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1109 - auc: 0.9909 - accuracy: 0.9637 - val_loss: 0.1290 - val_auc: 0.9880 - val_accuracy: 0.9591\n",
            "Epoch 109/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1102 - auc: 0.9909 - accuracy: 0.9637 - val_loss: 0.1276 - val_auc: 0.9882 - val_accuracy: 0.9587\n",
            "Epoch 110/1000\n",
            "1600/1600 [==============================] - 6s 4ms/step - loss: 0.1100 - auc: 0.9908 - accuracy: 0.9642 - val_loss: 0.1277 - val_auc: 0.9882 - val_accuracy: 0.9595\n",
            "Epoch 111/1000\n",
            "1600/1600 [==============================] - 6s 4ms/step - loss: 0.1096 - auc: 0.9910 - accuracy: 0.9645 - val_loss: 0.1280 - val_auc: 0.9883 - val_accuracy: 0.9591\n",
            "Epoch 112/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1084 - auc: 0.9912 - accuracy: 0.9645 - val_loss: 0.1267 - val_auc: 0.9883 - val_accuracy: 0.9599\n",
            "Epoch 113/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1088 - auc: 0.9911 - accuracy: 0.9649 - val_loss: 0.1266 - val_auc: 0.9884 - val_accuracy: 0.9594\n",
            "Epoch 114/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1083 - auc: 0.9911 - accuracy: 0.9651 - val_loss: 0.1266 - val_auc: 0.9881 - val_accuracy: 0.9598\n",
            "Epoch 115/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1062 - auc: 0.9914 - accuracy: 0.9659 - val_loss: 0.1257 - val_auc: 0.9885 - val_accuracy: 0.9605\n",
            "Epoch 116/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1077 - auc: 0.9911 - accuracy: 0.9657 - val_loss: 0.1250 - val_auc: 0.9884 - val_accuracy: 0.9609\n",
            "Epoch 117/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1072 - auc: 0.9913 - accuracy: 0.9657 - val_loss: 0.1250 - val_auc: 0.9886 - val_accuracy: 0.9605\n",
            "Epoch 118/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1058 - auc: 0.9915 - accuracy: 0.9660 - val_loss: 0.1245 - val_auc: 0.9886 - val_accuracy: 0.9607\n",
            "Epoch 119/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1056 - auc: 0.9915 - accuracy: 0.9659 - val_loss: 0.1252 - val_auc: 0.9885 - val_accuracy: 0.9604\n",
            "Epoch 120/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1054 - auc: 0.9915 - accuracy: 0.9662 - val_loss: 0.1244 - val_auc: 0.9887 - val_accuracy: 0.9605\n",
            "Epoch 121/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1048 - auc: 0.9915 - accuracy: 0.9663 - val_loss: 0.1238 - val_auc: 0.9886 - val_accuracy: 0.9609\n",
            "Epoch 122/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1048 - auc: 0.9917 - accuracy: 0.9666 - val_loss: 0.1241 - val_auc: 0.9887 - val_accuracy: 0.9613\n",
            "Epoch 123/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1025 - auc: 0.9919 - accuracy: 0.9674 - val_loss: 0.1234 - val_auc: 0.9887 - val_accuracy: 0.9615\n",
            "Epoch 124/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1044 - auc: 0.9916 - accuracy: 0.9670 - val_loss: 0.1239 - val_auc: 0.9888 - val_accuracy: 0.9614\n",
            "Epoch 125/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1024 - auc: 0.9919 - accuracy: 0.9679 - val_loss: 0.1232 - val_auc: 0.9890 - val_accuracy: 0.9621\n",
            "Epoch 126/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1034 - auc: 0.9917 - accuracy: 0.9665 - val_loss: 0.1229 - val_auc: 0.9888 - val_accuracy: 0.9619\n",
            "Epoch 127/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1020 - auc: 0.9918 - accuracy: 0.9673 - val_loss: 0.1221 - val_auc: 0.9889 - val_accuracy: 0.9616\n",
            "Epoch 128/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1025 - auc: 0.9918 - accuracy: 0.9679 - val_loss: 0.1222 - val_auc: 0.9890 - val_accuracy: 0.9616\n",
            "Epoch 129/1000\n",
            "1600/1600 [==============================] - 6s 4ms/step - loss: 0.1020 - auc: 0.9919 - accuracy: 0.9680 - val_loss: 0.1230 - val_auc: 0.9889 - val_accuracy: 0.9619\n",
            "Epoch 130/1000\n",
            "1600/1600 [==============================] - 6s 4ms/step - loss: 0.1022 - auc: 0.9918 - accuracy: 0.9676 - val_loss: 0.1220 - val_auc: 0.9890 - val_accuracy: 0.9621\n",
            "Epoch 131/1000\n",
            "1600/1600 [==============================] - 6s 4ms/step - loss: 0.1025 - auc: 0.9918 - accuracy: 0.9677 - val_loss: 0.1219 - val_auc: 0.9890 - val_accuracy: 0.9625\n",
            "Epoch 132/1000\n",
            "1600/1600 [==============================] - 6s 4ms/step - loss: 0.1014 - auc: 0.9920 - accuracy: 0.9676 - val_loss: 0.1215 - val_auc: 0.9890 - val_accuracy: 0.9625\n",
            "Epoch 133/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.1001 - auc: 0.9921 - accuracy: 0.9685 - val_loss: 0.1208 - val_auc: 0.9891 - val_accuracy: 0.9633\n",
            "Epoch 134/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1002 - auc: 0.9920 - accuracy: 0.9686 - val_loss: 0.1213 - val_auc: 0.9891 - val_accuracy: 0.9626\n",
            "Epoch 135/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0997 - auc: 0.9922 - accuracy: 0.9676 - val_loss: 0.1212 - val_auc: 0.9891 - val_accuracy: 0.9627\n",
            "Epoch 136/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0995 - auc: 0.9922 - accuracy: 0.9689 - val_loss: 0.1201 - val_auc: 0.9892 - val_accuracy: 0.9629\n",
            "Epoch 137/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0985 - auc: 0.9924 - accuracy: 0.9683 - val_loss: 0.1209 - val_auc: 0.9892 - val_accuracy: 0.9627\n",
            "Epoch 138/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.1000 - auc: 0.9922 - accuracy: 0.9686 - val_loss: 0.1212 - val_auc: 0.9893 - val_accuracy: 0.9630\n",
            "Epoch 139/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0983 - auc: 0.9923 - accuracy: 0.9687 - val_loss: 0.1204 - val_auc: 0.9892 - val_accuracy: 0.9626\n",
            "Epoch 140/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0991 - auc: 0.9923 - accuracy: 0.9690 - val_loss: 0.1208 - val_auc: 0.9892 - val_accuracy: 0.9629\n",
            "Epoch 141/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0978 - auc: 0.9923 - accuracy: 0.9696 - val_loss: 0.1196 - val_auc: 0.9893 - val_accuracy: 0.9631\n",
            "Epoch 142/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0977 - auc: 0.9924 - accuracy: 0.9698 - val_loss: 0.1193 - val_auc: 0.9893 - val_accuracy: 0.9632\n",
            "Epoch 143/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0973 - auc: 0.9924 - accuracy: 0.9696 - val_loss: 0.1193 - val_auc: 0.9895 - val_accuracy: 0.9639\n",
            "Epoch 144/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0969 - auc: 0.9924 - accuracy: 0.9698 - val_loss: 0.1195 - val_auc: 0.9896 - val_accuracy: 0.9632\n",
            "Epoch 145/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0971 - auc: 0.9925 - accuracy: 0.9694 - val_loss: 0.1181 - val_auc: 0.9895 - val_accuracy: 0.9636\n",
            "Epoch 146/1000\n",
            "1600/1600 [==============================] - 6s 4ms/step - loss: 0.0964 - auc: 0.9926 - accuracy: 0.9701 - val_loss: 0.1180 - val_auc: 0.9895 - val_accuracy: 0.9635\n",
            "Epoch 147/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0962 - auc: 0.9925 - accuracy: 0.9701 - val_loss: 0.1189 - val_auc: 0.9893 - val_accuracy: 0.9635\n",
            "Epoch 148/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0966 - auc: 0.9925 - accuracy: 0.9699 - val_loss: 0.1176 - val_auc: 0.9894 - val_accuracy: 0.9642\n",
            "Epoch 149/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0958 - auc: 0.9925 - accuracy: 0.9700 - val_loss: 0.1186 - val_auc: 0.9893 - val_accuracy: 0.9630\n",
            "Epoch 150/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0958 - auc: 0.9926 - accuracy: 0.9704 - val_loss: 0.1177 - val_auc: 0.9894 - val_accuracy: 0.9642\n",
            "Epoch 151/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0961 - auc: 0.9927 - accuracy: 0.9700 - val_loss: 0.1183 - val_auc: 0.9895 - val_accuracy: 0.9636\n",
            "Epoch 152/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0948 - auc: 0.9927 - accuracy: 0.9709 - val_loss: 0.1178 - val_auc: 0.9896 - val_accuracy: 0.9643\n",
            "Epoch 153/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0946 - auc: 0.9927 - accuracy: 0.9709 - val_loss: 0.1172 - val_auc: 0.9896 - val_accuracy: 0.9636\n",
            "Epoch 154/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0941 - auc: 0.9928 - accuracy: 0.9713 - val_loss: 0.1176 - val_auc: 0.9895 - val_accuracy: 0.9639\n",
            "Epoch 155/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0941 - auc: 0.9929 - accuracy: 0.9706 - val_loss: 0.1175 - val_auc: 0.9896 - val_accuracy: 0.9641\n",
            "Epoch 156/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0933 - auc: 0.9931 - accuracy: 0.9709 - val_loss: 0.1178 - val_auc: 0.9895 - val_accuracy: 0.9643\n",
            "Epoch 157/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0933 - auc: 0.9929 - accuracy: 0.9714 - val_loss: 0.1171 - val_auc: 0.9895 - val_accuracy: 0.9645\n",
            "Epoch 158/1000\n",
            "1600/1600 [==============================] - 7s 4ms/step - loss: 0.0942 - auc: 0.9928 - accuracy: 0.9712 - val_loss: 0.1167 - val_auc: 0.9895 - val_accuracy: 0.9650\n",
            "Epoch 159/1000\n",
            "1600/1600 [==============================] - 6s 4ms/step - loss: 0.0935 - auc: 0.9928 - accuracy: 0.9715 - val_loss: 0.1173 - val_auc: 0.9895 - val_accuracy: 0.9653\n",
            "Epoch 160/1000\n",
            "1600/1600 [==============================] - 6s 4ms/step - loss: 0.0921 - auc: 0.9930 - accuracy: 0.9719 - val_loss: 0.1169 - val_auc: 0.9898 - val_accuracy: 0.9643\n",
            "Epoch 161/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0917 - auc: 0.9932 - accuracy: 0.9715 - val_loss: 0.1163 - val_auc: 0.9897 - val_accuracy: 0.9651\n",
            "Epoch 162/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0937 - auc: 0.9929 - accuracy: 0.9713 - val_loss: 0.1161 - val_auc: 0.9897 - val_accuracy: 0.9649\n",
            "Epoch 163/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0923 - auc: 0.9930 - accuracy: 0.9717 - val_loss: 0.1154 - val_auc: 0.9897 - val_accuracy: 0.9654\n",
            "Epoch 164/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0931 - auc: 0.9928 - accuracy: 0.9716 - val_loss: 0.1162 - val_auc: 0.9898 - val_accuracy: 0.9648\n",
            "Epoch 165/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0925 - auc: 0.9930 - accuracy: 0.9714 - val_loss: 0.1165 - val_auc: 0.9897 - val_accuracy: 0.9652\n",
            "Epoch 166/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0911 - auc: 0.9931 - accuracy: 0.9721 - val_loss: 0.1157 - val_auc: 0.9898 - val_accuracy: 0.9652\n",
            "Epoch 167/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0919 - auc: 0.9930 - accuracy: 0.9719 - val_loss: 0.1162 - val_auc: 0.9898 - val_accuracy: 0.9653\n",
            "Epoch 168/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0912 - auc: 0.9932 - accuracy: 0.9721 - val_loss: 0.1160 - val_auc: 0.9898 - val_accuracy: 0.9650\n",
            "Epoch 169/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0906 - auc: 0.9932 - accuracy: 0.9725 - val_loss: 0.1160 - val_auc: 0.9898 - val_accuracy: 0.9655\n",
            "Epoch 170/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0907 - auc: 0.9930 - accuracy: 0.9728 - val_loss: 0.1158 - val_auc: 0.9897 - val_accuracy: 0.9651\n",
            "Epoch 171/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0899 - auc: 0.9932 - accuracy: 0.9727 - val_loss: 0.1162 - val_auc: 0.9898 - val_accuracy: 0.9649\n",
            "Epoch 172/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0914 - auc: 0.9931 - accuracy: 0.9719 - val_loss: 0.1157 - val_auc: 0.9897 - val_accuracy: 0.9651\n",
            "Epoch 173/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0895 - auc: 0.9933 - accuracy: 0.9728 - val_loss: 0.1154 - val_auc: 0.9898 - val_accuracy: 0.9656\n",
            "Epoch 174/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0914 - auc: 0.9931 - accuracy: 0.9717 - val_loss: 0.1158 - val_auc: 0.9898 - val_accuracy: 0.9656\n",
            "Epoch 175/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0895 - auc: 0.9932 - accuracy: 0.9729 - val_loss: 0.1159 - val_auc: 0.9898 - val_accuracy: 0.9657\n",
            "Epoch 176/1000\n",
            "1600/1600 [==============================] - 6s 4ms/step - loss: 0.0886 - auc: 0.9935 - accuracy: 0.9725 - val_loss: 0.1157 - val_auc: 0.9897 - val_accuracy: 0.9652\n",
            "Epoch 177/1000\n",
            "1600/1600 [==============================] - 6s 4ms/step - loss: 0.0903 - auc: 0.9932 - accuracy: 0.9722 - val_loss: 0.1150 - val_auc: 0.9898 - val_accuracy: 0.9658\n",
            "Epoch 178/1000\n",
            "1600/1600 [==============================] - 6s 4ms/step - loss: 0.0897 - auc: 0.9934 - accuracy: 0.9725 - val_loss: 0.1158 - val_auc: 0.9899 - val_accuracy: 0.9653\n",
            "Epoch 179/1000\n",
            "1600/1600 [==============================] - 6s 4ms/step - loss: 0.0882 - auc: 0.9935 - accuracy: 0.9728 - val_loss: 0.1153 - val_auc: 0.9897 - val_accuracy: 0.9652\n",
            "Epoch 180/1000\n",
            "1600/1600 [==============================] - 6s 3ms/step - loss: 0.0884 - auc: 0.9935 - accuracy: 0.9729 - val_loss: 0.1153 - val_auc: 0.9896 - val_accuracy: 0.9654\n",
            "Epoch 181/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0898 - auc: 0.9932 - accuracy: 0.9725 - val_loss: 0.1156 - val_auc: 0.9899 - val_accuracy: 0.9657\n",
            "Epoch 182/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0883 - auc: 0.9935 - accuracy: 0.9728 - val_loss: 0.1162 - val_auc: 0.9897 - val_accuracy: 0.9654\n",
            "Epoch 183/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0894 - auc: 0.9933 - accuracy: 0.9730 - val_loss: 0.1154 - val_auc: 0.9896 - val_accuracy: 0.9658\n",
            "Epoch 184/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0870 - auc: 0.9936 - accuracy: 0.9735 - val_loss: 0.1151 - val_auc: 0.9898 - val_accuracy: 0.9660\n",
            "Epoch 185/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0879 - auc: 0.9935 - accuracy: 0.9735 - val_loss: 0.1147 - val_auc: 0.9898 - val_accuracy: 0.9657\n",
            "Epoch 186/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0885 - auc: 0.9934 - accuracy: 0.9731 - val_loss: 0.1154 - val_auc: 0.9898 - val_accuracy: 0.9659\n",
            "Epoch 187/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0891 - auc: 0.9934 - accuracy: 0.9729 - val_loss: 0.1144 - val_auc: 0.9898 - val_accuracy: 0.9657\n",
            "Epoch 188/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0878 - auc: 0.9935 - accuracy: 0.9731 - val_loss: 0.1143 - val_auc: 0.9897 - val_accuracy: 0.9659\n",
            "Epoch 189/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0878 - auc: 0.9935 - accuracy: 0.9735 - val_loss: 0.1143 - val_auc: 0.9898 - val_accuracy: 0.9664\n",
            "Epoch 190/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0872 - auc: 0.9936 - accuracy: 0.9736 - val_loss: 0.1148 - val_auc: 0.9897 - val_accuracy: 0.9662\n",
            "Epoch 191/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0855 - auc: 0.9938 - accuracy: 0.9740 - val_loss: 0.1154 - val_auc: 0.9897 - val_accuracy: 0.9655\n",
            "Epoch 192/1000\n",
            "1600/1600 [==============================] - 6s 4ms/step - loss: 0.0879 - auc: 0.9935 - accuracy: 0.9731 - val_loss: 0.1158 - val_auc: 0.9898 - val_accuracy: 0.9657\n",
            "Epoch 193/1000\n",
            "1600/1600 [==============================] - 6s 3ms/step - loss: 0.0862 - auc: 0.9937 - accuracy: 0.9740 - val_loss: 0.1137 - val_auc: 0.9899 - val_accuracy: 0.9659\n",
            "Epoch 194/1000\n",
            "1600/1600 [==============================] - 6s 4ms/step - loss: 0.0868 - auc: 0.9936 - accuracy: 0.9737 - val_loss: 0.1142 - val_auc: 0.9898 - val_accuracy: 0.9662\n",
            "Epoch 195/1000\n",
            "1600/1600 [==============================] - 6s 3ms/step - loss: 0.0850 - auc: 0.9938 - accuracy: 0.9747 - val_loss: 0.1149 - val_auc: 0.9898 - val_accuracy: 0.9660\n",
            "Epoch 196/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0862 - auc: 0.9935 - accuracy: 0.9730 - val_loss: 0.1141 - val_auc: 0.9898 - val_accuracy: 0.9661\n",
            "Epoch 197/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0874 - auc: 0.9935 - accuracy: 0.9736 - val_loss: 0.1142 - val_auc: 0.9898 - val_accuracy: 0.9656\n",
            "Epoch 198/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0859 - auc: 0.9938 - accuracy: 0.9740 - val_loss: 0.1145 - val_auc: 0.9898 - val_accuracy: 0.9660\n",
            "Epoch 199/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0856 - auc: 0.9937 - accuracy: 0.9744 - val_loss: 0.1139 - val_auc: 0.9898 - val_accuracy: 0.9661\n",
            "Epoch 200/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0856 - auc: 0.9937 - accuracy: 0.9742 - val_loss: 0.1145 - val_auc: 0.9897 - val_accuracy: 0.9660\n",
            "Epoch 201/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0854 - auc: 0.9937 - accuracy: 0.9741 - val_loss: 0.1134 - val_auc: 0.9899 - val_accuracy: 0.9664\n",
            "Epoch 202/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0851 - auc: 0.9939 - accuracy: 0.9745 - val_loss: 0.1144 - val_auc: 0.9898 - val_accuracy: 0.9659\n",
            "Epoch 203/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0858 - auc: 0.9937 - accuracy: 0.9744 - val_loss: 0.1137 - val_auc: 0.9899 - val_accuracy: 0.9656\n",
            "Epoch 204/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0845 - auc: 0.9938 - accuracy: 0.9749 - val_loss: 0.1141 - val_auc: 0.9898 - val_accuracy: 0.9667\n",
            "Epoch 205/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0856 - auc: 0.9937 - accuracy: 0.9741 - val_loss: 0.1140 - val_auc: 0.9897 - val_accuracy: 0.9664\n",
            "Epoch 206/1000\n",
            "1600/1600 [==============================] - 6s 4ms/step - loss: 0.0839 - auc: 0.9939 - accuracy: 0.9746 - val_loss: 0.1135 - val_auc: 0.9898 - val_accuracy: 0.9668\n",
            "Epoch 207/1000\n",
            "1600/1600 [==============================] - 6s 4ms/step - loss: 0.0846 - auc: 0.9939 - accuracy: 0.9745 - val_loss: 0.1145 - val_auc: 0.9899 - val_accuracy: 0.9671\n",
            "Epoch 208/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0849 - auc: 0.9938 - accuracy: 0.9744 - val_loss: 0.1133 - val_auc: 0.9899 - val_accuracy: 0.9671\n",
            "Epoch 209/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0831 - auc: 0.9941 - accuracy: 0.9748 - val_loss: 0.1137 - val_auc: 0.9899 - val_accuracy: 0.9664\n",
            "Epoch 210/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0840 - auc: 0.9939 - accuracy: 0.9750 - val_loss: 0.1138 - val_auc: 0.9898 - val_accuracy: 0.9664\n",
            "Epoch 211/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0843 - auc: 0.9938 - accuracy: 0.9746 - val_loss: 0.1131 - val_auc: 0.9899 - val_accuracy: 0.9667\n",
            "Epoch 212/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0838 - auc: 0.9939 - accuracy: 0.9746 - val_loss: 0.1133 - val_auc: 0.9898 - val_accuracy: 0.9672\n",
            "Epoch 213/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0837 - auc: 0.9940 - accuracy: 0.9753 - val_loss: 0.1134 - val_auc: 0.9900 - val_accuracy: 0.9666\n",
            "Epoch 214/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0834 - auc: 0.9940 - accuracy: 0.9749 - val_loss: 0.1140 - val_auc: 0.9896 - val_accuracy: 0.9664\n",
            "Epoch 215/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0844 - auc: 0.9938 - accuracy: 0.9750 - val_loss: 0.1132 - val_auc: 0.9899 - val_accuracy: 0.9664\n",
            "Epoch 216/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0839 - auc: 0.9940 - accuracy: 0.9743 - val_loss: 0.1139 - val_auc: 0.9897 - val_accuracy: 0.9661\n",
            "Epoch 217/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0830 - auc: 0.9941 - accuracy: 0.9753 - val_loss: 0.1138 - val_auc: 0.9900 - val_accuracy: 0.9666\n",
            "Epoch 218/1000\n",
            "1600/1600 [==============================] - 6s 4ms/step - loss: 0.0825 - auc: 0.9942 - accuracy: 0.9750 - val_loss: 0.1140 - val_auc: 0.9898 - val_accuracy: 0.9662\n",
            "Epoch 219/1000\n",
            "1600/1600 [==============================] - 6s 4ms/step - loss: 0.0831 - auc: 0.9940 - accuracy: 0.9753 - val_loss: 0.1141 - val_auc: 0.9899 - val_accuracy: 0.9663\n",
            "Epoch 220/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0834 - auc: 0.9938 - accuracy: 0.9754 - val_loss: 0.1146 - val_auc: 0.9897 - val_accuracy: 0.9661\n",
            "Epoch 221/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0830 - auc: 0.9941 - accuracy: 0.9750 - val_loss: 0.1144 - val_auc: 0.9899 - val_accuracy: 0.9664\n",
            "Epoch 222/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0833 - auc: 0.9939 - accuracy: 0.9748 - val_loss: 0.1139 - val_auc: 0.9897 - val_accuracy: 0.9664\n",
            "Epoch 223/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0830 - auc: 0.9940 - accuracy: 0.9751 - val_loss: 0.1138 - val_auc: 0.9899 - val_accuracy: 0.9668\n",
            "Epoch 224/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.0815 - auc: 0.9943 - accuracy: 0.9754 - val_loss: 0.1142 - val_auc: 0.9899 - val_accuracy: 0.9671\n",
            "Epoch 225/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0834 - auc: 0.9941 - accuracy: 0.9753 - val_loss: 0.1137 - val_auc: 0.9899 - val_accuracy: 0.9666\n",
            "Epoch 226/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0818 - auc: 0.9943 - accuracy: 0.9750 - val_loss: 0.1139 - val_auc: 0.9899 - val_accuracy: 0.9665\n",
            "Epoch 227/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0828 - auc: 0.9941 - accuracy: 0.9750 - val_loss: 0.1134 - val_auc: 0.9899 - val_accuracy: 0.9666\n",
            "Epoch 228/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0822 - auc: 0.9941 - accuracy: 0.9750 - val_loss: 0.1134 - val_auc: 0.9899 - val_accuracy: 0.9667\n",
            "Epoch 229/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.0818 - auc: 0.9940 - accuracy: 0.9755 - val_loss: 0.1141 - val_auc: 0.9900 - val_accuracy: 0.9665\n",
            "Epoch 230/1000\n",
            "1600/1600 [==============================] - 6s 4ms/step - loss: 0.0812 - auc: 0.9943 - accuracy: 0.9753 - val_loss: 0.1139 - val_auc: 0.9898 - val_accuracy: 0.9668\n",
            "Epoch 231/1000\n",
            "1600/1600 [==============================] - 6s 4ms/step - loss: 0.0816 - auc: 0.9942 - accuracy: 0.9759 - val_loss: 0.1132 - val_auc: 0.9898 - val_accuracy: 0.9665\n",
            "1000/1000 [==============================] - 1s 1ms/step\n",
            "fold train/predict time: 0:18:25.406849\n",
            "x_train shape: (128000, 67)\n",
            "Epoch 1/1000\n",
            "1600/1600 [==============================] - 7s 4ms/step - loss: 0.5984 - auc: 0.7163 - accuracy: 0.6764 - val_loss: 0.5159 - val_auc: 0.8191 - val_accuracy: 0.7489\n",
            "Epoch 2/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4844 - auc: 0.8415 - accuracy: 0.7727 - val_loss: 0.4227 - val_auc: 0.8868 - val_accuracy: 0.8153\n",
            "Epoch 3/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4094 - auc: 0.8920 - accuracy: 0.8197 - val_loss: 0.3693 - val_auc: 0.9140 - val_accuracy: 0.8420\n",
            "Epoch 4/1000\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3690 - auc: 0.9133 - accuracy: 0.8419 - val_loss: 0.3413 - val_auc: 0.9264 - val_accuracy: 0.8546\n",
            "Epoch 5/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3457 - auc: 0.9242 - accuracy: 0.8538 - val_loss: 0.3240 - val_auc: 0.9338 - val_accuracy: 0.8637\n",
            "Epoch 6/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3280 - auc: 0.9320 - accuracy: 0.8628 - val_loss: 0.3102 - val_auc: 0.9392 - val_accuracy: 0.8682\n",
            "Epoch 7/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3148 - auc: 0.9373 - accuracy: 0.8688 - val_loss: 0.2985 - val_auc: 0.9438 - val_accuracy: 0.8737\n",
            "Epoch 8/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3033 - auc: 0.9418 - accuracy: 0.8747 - val_loss: 0.2889 - val_auc: 0.9474 - val_accuracy: 0.8791\n",
            "Epoch 9/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2933 - auc: 0.9457 - accuracy: 0.8800 - val_loss: 0.2797 - val_auc: 0.9507 - val_accuracy: 0.8830\n",
            "Epoch 10/1000\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2823 - auc: 0.9498 - accuracy: 0.8848 - val_loss: 0.2712 - val_auc: 0.9538 - val_accuracy: 0.8877\n",
            "Epoch 11/1000\n",
            "1114/1600 [===================>..........] - ETA: 1s - loss: 0.2748 - auc: 0.9524 - accuracy: 0.8885"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_m4 = np.zeros(len(y))\n",
        "for i in fold_results.keys():\n",
        "  for j in range(len(fold_results.get(i).get('predictions'))):\n",
        "    idx = fold_results.get(i).get('index')[j]\n",
        "    preds_m4[idx] = np.round(fold_results.get(i).get('predictions')[j],0)\n",
        "\n",
        "cost(preds_m4,y)"
      ],
      "metadata": {
        "id": "R0lDaXwGVq5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_new = np.zeros(len(y))\n",
        "for i in fold_results.keys():\n",
        "  for j in range(len(fold_results.get(i).get('predictions'))):\n",
        "    idx = fold_results.get(i).get('index')[j]\n",
        "    if fold_results.get(i).get('predictions')[j] > 0.4:\n",
        "      preds_new[idx] = 1\n",
        "    else:\n",
        "      preds_new[idx] = 0\n",
        "\n",
        "cost(preds_new,y)"
      ],
      "metadata": {
        "id": "FKbDIA6RiBpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model4.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jg2oQFvH2QS",
        "outputId": "e1bb0347-3744-44a1-ba0c-a4630212a863"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Relu1 (Dense)               (None, 64)                4352      \n",
            "                                                                 \n",
            " Relu2 (Dense)               (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " Activation (Dense)          (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,577\n",
            "Trainable params: 8,577\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(preds_m4-y).value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVNOkJr3oYGb",
        "outputId": "80da0d73-79e8-4000-bde2-49490bb1c24e"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 0.0    154724\n",
              "-1.0      3031\n",
              " 1.0      2245\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    }
  ]
}